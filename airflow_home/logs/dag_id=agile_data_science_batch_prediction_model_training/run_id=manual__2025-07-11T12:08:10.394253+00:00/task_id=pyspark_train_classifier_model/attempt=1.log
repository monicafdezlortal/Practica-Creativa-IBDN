[2025-07-11T14:08:18.403+0200] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: agile_data_science_batch_prediction_model_training.pyspark_train_classifier_model manual__2025-07-11T12:08:10.394253+00:00 [queued]>
[2025-07-11T14:08:18.424+0200] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: agile_data_science_batch_prediction_model_training.pyspark_train_classifier_model manual__2025-07-11T12:08:10.394253+00:00 [queued]>
[2025-07-11T14:08:18.424+0200] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2025-07-11T14:08:18.424+0200] {taskinstance.py:1280} INFO - Starting attempt 1 of 4
[2025-07-11T14:08:18.425+0200] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2025-07-11T14:08:18.451+0200] {taskinstance.py:1300} INFO - Executing <Task(BashOperator): pyspark_train_classifier_model> on 2025-07-11 12:08:10.394253+00:00
[2025-07-11T14:08:18.454+0200] {standard_task_runner.py:55} INFO - Started process 174953 to run task
[2025-07-11T14:08:18.458+0200] {standard_task_runner.py:82} INFO - Running: ['airflow', 'tasks', 'run', 'agile_data_science_batch_prediction_model_training', 'pyspark_train_classifier_model', 'manual__2025-07-11T12:08:10.394253+00:00', '--job-id', '188', '--raw', '--subdir', 'DAGS_FOLDER/setup.py', '--cfg-path', '/tmp/tmpw3prn9o4']
[2025-07-11T14:08:18.460+0200] {standard_task_runner.py:83} INFO - Job 188: Subtask pyspark_train_classifier_model
[2025-07-11T14:08:18.554+0200] {task_command.py:388} INFO - Running <TaskInstance: agile_data_science_batch_prediction_model_training.pyspark_train_classifier_model manual__2025-07-11T12:08:10.394253+00:00 [running]> on host l023.lab.dit.upm.es
[2025-07-11T14:08:18.711+0200] {taskinstance.py:1507} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=agile_data_science_batch_prediction_model_training
AIRFLOW_CTX_TASK_ID=pyspark_train_classifier_model
AIRFLOW_CTX_EXECUTION_DATE=2025-07-11T12:08:10.394253+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2025-07-11T12:08:10.394253+00:00
[2025-07-11T14:08:18.718+0200] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-11T14:08:18.719+0200] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', '\nsource /home/monica.fernandez/practica_creativa/venv-airflow/bin/activate && export PYSPARK_PYTHON=/home/monica.fernandez/practica_creativa/venv-airflow/bin/python && spark-submit   --master local[4]   --packages com.datastax.spark:spark-cassandra-connector_2.12:3.5.0,com.github.jnr:jnr-posix:3.1.15   /home/monica.fernandez/practica_creativa/resources/train_spark_mllib_model.py   /home/monica.fernandez/practica_creativa']
[2025-07-11T14:08:18.740+0200] {subprocess.py:86} INFO - Output:
[2025-07-11T14:08:21.809+0200] {subprocess.py:93} INFO - 25/07/11 14:08:21 WARN Utils: Your hostname, l023 resolves to a loopback address: 127.0.1.1; using 138.4.31.23 instead (on interface enp1s0)
[2025-07-11T14:08:21.812+0200] {subprocess.py:93} INFO - 25/07/11 14:08:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
[2025-07-11T14:08:22.070+0200] {subprocess.py:93} INFO - :: loading settings :: url = jar:file:/home/monica.fernandez/.sdkman/candidates/spark/3.5.3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-07-11T14:08:22.182+0200] {subprocess.py:93} INFO - Ivy Default Cache set to: /home/monica.fernandez/.ivy2/cache
[2025-07-11T14:08:22.182+0200] {subprocess.py:93} INFO - The jars for the packages stored in: /home/monica.fernandez/.ivy2/jars
[2025-07-11T14:08:22.187+0200] {subprocess.py:93} INFO - com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency
[2025-07-11T14:08:22.187+0200] {subprocess.py:93} INFO - com.github.jnr#jnr-posix added as a dependency
[2025-07-11T14:08:22.187+0200] {subprocess.py:93} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-47e4de8c-5a80-4ea2-9417-072e2d42cd3b;1.0
[2025-07-11T14:08:22.187+0200] {subprocess.py:93} INFO - 	confs: [default]
[2025-07-11T14:08:22.375+0200] {subprocess.py:93} INFO - 	found com.datastax.spark#spark-cassandra-connector_2.12;3.5.0 in central
[2025-07-11T14:08:22.419+0200] {subprocess.py:93} INFO - 	found com.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.0 in central
[2025-07-11T14:08:22.463+0200] {subprocess.py:93} INFO - 	found org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 in central
[2025-07-11T14:08:22.539+0200] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-core-shaded;4.13.0 in central
[2025-07-11T14:08:22.590+0200] {subprocess.py:93} INFO - 	found com.datastax.oss#native-protocol;1.5.0 in central
[2025-07-11T14:08:22.653+0200] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central
[2025-07-11T14:08:22.708+0200] {subprocess.py:93} INFO - 	found com.typesafe#config;1.4.1 in central
[2025-07-11T14:08:22.751+0200] {subprocess.py:93} INFO - 	found org.slf4j#slf4j-api;1.7.26 in central
[2025-07-11T14:08:22.790+0200] {subprocess.py:93} INFO - 	found io.dropwizard.metrics#metrics-core;4.1.18 in central
[2025-07-11T14:08:22.826+0200] {subprocess.py:93} INFO - 	found org.hdrhistogram#HdrHistogram;2.1.12 in central
[2025-07-11T14:08:22.853+0200] {subprocess.py:93} INFO - 	found org.reactivestreams#reactive-streams;1.0.3 in central
[2025-07-11T14:08:22.879+0200] {subprocess.py:93} INFO - 	found com.github.stephenc.jcip#jcip-annotations;1.0-1 in central
[2025-07-11T14:08:22.903+0200] {subprocess.py:93} INFO - 	found com.github.spotbugs#spotbugs-annotations;3.1.12 in central
[2025-07-11T14:08:22.933+0200] {subprocess.py:93} INFO - 	found com.google.code.findbugs#jsr305;3.0.2 in central
[2025-07-11T14:08:22.959+0200] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central
[2025-07-11T14:08:23.002+0200] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-query-builder;4.13.0 in central
[2025-07-11T14:08:23.030+0200] {subprocess.py:93} INFO - 	found org.apache.commons#commons-lang3;3.10 in central
[2025-07-11T14:08:23.060+0200] {subprocess.py:93} INFO - 	found com.thoughtworks.paranamer#paranamer;2.8 in central
[2025-07-11T14:08:23.091+0200] {subprocess.py:93} INFO - 	found org.scala-lang#scala-reflect;2.12.11 in central
[2025-07-11T14:08:23.148+0200] {subprocess.py:93} INFO - 	found com.github.jnr#jnr-posix;3.1.15 in central
[2025-07-11T14:08:23.192+0200] {subprocess.py:93} INFO - 	found com.github.jnr#jnr-ffi;2.2.11 in central
[2025-07-11T14:08:23.207+0200] {subprocess.py:93} INFO - 	found com.github.jnr#jffi;1.3.9 in central
[2025-07-11T14:08:23.227+0200] {subprocess.py:93} INFO - 	found org.ow2.asm#asm;9.2 in central
[2025-07-11T14:08:23.240+0200] {subprocess.py:93} INFO - 	found org.ow2.asm#asm-commons;9.2 in central
[2025-07-11T14:08:23.255+0200] {subprocess.py:93} INFO - 	found org.ow2.asm#asm-tree;9.2 in central
[2025-07-11T14:08:23.270+0200] {subprocess.py:93} INFO - 	found org.ow2.asm#asm-analysis;9.2 in central
[2025-07-11T14:08:23.292+0200] {subprocess.py:93} INFO - 	found org.ow2.asm#asm-util;9.2 in central
[2025-07-11T14:08:23.344+0200] {subprocess.py:93} INFO - 	found com.github.jnr#jnr-a64asm;1.0.0 in central
[2025-07-11T14:08:23.371+0200] {subprocess.py:93} INFO - 	found com.github.jnr#jnr-x86asm;1.0.2 in central
[2025-07-11T14:08:23.407+0200] {subprocess.py:93} INFO - 	found com.github.jnr#jnr-constants;0.10.3 in central
[2025-07-11T14:08:23.555+0200] {subprocess.py:93} INFO - :: resolution report :: resolve 1258ms :: artifacts dl 110ms
[2025-07-11T14:08:23.555+0200] {subprocess.py:93} INFO - 	:: modules in use:
[2025-07-11T14:08:23.556+0200] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]
[2025-07-11T14:08:23.556+0200] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]
[2025-07-11T14:08:23.556+0200] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]
[2025-07-11T14:08:23.556+0200] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]
[2025-07-11T14:08:23.556+0200] {subprocess.py:93} INFO - 	com.datastax.oss#native-protocol;1.5.0 from central in [default]
[2025-07-11T14:08:23.556+0200] {subprocess.py:93} INFO - 	com.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.0 from central in [default]
[2025-07-11T14:08:23.556+0200] {subprocess.py:93} INFO - 	com.datastax.spark#spark-cassandra-connector_2.12;3.5.0 from central in [default]
[2025-07-11T14:08:23.557+0200] {subprocess.py:93} INFO - 	com.github.jnr#jffi;1.3.9 from central in [default]
[2025-07-11T14:08:23.557+0200] {subprocess.py:93} INFO - 	com.github.jnr#jnr-a64asm;1.0.0 from central in [default]
[2025-07-11T14:08:23.557+0200] {subprocess.py:93} INFO - 	com.github.jnr#jnr-constants;0.10.3 from central in [default]
[2025-07-11T14:08:23.557+0200] {subprocess.py:93} INFO - 	com.github.jnr#jnr-ffi;2.2.11 from central in [default]
[2025-07-11T14:08:23.557+0200] {subprocess.py:93} INFO - 	com.github.jnr#jnr-posix;3.1.15 from central in [default]
[2025-07-11T14:08:23.557+0200] {subprocess.py:93} INFO - 	com.github.jnr#jnr-x86asm;1.0.2 from central in [default]
[2025-07-11T14:08:23.557+0200] {subprocess.py:93} INFO - 	com.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]
[2025-07-11T14:08:23.557+0200] {subprocess.py:93} INFO - 	com.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]
[2025-07-11T14:08:23.558+0200] {subprocess.py:93} INFO - 	com.google.code.findbugs#jsr305;3.0.2 from central in [default]
[2025-07-11T14:08:23.558+0200] {subprocess.py:93} INFO - 	com.thoughtworks.paranamer#paranamer;2.8 from central in [default]
[2025-07-11T14:08:23.558+0200] {subprocess.py:93} INFO - 	com.typesafe#config;1.4.1 from central in [default]
[2025-07-11T14:08:23.558+0200] {subprocess.py:93} INFO - 	io.dropwizard.metrics#metrics-core;4.1.18 from central in [default]
[2025-07-11T14:08:23.558+0200] {subprocess.py:93} INFO - 	org.apache.commons#commons-lang3;3.10 from central in [default]
[2025-07-11T14:08:23.558+0200] {subprocess.py:93} INFO - 	org.hdrhistogram#HdrHistogram;2.1.12 from central in [default]
[2025-07-11T14:08:23.558+0200] {subprocess.py:93} INFO - 	org.ow2.asm#asm;9.2 from central in [default]
[2025-07-11T14:08:23.558+0200] {subprocess.py:93} INFO - 	org.ow2.asm#asm-analysis;9.2 from central in [default]
[2025-07-11T14:08:23.558+0200] {subprocess.py:93} INFO - 	org.ow2.asm#asm-commons;9.2 from central in [default]
[2025-07-11T14:08:23.559+0200] {subprocess.py:93} INFO - 	org.ow2.asm#asm-tree;9.2 from central in [default]
[2025-07-11T14:08:23.559+0200] {subprocess.py:93} INFO - 	org.ow2.asm#asm-util;9.2 from central in [default]
[2025-07-11T14:08:23.559+0200] {subprocess.py:93} INFO - 	org.reactivestreams#reactive-streams;1.0.3 from central in [default]
[2025-07-11T14:08:23.559+0200] {subprocess.py:93} INFO - 	org.scala-lang#scala-reflect;2.12.11 from central in [default]
[2025-07-11T14:08:23.559+0200] {subprocess.py:93} INFO - 	org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 from central in [default]
[2025-07-11T14:08:23.559+0200] {subprocess.py:93} INFO - 	org.slf4j#slf4j-api;1.7.26 from central in [default]
[2025-07-11T14:08:23.559+0200] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-07-11T14:08:23.560+0200] {subprocess.py:93} INFO - 	|                  |            modules            ||   artifacts   |
[2025-07-11T14:08:23.560+0200] {subprocess.py:93} INFO - 	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-07-11T14:08:23.560+0200] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-07-11T14:08:23.560+0200] {subprocess.py:93} INFO - 	|      default     |   30  |   0   |   0   |   0   ||   30  |   0   |
[2025-07-11T14:08:23.560+0200] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-07-11T14:08:23.572+0200] {subprocess.py:93} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-47e4de8c-5a80-4ea2-9417-072e2d42cd3b
[2025-07-11T14:08:23.572+0200] {subprocess.py:93} INFO - 	confs: [default]
[2025-07-11T14:08:23.591+0200] {subprocess.py:93} INFO - 	0 artifacts copied, 30 already retrieved (0kB/19ms)
[2025-07-11T14:08:23.928+0200] {subprocess.py:93} INFO - 25/07/11 14:08:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-07-11T14:08:29.155+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO SparkContext: Running Spark version 3.5.3
[2025-07-11T14:08:29.156+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO SparkContext: OS info Linux, 6.1.0-35-amd64, amd64
[2025-07-11T14:08:29.156+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO SparkContext: Java version 17.0.14
[2025-07-11T14:08:29.180+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO ResourceUtils: ==============================================================
[2025-07-11T14:08:29.181+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-07-11T14:08:29.181+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO ResourceUtils: ==============================================================
[2025-07-11T14:08:29.182+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO SparkContext: Submitted application: train_spark_mllib_model.py
[2025-07-11T14:08:29.216+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-07-11T14:08:29.225+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO ResourceProfile: Limiting resource is cpu
[2025-07-11T14:08:29.226+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-07-11T14:08:29.325+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO SecurityManager: Changing view acls to: monica.fernandez
[2025-07-11T14:08:29.325+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO SecurityManager: Changing modify acls to: monica.fernandez
[2025-07-11T14:08:29.326+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO SecurityManager: Changing view acls groups to:
[2025-07-11T14:08:29.327+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO SecurityManager: Changing modify acls groups to:
[2025-07-11T14:08:29.327+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: monica.fernandez; groups with view permissions: EMPTY; users with modify permissions: monica.fernandez; groups with modify permissions: EMPTY
[2025-07-11T14:08:29.651+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO Utils: Successfully started service 'sparkDriver' on port 41093.
[2025-07-11T14:08:29.701+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO SparkEnv: Registering MapOutputTracker
[2025-07-11T14:08:29.743+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO SparkEnv: Registering BlockManagerMaster
[2025-07-11T14:08:29.767+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-07-11T14:08:29.768+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-07-11T14:08:29.775+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-07-11T14:08:29.812+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0581da1a-3e82-4c44-b64e-688df56ba765
[2025-07-11T14:08:29.832+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-07-11T14:08:29.852+0200] {subprocess.py:93} INFO - 25/07/11 14:08:29 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-07-11T14:08:30.051+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-07-11T14:08:30.137+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[2025-07-11T14:08:30.156+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Successfully started service 'SparkUI' on port 4041.
[2025-07-11T14:08:30.204+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar at spark://138.4.31.23:41093/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.205+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-posix-3.1.15.jar at spark://138.4.31.23:41093/jars/com.github.jnr_jnr-posix-3.1.15.jar with timestamp 1752235709148
[2025-07-11T14:08:30.206+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar at spark://138.4.31.23:41093/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.207+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar at spark://138.4.31.23:41093/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.208+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar at spark://138.4.31.23:41093/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.208+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar at spark://138.4.31.23:41093/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.210+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar at spark://138.4.31.23:41093/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1752235709148
[2025-07-11T14:08:30.212+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar at spark://138.4.31.23:41093/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1752235709148
[2025-07-11T14:08:30.213+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar at spark://138.4.31.23:41093/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1752235709148
[2025-07-11T14:08:30.214+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar at spark://138.4.31.23:41093/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.215+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar at spark://138.4.31.23:41093/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1752235709148
[2025-07-11T14:08:30.216+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.typesafe_config-1.4.1.jar at spark://138.4.31.23:41093/jars/com.typesafe_config-1.4.1.jar with timestamp 1752235709148
[2025-07-11T14:08:30.216+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.slf4j_slf4j-api-1.7.26.jar at spark://138.4.31.23:41093/jars/org.slf4j_slf4j-api-1.7.26.jar with timestamp 1752235709148
[2025-07-11T14:08:30.217+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar at spark://138.4.31.23:41093/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1752235709148
[2025-07-11T14:08:30.218+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar at spark://138.4.31.23:41093/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1752235709148
[2025-07-11T14:08:30.219+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar at spark://138.4.31.23:41093/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1752235709148
[2025-07-11T14:08:30.219+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar at spark://138.4.31.23:41093/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1752235709148
[2025-07-11T14:08:30.220+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar at spark://138.4.31.23:41093/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1752235709148
[2025-07-11T14:08:30.221+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar at spark://138.4.31.23:41093/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1752235709148
[2025-07-11T14:08:30.222+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar at spark://138.4.31.23:41093/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.223+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-ffi-2.2.11.jar at spark://138.4.31.23:41093/jars/com.github.jnr_jnr-ffi-2.2.11.jar with timestamp 1752235709148
[2025-07-11T14:08:30.224+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-constants-0.10.3.jar at spark://138.4.31.23:41093/jars/com.github.jnr_jnr-constants-0.10.3.jar with timestamp 1752235709148
[2025-07-11T14:08:30.226+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jffi-1.3.9-native.jar at spark://138.4.31.23:41093/jars/com.github.jnr_jffi-1.3.9-native.jar with timestamp 1752235709148
[2025-07-11T14:08:30.228+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-9.2.jar at spark://138.4.31.23:41093/jars/org.ow2.asm_asm-9.2.jar with timestamp 1752235709148
[2025-07-11T14:08:30.229+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-commons-9.2.jar at spark://138.4.31.23:41093/jars/org.ow2.asm_asm-commons-9.2.jar with timestamp 1752235709148
[2025-07-11T14:08:30.229+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-analysis-9.2.jar at spark://138.4.31.23:41093/jars/org.ow2.asm_asm-analysis-9.2.jar with timestamp 1752235709148
[2025-07-11T14:08:30.230+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-tree-9.2.jar at spark://138.4.31.23:41093/jars/org.ow2.asm_asm-tree-9.2.jar with timestamp 1752235709148
[2025-07-11T14:08:30.231+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-util-9.2.jar at spark://138.4.31.23:41093/jars/org.ow2.asm_asm-util-9.2.jar with timestamp 1752235709148
[2025-07-11T14:08:30.231+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-a64asm-1.0.0.jar at spark://138.4.31.23:41093/jars/com.github.jnr_jnr-a64asm-1.0.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.233+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-x86asm-1.0.2.jar at spark://138.4.31.23:41093/jars/com.github.jnr_jnr-x86asm-1.0.2.jar with timestamp 1752235709148
[2025-07-11T14:08:30.238+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar at file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.239+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar
[2025-07-11T14:08:30.274+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-posix-3.1.15.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-posix-3.1.15.jar with timestamp 1752235709148
[2025-07-11T14:08:30.274+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-posix-3.1.15.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jnr-posix-3.1.15.jar
[2025-07-11T14:08:30.292+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar at file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.292+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar
[2025-07-11T14:08:30.305+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar at file:///home/monica.fernandez/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.305+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar
[2025-07-11T14:08:30.318+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar at file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.319+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.oss_java-driver-core-shaded-4.13.0.jar
[2025-07-11T14:08:30.384+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar at file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.384+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar
[2025-07-11T14:08:30.388+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar at file:///home/monica.fernandez/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1752235709148
[2025-07-11T14:08:30.389+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.apache.commons_commons-lang3-3.10.jar
[2025-07-11T14:08:30.397+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar at file:///home/monica.fernandez/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1752235709148
[2025-07-11T14:08:30.397+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.thoughtworks.paranamer_paranamer-2.8.jar
[2025-07-11T14:08:30.401+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar at file:///home/monica.fernandez/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1752235709148
[2025-07-11T14:08:30.401+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.scala-lang_scala-reflect-2.12.11.jar
[2025-07-11T14:08:30.440+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar at file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.441+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.oss_native-protocol-1.5.0.jar
[2025-07-11T14:08:30.450+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar at file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1752235709148
[2025-07-11T14:08:30.450+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar
[2025-07-11T14:08:30.476+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.typesafe_config-1.4.1.jar at file:///home/monica.fernandez/.ivy2/jars/com.typesafe_config-1.4.1.jar with timestamp 1752235709148
[2025-07-11T14:08:30.477+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.typesafe_config-1.4.1.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.typesafe_config-1.4.1.jar
[2025-07-11T14:08:30.483+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.slf4j_slf4j-api-1.7.26.jar at file:///home/monica.fernandez/.ivy2/jars/org.slf4j_slf4j-api-1.7.26.jar with timestamp 1752235709148
[2025-07-11T14:08:30.483+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.slf4j_slf4j-api-1.7.26.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.slf4j_slf4j-api-1.7.26.jar
[2025-07-11T14:08:30.487+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar at file:///home/monica.fernandez/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1752235709148
[2025-07-11T14:08:30.487+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/io.dropwizard.metrics_metrics-core-4.1.18.jar
[2025-07-11T14:08:30.505+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar at file:///home/monica.fernandez/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1752235709148
[2025-07-11T14:08:30.505+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.hdrhistogram_HdrHistogram-2.1.12.jar
[2025-07-11T14:08:30.510+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar at file:///home/monica.fernandez/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1752235709148
[2025-07-11T14:08:30.510+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.reactivestreams_reactive-streams-1.0.3.jar
[2025-07-11T14:08:30.514+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1752235709148
[2025-07-11T14:08:30.514+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar
[2025-07-11T14:08:30.518+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1752235709148
[2025-07-11T14:08:30.518+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.spotbugs_spotbugs-annotations-3.1.12.jar
[2025-07-11T14:08:30.522+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar at file:///home/monica.fernandez/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1752235709148
[2025-07-11T14:08:30.523+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.google.code.findbugs_jsr305-3.0.2.jar
[2025-07-11T14:08:30.526+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar at file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.526+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.oss_java-driver-query-builder-4.13.0.jar
[2025-07-11T14:08:30.534+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-ffi-2.2.11.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-ffi-2.2.11.jar with timestamp 1752235709148
[2025-07-11T14:08:30.534+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-ffi-2.2.11.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jnr-ffi-2.2.11.jar
[2025-07-11T14:08:30.543+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-constants-0.10.3.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-constants-0.10.3.jar with timestamp 1752235709148
[2025-07-11T14:08:30.544+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-constants-0.10.3.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jnr-constants-0.10.3.jar
[2025-07-11T14:08:30.561+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jffi-1.3.9-native.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jffi-1.3.9-native.jar with timestamp 1752235709148
[2025-07-11T14:08:30.561+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.jnr_jffi-1.3.9-native.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jffi-1.3.9-native.jar
[2025-07-11T14:08:30.572+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-9.2.jar at file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-9.2.jar with timestamp 1752235709148
[2025-07-11T14:08:30.573+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-9.2.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.ow2.asm_asm-9.2.jar
[2025-07-11T14:08:30.579+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-commons-9.2.jar at file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-commons-9.2.jar with timestamp 1752235709148
[2025-07-11T14:08:30.580+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-commons-9.2.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.ow2.asm_asm-commons-9.2.jar
[2025-07-11T14:08:30.585+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-analysis-9.2.jar at file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-analysis-9.2.jar with timestamp 1752235709148
[2025-07-11T14:08:30.585+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-analysis-9.2.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.ow2.asm_asm-analysis-9.2.jar
[2025-07-11T14:08:30.591+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-tree-9.2.jar at file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-tree-9.2.jar with timestamp 1752235709148
[2025-07-11T14:08:30.591+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-tree-9.2.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.ow2.asm_asm-tree-9.2.jar
[2025-07-11T14:08:30.595+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-util-9.2.jar at file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-util-9.2.jar with timestamp 1752235709148
[2025-07-11T14:08:30.596+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-util-9.2.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.ow2.asm_asm-util-9.2.jar
[2025-07-11T14:08:30.605+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-a64asm-1.0.0.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-a64asm-1.0.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.606+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-a64asm-1.0.0.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jnr-a64asm-1.0.0.jar
[2025-07-11T14:08:30.610+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-x86asm-1.0.2.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-x86asm-1.0.2.jar with timestamp 1752235709148
[2025-07-11T14:08:30.610+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-x86asm-1.0.2.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jnr-x86asm-1.0.2.jar
[2025-07-11T14:08:30.703+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Starting executor ID driver on host 138.4.31.23
[2025-07-11T14:08:30.703+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: OS info Linux, 6.1.0-35-amd64, amd64
[2025-07-11T14:08:30.704+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Java version 17.0.14
[2025-07-11T14:08:30.710+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-07-11T14:08:30.711+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@2198b397 for default.
[2025-07-11T14:08:30.722+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.748+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar
[2025-07-11T14:08:30.752+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1752235709148
[2025-07-11T14:08:30.752+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.google.code.findbugs_jsr305-3.0.2.jar
[2025-07-11T14:08:30.756+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.typesafe_config-1.4.1.jar with timestamp 1752235709148
[2025-07-11T14:08:30.757+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.typesafe_config-1.4.1.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.typesafe_config-1.4.1.jar
[2025-07-11T14:08:30.760+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1752235709148
[2025-07-11T14:08:30.761+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.thoughtworks.paranamer_paranamer-2.8.jar
[2025-07-11T14:08:30.764+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1752235709148
[2025-07-11T14:08:30.765+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.hdrhistogram_HdrHistogram-2.1.12.jar
[2025-07-11T14:08:30.769+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-a64asm-1.0.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.769+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-a64asm-1.0.0.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jnr-a64asm-1.0.0.jar
[2025-07-11T14:08:30.773+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jffi-1.3.9-native.jar with timestamp 1752235709148
[2025-07-11T14:08:30.774+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.jnr_jffi-1.3.9-native.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jffi-1.3.9-native.jar
[2025-07-11T14:08:30.778+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1752235709148
[2025-07-11T14:08:30.779+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.spotbugs_spotbugs-annotations-3.1.12.jar
[2025-07-11T14:08:30.782+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1752235709148
[2025-07-11T14:08:30.783+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.apache.commons_commons-lang3-3.10.jar
[2025-07-11T14:08:30.787+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1752235709148
[2025-07-11T14:08:30.788+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/io.dropwizard.metrics_metrics-core-4.1.18.jar
[2025-07-11T14:08:30.791+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1752235709148
[2025-07-11T14:08:30.795+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar
[2025-07-11T14:08:30.799+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-util-9.2.jar with timestamp 1752235709148
[2025-07-11T14:08:30.800+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-util-9.2.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.ow2.asm_asm-util-9.2.jar
[2025-07-11T14:08:30.803+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-9.2.jar with timestamp 1752235709148
[2025-07-11T14:08:30.804+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-9.2.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.ow2.asm_asm-9.2.jar
[2025-07-11T14:08:30.807+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.816+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.oss_java-driver-core-shaded-4.13.0.jar
[2025-07-11T14:08:30.820+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.821+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.oss_native-protocol-1.5.0.jar
[2025-07-11T14:08:30.824+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-tree-9.2.jar with timestamp 1752235709148
[2025-07-11T14:08:30.825+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-tree-9.2.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.ow2.asm_asm-tree-9.2.jar
[2025-07-11T14:08:30.828+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.slf4j_slf4j-api-1.7.26.jar with timestamp 1752235709148
[2025-07-11T14:08:30.828+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.slf4j_slf4j-api-1.7.26.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.slf4j_slf4j-api-1.7.26.jar
[2025-07-11T14:08:30.832+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-ffi-2.2.11.jar with timestamp 1752235709148
[2025-07-11T14:08:30.833+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-ffi-2.2.11.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jnr-ffi-2.2.11.jar
[2025-07-11T14:08:30.837+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.838+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar
[2025-07-11T14:08:30.841+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.844+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar
[2025-07-11T14:08:30.847+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.848+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.oss_java-driver-query-builder-4.13.0.jar
[2025-07-11T14:08:30.851+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1752235709148
[2025-07-11T14:08:30.852+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar
[2025-07-11T14:08:30.855+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-analysis-9.2.jar with timestamp 1752235709148
[2025-07-11T14:08:30.856+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-analysis-9.2.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.ow2.asm_asm-analysis-9.2.jar
[2025-07-11T14:08:30.860+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1752235709148
[2025-07-11T14:08:30.860+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.reactivestreams_reactive-streams-1.0.3.jar
[2025-07-11T14:08:30.864+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-x86asm-1.0.2.jar with timestamp 1752235709148
[2025-07-11T14:08:30.865+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-x86asm-1.0.2.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jnr-x86asm-1.0.2.jar
[2025-07-11T14:08:30.868+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.869+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar
[2025-07-11T14:08:30.872+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-commons-9.2.jar with timestamp 1752235709148
[2025-07-11T14:08:30.873+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-commons-9.2.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.ow2.asm_asm-commons-9.2.jar
[2025-07-11T14:08:30.876+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1752235709148
[2025-07-11T14:08:30.881+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.scala-lang_scala-reflect-2.12.11.jar
[2025-07-11T14:08:30.885+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-posix-3.1.15.jar with timestamp 1752235709148
[2025-07-11T14:08:30.886+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-posix-3.1.15.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jnr-posix-3.1.15.jar
[2025-07-11T14:08:30.889+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-constants-0.10.3.jar with timestamp 1752235709148
[2025-07-11T14:08:30.892+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-constants-0.10.3.jar has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jnr-constants-0.10.3.jar
[2025-07-11T14:08:30.898+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching spark://138.4.31.23:41093/jars/com.github.jnr_jnr-posix-3.1.15.jar with timestamp 1752235709148
[2025-07-11T14:08:30.937+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO TransportClientFactory: Successfully created connection to /138.4.31.23:41093 after 26 ms (0 ms spent in bootstraps)
[2025-07-11T14:08:30.944+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Fetching spark://138.4.31.23:41093/jars/com.github.jnr_jnr-posix-3.1.15.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp13140379702428604122.tmp
[2025-07-11T14:08:30.966+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp13140379702428604122.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jnr-posix-3.1.15.jar
[2025-07-11T14:08:30.970+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jnr-posix-3.1.15.jar to class loader default
[2025-07-11T14:08:30.970+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching spark://138.4.31.23:41093/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1752235709148
[2025-07-11T14:08:30.971+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Fetching spark://138.4.31.23:41093/jars/com.google.code.findbugs_jsr305-3.0.2.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp3789697160054787206.tmp
[2025-07-11T14:08:30.972+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp3789697160054787206.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.google.code.findbugs_jsr305-3.0.2.jar
[2025-07-11T14:08:30.975+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.google.code.findbugs_jsr305-3.0.2.jar to class loader default
[2025-07-11T14:08:30.976+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching spark://138.4.31.23:41093/jars/com.github.jnr_jnr-ffi-2.2.11.jar with timestamp 1752235709148
[2025-07-11T14:08:30.976+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Fetching spark://138.4.31.23:41093/jars/com.github.jnr_jnr-ffi-2.2.11.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp14934123573011774317.tmp
[2025-07-11T14:08:30.981+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp14934123573011774317.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jnr-ffi-2.2.11.jar
[2025-07-11T14:08:30.984+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jnr-ffi-2.2.11.jar to class loader default
[2025-07-11T14:08:30.984+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching spark://138.4.31.23:41093/jars/com.github.jnr_jffi-1.3.9-native.jar with timestamp 1752235709148
[2025-07-11T14:08:30.984+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Fetching spark://138.4.31.23:41093/jars/com.github.jnr_jffi-1.3.9-native.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp12630882159959019568.tmp
[2025-07-11T14:08:30.990+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp12630882159959019568.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jffi-1.3.9-native.jar
[2025-07-11T14:08:30.994+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jffi-1.3.9-native.jar to class loader default
[2025-07-11T14:08:30.994+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching spark://138.4.31.23:41093/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1752235709148
[2025-07-11T14:08:30.994+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: Fetching spark://138.4.31.23:41093/jars/com.datastax.oss_native-protocol-1.5.0.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp1799714269428723106.tmp
[2025-07-11T14:08:30.996+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp1799714269428723106.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.oss_native-protocol-1.5.0.jar
[2025-07-11T14:08:30.999+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.oss_native-protocol-1.5.0.jar to class loader default
[2025-07-11T14:08:31.000+0200] {subprocess.py:93} INFO - 25/07/11 14:08:30 INFO Executor: Fetching spark://138.4.31.23:41093/jars/org.ow2.asm_asm-analysis-9.2.jar with timestamp 1752235709148
[2025-07-11T14:08:31.000+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/org.ow2.asm_asm-analysis-9.2.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp1030806589547836264.tmp
[2025-07-11T14:08:31.001+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp1030806589547836264.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.ow2.asm_asm-analysis-9.2.jar
[2025-07-11T14:08:31.005+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.ow2.asm_asm-analysis-9.2.jar to class loader default
[2025-07-11T14:08:31.005+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1752235709148
[2025-07-11T14:08:31.005+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/com.thoughtworks.paranamer_paranamer-2.8.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp4567291169485312861.tmp
[2025-07-11T14:08:31.007+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp4567291169485312861.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.thoughtworks.paranamer_paranamer-2.8.jar
[2025-07-11T14:08:31.010+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.thoughtworks.paranamer_paranamer-2.8.jar to class loader default
[2025-07-11T14:08:31.010+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1752235709148
[2025-07-11T14:08:31.010+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/org.reactivestreams_reactive-streams-1.0.3.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp5275394999115462926.tmp
[2025-07-11T14:08:31.011+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp5275394999115462926.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.reactivestreams_reactive-streams-1.0.3.jar
[2025-07-11T14:08:31.015+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.reactivestreams_reactive-streams-1.0.3.jar to class loader default
[2025-07-11T14:08:31.015+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/com.github.jnr_jnr-a64asm-1.0.0.jar with timestamp 1752235709148
[2025-07-11T14:08:31.016+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/com.github.jnr_jnr-a64asm-1.0.0.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp3881534351384211359.tmp
[2025-07-11T14:08:31.017+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp3881534351384211359.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jnr-a64asm-1.0.0.jar
[2025-07-11T14:08:31.020+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jnr-a64asm-1.0.0.jar to class loader default
[2025-07-11T14:08:31.020+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1752235709148
[2025-07-11T14:08:31.021+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp3831722126302093893.tmp
[2025-07-11T14:08:31.046+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp3831722126302093893.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.oss_java-driver-core-shaded-4.13.0.jar
[2025-07-11T14:08:31.050+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.oss_java-driver-core-shaded-4.13.0.jar to class loader default
[2025-07-11T14:08:31.050+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1752235709148
[2025-07-11T14:08:31.050+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/org.scala-lang_scala-reflect-2.12.11.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp16016521092299011242.tmp
[2025-07-11T14:08:31.061+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp16016521092299011242.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.scala-lang_scala-reflect-2.12.11.jar
[2025-07-11T14:08:31.064+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.scala-lang_scala-reflect-2.12.11.jar to class loader default
[2025-07-11T14:08:31.064+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1752235709148
[2025-07-11T14:08:31.064+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp16046643222342123560.tmp
[2025-07-11T14:08:31.066+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp16046643222342123560.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.oss_java-driver-query-builder-4.13.0.jar
[2025-07-11T14:08:31.069+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.oss_java-driver-query-builder-4.13.0.jar to class loader default
[2025-07-11T14:08:31.069+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1752235709148
[2025-07-11T14:08:31.070+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp17862786726686598473.tmp
[2025-07-11T14:08:31.071+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp17862786726686598473.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/io.dropwizard.metrics_metrics-core-4.1.18.jar
[2025-07-11T14:08:31.074+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/io.dropwizard.metrics_metrics-core-4.1.18.jar to class loader default
[2025-07-11T14:08:31.074+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/org.ow2.asm_asm-9.2.jar with timestamp 1752235709148
[2025-07-11T14:08:31.075+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/org.ow2.asm_asm-9.2.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp5987500899613241352.tmp
[2025-07-11T14:08:31.076+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp5987500899613241352.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.ow2.asm_asm-9.2.jar
[2025-07-11T14:08:31.080+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.ow2.asm_asm-9.2.jar to class loader default
[2025-07-11T14:08:31.080+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/org.ow2.asm_asm-commons-9.2.jar with timestamp 1752235709148
[2025-07-11T14:08:31.080+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/org.ow2.asm_asm-commons-9.2.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp16390080347408518860.tmp
[2025-07-11T14:08:31.081+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp16390080347408518860.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.ow2.asm_asm-commons-9.2.jar
[2025-07-11T14:08:31.085+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.ow2.asm_asm-commons-9.2.jar to class loader default
[2025-07-11T14:08:31.085+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1752235709148
[2025-07-11T14:08:31.085+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp4068199352337040857.tmp
[2025-07-11T14:08:31.094+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp4068199352337040857.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar
[2025-07-11T14:08:31.097+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar to class loader default
[2025-07-11T14:08:31.097+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1752235709148
[2025-07-11T14:08:31.098+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp16879388646561128270.tmp
[2025-07-11T14:08:31.100+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp16879388646561128270.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar
[2025-07-11T14:08:31.103+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar to class loader default
[2025-07-11T14:08:31.104+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1752235709148
[2025-07-11T14:08:31.104+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/org.apache.commons_commons-lang3-3.10.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp16266620332369592013.tmp
[2025-07-11T14:08:31.106+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp16266620332369592013.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.apache.commons_commons-lang3-3.10.jar
[2025-07-11T14:08:31.110+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.apache.commons_commons-lang3-3.10.jar to class loader default
[2025-07-11T14:08:31.110+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1752235709148
[2025-07-11T14:08:31.111+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp8021676975815969957.tmp
[2025-07-11T14:08:31.112+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp8021676975815969957.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar
[2025-07-11T14:08:31.115+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar to class loader default
[2025-07-11T14:08:31.116+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1752235709148
[2025-07-11T14:08:31.116+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp6916085978038947588.tmp
[2025-07-11T14:08:31.117+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp6916085978038947588.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar
[2025-07-11T14:08:31.120+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar to class loader default
[2025-07-11T14:08:31.120+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/com.typesafe_config-1.4.1.jar with timestamp 1752235709148
[2025-07-11T14:08:31.121+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/com.typesafe_config-1.4.1.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp9741555241250893578.tmp
[2025-07-11T14:08:31.123+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp9741555241250893578.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.typesafe_config-1.4.1.jar
[2025-07-11T14:08:31.126+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.typesafe_config-1.4.1.jar to class loader default
[2025-07-11T14:08:31.126+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1752235709148
[2025-07-11T14:08:31.127+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp10148871710057428943.tmp
[2025-07-11T14:08:31.130+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp10148871710057428943.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar
[2025-07-11T14:08:31.134+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar to class loader default
[2025-07-11T14:08:31.134+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/com.github.jnr_jnr-constants-0.10.3.jar with timestamp 1752235709148
[2025-07-11T14:08:31.134+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/com.github.jnr_jnr-constants-0.10.3.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp18434823870402293111.tmp
[2025-07-11T14:08:31.139+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp18434823870402293111.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jnr-constants-0.10.3.jar
[2025-07-11T14:08:31.143+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jnr-constants-0.10.3.jar to class loader default
[2025-07-11T14:08:31.143+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/org.slf4j_slf4j-api-1.7.26.jar with timestamp 1752235709148
[2025-07-11T14:08:31.144+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/org.slf4j_slf4j-api-1.7.26.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp11141106130443018363.tmp
[2025-07-11T14:08:31.145+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp11141106130443018363.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.slf4j_slf4j-api-1.7.26.jar
[2025-07-11T14:08:31.148+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.slf4j_slf4j-api-1.7.26.jar to class loader default
[2025-07-11T14:08:31.148+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/com.github.jnr_jnr-x86asm-1.0.2.jar with timestamp 1752235709148
[2025-07-11T14:08:31.148+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/com.github.jnr_jnr-x86asm-1.0.2.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp10531030296126568812.tmp
[2025-07-11T14:08:31.150+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp10531030296126568812.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jnr-x86asm-1.0.2.jar
[2025-07-11T14:08:31.153+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.jnr_jnr-x86asm-1.0.2.jar to class loader default
[2025-07-11T14:08:31.154+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1752235709148
[2025-07-11T14:08:31.155+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp3921124683910613057.tmp
[2025-07-11T14:08:31.157+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp3921124683910613057.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.hdrhistogram_HdrHistogram-2.1.12.jar
[2025-07-11T14:08:31.160+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.hdrhistogram_HdrHistogram-2.1.12.jar to class loader default
[2025-07-11T14:08:31.160+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/org.ow2.asm_asm-util-9.2.jar with timestamp 1752235709148
[2025-07-11T14:08:31.161+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/org.ow2.asm_asm-util-9.2.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp16225356239444626995.tmp
[2025-07-11T14:08:31.162+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp16225356239444626995.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.ow2.asm_asm-util-9.2.jar
[2025-07-11T14:08:31.166+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.ow2.asm_asm-util-9.2.jar to class loader default
[2025-07-11T14:08:31.166+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1752235709148
[2025-07-11T14:08:31.167+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp16879898608218091408.tmp
[2025-07-11T14:08:31.172+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp16879898608218091408.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar
[2025-07-11T14:08:31.175+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar to class loader default
[2025-07-11T14:08:31.175+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1752235709148
[2025-07-11T14:08:31.175+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp8758182215879352408.tmp
[2025-07-11T14:08:31.178+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp8758182215879352408.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.spotbugs_spotbugs-annotations-3.1.12.jar
[2025-07-11T14:08:31.181+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/com.github.spotbugs_spotbugs-annotations-3.1.12.jar to class loader default
[2025-07-11T14:08:31.181+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Fetching spark://138.4.31.23:41093/jars/org.ow2.asm_asm-tree-9.2.jar with timestamp 1752235709148
[2025-07-11T14:08:31.181+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Fetching spark://138.4.31.23:41093/jars/org.ow2.asm_asm-tree-9.2.jar to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp421626925910481857.tmp
[2025-07-11T14:08:31.182+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/fetchFileTemp421626925910481857.tmp has been previously copied to /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.ow2.asm_asm-tree-9.2.jar
[2025-07-11T14:08:31.185+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Executor: Adding file:/tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/userFiles-5cbb6d53-dadc-4dd5-86cc-6161def252c9/org.ow2.asm_asm-tree-9.2.jar to class loader default
[2025-07-11T14:08:31.193+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43033.
[2025-07-11T14:08:31.193+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO NettyBlockTransferService: Server created on 138.4.31.23:43033
[2025-07-11T14:08:31.195+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-07-11T14:08:31.202+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 138.4.31.23, 43033, None)
[2025-07-11T14:08:31.204+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO BlockManagerMasterEndpoint: Registering block manager 138.4.31.23:43033 with 434.4 MiB RAM, BlockManagerId(driver, 138.4.31.23, 43033, None)
[2025-07-11T14:08:31.207+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 138.4.31.23, 43033, None)
[2025-07-11T14:08:31.208+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 138.4.31.23, 43033, None)
[2025-07-11T14:08:31.688+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-07-11T14:08:31.690+0200] {subprocess.py:93} INFO - 25/07/11 14:08:31 INFO SharedState: Warehouse path is 'file:/tmp/airflowtmpa75f1s1k/spark-warehouse'.
[2025-07-11T14:08:32.651+0200] {subprocess.py:93} INFO - 25/07/11 14:08:32 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.
[2025-07-11T14:08:34.225+0200] {subprocess.py:93} INFO - MLflow Run ID: 4511049f0cf4443aa9de1decca0cfca4
[2025-07-11T14:08:34.225+0200] {subprocess.py:93} INFO - MLflow Tracking URI: file:///home/monica.fernandez/practica_creativa/mlruns
[2025-07-11T14:08:34.471+0200] {subprocess.py:93} INFO - 25/07/11 14:08:34 INFO InMemoryFileIndex: It took 43 ms to list leaf files for 1 paths.
[2025-07-11T14:08:36.648+0200] {subprocess.py:93} INFO - 25/07/11 14:08:36 INFO DefaultMavenCoordinates: DataStax Java driver for Apache Cassandra(R) (com.datastax.oss:java-driver-core-shaded) version 4.13.0
[2025-07-11T14:08:36.846+0200] {subprocess.py:93} INFO - 25/07/11 14:08:36 INFO Clock: Could not access native clock (see debug logs for details), falling back to Java system clock
[2025-07-11T14:08:37.291+0200] {subprocess.py:93} INFO - 25/07/11 14:08:37 INFO CassandraConnector: Connected to Cassandra cluster.
[2025-07-11T14:08:37.374+0200] {subprocess.py:93} INFO - Columnas tras join con Cassandra: ['origin', 'dest', 'ArrDelay', 'CRSArrTime', 'CRSDepTime', 'Carrier', 'DayOfMonth', 'DayOfWeek', 'DayOfYear', 'DepDelay', 'FlightDate', 'FlightNum', 'Route', 'distance']
[2025-07-11T14:08:37.835+0200] {subprocess.py:93} INFO - 25/07/11 14:08:37 INFO V2ScanRelationPushDown:
[2025-07-11T14:08:37.835+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:08:37.835+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:08:37.835+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:08:37.835+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:08:37.921+0200] {subprocess.py:93} INFO - 25/07/11 14:08:37 INFO V2ScanRelationPushDown:
[2025-07-11T14:08:37.921+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-11T14:08:37.921+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:08:38.246+0200] {subprocess.py:93} INFO - 25/07/11 14:08:38 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:08:38.246+0200] {subprocess.py:93} INFO - 25/07/11 14:08:38 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:08:38.849+0200] {subprocess.py:93} INFO - 25/07/11 14:08:38 INFO CodeGenerator: Code generated in 196.636134 ms
[2025-07-11T14:08:38.892+0200] {subprocess.py:93} INFO - 25/07/11 14:08:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 214.5 KiB, free 434.2 MiB)
[2025-07-11T14:08:38.954+0200] {subprocess.py:93} INFO - 25/07/11 14:08:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 434.2 MiB)
[2025-07-11T14:08:38.956+0200] {subprocess.py:93} INFO - 25/07/11 14:08:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 138.4.31.23:43033 (size: 38.9 KiB, free: 434.4 MiB)
[2025-07-11T14:08:38.960+0200] {subprocess.py:93} INFO - 25/07/11 14:08:38 INFO SparkContext: Created broadcast 0 from showString at NativeMethodAccessorImpl.java:0
[2025-07-11T14:08:38.982+0200] {subprocess.py:93} INFO - 25/07/11 14:08:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:08:39.124+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO DAGScheduler: Registering RDD 3 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2025-07-11T14:08:39.129+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO DAGScheduler: Got map stage job 0 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-07-11T14:08:39.130+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:08:39.130+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:08:39.131+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO CodeGenerator: Code generated in 13.2921 ms
[2025-07-11T14:08:39.132+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:39.136+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:08:39.236+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 17.1 KiB, free 434.1 MiB)
[2025-07-11T14:08:39.242+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 434.1 MiB)
[2025-07-11T14:08:39.243+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 138.4.31.23:43033 (size: 8.3 KiB, free: 434.4 MiB)
[2025-07-11T14:08:39.243+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:39.257+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:08:39.258+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks resource profile 0
[2025-07-11T14:08:39.275+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO DAGScheduler: Registering RDD 7 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2025-07-11T14:08:39.275+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO DAGScheduler: Got map stage job 1 (showString at NativeMethodAccessorImpl.java:0) with 13 output partitions
[2025-07-11T14:08:39.275+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:08:39.276+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:08:39.276+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:39.277+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:08:39.301+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:08:39.308+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:08:39.322+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 18.7 KiB, free 434.1 MiB)
[2025-07-11T14:08:39.329+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 434.1 MiB)
[2025-07-11T14:08:39.330+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 138.4.31.23:43033 (size: 9.2 KiB, free: 434.3 MiB)
[2025-07-11T14:08:39.330+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2025-07-11T14:08:39.330+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:39.330+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
[2025-07-11T14:08:39.331+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-11T14:08:39.332+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO TaskSchedulerImpl: Adding task set 1.0 with 13 tasks resource profile 0
[2025-07-11T14:08:39.344+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2) (138.4.31.23, executor driver, partition 0, ANY, 16715 bytes)
[2025-07-11T14:08:39.345+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3) (138.4.31.23, executor driver, partition 1, ANY, 16719 bytes)
[2025-07-11T14:08:39.346+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
[2025-07-11T14:08:39.350+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
[2025-07-11T14:08:39.445+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO CodeGenerator: Code generated in 19.024963 ms
[2025-07-11T14:08:39.446+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO CodeGenerator: Code generated in 17.510996 ms
[2025-07-11T14:08:39.483+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO CodeGenerator: Code generated in 23.427795 ms
[2025-07-11T14:08:39.485+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO CodeGenerator: Code generated in 23.934601 ms
[2025-07-11T14:08:39.494+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:08:39.495+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:08:39.510+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO CodeGenerator: Code generated in 12.60478 ms
[2025-07-11T14:08:39.578+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO CodecPool: Got brand-new decompressor [.bz2]
[2025-07-11T14:08:39.579+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO CodecPool: Got brand-new decompressor [.bz2]
[2025-07-11T14:08:39.780+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2074 bytes result sent to driver
[2025-07-11T14:08:39.785+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2074 bytes result sent to driver
[2025-07-11T14:08:39.789+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 4) (138.4.31.23, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-11T14:08:39.792+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO Executor: Running task 2.0 in stage 1.0 (TID 4)
[2025-07-11T14:08:39.794+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 5) (138.4.31.23, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-11T14:08:39.795+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO Executor: Running task 3.0 in stage 1.0 (TID 5)
[2025-07-11T14:08:39.826+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 520 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:08:39.839+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 550 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:08:39.840+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-07-11T14:08:39.844+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO CodeGenerator: Code generated in 52.011855 ms
[2025-07-11T14:08:39.854+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO DAGScheduler: ShuffleMapStage 0 (showString at NativeMethodAccessorImpl.java:0) finished in 0,701 s
[2025-07-11T14:08:39.854+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:08:39.856+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO DAGScheduler: running: Set(ShuffleMapStage 1)
[2025-07-11T14:08:39.856+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:08:39.856+0200] {subprocess.py:93} INFO - 25/07/11 14:08:39 INFO DAGScheduler: failed: Set()
[2025-07-11T14:08:40.077+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1988 bytes result sent to driver
[2025-07-11T14:08:40.082+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 6) (138.4.31.23, executor driver, partition 4, ANY, 16839 bytes)
[2025-07-11T14:08:40.085+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Running task 4.0 in stage 1.0 (TID 6)
[2025-07-11T14:08:40.103+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 756 ms on 138.4.31.23 (executor driver) (1/13)
[2025-07-11T14:08:40.170+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 138.4.31.23:43033 in memory (size: 8.3 KiB, free: 434.4 MiB)
[2025-07-11T14:08:40.175+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1988 bytes result sent to driver
[2025-07-11T14:08:40.194+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 7) (138.4.31.23, executor driver, partition 5, ANY, 16839 bytes)
[2025-07-11T14:08:40.195+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Running task 5.0 in stage 1.0 (TID 7)
[2025-07-11T14:08:40.198+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 863 ms on 138.4.31.23 (executor driver) (2/13)
[2025-07-11T14:08:40.214+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Finished task 3.0 in stage 1.0 (TID 5). 1988 bytes result sent to driver
[2025-07-11T14:08:40.216+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 8) (138.4.31.23, executor driver, partition 6, ANY, 16719 bytes)
[2025-07-11T14:08:40.217+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 5) in 423 ms on 138.4.31.23 (executor driver) (3/13)
[2025-07-11T14:08:40.219+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Finished task 2.0 in stage 1.0 (TID 4). 1988 bytes result sent to driver
[2025-07-11T14:08:40.220+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Running task 6.0 in stage 1.0 (TID 8)
[2025-07-11T14:08:40.224+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 9) (138.4.31.23, executor driver, partition 7, ANY, 16839 bytes)
[2025-07-11T14:08:40.225+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 4) in 432 ms on 138.4.31.23 (executor driver) (4/13)
[2025-07-11T14:08:40.226+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Running task 7.0 in stage 1.0 (TID 9)
[2025-07-11T14:08:40.348+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Finished task 5.0 in stage 1.0 (TID 7). 2031 bytes result sent to driver
[2025-07-11T14:08:40.350+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 10) (138.4.31.23, executor driver, partition 8, ANY, 16719 bytes)
[2025-07-11T14:08:40.350+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Running task 8.0 in stage 1.0 (TID 10)
[2025-07-11T14:08:40.351+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 7) in 157 ms on 138.4.31.23 (executor driver) (5/13)
[2025-07-11T14:08:40.359+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Finished task 4.0 in stage 1.0 (TID 6). 2031 bytes result sent to driver
[2025-07-11T14:08:40.361+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 11) (138.4.31.23, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-11T14:08:40.363+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 6) in 281 ms on 138.4.31.23 (executor driver) (6/13)
[2025-07-11T14:08:40.369+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Running task 9.0 in stage 1.0 (TID 11)
[2025-07-11T14:08:40.389+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Finished task 6.0 in stage 1.0 (TID 8). 2031 bytes result sent to driver
[2025-07-11T14:08:40.391+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 12) (138.4.31.23, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-11T14:08:40.391+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Running task 10.0 in stage 1.0 (TID 12)
[2025-07-11T14:08:40.391+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 8) in 177 ms on 138.4.31.23 (executor driver) (7/13)
[2025-07-11T14:08:40.396+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Finished task 7.0 in stage 1.0 (TID 9). 2031 bytes result sent to driver
[2025-07-11T14:08:40.401+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Starting task 11.0 in stage 1.0 (TID 13) (138.4.31.23, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-11T14:08:40.402+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 9) in 184 ms on 138.4.31.23 (executor driver) (8/13)
[2025-07-11T14:08:40.414+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Running task 11.0 in stage 1.0 (TID 13)
[2025-07-11T14:08:40.482+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Finished task 8.0 in stage 1.0 (TID 10). 1988 bytes result sent to driver
[2025-07-11T14:08:40.484+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Starting task 12.0 in stage 1.0 (TID 14) (138.4.31.23, executor driver, partition 12, ANY, 16719 bytes)
[2025-07-11T14:08:40.486+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 10) in 136 ms on 138.4.31.23 (executor driver) (9/13)
[2025-07-11T14:08:40.486+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Running task 12.0 in stage 1.0 (TID 14)
[2025-07-11T14:08:40.510+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Finished task 10.0 in stage 1.0 (TID 12). 1988 bytes result sent to driver
[2025-07-11T14:08:40.512+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 12) in 121 ms on 138.4.31.23 (executor driver) (10/13)
[2025-07-11T14:08:40.513+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Finished task 9.0 in stage 1.0 (TID 11). 1988 bytes result sent to driver
[2025-07-11T14:08:40.518+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Finished task 11.0 in stage 1.0 (TID 13). 1988 bytes result sent to driver
[2025-07-11T14:08:40.519+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Finished task 11.0 in stage 1.0 (TID 13) in 120 ms on 138.4.31.23 (executor driver) (11/13)
[2025-07-11T14:08:40.520+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 11) in 160 ms on 138.4.31.23 (executor driver) (12/13)
[2025-07-11T14:08:40.564+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Finished task 12.0 in stage 1.0 (TID 14). 1988 bytes result sent to driver
[2025-07-11T14:08:40.566+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Finished task 12.0 in stage 1.0 (TID 14) in 82 ms on 138.4.31.23 (executor driver) (13/13)
[2025-07-11T14:08:40.566+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2025-07-11T14:08:40.566+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO DAGScheduler: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 1,285 s
[2025-07-11T14:08:40.567+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:08:40.567+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO DAGScheduler: running: Set()
[2025-07-11T14:08:40.567+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:08:40.567+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO DAGScheduler: failed: Set()
[2025-07-11T14:08:40.595+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO ShufflePartitionsUtil: For shuffle(0, 1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:08:40.663+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO CodeGenerator: Code generated in 33.136022 ms
[2025-07-11T14:08:40.680+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO CodeGenerator: Code generated in 11.987489 ms
[2025-07-11T14:08:40.724+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO CodeGenerator: Code generated in 10.739841 ms
[2025-07-11T14:08:40.761+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2025-07-11T14:08:40.764+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO DAGScheduler: Got job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-07-11T14:08:40.765+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO DAGScheduler: Final stage: ResultStage 4 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:08:40.765+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2, ShuffleMapStage 3)
[2025-07-11T14:08:40.766+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:40.767+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[14] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:08:40.780+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 54.2 KiB, free 434.1 MiB)
[2025-07-11T14:08:40.788+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 25.2 KiB, free 434.0 MiB)
[2025-07-11T14:08:40.788+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 138.4.31.23:43033 (size: 25.2 KiB, free: 434.3 MiB)
[2025-07-11T14:08:40.789+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:40.791+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:08:40.791+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
[2025-07-11T14:08:40.796+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 15) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 15110 bytes)
[2025-07-11T14:08:40.796+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO Executor: Running task 0.0 in stage 4.0 (TID 15)
[2025-07-11T14:08:40.860+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO ShuffleBlockFetcherIterator: Getting 2 (512.0 B) non-empty blocks including 2 (512.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:08:40.862+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 17 ms
[2025-07-11T14:08:40.882+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 138.4.31.23:43033 in memory (size: 9.2 KiB, free: 434.3 MiB)
[2025-07-11T14:08:40.883+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO CodeGenerator: Code generated in 18.069031 ms
[2025-07-11T14:08:40.901+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO CodeGenerator: Code generated in 10.961297 ms
[2025-07-11T14:08:40.916+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO CodeGenerator: Code generated in 9.590753 ms
[2025-07-11T14:08:40.931+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO ShuffleBlockFetcherIterator: Getting 13 (221.8 KiB) non-empty blocks including 13 (221.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:08:40.931+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-11T14:08:40.943+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO CodeGenerator: Code generated in 10.725391 ms
[2025-07-11T14:08:40.952+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO CodeGenerator: Code generated in 6.197689 ms
[2025-07-11T14:08:40.963+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO CodeGenerator: Code generated in 9.106028 ms
[2025-07-11T14:08:40.988+0200] {subprocess.py:93} INFO - 25/07/11 14:08:40 INFO CodeGenerator: Code generated in 23.910959 ms
[2025-07-11T14:08:41.063+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO Executor: Finished task 0.0 in stage 4.0 (TID 15). 6286 bytes result sent to driver
[2025-07-11T14:08:41.063+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 15) in 269 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:08:41.063+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2025-07-11T14:08:41.063+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO DAGScheduler: ResultStage 4 (showString at NativeMethodAccessorImpl.java:0) finished in 0,290 s
[2025-07-11T14:08:41.065+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:08:41.065+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
[2025-07-11T14:08:41.066+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO DAGScheduler: Job 2 finished: showString at NativeMethodAccessorImpl.java:0, took 0,304586 s
[2025-07-11T14:08:41.099+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO CodeGenerator: Code generated in 8.123801 ms
[2025-07-11T14:08:41.106+0200] {subprocess.py:93} INFO - +------+----+--------+
[2025-07-11T14:08:41.106+0200] {subprocess.py:93} INFO - |origin|dest|distance|
[2025-07-11T14:08:41.107+0200] {subprocess.py:93} INFO - +------+----+--------+
[2025-07-11T14:08:41.107+0200] {subprocess.py:93} INFO - |   ABQ| DFW|   569.0|
[2025-07-11T14:08:41.107+0200] {subprocess.py:93} INFO - |   ABQ| DFW|   569.0|
[2025-07-11T14:08:41.107+0200] {subprocess.py:93} INFO - |   ABQ| DFW|   569.0|
[2025-07-11T14:08:41.107+0200] {subprocess.py:93} INFO - |   ATL| DFW|   731.0|
[2025-07-11T14:08:41.107+0200] {subprocess.py:93} INFO - |   ATL| DFW|   731.0|
[2025-07-11T14:08:41.107+0200] {subprocess.py:93} INFO - +------+----+--------+
[2025-07-11T14:08:41.107+0200] {subprocess.py:93} INFO - only showing top 5 rows
[2025-07-11T14:08:41.107+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:08:41.620+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO FileSystemOverwrite: Path /home/monica.fernandez/practica_creativa/models/arrival_bucketizer_2.0.bin already exists. It will be overwritten.
[2025-07-11T14:08:41.666+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
[2025-07-11T14:08:41.669+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:08:41.671+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:08:41.671+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:08:41.724+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-11T14:08:41.725+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO DAGScheduler: Got job 3 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-11T14:08:41.725+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO DAGScheduler: Final stage: ResultStage 5 (runJob at SparkHadoopWriter.scala:83)
[2025-07-11T14:08:41.725+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:08:41.725+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:41.725+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[16] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-11T14:08:41.739+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 101.3 KiB, free 434.0 MiB)
[2025-07-11T14:08:41.740+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 433.9 MiB)
[2025-07-11T14:08:41.741+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 138.4.31.23:43033 (size: 36.5 KiB, free: 434.3 MiB)
[2025-07-11T14:08:41.743+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:41.743+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[16] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:08:41.743+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2025-07-11T14:08:41.755+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 16) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15151 bytes)
[2025-07-11T14:08:41.757+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO Executor: Running task 0.0 in stage 5.0 (TID 16)
[2025-07-11T14:08:41.792+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:08:41.792+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:08:41.792+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:08:41.857+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO FileOutputCommitter: Saved output of task 'attempt_202507111408412393022240139353901_0016_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/arrival_bucketizer_2.0.bin/metadata/_temporary/0/task_202507111408412393022240139353901_0016_m_000000
[2025-07-11T14:08:41.857+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO SparkHadoopMapRedUtil: attempt_202507111408412393022240139353901_0016_m_000000_0: Committed. Elapsed time: 2 ms.
[2025-07-11T14:08:41.858+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO Executor: Finished task 0.0 in stage 5.0 (TID 16). 1213 bytes result sent to driver
[2025-07-11T14:08:41.859+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 16) in 106 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:08:41.859+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-07-11T14:08:41.860+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO DAGScheduler: ResultStage 5 (runJob at SparkHadoopWriter.scala:83) finished in 0,132 s
[2025-07-11T14:08:41.860+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:08:41.861+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-07-11T14:08:41.861+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO DAGScheduler: Job 3 finished: runJob at SparkHadoopWriter.scala:83, took 0,137273 s
[2025-07-11T14:08:41.863+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO SparkHadoopWriter: Start to commit write Job job_202507111408412393022240139353901_0016.
[2025-07-11T14:08:41.894+0200] {subprocess.py:93} INFO - 25/07/11 14:08:41 INFO SparkHadoopWriter: Write Job job_202507111408412393022240139353901_0016 committed. Elapsed time: 29 ms.
[2025-07-11T14:08:42.070+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO V2ScanRelationPushDown:
[2025-07-11T14:08:42.070+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:08:42.070+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:08:42.070+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:08:42.071+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:08:42.078+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO V2ScanRelationPushDown:
[2025-07-11T14:08:42.078+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68
[2025-07-11T14:08:42.078+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:08:42.131+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:08:42.132+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:08:42.169+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO CodeGenerator: Code generated in 6.724963 ms
[2025-07-11T14:08:42.173+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 214.5 KiB, free 433.7 MiB)
[2025-07-11T14:08:42.184+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 433.7 MiB)
[2025-07-11T14:08:42.185+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 138.4.31.23:43033 (size: 38.9 KiB, free: 434.3 MiB)
[2025-07-11T14:08:42.186+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO SparkContext: Created broadcast 5 from collect at StringIndexer.scala:204
[2025-07-11T14:08:42.187+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:08:42.193+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO DAGScheduler: Registering RDD 20 (collect at StringIndexer.scala:204) as input to shuffle 2
[2025-07-11T14:08:42.193+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO DAGScheduler: Got map stage job 4 (collect at StringIndexer.scala:204) with 2 output partitions
[2025-07-11T14:08:42.193+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (collect at StringIndexer.scala:204)
[2025-07-11T14:08:42.193+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:08:42.195+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:42.196+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[20] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:08:42.197+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 17.4 KiB, free 433.7 MiB)
[2025-07-11T14:08:42.198+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 433.7 MiB)
[2025-07-11T14:08:42.199+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 138.4.31.23:43033 (size: 8.3 KiB, free: 434.3 MiB)
[2025-07-11T14:08:42.199+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:42.200+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[20] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:08:42.200+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSchedulerImpl: Adding task set 6.0 with 2 tasks resource profile 0
[2025-07-11T14:08:42.203+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 17) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:08:42.203+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 18) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:08:42.203+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Running task 0.0 in stage 6.0 (TID 17)
[2025-07-11T14:08:42.208+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO CodeGenerator: Code generated in 5.505628 ms
[2025-07-11T14:08:42.209+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Running task 1.0 in stage 6.0 (TID 18)
[2025-07-11T14:08:42.217+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO CodeGenerator: Code generated in 9.098408 ms
[2025-07-11T14:08:42.222+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO DAGScheduler: Registering RDD 24 (collect at StringIndexer.scala:204) as input to shuffle 3
[2025-07-11T14:08:42.222+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO DAGScheduler: Got map stage job 5 (collect at StringIndexer.scala:204) with 13 output partitions
[2025-07-11T14:08:42.222+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (collect at StringIndexer.scala:204)
[2025-07-11T14:08:42.222+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:08:42.222+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:42.224+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[24] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:08:42.226+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 18.2 KiB, free 433.6 MiB)
[2025-07-11T14:08:42.227+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.6 MiB)
[2025-07-11T14:08:42.228+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 138.4.31.23:43033 (size: 9.0 KiB, free: 434.2 MiB)
[2025-07-11T14:08:42.228+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:42.229+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[24] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-11T14:08:42.230+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSchedulerImpl: Adding task set 7.0 with 13 tasks resource profile 0
[2025-07-11T14:08:42.232+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 19) (138.4.31.23, executor driver, partition 0, ANY, 16715 bytes)
[2025-07-11T14:08:42.232+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 20) (138.4.31.23, executor driver, partition 1, ANY, 16839 bytes)
[2025-07-11T14:08:42.233+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Running task 0.0 in stage 7.0 (TID 19)
[2025-07-11T14:08:42.245+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Running task 1.0 in stage 7.0 (TID 20)
[2025-07-11T14:08:42.252+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO CodeGenerator: Code generated in 7.840525 ms
[2025-07-11T14:08:42.253+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO CodeGenerator: Code generated in 32.810395 ms
[2025-07-11T14:08:42.254+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:08:42.266+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:08:42.270+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO CodeGenerator: Code generated in 14.266758 ms
[2025-07-11T14:08:42.399+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Finished task 0.0 in stage 7.0 (TID 19). 1945 bytes result sent to driver
[2025-07-11T14:08:42.401+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 21) (138.4.31.23, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-11T14:08:42.402+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Running task 2.0 in stage 7.0 (TID 21)
[2025-07-11T14:08:42.404+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 19) in 173 ms on 138.4.31.23 (executor driver) (1/13)
[2025-07-11T14:08:42.450+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Finished task 1.0 in stage 7.0 (TID 20). 1988 bytes result sent to driver
[2025-07-11T14:08:42.454+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 22) (138.4.31.23, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-11T14:08:42.456+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 20) in 224 ms on 138.4.31.23 (executor driver) (2/13)
[2025-07-11T14:08:42.457+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Running task 3.0 in stage 7.0 (TID 22)
[2025-07-11T14:08:42.488+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Finished task 2.0 in stage 7.0 (TID 21). 1945 bytes result sent to driver
[2025-07-11T14:08:42.491+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 23) (138.4.31.23, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-11T14:08:42.492+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Running task 4.0 in stage 7.0 (TID 23)
[2025-07-11T14:08:42.492+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 21) in 91 ms on 138.4.31.23 (executor driver) (3/13)
[2025-07-11T14:08:42.529+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Finished task 3.0 in stage 7.0 (TID 22). 1945 bytes result sent to driver
[2025-07-11T14:08:42.531+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 24) (138.4.31.23, executor driver, partition 5, ANY, 16719 bytes)
[2025-07-11T14:08:42.532+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 22) in 79 ms on 138.4.31.23 (executor driver) (4/13)
[2025-07-11T14:08:42.533+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Running task 5.0 in stage 7.0 (TID 24)
[2025-07-11T14:08:42.565+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Finished task 4.0 in stage 7.0 (TID 23). 1945 bytes result sent to driver
[2025-07-11T14:08:42.567+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 25) (138.4.31.23, executor driver, partition 6, ANY, 16719 bytes)
[2025-07-11T14:08:42.569+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 23) in 79 ms on 138.4.31.23 (executor driver) (5/13)
[2025-07-11T14:08:42.569+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Running task 6.0 in stage 7.0 (TID 25)
[2025-07-11T14:08:42.622+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 138.4.31.23:43033 in memory (size: 25.2 KiB, free: 434.3 MiB)
[2025-07-11T14:08:42.660+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Finished task 5.0 in stage 7.0 (TID 24). 2031 bytes result sent to driver
[2025-07-11T14:08:42.661+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 26) (138.4.31.23, executor driver, partition 7, ANY, 16839 bytes)
[2025-07-11T14:08:42.663+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Running task 7.0 in stage 7.0 (TID 26)
[2025-07-11T14:08:42.663+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 24) in 130 ms on 138.4.31.23 (executor driver) (6/13)
[2025-07-11T14:08:42.678+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Finished task 6.0 in stage 7.0 (TID 25). 1988 bytes result sent to driver
[2025-07-11T14:08:42.681+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 27) (138.4.31.23, executor driver, partition 8, ANY, 16839 bytes)
[2025-07-11T14:08:42.681+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 25) in 113 ms on 138.4.31.23 (executor driver) (7/13)
[2025-07-11T14:08:42.681+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Running task 8.0 in stage 7.0 (TID 27)
[2025-07-11T14:08:42.688+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 138.4.31.23:43033 in memory (size: 36.5 KiB, free: 434.3 MiB)
[2025-07-11T14:08:42.753+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Finished task 7.0 in stage 7.0 (TID 26). 1945 bytes result sent to driver
[2025-07-11T14:08:42.755+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 28) (138.4.31.23, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-11T14:08:42.755+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 26) in 95 ms on 138.4.31.23 (executor driver) (8/13)
[2025-07-11T14:08:42.758+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Running task 9.0 in stage 7.0 (TID 28)
[2025-07-11T14:08:42.818+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 138.4.31.23:43033 in memory (size: 38.9 KiB, free: 434.3 MiB)
[2025-07-11T14:08:42.824+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Finished task 8.0 in stage 7.0 (TID 27). 1945 bytes result sent to driver
[2025-07-11T14:08:42.826+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Starting task 10.0 in stage 7.0 (TID 29) (138.4.31.23, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-11T14:08:42.826+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Running task 10.0 in stage 7.0 (TID 29)
[2025-07-11T14:08:42.828+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 27) in 149 ms on 138.4.31.23 (executor driver) (9/13)
[2025-07-11T14:08:42.874+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Finished task 9.0 in stage 7.0 (TID 28). 1945 bytes result sent to driver
[2025-07-11T14:08:42.877+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Starting task 11.0 in stage 7.0 (TID 30) (138.4.31.23, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-11T14:08:42.878+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 28) in 122 ms on 138.4.31.23 (executor driver) (10/13)
[2025-07-11T14:08:42.878+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Running task 11.0 in stage 7.0 (TID 30)
[2025-07-11T14:08:42.943+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Finished task 10.0 in stage 7.0 (TID 29). 1945 bytes result sent to driver
[2025-07-11T14:08:42.945+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Starting task 12.0 in stage 7.0 (TID 31) (138.4.31.23, executor driver, partition 12, ANY, 16719 bytes)
[2025-07-11T14:08:42.945+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO Executor: Running task 12.0 in stage 7.0 (TID 31)
[2025-07-11T14:08:42.948+0200] {subprocess.py:93} INFO - 25/07/11 14:08:42 INFO TaskSetManager: Finished task 10.0 in stage 7.0 (TID 29) in 121 ms on 138.4.31.23 (executor driver) (11/13)
[2025-07-11T14:08:43.091+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO Executor: Finished task 11.0 in stage 7.0 (TID 30). 2031 bytes result sent to driver
[2025-07-11T14:08:43.091+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO Executor: Finished task 12.0 in stage 7.0 (TID 31). 1988 bytes result sent to driver
[2025-07-11T14:08:43.095+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO TaskSetManager: Finished task 11.0 in stage 7.0 (TID 30) in 217 ms on 138.4.31.23 (executor driver) (12/13)
[2025-07-11T14:08:43.095+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO TaskSetManager: Finished task 12.0 in stage 7.0 (TID 31) in 148 ms on 138.4.31.23 (executor driver) (13/13)
[2025-07-11T14:08:43.095+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2025-07-11T14:08:43.095+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO DAGScheduler: ShuffleMapStage 7 (collect at StringIndexer.scala:204) finished in 0,868 s
[2025-07-11T14:08:43.095+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:08:43.095+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO DAGScheduler: running: Set(ShuffleMapStage 6)
[2025-07-11T14:08:43.095+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:08:43.095+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO DAGScheduler: failed: Set()
[2025-07-11T14:08:43.139+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:08:43.224+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:08:43.229+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO DAGScheduler: Got job 6 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-11T14:08:43.229+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO DAGScheduler: Final stage: ResultStage 9 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-11T14:08:43.229+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
[2025-07-11T14:08:43.229+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:43.229+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[26] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-11T14:08:43.229+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 8.2 KiB, free 434.1 MiB)
[2025-07-11T14:08:43.234+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 434.1 MiB)
[2025-07-11T14:08:43.235+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 138.4.31.23:43033 (size: 4.2 KiB, free: 434.3 MiB)
[2025-07-11T14:08:43.237+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:43.239+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[26] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:08:43.239+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
[2025-07-11T14:08:43.239+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 32) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-11T14:08:43.240+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO Executor: Running task 0.0 in stage 9.0 (TID 32)
[2025-07-11T14:08:43.250+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO ShuffleBlockFetcherIterator: Getting 13 (200.0 KiB) non-empty blocks including 13 (200.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:08:43.250+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-11T14:08:43.303+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO Executor: Finished task 0.0 in stage 9.0 (TID 32). 40648 bytes result sent to driver
[2025-07-11T14:08:43.305+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 32) in 66 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:08:43.305+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-07-11T14:08:43.309+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO DAGScheduler: ResultStage 9 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,079 s
[2025-07-11T14:08:43.309+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:08:43.310+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
[2025-07-11T14:08:43.310+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO DAGScheduler: Job 6 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,082902 s
[2025-07-11T14:08:43.332+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO CodeGenerator: Code generated in 11.354642 ms
[2025-07-11T14:08:43.370+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 4.3 MiB, free 429.8 MiB)
[2025-07-11T14:08:43.381+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 89.0 KiB, free 429.8 MiB)
[2025-07-11T14:08:43.384+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 138.4.31.23:43033 (size: 89.0 KiB, free: 434.3 MiB)
[2025-07-11T14:08:43.384+0200] {subprocess.py:93} INFO - 25/07/11 14:08:43 INFO SparkContext: Created broadcast 9 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:08:44.280+0200] {subprocess.py:93} INFO - 25/07/11 14:08:44 INFO Executor: Finished task 1.0 in stage 6.0 (TID 18). 2031 bytes result sent to driver
[2025-07-11T14:08:44.281+0200] {subprocess.py:93} INFO - 25/07/11 14:08:44 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 18) in 2079 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:08:44.365+0200] {subprocess.py:93} INFO - 25/07/11 14:08:44 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 138.4.31.23:43033 in memory (size: 4.2 KiB, free: 434.3 MiB)
[2025-07-11T14:08:46.159+0200] {subprocess.py:93} INFO - 25/07/11 14:08:46 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 138.4.31.23:43033 in memory (size: 9.0 KiB, free: 434.3 MiB)
[2025-07-11T14:08:49.639+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO Executor: Finished task 0.0 in stage 6.0 (TID 17). 2074 bytes result sent to driver
[2025-07-11T14:08:49.639+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 17) in 7438 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:08:49.639+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2025-07-11T14:08:49.640+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO DAGScheduler: ShuffleMapStage 6 (collect at StringIndexer.scala:204) finished in 7,445 s
[2025-07-11T14:08:49.640+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:08:49.641+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO DAGScheduler: running: Set()
[2025-07-11T14:08:49.641+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:08:49.641+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO DAGScheduler: failed: Set()
[2025-07-11T14:08:49.647+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:08:49.672+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO CodeGenerator: Code generated in 10.426549 ms
[2025-07-11T14:08:49.685+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO DAGScheduler: Registering RDD 30 (collect at StringIndexer.scala:204) as input to shuffle 4
[2025-07-11T14:08:49.685+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO DAGScheduler: Got map stage job 7 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-11T14:08:49.685+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO DAGScheduler: Final stage: ShuffleMapStage 11 (collect at StringIndexer.scala:204)
[2025-07-11T14:08:49.685+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
[2025-07-11T14:08:49.685+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:49.685+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[30] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:08:49.704+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 50.7 KiB, free 429.7 MiB)
[2025-07-11T14:08:49.705+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 429.7 MiB)
[2025-07-11T14:08:49.706+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 138.4.31.23:43033 (size: 24.0 KiB, free: 434.2 MiB)
[2025-07-11T14:08:49.707+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:49.708+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[30] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:08:49.708+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
[2025-07-11T14:08:49.710+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 33) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14833 bytes)
[2025-07-11T14:08:49.710+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO Executor: Running task 0.0 in stage 11.0 (TID 33)
[2025-07-11T14:08:49.737+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO ShuffleBlockFetcherIterator: Getting 2 (1126.9 KiB) non-empty blocks including 2 (1126.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:08:49.737+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-11T14:08:49.745+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO CodeGenerator: Code generated in 7.55199 ms
[2025-07-11T14:08:49.760+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO CodeGenerator: Code generated in 3.719162 ms
[2025-07-11T14:08:49.769+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO CodeGenerator: Code generated in 3.879869 ms
[2025-07-11T14:08:49.779+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO CodeGenerator: Code generated in 5.54574 ms
[2025-07-11T14:08:49.792+0200] {subprocess.py:93} INFO - 25/07/11 14:08:49 INFO CodeGenerator: Code generated in 5.20484 ms
[2025-07-11T14:08:50.411+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO CodeGenerator: Code generated in 8.848649 ms
[2025-07-11T14:08:50.600+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO Executor: Finished task 0.0 in stage 11.0 (TID 33). 6500 bytes result sent to driver
[2025-07-11T14:08:50.601+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 33) in 891 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:08:50.601+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2025-07-11T14:08:50.603+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: ShuffleMapStage 11 (collect at StringIndexer.scala:204) finished in 0,920 s
[2025-07-11T14:08:50.603+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:08:50.603+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: running: Set()
[2025-07-11T14:08:50.603+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:08:50.603+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: failed: Set()
[2025-07-11T14:08:50.621+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
[2025-07-11T14:08:50.622+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: Got job 8 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-11T14:08:50.622+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: Final stage: ResultStage 14 (collect at StringIndexer.scala:204)
[2025-07-11T14:08:50.622+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
[2025-07-11T14:08:50.622+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:50.622+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[33] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:08:50.626+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 49.9 KiB, free 429.7 MiB)
[2025-07-11T14:08:50.627+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 429.6 MiB)
[2025-07-11T14:08:50.627+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 138.4.31.23:43033 (size: 23.6 KiB, free: 434.2 MiB)
[2025-07-11T14:08:50.627+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:50.628+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[33] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:08:50.628+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
[2025-07-11T14:08:50.629+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 34) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:08:50.629+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO Executor: Running task 0.0 in stage 14.0 (TID 34)
[2025-07-11T14:08:50.636+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:08:50.636+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:08:50.651+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO CodeGenerator: Code generated in 6.698526 ms
[2025-07-11T14:08:50.687+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO Executor: Finished task 0.0 in stage 14.0 (TID 34). 8145 bytes result sent to driver
[2025-07-11T14:08:50.694+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 34) in 66 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:08:50.694+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2025-07-11T14:08:50.695+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: ResultStage 14 (collect at StringIndexer.scala:204) finished in 0,071 s
[2025-07-11T14:08:50.696+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:08:50.696+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
[2025-07-11T14:08:50.696+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: Job 8 finished: collect at StringIndexer.scala:204, took 0,074978 s
[2025-07-11T14:08:50.706+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO CodeGenerator: Code generated in 6.645049 ms
[2025-07-11T14:08:50.807+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO FileSystemOverwrite: Path /home/monica.fernandez/practica_creativa/models/string_indexer_model_Carrier.bin already exists. It will be overwritten.
[2025-07-11T14:08:50.821+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:08:50.822+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:08:50.822+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:08:50.853+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-11T14:08:50.854+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: Got job 9 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-11T14:08:50.854+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: Final stage: ResultStage 15 (runJob at SparkHadoopWriter.scala:83)
[2025-07-11T14:08:50.854+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:08:50.854+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:50.856+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[35] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-11T14:08:50.866+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 101.3 KiB, free 429.5 MiB)
[2025-07-11T14:08:50.866+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 36.6 KiB, free 429.5 MiB)
[2025-07-11T14:08:50.866+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 138.4.31.23:43033 (size: 36.6 KiB, free: 434.2 MiB)
[2025-07-11T14:08:50.867+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:50.867+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[35] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:08:50.867+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
[2025-07-11T14:08:50.868+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 35) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15158 bytes)
[2025-07-11T14:08:50.870+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO Executor: Running task 0.0 in stage 15.0 (TID 35)
[2025-07-11T14:08:50.876+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:08:50.876+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:08:50.877+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:08:50.913+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO FileOutputCommitter: Saved output of task 'attempt_202507111408507334323457243890172_0035_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Carrier.bin/metadata/_temporary/0/task_202507111408507334323457243890172_0035_m_000000
[2025-07-11T14:08:50.914+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO SparkHadoopMapRedUtil: attempt_202507111408507334323457243890172_0035_m_000000_0: Committed. Elapsed time: 1 ms.
[2025-07-11T14:08:50.915+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO Executor: Finished task 0.0 in stage 15.0 (TID 35). 1170 bytes result sent to driver
[2025-07-11T14:08:50.922+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 35) in 51 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:08:50.922+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2025-07-11T14:08:50.922+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: ResultStage 15 (runJob at SparkHadoopWriter.scala:83) finished in 0,063 s
[2025-07-11T14:08:50.923+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:08:50.923+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
[2025-07-11T14:08:50.923+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO DAGScheduler: Job 9 finished: runJob at SparkHadoopWriter.scala:83, took 0,067093 s
[2025-07-11T14:08:50.923+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO SparkHadoopWriter: Start to commit write Job job_202507111408507334323457243890172_0035.
[2025-07-11T14:08:50.953+0200] {subprocess.py:93} INFO - 25/07/11 14:08:50 INFO SparkHadoopWriter: Write Job job_202507111408507334323457243890172_0035 committed. Elapsed time: 30 ms.
[2025-07-11T14:08:51.189+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO CodeGenerator: Code generated in 16.375016 ms
[2025-07-11T14:08:51.212+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO DAGScheduler: Registering RDD 38 (parquet at StringIndexer.scala:499) as input to shuffle 5
[2025-07-11T14:08:51.212+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO DAGScheduler: Got map stage job 10 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-11T14:08:51.212+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO DAGScheduler: Final stage: ShuffleMapStage 16 (parquet at StringIndexer.scala:499)
[2025-07-11T14:08:51.212+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:08:51.212+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:51.212+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[38] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-11T14:08:51.213+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.1 KiB, free 429.5 MiB)
[2025-07-11T14:08:51.214+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 429.5 MiB)
[2025-07-11T14:08:51.214+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 138.4.31.23:43033 (size: 4.4 KiB, free: 434.2 MiB)
[2025-07-11T14:08:51.214+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:51.215+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[38] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:08:51.215+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
[2025-07-11T14:08:51.216+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 36) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15256 bytes)
[2025-07-11T14:08:51.217+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO Executor: Running task 0.0 in stage 16.0 (TID 36)
[2025-07-11T14:08:51.223+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO Executor: Finished task 0.0 in stage 16.0 (TID 36). 1628 bytes result sent to driver
[2025-07-11T14:08:51.224+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 36) in 9 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:08:51.224+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool
[2025-07-11T14:08:51.224+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO DAGScheduler: ShuffleMapStage 16 (parquet at StringIndexer.scala:499) finished in 0,025 s
[2025-07-11T14:08:51.225+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:08:51.225+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO DAGScheduler: running: Set()
[2025-07-11T14:08:51.225+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:08:51.225+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO DAGScheduler: failed: Set()
[2025-07-11T14:08:51.268+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:08:51.283+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:08:51.283+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:08:51.287+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:08:51.287+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:08:51.287+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:08:51.289+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:08:51.314+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO SparkContext: Starting job: parquet at StringIndexer.scala:499
[2025-07-11T14:08:51.314+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO DAGScheduler: Got job 11 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-11T14:08:51.314+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO DAGScheduler: Final stage: ResultStage 18 (parquet at StringIndexer.scala:499)
[2025-07-11T14:08:51.314+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
[2025-07-11T14:08:51.314+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:51.314+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[40] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-11T14:08:51.338+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 239.5 KiB, free 429.3 MiB)
[2025-07-11T14:08:51.339+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 83.6 KiB, free 429.2 MiB)
[2025-07-11T14:08:51.340+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 138.4.31.23:43033 (size: 83.6 KiB, free: 434.1 MiB)
[2025-07-11T14:08:51.340+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:51.341+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[40] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:08:51.341+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
[2025-07-11T14:08:51.342+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 37) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:08:51.345+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO Executor: Running task 0.0 in stage 18.0 (TID 37)
[2025-07-11T14:08:51.363+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:08:51.363+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-11T14:08:51.365+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:08:51.365+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:08:51.365+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:08:51.365+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:08:51.365+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:08:51.365+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:08:51.368+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:08:51.370+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:08:51.388+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-11T14:08:51.410+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-11T14:08:51.411+0200] {subprocess.py:93} INFO - {
[2025-07-11T14:08:51.411+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-11T14:08:51.411+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-11T14:08:51.411+0200] {subprocess.py:93} INFO -     "name" : "labelsArray",
[2025-07-11T14:08:51.412+0200] {subprocess.py:93} INFO -     "type" : {
[2025-07-11T14:08:51.412+0200] {subprocess.py:93} INFO -       "type" : "array",
[2025-07-11T14:08:51.412+0200] {subprocess.py:93} INFO -       "elementType" : {
[2025-07-11T14:08:51.412+0200] {subprocess.py:93} INFO -         "type" : "array",
[2025-07-11T14:08:51.412+0200] {subprocess.py:93} INFO -         "elementType" : "string",
[2025-07-11T14:08:51.412+0200] {subprocess.py:93} INFO -         "containsNull" : true
[2025-07-11T14:08:51.412+0200] {subprocess.py:93} INFO -       },
[2025-07-11T14:08:51.412+0200] {subprocess.py:93} INFO -       "containsNull" : true
[2025-07-11T14:08:51.412+0200] {subprocess.py:93} INFO -     },
[2025-07-11T14:08:51.412+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-11T14:08:51.412+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:08:51.412+0200] {subprocess.py:93} INFO -   } ]
[2025-07-11T14:08:51.412+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:08:51.412+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-11T14:08:51.412+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-11T14:08:51.412+0200] {subprocess.py:93} INFO -   optional group labelsArray (LIST) {
[2025-07-11T14:08:51.412+0200] {subprocess.py:93} INFO -     repeated group list {
[2025-07-11T14:08:51.412+0200] {subprocess.py:93} INFO -       optional group element (LIST) {
[2025-07-11T14:08:51.413+0200] {subprocess.py:93} INFO -         repeated group list {
[2025-07-11T14:08:51.413+0200] {subprocess.py:93} INFO -           optional binary element (STRING);
[2025-07-11T14:08:51.413+0200] {subprocess.py:93} INFO -         }
[2025-07-11T14:08:51.413+0200] {subprocess.py:93} INFO -       }
[2025-07-11T14:08:51.413+0200] {subprocess.py:93} INFO -     }
[2025-07-11T14:08:51.413+0200] {subprocess.py:93} INFO -   }
[2025-07-11T14:08:51.413+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:08:51.413+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:08:51.413+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:08:51.468+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO CodecPool: Got brand-new compressor [.snappy]
[2025-07-11T14:08:51.950+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO FileOutputCommitter: Saved output of task 'attempt_202507111408515284204835991814867_0018_m_000000_37' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Carrier.bin/data/_temporary/0/task_202507111408515284204835991814867_0018_m_000000
[2025-07-11T14:08:51.950+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO SparkHadoopMapRedUtil: attempt_202507111408515284204835991814867_0018_m_000000_37: Committed. Elapsed time: 1 ms.
[2025-07-11T14:08:51.954+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO Executor: Finished task 0.0 in stage 18.0 (TID 37). 4783 bytes result sent to driver
[2025-07-11T14:08:51.954+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 37) in 612 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:08:51.954+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool
[2025-07-11T14:08:51.955+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO DAGScheduler: ResultStage 18 (parquet at StringIndexer.scala:499) finished in 0,641 s
[2025-07-11T14:08:51.955+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:08:51.955+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
[2025-07-11T14:08:51.956+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO DAGScheduler: Job 11 finished: parquet at StringIndexer.scala:499, took 0,643081 s
[2025-07-11T14:08:51.957+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO FileFormatWriter: Start to commit write Job 8ac636af-7f79-4c88-bc6c-c96359c3a560.
[2025-07-11T14:08:51.978+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 138.4.31.23:43033 in memory (size: 4.4 KiB, free: 434.1 MiB)
[2025-07-11T14:08:51.980+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 138.4.31.23:43033 in memory (size: 36.6 KiB, free: 434.1 MiB)
[2025-07-11T14:08:51.983+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 138.4.31.23:43033 in memory (size: 83.6 KiB, free: 434.2 MiB)
[2025-07-11T14:08:51.984+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO FileFormatWriter: Write Job 8ac636af-7f79-4c88-bc6c-c96359c3a560 committed. Elapsed time: 26 ms.
[2025-07-11T14:08:51.985+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 138.4.31.23:43033 in memory (size: 24.0 KiB, free: 434.2 MiB)
[2025-07-11T14:08:51.987+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO FileFormatWriter: Finished processing stats for write job 8ac636af-7f79-4c88-bc6c-c96359c3a560.
[2025-07-11T14:08:51.989+0200] {subprocess.py:93} INFO - 25/07/11 14:08:51 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 138.4.31.23:43033 in memory (size: 23.6 KiB, free: 434.3 MiB)
[2025-07-11T14:08:52.055+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO V2ScanRelationPushDown:
[2025-07-11T14:08:52.056+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:08:52.056+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:08:52.056+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:08:52.056+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:08:52.063+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO V2ScanRelationPushDown:
[2025-07-11T14:08:52.063+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68
[2025-07-11T14:08:52.063+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:08:52.084+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:08:52.084+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:08:52.112+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO CodeGenerator: Code generated in 5.360387 ms
[2025-07-11T14:08:52.115+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 214.5 KiB, free 429.6 MiB)
[2025-07-11T14:08:52.124+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 429.5 MiB)
[2025-07-11T14:08:52.125+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 138.4.31.23:43033 (size: 38.9 KiB, free: 434.2 MiB)
[2025-07-11T14:08:52.126+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO SparkContext: Created broadcast 15 from collect at StringIndexer.scala:204
[2025-07-11T14:08:52.127+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:08:52.131+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: Registering RDD 44 (collect at StringIndexer.scala:204) as input to shuffle 6
[2025-07-11T14:08:52.133+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: Got map stage job 12 (collect at StringIndexer.scala:204) with 2 output partitions
[2025-07-11T14:08:52.133+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: Final stage: ShuffleMapStage 19 (collect at StringIndexer.scala:204)
[2025-07-11T14:08:52.133+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:08:52.133+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:52.133+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[44] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:08:52.137+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 16.9 KiB, free 429.5 MiB)
[2025-07-11T14:08:52.138+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 429.5 MiB)
[2025-07-11T14:08:52.138+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 138.4.31.23:43033 (size: 8.2 KiB, free: 434.2 MiB)
[2025-07-11T14:08:52.140+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:52.140+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[44] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:08:52.140+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSchedulerImpl: Adding task set 19.0 with 2 tasks resource profile 0
[2025-07-11T14:08:52.141+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: Registering RDD 48 (collect at StringIndexer.scala:204) as input to shuffle 7
[2025-07-11T14:08:52.141+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: Got map stage job 13 (collect at StringIndexer.scala:204) with 13 output partitions
[2025-07-11T14:08:52.141+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: Final stage: ShuffleMapStage 20 (collect at StringIndexer.scala:204)
[2025-07-11T14:08:52.141+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:08:52.141+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 38) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:08:52.141+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:52.141+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 39) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:08:52.142+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Running task 0.0 in stage 19.0 (TID 38)
[2025-07-11T14:08:52.142+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[48] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:08:52.144+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Running task 1.0 in stage 19.0 (TID 39)
[2025-07-11T14:08:52.147+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 18.2 KiB, free 429.5 MiB)
[2025-07-11T14:08:52.148+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 429.5 MiB)
[2025-07-11T14:08:52.148+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 138.4.31.23:43033 (size: 9.0 KiB, free: 434.2 MiB)
[2025-07-11T14:08:52.149+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:52.149+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[48] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-11T14:08:52.149+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSchedulerImpl: Adding task set 20.0 with 13 tasks resource profile 0
[2025-07-11T14:08:52.151+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 40) (138.4.31.23, executor driver, partition 0, ANY, 16719 bytes)
[2025-07-11T14:08:52.151+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 41) (138.4.31.23, executor driver, partition 1, ANY, 16839 bytes)
[2025-07-11T14:08:52.151+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Running task 0.0 in stage 20.0 (TID 40)
[2025-07-11T14:08:52.152+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO CodeGenerator: Code generated in 6.68412 ms
[2025-07-11T14:08:52.153+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Running task 1.0 in stage 20.0 (TID 41)
[2025-07-11T14:08:52.155+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:08:52.155+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:08:52.234+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Finished task 1.0 in stage 20.0 (TID 41). 2031 bytes result sent to driver
[2025-07-11T14:08:52.235+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 42) (138.4.31.23, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-11T14:08:52.236+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 41) in 85 ms on 138.4.31.23 (executor driver) (1/13)
[2025-07-11T14:08:52.237+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Running task 2.0 in stage 20.0 (TID 42)
[2025-07-11T14:08:52.272+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Finished task 0.0 in stage 20.0 (TID 40). 2031 bytes result sent to driver
[2025-07-11T14:08:52.274+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 43) (138.4.31.23, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-11T14:08:52.275+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 40) in 125 ms on 138.4.31.23 (executor driver) (2/13)
[2025-07-11T14:08:52.277+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Running task 3.0 in stage 20.0 (TID 43)
[2025-07-11T14:08:52.302+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Finished task 2.0 in stage 20.0 (TID 42). 1945 bytes result sent to driver
[2025-07-11T14:08:52.304+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Starting task 4.0 in stage 20.0 (TID 44) (138.4.31.23, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-11T14:08:52.304+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Running task 4.0 in stage 20.0 (TID 44)
[2025-07-11T14:08:52.304+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 42) in 69 ms on 138.4.31.23 (executor driver) (3/13)
[2025-07-11T14:08:52.348+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Finished task 3.0 in stage 20.0 (TID 43). 1945 bytes result sent to driver
[2025-07-11T14:08:52.350+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Starting task 5.0 in stage 20.0 (TID 45) (138.4.31.23, executor driver, partition 5, ANY, 16719 bytes)
[2025-07-11T14:08:52.350+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 43) in 76 ms on 138.4.31.23 (executor driver) (4/13)
[2025-07-11T14:08:52.350+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Running task 5.0 in stage 20.0 (TID 45)
[2025-07-11T14:08:52.420+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Finished task 4.0 in stage 20.0 (TID 44). 1945 bytes result sent to driver
[2025-07-11T14:08:52.422+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Starting task 6.0 in stage 20.0 (TID 46) (138.4.31.23, executor driver, partition 6, ANY, 16719 bytes)
[2025-07-11T14:08:52.422+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Finished task 4.0 in stage 20.0 (TID 44) in 119 ms on 138.4.31.23 (executor driver) (5/13)
[2025-07-11T14:08:52.424+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Running task 6.0 in stage 20.0 (TID 46)
[2025-07-11T14:08:52.457+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Finished task 5.0 in stage 20.0 (TID 45). 1988 bytes result sent to driver
[2025-07-11T14:08:52.458+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Starting task 7.0 in stage 20.0 (TID 47) (138.4.31.23, executor driver, partition 7, ANY, 16839 bytes)
[2025-07-11T14:08:52.459+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Finished task 5.0 in stage 20.0 (TID 45) in 110 ms on 138.4.31.23 (executor driver) (6/13)
[2025-07-11T14:08:52.459+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Running task 7.0 in stage 20.0 (TID 47)
[2025-07-11T14:08:52.466+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 138.4.31.23:43033 in memory (size: 89.0 KiB, free: 434.3 MiB)
[2025-07-11T14:08:52.521+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Finished task 6.0 in stage 20.0 (TID 46). 1945 bytes result sent to driver
[2025-07-11T14:08:52.522+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Starting task 8.0 in stage 20.0 (TID 48) (138.4.31.23, executor driver, partition 8, ANY, 16715 bytes)
[2025-07-11T14:08:52.523+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Finished task 6.0 in stage 20.0 (TID 46) in 102 ms on 138.4.31.23 (executor driver) (7/13)
[2025-07-11T14:08:52.524+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Running task 8.0 in stage 20.0 (TID 48)
[2025-07-11T14:08:52.549+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 138.4.31.23:43033 in memory (size: 8.3 KiB, free: 434.3 MiB)
[2025-07-11T14:08:52.647+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 138.4.31.23:43033 in memory (size: 38.9 KiB, free: 434.3 MiB)
[2025-07-11T14:08:52.656+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Finished task 8.0 in stage 20.0 (TID 48). 2031 bytes result sent to driver
[2025-07-11T14:08:52.657+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Starting task 9.0 in stage 20.0 (TID 49) (138.4.31.23, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-11T14:08:52.663+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Finished task 8.0 in stage 20.0 (TID 48) in 140 ms on 138.4.31.23 (executor driver) (8/13)
[2025-07-11T14:08:52.664+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Running task 9.0 in stage 20.0 (TID 49)
[2025-07-11T14:08:52.677+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Finished task 7.0 in stage 20.0 (TID 47). 2031 bytes result sent to driver
[2025-07-11T14:08:52.679+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Starting task 10.0 in stage 20.0 (TID 50) (138.4.31.23, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-11T14:08:52.679+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Running task 10.0 in stage 20.0 (TID 50)
[2025-07-11T14:08:52.680+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Finished task 7.0 in stage 20.0 (TID 47) in 222 ms on 138.4.31.23 (executor driver) (9/13)
[2025-07-11T14:08:52.792+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Finished task 9.0 in stage 20.0 (TID 49). 1945 bytes result sent to driver
[2025-07-11T14:08:52.795+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Starting task 11.0 in stage 20.0 (TID 51) (138.4.31.23, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-11T14:08:52.795+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Running task 11.0 in stage 20.0 (TID 51)
[2025-07-11T14:08:52.797+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Finished task 9.0 in stage 20.0 (TID 49) in 140 ms on 138.4.31.23 (executor driver) (10/13)
[2025-07-11T14:08:52.832+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Finished task 10.0 in stage 20.0 (TID 50). 1945 bytes result sent to driver
[2025-07-11T14:08:52.833+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Starting task 12.0 in stage 20.0 (TID 52) (138.4.31.23, executor driver, partition 12, ANY, 16839 bytes)
[2025-07-11T14:08:52.834+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Running task 12.0 in stage 20.0 (TID 52)
[2025-07-11T14:08:52.834+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Finished task 10.0 in stage 20.0 (TID 50) in 155 ms on 138.4.31.23 (executor driver) (11/13)
[2025-07-11T14:08:52.870+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Finished task 11.0 in stage 20.0 (TID 51). 1945 bytes result sent to driver
[2025-07-11T14:08:52.871+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Finished task 11.0 in stage 20.0 (TID 51) in 77 ms on 138.4.31.23 (executor driver) (12/13)
[2025-07-11T14:08:52.884+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Finished task 12.0 in stage 20.0 (TID 52). 1945 bytes result sent to driver
[2025-07-11T14:08:52.886+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Finished task 12.0 in stage 20.0 (TID 52) in 53 ms on 138.4.31.23 (executor driver) (13/13)
[2025-07-11T14:08:52.886+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool
[2025-07-11T14:08:52.888+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: ShuffleMapStage 20 (collect at StringIndexer.scala:204) finished in 0,743 s
[2025-07-11T14:08:52.888+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:08:52.888+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: running: Set(ShuffleMapStage 19)
[2025-07-11T14:08:52.888+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:08:52.888+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: failed: Set()
[2025-07-11T14:08:52.900+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:08:52.934+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:08:52.935+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: Got job 14 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-11T14:08:52.935+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: Final stage: ResultStage 22 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-11T14:08:52.935+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
[2025-07-11T14:08:52.935+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:52.935+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[50] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-11T14:08:52.937+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 8.2 KiB, free 434.1 MiB)
[2025-07-11T14:08:52.938+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 434.1 MiB)
[2025-07-11T14:08:52.938+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 138.4.31.23:43033 (size: 4.2 KiB, free: 434.3 MiB)
[2025-07-11T14:08:52.939+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:52.940+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[50] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:08:52.940+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
[2025-07-11T14:08:52.941+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 53) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-11T14:08:52.943+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Running task 0.0 in stage 22.0 (TID 53)
[2025-07-11T14:08:52.947+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO ShuffleBlockFetcherIterator: Getting 13 (200.0 KiB) non-empty blocks including 13 (200.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:08:52.948+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-11T14:08:52.970+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO Executor: Finished task 0.0 in stage 22.0 (TID 53). 40493 bytes result sent to driver
[2025-07-11T14:08:52.971+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 53) in 31 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:08:52.971+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool
[2025-07-11T14:08:52.975+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: ResultStage 22 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,035 s
[2025-07-11T14:08:52.975+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:08:52.975+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
[2025-07-11T14:08:52.975+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO DAGScheduler: Job 14 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,037636 s
[2025-07-11T14:08:52.985+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 4.3 MiB, free 429.8 MiB)
[2025-07-11T14:08:52.990+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 89.5 KiB, free 429.8 MiB)
[2025-07-11T14:08:52.991+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 138.4.31.23:43033 (size: 89.5 KiB, free: 434.3 MiB)
[2025-07-11T14:08:52.991+0200] {subprocess.py:93} INFO - 25/07/11 14:08:52 INFO SparkContext: Created broadcast 19 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:08:53.154+0200] {subprocess.py:93} INFO - 25/07/11 14:08:53 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 138.4.31.23:43033 in memory (size: 4.2 KiB, free: 434.3 MiB)
[2025-07-11T14:08:53.544+0200] {subprocess.py:93} INFO - 25/07/11 14:08:53 INFO Executor: Finished task 1.0 in stage 19.0 (TID 39). 2074 bytes result sent to driver
[2025-07-11T14:08:53.546+0200] {subprocess.py:93} INFO - 25/07/11 14:08:53 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 39) in 1405 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:08:53.642+0200] {subprocess.py:93} INFO - 25/07/11 14:08:53 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 138.4.31.23:43033 in memory (size: 9.0 KiB, free: 434.3 MiB)
[2025-07-11T14:08:58.098+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO Executor: Finished task 0.0 in stage 19.0 (TID 38). 2031 bytes result sent to driver
[2025-07-11T14:08:58.099+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 38) in 5957 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:08:58.099+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool
[2025-07-11T14:08:58.099+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: ShuffleMapStage 19 (collect at StringIndexer.scala:204) finished in 5,963 s
[2025-07-11T14:08:58.099+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:08:58.099+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: running: Set()
[2025-07-11T14:08:58.099+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:08:58.099+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: failed: Set()
[2025-07-11T14:08:58.104+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO ShufflePartitionsUtil: For shuffle(6), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:08:58.122+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO CodeGenerator: Code generated in 6.241155 ms
[2025-07-11T14:08:58.126+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Registering RDD 54 (collect at StringIndexer.scala:204) as input to shuffle 8
[2025-07-11T14:08:58.126+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Got map stage job 15 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-11T14:08:58.126+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Final stage: ShuffleMapStage 24 (collect at StringIndexer.scala:204)
[2025-07-11T14:08:58.126+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
[2025-07-11T14:08:58.127+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:58.127+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[54] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:08:58.130+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 50.6 KiB, free 429.7 MiB)
[2025-07-11T14:08:58.130+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 24.1 KiB, free 429.7 MiB)
[2025-07-11T14:08:58.130+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 138.4.31.23:43033 (size: 24.1 KiB, free: 434.2 MiB)
[2025-07-11T14:08:58.131+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:58.131+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[54] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:08:58.131+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
[2025-07-11T14:08:58.132+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 54) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14833 bytes)
[2025-07-11T14:08:58.133+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO Executor: Running task 0.0 in stage 24.0 (TID 54)
[2025-07-11T14:08:58.138+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO ShuffleBlockFetcherIterator: Getting 2 (887.5 KiB) non-empty blocks including 2 (887.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:08:58.138+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:08:58.146+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO CodeGenerator: Code generated in 7.779383 ms
[2025-07-11T14:08:58.474+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO Executor: Finished task 0.0 in stage 24.0 (TID 54). 6543 bytes result sent to driver
[2025-07-11T14:08:58.474+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 54) in 342 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:08:58.474+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool
[2025-07-11T14:08:58.475+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: ShuffleMapStage 24 (collect at StringIndexer.scala:204) finished in 0,348 s
[2025-07-11T14:08:58.475+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:08:58.475+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: running: Set()
[2025-07-11T14:08:58.475+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:08:58.476+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: failed: Set()
[2025-07-11T14:08:58.493+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
[2025-07-11T14:08:58.494+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Got job 16 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-11T14:08:58.494+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Final stage: ResultStage 27 (collect at StringIndexer.scala:204)
[2025-07-11T14:08:58.494+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
[2025-07-11T14:08:58.494+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:58.495+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[57] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:08:58.497+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 49.7 KiB, free 429.7 MiB)
[2025-07-11T14:08:58.497+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 429.6 MiB)
[2025-07-11T14:08:58.498+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 138.4.31.23:43033 (size: 23.6 KiB, free: 434.2 MiB)
[2025-07-11T14:08:58.498+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:58.499+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[57] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:08:58.499+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
[2025-07-11T14:08:58.500+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 55) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:08:58.501+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO Executor: Running task 0.0 in stage 27.0 (TID 55)
[2025-07-11T14:08:58.505+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO ShuffleBlockFetcherIterator: Getting 1 (3.2 KiB) non-empty blocks including 1 (3.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:08:58.505+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:08:58.523+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO Executor: Finished task 0.0 in stage 27.0 (TID 55). 10936 bytes result sent to driver
[2025-07-11T14:08:58.524+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 55) in 24 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:08:58.524+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool
[2025-07-11T14:08:58.524+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: ResultStage 27 (collect at StringIndexer.scala:204) finished in 0,030 s
[2025-07-11T14:08:58.525+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:08:58.525+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
[2025-07-11T14:08:58.525+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Job 16 finished: collect at StringIndexer.scala:204, took 0,031997 s
[2025-07-11T14:08:58.575+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO FileSystemOverwrite: Path /home/monica.fernandez/practica_creativa/models/string_indexer_model_Origin.bin already exists. It will be overwritten.
[2025-07-11T14:08:58.591+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:08:58.591+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:08:58.592+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:08:58.622+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-11T14:08:58.622+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Got job 17 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-11T14:08:58.622+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Final stage: ResultStage 28 (runJob at SparkHadoopWriter.scala:83)
[2025-07-11T14:08:58.622+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:08:58.622+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:58.622+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[59] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-11T14:08:58.631+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 101.3 KiB, free 429.5 MiB)
[2025-07-11T14:08:58.632+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 429.5 MiB)
[2025-07-11T14:08:58.633+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 138.4.31.23:43033 (size: 36.5 KiB, free: 434.2 MiB)
[2025-07-11T14:08:58.633+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:58.634+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[59] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:08:58.634+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
[2025-07-11T14:08:58.637+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 56) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15156 bytes)
[2025-07-11T14:08:58.637+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO Executor: Running task 0.0 in stage 28.0 (TID 56)
[2025-07-11T14:08:58.641+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:08:58.641+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:08:58.641+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:08:58.669+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO FileOutputCommitter: Saved output of task 'attempt_202507111408588233354787003223663_0059_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Origin.bin/metadata/_temporary/0/task_202507111408588233354787003223663_0059_m_000000
[2025-07-11T14:08:58.669+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO SparkHadoopMapRedUtil: attempt_202507111408588233354787003223663_0059_m_000000_0: Committed. Elapsed time: 2 ms.
[2025-07-11T14:08:58.670+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO Executor: Finished task 0.0 in stage 28.0 (TID 56). 1170 bytes result sent to driver
[2025-07-11T14:08:58.671+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 56) in 37 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:08:58.671+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool
[2025-07-11T14:08:58.671+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: ResultStage 28 (runJob at SparkHadoopWriter.scala:83) finished in 0,048 s
[2025-07-11T14:08:58.672+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:08:58.672+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
[2025-07-11T14:08:58.672+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Job 17 finished: runJob at SparkHadoopWriter.scala:83, took 0,050061 s
[2025-07-11T14:08:58.672+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO SparkHadoopWriter: Start to commit write Job job_202507111408588233354787003223663_0059.
[2025-07-11T14:08:58.697+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO SparkHadoopWriter: Write Job job_202507111408588233354787003223663_0059 committed. Elapsed time: 23 ms.
[2025-07-11T14:08:58.752+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Registering RDD 62 (parquet at StringIndexer.scala:499) as input to shuffle 9
[2025-07-11T14:08:58.755+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Got map stage job 18 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-11T14:08:58.755+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Final stage: ShuffleMapStage 29 (parquet at StringIndexer.scala:499)
[2025-07-11T14:08:58.755+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:08:58.755+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:58.756+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[62] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-11T14:08:58.756+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 8.1 KiB, free 429.5 MiB)
[2025-07-11T14:08:58.775+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 429.5 MiB)
[2025-07-11T14:08:58.775+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 138.4.31.23:43033 (size: 4.4 KiB, free: 434.2 MiB)
[2025-07-11T14:08:58.775+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:58.781+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[62] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:08:58.781+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
[2025-07-11T14:08:58.781+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 57) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 20076 bytes)
[2025-07-11T14:08:58.781+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO Executor: Running task 0.0 in stage 29.0 (TID 57)
[2025-07-11T14:08:58.784+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO Executor: Finished task 0.0 in stage 29.0 (TID 57). 1628 bytes result sent to driver
[2025-07-11T14:08:58.785+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 57) in 7 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:08:58.787+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool
[2025-07-11T14:08:58.787+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: ShuffleMapStage 29 (parquet at StringIndexer.scala:499) finished in 0,038 s
[2025-07-11T14:08:58.787+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:08:58.787+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: running: Set()
[2025-07-11T14:08:58.787+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:08:58.787+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: failed: Set()
[2025-07-11T14:08:58.791+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 138.4.31.23:43033 in memory (size: 24.1 KiB, free: 434.2 MiB)
[2025-07-11T14:08:58.800+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 138.4.31.23:43033 in memory (size: 36.5 KiB, free: 434.2 MiB)
[2025-07-11T14:08:58.807+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:08:58.812+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:08:58.812+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:08:58.812+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:08:58.813+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:08:58.813+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:08:58.813+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:08:58.822+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 138.4.31.23:43033 in memory (size: 23.6 KiB, free: 434.3 MiB)
[2025-07-11T14:08:58.839+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO SparkContext: Starting job: parquet at StringIndexer.scala:499
[2025-07-11T14:08:58.840+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Got job 19 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-11T14:08:58.840+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Final stage: ResultStage 31 (parquet at StringIndexer.scala:499)
[2025-07-11T14:08:58.840+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)
[2025-07-11T14:08:58.840+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:58.840+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[64] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-11T14:08:58.856+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 239.5 KiB, free 429.5 MiB)
[2025-07-11T14:08:58.861+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 83.6 KiB, free 429.5 MiB)
[2025-07-11T14:08:58.862+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 138.4.31.23:43033 (size: 83.6 KiB, free: 434.2 MiB)
[2025-07-11T14:08:58.862+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:58.863+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[64] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:08:58.863+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
[2025-07-11T14:08:58.863+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 138.4.31.23:43033 in memory (size: 4.4 KiB, free: 434.2 MiB)
[2025-07-11T14:08:58.865+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 58) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:08:58.866+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO Executor: Running task 0.0 in stage 31.0 (TID 58)
[2025-07-11T14:08:58.889+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:08:58.889+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:08:58.890+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:08:58.890+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:08:58.891+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:08:58.891+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:08:58.891+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:08:58.891+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:08:58.891+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:08:58.891+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:08:58.892+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-11T14:08:58.893+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-11T14:08:58.893+0200] {subprocess.py:93} INFO - {
[2025-07-11T14:08:58.893+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-11T14:08:58.893+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-11T14:08:58.893+0200] {subprocess.py:93} INFO -     "name" : "labelsArray",
[2025-07-11T14:08:58.893+0200] {subprocess.py:93} INFO -     "type" : {
[2025-07-11T14:08:58.893+0200] {subprocess.py:93} INFO -       "type" : "array",
[2025-07-11T14:08:58.893+0200] {subprocess.py:93} INFO -       "elementType" : {
[2025-07-11T14:08:58.893+0200] {subprocess.py:93} INFO -         "type" : "array",
[2025-07-11T14:08:58.893+0200] {subprocess.py:93} INFO -         "elementType" : "string",
[2025-07-11T14:08:58.894+0200] {subprocess.py:93} INFO -         "containsNull" : true
[2025-07-11T14:08:58.894+0200] {subprocess.py:93} INFO -       },
[2025-07-11T14:08:58.894+0200] {subprocess.py:93} INFO -       "containsNull" : true
[2025-07-11T14:08:58.894+0200] {subprocess.py:93} INFO -     },
[2025-07-11T14:08:58.894+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-11T14:08:58.894+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:08:58.894+0200] {subprocess.py:93} INFO -   } ]
[2025-07-11T14:08:58.894+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:08:58.894+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-11T14:08:58.895+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-11T14:08:58.895+0200] {subprocess.py:93} INFO -   optional group labelsArray (LIST) {
[2025-07-11T14:08:58.895+0200] {subprocess.py:93} INFO -     repeated group list {
[2025-07-11T14:08:58.895+0200] {subprocess.py:93} INFO -       optional group element (LIST) {
[2025-07-11T14:08:58.895+0200] {subprocess.py:93} INFO -         repeated group list {
[2025-07-11T14:08:58.895+0200] {subprocess.py:93} INFO -           optional binary element (STRING);
[2025-07-11T14:08:58.895+0200] {subprocess.py:93} INFO -         }
[2025-07-11T14:08:58.895+0200] {subprocess.py:93} INFO -       }
[2025-07-11T14:08:58.895+0200] {subprocess.py:93} INFO -     }
[2025-07-11T14:08:58.895+0200] {subprocess.py:93} INFO -   }
[2025-07-11T14:08:58.895+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:08:58.895+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:08:58.895+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:08:58.958+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO FileOutputCommitter: Saved output of task 'attempt_202507111408581986352864121350298_0031_m_000000_58' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Origin.bin/data/_temporary/0/task_202507111408581986352864121350298_0031_m_000000
[2025-07-11T14:08:58.958+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO SparkHadoopMapRedUtil: attempt_202507111408581986352864121350298_0031_m_000000_58: Committed. Elapsed time: 3 ms.
[2025-07-11T14:08:58.974+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO Executor: Finished task 0.0 in stage 31.0 (TID 58). 4740 bytes result sent to driver
[2025-07-11T14:08:58.975+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 138.4.31.23:43033 in memory (size: 8.2 KiB, free: 434.2 MiB)
[2025-07-11T14:08:58.976+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 58) in 112 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:08:58.976+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool
[2025-07-11T14:08:58.977+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: ResultStage 31 (parquet at StringIndexer.scala:499) finished in 0,136 s
[2025-07-11T14:08:58.978+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:08:58.978+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
[2025-07-11T14:08:58.978+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO DAGScheduler: Job 19 finished: parquet at StringIndexer.scala:499, took 0,137820 s
[2025-07-11T14:08:58.978+0200] {subprocess.py:93} INFO - 25/07/11 14:08:58 INFO FileFormatWriter: Start to commit write Job 481258af-718e-4299-a088-9331f4d674b4.
[2025-07-11T14:08:59.004+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO FileFormatWriter: Write Job 481258af-718e-4299-a088-9331f4d674b4 committed. Elapsed time: 26 ms.
[2025-07-11T14:08:59.004+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO FileFormatWriter: Finished processing stats for write job 481258af-718e-4299-a088-9331f4d674b4.
[2025-07-11T14:08:59.062+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO V2ScanRelationPushDown:
[2025-07-11T14:08:59.062+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:08:59.062+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:08:59.062+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:08:59.062+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:08:59.069+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO V2ScanRelationPushDown:
[2025-07-11T14:08:59.069+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68
[2025-07-11T14:08:59.069+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:08:59.085+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:08:59.085+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:08:59.110+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 214.5 KiB, free 429.3 MiB)
[2025-07-11T14:08:59.118+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 429.3 MiB)
[2025-07-11T14:08:59.119+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 138.4.31.23:43033 (size: 38.9 KiB, free: 434.2 MiB)
[2025-07-11T14:08:59.120+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO SparkContext: Created broadcast 25 from collect at StringIndexer.scala:204
[2025-07-11T14:08:59.120+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:08:59.128+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: Registering RDD 68 (collect at StringIndexer.scala:204) as input to shuffle 10
[2025-07-11T14:08:59.128+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: Got map stage job 20 (collect at StringIndexer.scala:204) with 2 output partitions
[2025-07-11T14:08:59.128+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: Final stage: ShuffleMapStage 32 (collect at StringIndexer.scala:204)
[2025-07-11T14:08:59.129+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:08:59.129+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:59.129+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[68] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:08:59.129+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 16.9 KiB, free 429.2 MiB)
[2025-07-11T14:08:59.130+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 429.2 MiB)
[2025-07-11T14:08:59.131+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 138.4.31.23:43033 (size: 8.2 KiB, free: 434.1 MiB)
[2025-07-11T14:08:59.131+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:59.132+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[68] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:08:59.132+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSchedulerImpl: Adding task set 32.0 with 2 tasks resource profile 0
[2025-07-11T14:08:59.132+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: Registering RDD 72 (collect at StringIndexer.scala:204) as input to shuffle 11
[2025-07-11T14:08:59.133+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: Got map stage job 21 (collect at StringIndexer.scala:204) with 13 output partitions
[2025-07-11T14:08:59.133+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: Final stage: ShuffleMapStage 33 (collect at StringIndexer.scala:204)
[2025-07-11T14:08:59.133+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:08:59.133+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:59.133+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[72] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:08:59.134+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 59) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:08:59.134+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 60) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:08:59.134+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Running task 1.0 in stage 32.0 (TID 60)
[2025-07-11T14:08:59.134+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Running task 0.0 in stage 32.0 (TID 59)
[2025-07-11T14:08:59.135+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 18.2 KiB, free 429.2 MiB)
[2025-07-11T14:08:59.136+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 429.2 MiB)
[2025-07-11T14:08:59.137+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 138.4.31.23:43033 (size: 9.1 KiB, free: 434.1 MiB)
[2025-07-11T14:08:59.137+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:59.138+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[72] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-11T14:08:59.138+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSchedulerImpl: Adding task set 33.0 with 13 tasks resource profile 0
[2025-07-11T14:08:59.140+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:08:59.140+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 61) (138.4.31.23, executor driver, partition 0, ANY, 16839 bytes)
[2025-07-11T14:08:59.140+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 62) (138.4.31.23, executor driver, partition 1, ANY, 16719 bytes)
[2025-07-11T14:08:59.140+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Running task 0.0 in stage 33.0 (TID 61)
[2025-07-11T14:08:59.140+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Running task 1.0 in stage 33.0 (TID 62)
[2025-07-11T14:08:59.150+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:08:59.204+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Finished task 0.0 in stage 33.0 (TID 61). 1945 bytes result sent to driver
[2025-07-11T14:08:59.205+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 63) (138.4.31.23, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-11T14:08:59.205+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Running task 2.0 in stage 33.0 (TID 63)
[2025-07-11T14:08:59.205+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 61) in 66 ms on 138.4.31.23 (executor driver) (1/13)
[2025-07-11T14:08:59.213+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Finished task 1.0 in stage 33.0 (TID 62). 1945 bytes result sent to driver
[2025-07-11T14:08:59.213+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Starting task 3.0 in stage 33.0 (TID 64) (138.4.31.23, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-11T14:08:59.214+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 62) in 75 ms on 138.4.31.23 (executor driver) (2/13)
[2025-07-11T14:08:59.214+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Running task 3.0 in stage 33.0 (TID 64)
[2025-07-11T14:08:59.287+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Finished task 3.0 in stage 33.0 (TID 64). 1988 bytes result sent to driver
[2025-07-11T14:08:59.289+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Starting task 4.0 in stage 33.0 (TID 65) (138.4.31.23, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-11T14:08:59.289+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Finished task 3.0 in stage 33.0 (TID 64) in 76 ms on 138.4.31.23 (executor driver) (3/13)
[2025-07-11T14:08:59.292+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Running task 4.0 in stage 33.0 (TID 65)
[2025-07-11T14:08:59.307+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Finished task 2.0 in stage 33.0 (TID 63). 1945 bytes result sent to driver
[2025-07-11T14:08:59.309+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Starting task 5.0 in stage 33.0 (TID 66) (138.4.31.23, executor driver, partition 5, ANY, 16839 bytes)
[2025-07-11T14:08:59.309+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Running task 5.0 in stage 33.0 (TID 66)
[2025-07-11T14:08:59.310+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 63) in 106 ms on 138.4.31.23 (executor driver) (4/13)
[2025-07-11T14:08:59.386+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Finished task 5.0 in stage 33.0 (TID 66). 1945 bytes result sent to driver
[2025-07-11T14:08:59.388+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Finished task 4.0 in stage 33.0 (TID 65). 1945 bytes result sent to driver
[2025-07-11T14:08:59.388+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Starting task 6.0 in stage 33.0 (TID 67) (138.4.31.23, executor driver, partition 6, ANY, 16839 bytes)
[2025-07-11T14:08:59.388+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Running task 6.0 in stage 33.0 (TID 67)
[2025-07-11T14:08:59.390+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Starting task 7.0 in stage 33.0 (TID 68) (138.4.31.23, executor driver, partition 7, ANY, 16715 bytes)
[2025-07-11T14:08:59.391+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Running task 7.0 in stage 33.0 (TID 68)
[2025-07-11T14:08:59.391+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Finished task 4.0 in stage 33.0 (TID 65) in 103 ms on 138.4.31.23 (executor driver) (5/13)
[2025-07-11T14:08:59.391+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Finished task 5.0 in stage 33.0 (TID 66) in 83 ms on 138.4.31.23 (executor driver) (6/13)
[2025-07-11T14:08:59.480+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 138.4.31.23:43033 in memory (size: 83.6 KiB, free: 434.2 MiB)
[2025-07-11T14:08:59.503+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Finished task 7.0 in stage 33.0 (TID 68). 1988 bytes result sent to driver
[2025-07-11T14:08:59.504+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Starting task 8.0 in stage 33.0 (TID 69) (138.4.31.23, executor driver, partition 8, ANY, 16719 bytes)
[2025-07-11T14:08:59.505+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Finished task 7.0 in stage 33.0 (TID 68) in 117 ms on 138.4.31.23 (executor driver) (7/13)
[2025-07-11T14:08:59.507+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Running task 8.0 in stage 33.0 (TID 69)
[2025-07-11T14:08:59.529+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Finished task 6.0 in stage 33.0 (TID 67). 2031 bytes result sent to driver
[2025-07-11T14:08:59.530+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Starting task 9.0 in stage 33.0 (TID 70) (138.4.31.23, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-11T14:08:59.530+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Running task 9.0 in stage 33.0 (TID 70)
[2025-07-11T14:08:59.531+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Finished task 6.0 in stage 33.0 (TID 67) in 143 ms on 138.4.31.23 (executor driver) (8/13)
[2025-07-11T14:08:59.601+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Finished task 8.0 in stage 33.0 (TID 69). 1945 bytes result sent to driver
[2025-07-11T14:08:59.603+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Starting task 10.0 in stage 33.0 (TID 71) (138.4.31.23, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-11T14:08:59.605+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Finished task 8.0 in stage 33.0 (TID 69) in 99 ms on 138.4.31.23 (executor driver) (9/13)
[2025-07-11T14:08:59.605+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Running task 10.0 in stage 33.0 (TID 71)
[2025-07-11T14:08:59.640+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Finished task 9.0 in stage 33.0 (TID 70). 1945 bytes result sent to driver
[2025-07-11T14:08:59.641+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Starting task 11.0 in stage 33.0 (TID 72) (138.4.31.23, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-11T14:08:59.641+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Running task 11.0 in stage 33.0 (TID 72)
[2025-07-11T14:08:59.642+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Finished task 9.0 in stage 33.0 (TID 70) in 111 ms on 138.4.31.23 (executor driver) (10/13)
[2025-07-11T14:08:59.685+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Finished task 10.0 in stage 33.0 (TID 71). 1988 bytes result sent to driver
[2025-07-11T14:08:59.687+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Starting task 12.0 in stage 33.0 (TID 73) (138.4.31.23, executor driver, partition 12, ANY, 16719 bytes)
[2025-07-11T14:08:59.688+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Running task 12.0 in stage 33.0 (TID 73)
[2025-07-11T14:08:59.688+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Finished task 10.0 in stage 33.0 (TID 71) in 85 ms on 138.4.31.23 (executor driver) (11/13)
[2025-07-11T14:08:59.711+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Finished task 11.0 in stage 33.0 (TID 72). 1945 bytes result sent to driver
[2025-07-11T14:08:59.712+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Finished task 11.0 in stage 33.0 (TID 72) in 71 ms on 138.4.31.23 (executor driver) (12/13)
[2025-07-11T14:08:59.728+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Finished task 12.0 in stage 33.0 (TID 73). 1945 bytes result sent to driver
[2025-07-11T14:08:59.730+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Finished task 12.0 in stage 33.0 (TID 73) in 43 ms on 138.4.31.23 (executor driver) (13/13)
[2025-07-11T14:08:59.730+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool
[2025-07-11T14:08:59.730+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: ShuffleMapStage 33 (collect at StringIndexer.scala:204) finished in 0,595 s
[2025-07-11T14:08:59.730+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:08:59.730+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: running: Set(ShuffleMapStage 32)
[2025-07-11T14:08:59.730+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:08:59.730+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: failed: Set()
[2025-07-11T14:08:59.741+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO ShufflePartitionsUtil: For shuffle(11), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:08:59.764+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:08:59.766+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: Got job 22 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-11T14:08:59.766+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: Final stage: ResultStage 35 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-11T14:08:59.766+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
[2025-07-11T14:08:59.766+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:08:59.768+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[74] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-11T14:08:59.769+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 8.2 KiB, free 429.5 MiB)
[2025-07-11T14:08:59.801+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 429.5 MiB)
[2025-07-11T14:08:59.801+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 138.4.31.23:43033 (size: 4.2 KiB, free: 434.2 MiB)
[2025-07-11T14:08:59.801+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:08:59.801+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[74] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:08:59.802+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0
[2025-07-11T14:08:59.802+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 74) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-11T14:08:59.802+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Running task 0.0 in stage 35.0 (TID 74)
[2025-07-11T14:08:59.817+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO ShuffleBlockFetcherIterator: Getting 13 (200.0 KiB) non-empty blocks including 13 (200.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:08:59.817+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
[2025-07-11T14:08:59.837+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO Executor: Finished task 0.0 in stage 35.0 (TID 74). 40669 bytes result sent to driver
[2025-07-11T14:08:59.838+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 74) in 52 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:08:59.840+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool
[2025-07-11T14:08:59.840+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: ResultStage 35 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,073 s
[2025-07-11T14:08:59.841+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:08:59.841+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
[2025-07-11T14:08:59.841+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO DAGScheduler: Job 22 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,075778 s
[2025-07-11T14:08:59.849+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 4.3 MiB, free 425.3 MiB)
[2025-07-11T14:08:59.856+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 138.4.31.23:43033 in memory (size: 4.2 KiB, free: 434.2 MiB)
[2025-07-11T14:08:59.861+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 89.5 KiB, free 425.2 MiB)
[2025-07-11T14:08:59.862+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 138.4.31.23:43033 (size: 89.5 KiB, free: 434.1 MiB)
[2025-07-11T14:08:59.862+0200] {subprocess.py:93} INFO - 25/07/11 14:08:59 INFO SparkContext: Created broadcast 29 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:09:00.363+0200] {subprocess.py:93} INFO - 25/07/11 14:09:00 INFO Executor: Finished task 1.0 in stage 32.0 (TID 60). 2074 bytes result sent to driver
[2025-07-11T14:09:00.364+0200] {subprocess.py:93} INFO - 25/07/11 14:09:00 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 60) in 1230 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:09:00.478+0200] {subprocess.py:93} INFO - 25/07/11 14:09:00 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 138.4.31.23:43033 in memory (size: 38.9 KiB, free: 434.2 MiB)
[2025-07-11T14:09:00.488+0200] {subprocess.py:93} INFO - 25/07/11 14:09:00 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 138.4.31.23:43033 in memory (size: 89.5 KiB, free: 434.3 MiB)
[2025-07-11T14:09:00.495+0200] {subprocess.py:93} INFO - 25/07/11 14:09:00 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 138.4.31.23:43033 in memory (size: 9.1 KiB, free: 434.3 MiB)
[2025-07-11T14:09:04.881+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO Executor: Finished task 0.0 in stage 32.0 (TID 59). 2074 bytes result sent to driver
[2025-07-11T14:09:04.882+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 59) in 5749 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:09:04.882+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool
[2025-07-11T14:09:04.883+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO DAGScheduler: ShuffleMapStage 32 (collect at StringIndexer.scala:204) finished in 5,757 s
[2025-07-11T14:09:04.883+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:09:04.883+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO DAGScheduler: running: Set()
[2025-07-11T14:09:04.883+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:09:04.883+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO DAGScheduler: failed: Set()
[2025-07-11T14:09:04.887+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:09:04.904+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO CodeGenerator: Code generated in 6.457385 ms
[2025-07-11T14:09:04.908+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO DAGScheduler: Registering RDD 78 (collect at StringIndexer.scala:204) as input to shuffle 12
[2025-07-11T14:09:04.908+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO DAGScheduler: Got map stage job 23 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-11T14:09:04.908+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO DAGScheduler: Final stage: ShuffleMapStage 37 (collect at StringIndexer.scala:204)
[2025-07-11T14:09:04.908+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)
[2025-07-11T14:09:04.908+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:04.910+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[78] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:09:04.912+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 50.6 KiB, free 429.7 MiB)
[2025-07-11T14:09:04.912+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 24.1 KiB, free 429.7 MiB)
[2025-07-11T14:09:04.913+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 138.4.31.23:43033 (size: 24.1 KiB, free: 434.2 MiB)
[2025-07-11T14:09:04.913+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:04.914+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[78] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:09:04.914+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0
[2025-07-11T14:09:04.915+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 75) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14833 bytes)
[2025-07-11T14:09:04.915+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO Executor: Running task 0.0 in stage 37.0 (TID 75)
[2025-07-11T14:09:04.920+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO ShuffleBlockFetcherIterator: Getting 2 (887.5 KiB) non-empty blocks including 2 (887.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:04.920+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:04.927+0200] {subprocess.py:93} INFO - 25/07/11 14:09:04 INFO CodeGenerator: Code generated in 6.49526 ms
[2025-07-11T14:09:05.193+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO Executor: Finished task 0.0 in stage 37.0 (TID 75). 6500 bytes result sent to driver
[2025-07-11T14:09:05.196+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 75) in 280 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:09:05.196+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool
[2025-07-11T14:09:05.197+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: ShuffleMapStage 37 (collect at StringIndexer.scala:204) finished in 0,287 s
[2025-07-11T14:09:05.197+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:09:05.197+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: running: Set()
[2025-07-11T14:09:05.197+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:09:05.197+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: failed: Set()
[2025-07-11T14:09:05.218+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
[2025-07-11T14:09:05.219+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Got job 24 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-11T14:09:05.219+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Final stage: ResultStage 40 (collect at StringIndexer.scala:204)
[2025-07-11T14:09:05.219+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)
[2025-07-11T14:09:05.219+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:05.219+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[81] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:09:05.222+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 49.7 KiB, free 429.7 MiB)
[2025-07-11T14:09:05.225+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 429.6 MiB)
[2025-07-11T14:09:05.225+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 138.4.31.23:43033 (size: 23.6 KiB, free: 434.2 MiB)
[2025-07-11T14:09:05.225+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:05.226+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[81] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:09:05.226+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
[2025-07-11T14:09:05.227+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 76) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:09:05.228+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO Executor: Running task 0.0 in stage 40.0 (TID 76)
[2025-07-11T14:09:05.232+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO ShuffleBlockFetcherIterator: Getting 1 (3.2 KiB) non-empty blocks including 1 (3.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:05.232+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:05.249+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO Executor: Finished task 0.0 in stage 40.0 (TID 76). 10963 bytes result sent to driver
[2025-07-11T14:09:05.251+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 76) in 22 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:09:05.251+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool
[2025-07-11T14:09:05.251+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: ResultStage 40 (collect at StringIndexer.scala:204) finished in 0,030 s
[2025-07-11T14:09:05.251+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:09:05.251+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
[2025-07-11T14:09:05.251+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Job 24 finished: collect at StringIndexer.scala:204, took 0,031904 s
[2025-07-11T14:09:05.295+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileSystemOverwrite: Path /home/monica.fernandez/practica_creativa/models/string_indexer_model_Dest.bin already exists. It will be overwritten.
[2025-07-11T14:09:05.309+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:09:05.309+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:09:05.309+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:09:05.336+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-11T14:09:05.336+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Got job 25 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-11T14:09:05.337+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Final stage: ResultStage 41 (runJob at SparkHadoopWriter.scala:83)
[2025-07-11T14:09:05.337+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:09:05.337+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:05.337+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[83] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-11T14:09:05.344+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 101.3 KiB, free 429.5 MiB)
[2025-07-11T14:09:05.345+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 429.5 MiB)
[2025-07-11T14:09:05.345+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 138.4.31.23:43033 (size: 36.5 KiB, free: 434.2 MiB)
[2025-07-11T14:09:05.345+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:05.346+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[83] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:09:05.346+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
[2025-07-11T14:09:05.347+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 77) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15152 bytes)
[2025-07-11T14:09:05.347+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO Executor: Running task 0.0 in stage 41.0 (TID 77)
[2025-07-11T14:09:05.352+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:09:05.353+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:09:05.353+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:09:05.381+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileOutputCommitter: Saved output of task 'attempt_20250711140905967287267380708651_0083_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Dest.bin/metadata/_temporary/0/task_20250711140905967287267380708651_0083_m_000000
[2025-07-11T14:09:05.381+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO SparkHadoopMapRedUtil: attempt_20250711140905967287267380708651_0083_m_000000_0: Committed. Elapsed time: 1 ms.
[2025-07-11T14:09:05.382+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO Executor: Finished task 0.0 in stage 41.0 (TID 77). 1170 bytes result sent to driver
[2025-07-11T14:09:05.382+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 77) in 36 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:09:05.383+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool
[2025-07-11T14:09:05.383+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: ResultStage 41 (runJob at SparkHadoopWriter.scala:83) finished in 0,046 s
[2025-07-11T14:09:05.383+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:09:05.383+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished
[2025-07-11T14:09:05.384+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Job 25 finished: runJob at SparkHadoopWriter.scala:83, took 0,047170 s
[2025-07-11T14:09:05.384+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO SparkHadoopWriter: Start to commit write Job job_20250711140905967287267380708651_0083.
[2025-07-11T14:09:05.405+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO SparkHadoopWriter: Write Job job_20250711140905967287267380708651_0083 committed. Elapsed time: 20 ms.
[2025-07-11T14:09:05.457+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Registering RDD 86 (parquet at StringIndexer.scala:499) as input to shuffle 13
[2025-07-11T14:09:05.457+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Got map stage job 26 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-11T14:09:05.457+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Final stage: ShuffleMapStage 42 (parquet at StringIndexer.scala:499)
[2025-07-11T14:09:05.457+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:09:05.457+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:05.460+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[86] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-11T14:09:05.461+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 8.1 KiB, free 429.5 MiB)
[2025-07-11T14:09:05.461+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 429.5 MiB)
[2025-07-11T14:09:05.461+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 138.4.31.23:43033 (size: 4.4 KiB, free: 434.2 MiB)
[2025-07-11T14:09:05.461+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:05.461+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[86] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:09:05.462+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
[2025-07-11T14:09:05.462+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 78) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 20076 bytes)
[2025-07-11T14:09:05.463+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO Executor: Running task 0.0 in stage 42.0 (TID 78)
[2025-07-11T14:09:05.466+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO Executor: Finished task 0.0 in stage 42.0 (TID 78). 1628 bytes result sent to driver
[2025-07-11T14:09:05.472+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 78) in 9 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:09:05.472+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool
[2025-07-11T14:09:05.473+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: ShuffleMapStage 42 (parquet at StringIndexer.scala:499) finished in 0,014 s
[2025-07-11T14:09:05.473+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:09:05.473+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: running: Set()
[2025-07-11T14:09:05.473+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:09:05.474+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: failed: Set()
[2025-07-11T14:09:05.480+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:09:05.481+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:09:05.481+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:09:05.481+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:09:05.481+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:09:05.481+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:09:05.482+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:09:05.513+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO SparkContext: Starting job: parquet at StringIndexer.scala:499
[2025-07-11T14:09:05.515+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Got job 27 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-11T14:09:05.515+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Final stage: ResultStage 44 (parquet at StringIndexer.scala:499)
[2025-07-11T14:09:05.515+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
[2025-07-11T14:09:05.515+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:05.516+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[88] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-11T14:09:05.541+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 239.5 KiB, free 429.3 MiB)
[2025-07-11T14:09:05.541+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 83.7 KiB, free 429.2 MiB)
[2025-07-11T14:09:05.541+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 138.4.31.23:43033 (size: 83.7 KiB, free: 434.1 MiB)
[2025-07-11T14:09:05.541+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:05.541+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[88] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:09:05.541+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
[2025-07-11T14:09:05.541+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 79) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:09:05.541+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO Executor: Running task 0.0 in stage 44.0 (TID 79)
[2025-07-11T14:09:05.545+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:05.545+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:05.546+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:09:05.546+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:09:05.546+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:09:05.546+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:09:05.546+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:09:05.546+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:09:05.546+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:09:05.547+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:09:05.548+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-11T14:09:05.549+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-11T14:09:05.549+0200] {subprocess.py:93} INFO - {
[2025-07-11T14:09:05.549+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-11T14:09:05.549+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-11T14:09:05.549+0200] {subprocess.py:93} INFO -     "name" : "labelsArray",
[2025-07-11T14:09:05.549+0200] {subprocess.py:93} INFO -     "type" : {
[2025-07-11T14:09:05.549+0200] {subprocess.py:93} INFO -       "type" : "array",
[2025-07-11T14:09:05.549+0200] {subprocess.py:93} INFO -       "elementType" : {
[2025-07-11T14:09:05.549+0200] {subprocess.py:93} INFO -         "type" : "array",
[2025-07-11T14:09:05.549+0200] {subprocess.py:93} INFO -         "elementType" : "string",
[2025-07-11T14:09:05.549+0200] {subprocess.py:93} INFO -         "containsNull" : true
[2025-07-11T14:09:05.549+0200] {subprocess.py:93} INFO -       },
[2025-07-11T14:09:05.549+0200] {subprocess.py:93} INFO -       "containsNull" : true
[2025-07-11T14:09:05.550+0200] {subprocess.py:93} INFO -     },
[2025-07-11T14:09:05.550+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-11T14:09:05.550+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:09:05.550+0200] {subprocess.py:93} INFO -   } ]
[2025-07-11T14:09:05.550+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:09:05.550+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-11T14:09:05.550+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-11T14:09:05.550+0200] {subprocess.py:93} INFO -   optional group labelsArray (LIST) {
[2025-07-11T14:09:05.550+0200] {subprocess.py:93} INFO -     repeated group list {
[2025-07-11T14:09:05.550+0200] {subprocess.py:93} INFO -       optional group element (LIST) {
[2025-07-11T14:09:05.550+0200] {subprocess.py:93} INFO -         repeated group list {
[2025-07-11T14:09:05.550+0200] {subprocess.py:93} INFO -           optional binary element (STRING);
[2025-07-11T14:09:05.550+0200] {subprocess.py:93} INFO -         }
[2025-07-11T14:09:05.550+0200] {subprocess.py:93} INFO -       }
[2025-07-11T14:09:05.550+0200] {subprocess.py:93} INFO -     }
[2025-07-11T14:09:05.550+0200] {subprocess.py:93} INFO -   }
[2025-07-11T14:09:05.550+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:09:05.550+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:09:05.551+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:09:05.579+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileOutputCommitter: Saved output of task 'attempt_202507111409055158782215302558699_0044_m_000000_79' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Dest.bin/data/_temporary/0/task_202507111409055158782215302558699_0044_m_000000
[2025-07-11T14:09:05.579+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO SparkHadoopMapRedUtil: attempt_202507111409055158782215302558699_0044_m_000000_79: Committed. Elapsed time: 1 ms.
[2025-07-11T14:09:05.580+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO Executor: Finished task 0.0 in stage 44.0 (TID 79). 4740 bytes result sent to driver
[2025-07-11T14:09:05.581+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 79) in 47 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:09:05.581+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool
[2025-07-11T14:09:05.582+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: ResultStage 44 (parquet at StringIndexer.scala:499) finished in 0,066 s
[2025-07-11T14:09:05.582+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:09:05.582+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
[2025-07-11T14:09:05.582+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Job 27 finished: parquet at StringIndexer.scala:499, took 0,068494 s
[2025-07-11T14:09:05.582+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileFormatWriter: Start to commit write Job 02e4115e-18c9-483d-89dd-2f162f2dad01.
[2025-07-11T14:09:05.604+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileFormatWriter: Write Job 02e4115e-18c9-483d-89dd-2f162f2dad01 committed. Elapsed time: 21 ms.
[2025-07-11T14:09:05.604+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileFormatWriter: Finished processing stats for write job 02e4115e-18c9-483d-89dd-2f162f2dad01.
[2025-07-11T14:09:05.649+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO V2ScanRelationPushDown:
[2025-07-11T14:09:05.649+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:09:05.649+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:09:05.649+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:09:05.649+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:09:05.654+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO V2ScanRelationPushDown:
[2025-07-11T14:09:05.655+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68
[2025-07-11T14:09:05.655+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:09:05.667+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:09:05.667+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:09:05.688+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO CodeGenerator: Code generated in 5.926624 ms
[2025-07-11T14:09:05.691+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 214.5 KiB, free 429.0 MiB)
[2025-07-11T14:09:05.698+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 428.9 MiB)
[2025-07-11T14:09:05.698+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 138.4.31.23:43033 (size: 38.9 KiB, free: 434.1 MiB)
[2025-07-11T14:09:05.699+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO SparkContext: Created broadcast 35 from collect at StringIndexer.scala:204
[2025-07-11T14:09:05.700+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:09:05.703+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Registering RDD 92 (collect at StringIndexer.scala:204) as input to shuffle 14
[2025-07-11T14:09:05.704+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Got map stage job 28 (collect at StringIndexer.scala:204) with 2 output partitions
[2025-07-11T14:09:05.704+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Final stage: ShuffleMapStage 45 (collect at StringIndexer.scala:204)
[2025-07-11T14:09:05.704+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:09:05.704+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:05.704+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[92] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:09:05.706+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 18.1 KiB, free 428.9 MiB)
[2025-07-11T14:09:05.707+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 428.9 MiB)
[2025-07-11T14:09:05.707+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 138.4.31.23:43033 (size: 8.7 KiB, free: 434.1 MiB)
[2025-07-11T14:09:05.708+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:05.708+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[92] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:09:05.708+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSchedulerImpl: Adding task set 45.0 with 2 tasks resource profile 0
[2025-07-11T14:09:05.710+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Registering RDD 96 (collect at StringIndexer.scala:204) as input to shuffle 15
[2025-07-11T14:09:05.710+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Got map stage job 29 (collect at StringIndexer.scala:204) with 13 output partitions
[2025-07-11T14:09:05.710+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Final stage: ShuffleMapStage 46 (collect at StringIndexer.scala:204)
[2025-07-11T14:09:05.710+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:09:05.710+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 80) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:09:05.711+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 81) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:09:05.711+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO Executor: Running task 0.0 in stage 45.0 (TID 80)
[2025-07-11T14:09:05.712+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:05.713+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[96] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:09:05.715+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 18.2 KiB, free 428.9 MiB)
[2025-07-11T14:09:05.716+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 428.9 MiB)
[2025-07-11T14:09:05.720+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 138.4.31.23:43033 (size: 9.0 KiB, free: 434.0 MiB)
[2025-07-11T14:09:05.720+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO Executor: Running task 1.0 in stage 45.0 (TID 81)
[2025-07-11T14:09:05.723+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:05.723+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[96] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-11T14:09:05.724+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSchedulerImpl: Adding task set 46.0 with 13 tasks resource profile 0
[2025-07-11T14:09:05.725+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 82) (138.4.31.23, executor driver, partition 0, ANY, 16719 bytes)
[2025-07-11T14:09:05.725+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSetManager: Starting task 1.0 in stage 46.0 (TID 83) (138.4.31.23, executor driver, partition 1, ANY, 16839 bytes)
[2025-07-11T14:09:05.725+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO Executor: Running task 0.0 in stage 46.0 (TID 82)
[2025-07-11T14:09:05.725+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO Executor: Running task 1.0 in stage 46.0 (TID 83)
[2025-07-11T14:09:05.731+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO CodeGenerator: Code generated in 17.026155 ms
[2025-07-11T14:09:05.734+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:09:05.735+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:09:05.799+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO Executor: Finished task 0.0 in stage 46.0 (TID 82). 1945 bytes result sent to driver
[2025-07-11T14:09:05.800+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO Executor: Finished task 1.0 in stage 46.0 (TID 83). 1945 bytes result sent to driver
[2025-07-11T14:09:05.802+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSetManager: Starting task 2.0 in stage 46.0 (TID 84) (138.4.31.23, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-11T14:09:05.802+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSetManager: Starting task 3.0 in stage 46.0 (TID 85) (138.4.31.23, executor driver, partition 3, ANY, 16839 bytes)
[2025-07-11T14:09:05.802+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO Executor: Running task 2.0 in stage 46.0 (TID 84)
[2025-07-11T14:09:05.804+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO Executor: Running task 3.0 in stage 46.0 (TID 85)
[2025-07-11T14:09:05.822+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 82) in 98 ms on 138.4.31.23 (executor driver) (1/13)
[2025-07-11T14:09:05.823+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSetManager: Finished task 1.0 in stage 46.0 (TID 83) in 99 ms on 138.4.31.23 (executor driver) (2/13)
[2025-07-11T14:09:05.832+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 138.4.31.23:43033 in memory (size: 36.5 KiB, free: 434.1 MiB)
[2025-07-11T14:09:05.848+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 138.4.31.23:43033 in memory (size: 83.7 KiB, free: 434.2 MiB)
[2025-07-11T14:09:05.863+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 138.4.31.23:43033 in memory (size: 23.6 KiB, free: 434.2 MiB)
[2025-07-11T14:09:05.880+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 138.4.31.23:43033 in memory (size: 24.1 KiB, free: 434.2 MiB)
[2025-07-11T14:09:05.909+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 138.4.31.23:43033 in memory (size: 4.4 KiB, free: 434.2 MiB)
[2025-07-11T14:09:05.914+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO Executor: Finished task 3.0 in stage 46.0 (TID 85). 1988 bytes result sent to driver
[2025-07-11T14:09:05.916+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSetManager: Starting task 4.0 in stage 46.0 (TID 86) (138.4.31.23, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-11T14:09:05.917+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSetManager: Finished task 3.0 in stage 46.0 (TID 85) in 115 ms on 138.4.31.23 (executor driver) (3/13)
[2025-07-11T14:09:05.917+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO Executor: Running task 4.0 in stage 46.0 (TID 86)
[2025-07-11T14:09:05.921+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO Executor: Finished task 2.0 in stage 46.0 (TID 84). 1988 bytes result sent to driver
[2025-07-11T14:09:05.922+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSetManager: Starting task 5.0 in stage 46.0 (TID 87) (138.4.31.23, executor driver, partition 5, ANY, 16719 bytes)
[2025-07-11T14:09:05.924+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO TaskSetManager: Finished task 2.0 in stage 46.0 (TID 84) in 123 ms on 138.4.31.23 (executor driver) (4/13)
[2025-07-11T14:09:05.924+0200] {subprocess.py:93} INFO - 25/07/11 14:09:05 INFO Executor: Running task 5.0 in stage 46.0 (TID 87)
[2025-07-11T14:09:06.008+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO Executor: Finished task 5.0 in stage 46.0 (TID 87). 1945 bytes result sent to driver
[2025-07-11T14:09:06.010+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSetManager: Starting task 6.0 in stage 46.0 (TID 88) (138.4.31.23, executor driver, partition 6, ANY, 16719 bytes)
[2025-07-11T14:09:06.011+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSetManager: Finished task 5.0 in stage 46.0 (TID 87) in 89 ms on 138.4.31.23 (executor driver) (5/13)
[2025-07-11T14:09:06.012+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO Executor: Finished task 4.0 in stage 46.0 (TID 86). 1945 bytes result sent to driver
[2025-07-11T14:09:06.012+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO Executor: Running task 6.0 in stage 46.0 (TID 88)
[2025-07-11T14:09:06.013+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSetManager: Starting task 7.0 in stage 46.0 (TID 89) (138.4.31.23, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-11T14:09:06.013+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSetManager: Finished task 4.0 in stage 46.0 (TID 86) in 98 ms on 138.4.31.23 (executor driver) (6/13)
[2025-07-11T14:09:06.015+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO Executor: Running task 7.0 in stage 46.0 (TID 89)
[2025-07-11T14:09:06.069+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO Executor: Finished task 6.0 in stage 46.0 (TID 88). 1945 bytes result sent to driver
[2025-07-11T14:09:06.074+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSetManager: Starting task 8.0 in stage 46.0 (TID 90) (138.4.31.23, executor driver, partition 8, ANY, 16715 bytes)
[2025-07-11T14:09:06.076+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSetManager: Finished task 6.0 in stage 46.0 (TID 88) in 66 ms on 138.4.31.23 (executor driver) (7/13)
[2025-07-11T14:09:06.076+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO Executor: Running task 8.0 in stage 46.0 (TID 90)
[2025-07-11T14:09:06.103+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO Executor: Finished task 7.0 in stage 46.0 (TID 89). 1945 bytes result sent to driver
[2025-07-11T14:09:06.104+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSetManager: Starting task 9.0 in stage 46.0 (TID 91) (138.4.31.23, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-11T14:09:06.104+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO Executor: Running task 9.0 in stage 46.0 (TID 91)
[2025-07-11T14:09:06.105+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSetManager: Finished task 7.0 in stage 46.0 (TID 89) in 92 ms on 138.4.31.23 (executor driver) (8/13)
[2025-07-11T14:09:06.140+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO Executor: Finished task 8.0 in stage 46.0 (TID 90). 1945 bytes result sent to driver
[2025-07-11T14:09:06.151+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSetManager: Starting task 10.0 in stage 46.0 (TID 92) (138.4.31.23, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-11T14:09:06.151+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO Executor: Running task 10.0 in stage 46.0 (TID 92)
[2025-07-11T14:09:06.151+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSetManager: Finished task 8.0 in stage 46.0 (TID 90) in 77 ms on 138.4.31.23 (executor driver) (9/13)
[2025-07-11T14:09:06.162+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO Executor: Finished task 9.0 in stage 46.0 (TID 91). 1945 bytes result sent to driver
[2025-07-11T14:09:06.163+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSetManager: Starting task 11.0 in stage 46.0 (TID 93) (138.4.31.23, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-11T14:09:06.163+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSetManager: Finished task 9.0 in stage 46.0 (TID 91) in 60 ms on 138.4.31.23 (executor driver) (10/13)
[2025-07-11T14:09:06.164+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO Executor: Running task 11.0 in stage 46.0 (TID 93)
[2025-07-11T14:09:06.231+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO Executor: Finished task 11.0 in stage 46.0 (TID 93). 2031 bytes result sent to driver
[2025-07-11T14:09:06.233+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSetManager: Starting task 12.0 in stage 46.0 (TID 94) (138.4.31.23, executor driver, partition 12, ANY, 16839 bytes)
[2025-07-11T14:09:06.234+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO Executor: Finished task 10.0 in stage 46.0 (TID 92). 1988 bytes result sent to driver
[2025-07-11T14:09:06.234+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO Executor: Running task 12.0 in stage 46.0 (TID 94)
[2025-07-11T14:09:06.234+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSetManager: Finished task 10.0 in stage 46.0 (TID 92) in 83 ms on 138.4.31.23 (executor driver) (11/13)
[2025-07-11T14:09:06.234+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSetManager: Finished task 11.0 in stage 46.0 (TID 93) in 71 ms on 138.4.31.23 (executor driver) (12/13)
[2025-07-11T14:09:06.307+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO Executor: Finished task 12.0 in stage 46.0 (TID 94). 1945 bytes result sent to driver
[2025-07-11T14:09:06.310+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSetManager: Finished task 12.0 in stage 46.0 (TID 94) in 78 ms on 138.4.31.23 (executor driver) (13/13)
[2025-07-11T14:09:06.310+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool
[2025-07-11T14:09:06.312+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO DAGScheduler: ShuffleMapStage 46 (collect at StringIndexer.scala:204) finished in 0,597 s
[2025-07-11T14:09:06.312+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:09:06.312+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO DAGScheduler: running: Set(ShuffleMapStage 45)
[2025-07-11T14:09:06.312+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:09:06.312+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO DAGScheduler: failed: Set()
[2025-07-11T14:09:06.318+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:09:06.356+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:09:06.357+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO DAGScheduler: Got job 30 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-11T14:09:06.357+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO DAGScheduler: Final stage: ResultStage 48 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-11T14:09:06.357+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
[2025-07-11T14:09:06.357+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:06.357+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[98] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-11T14:09:06.361+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 8.2 KiB, free 429.5 MiB)
[2025-07-11T14:09:06.361+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 429.5 MiB)
[2025-07-11T14:09:06.361+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 138.4.31.23:43033 (size: 4.2 KiB, free: 434.2 MiB)
[2025-07-11T14:09:06.362+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:06.362+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[98] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:09:06.362+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
[2025-07-11T14:09:06.363+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 95) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-11T14:09:06.363+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO Executor: Running task 0.0 in stage 48.0 (TID 95)
[2025-07-11T14:09:06.391+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 138.4.31.23:43033 in memory (size: 89.5 KiB, free: 434.3 MiB)
[2025-07-11T14:09:06.401+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO ShuffleBlockFetcherIterator: Getting 13 (200.0 KiB) non-empty blocks including 13 (200.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:06.401+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
[2025-07-11T14:09:06.459+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 138.4.31.23:43033 in memory (size: 8.2 KiB, free: 434.3 MiB)
[2025-07-11T14:09:06.476+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO Executor: Finished task 0.0 in stage 48.0 (TID 95). 40531 bytes result sent to driver
[2025-07-11T14:09:06.478+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 95) in 115 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:09:06.478+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool
[2025-07-11T14:09:06.486+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO DAGScheduler: ResultStage 48 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,119 s
[2025-07-11T14:09:06.486+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:09:06.486+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
[2025-07-11T14:09:06.486+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO DAGScheduler: Job 30 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,123397 s
[2025-07-11T14:09:06.497+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 138.4.31.23:43033 in memory (size: 38.9 KiB, free: 434.3 MiB)
[2025-07-11T14:09:06.521+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 4.3 MiB, free 429.8 MiB)
[2025-07-11T14:09:06.528+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 89.7 KiB, free 429.8 MiB)
[2025-07-11T14:09:06.529+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 138.4.31.23:43033 (size: 89.7 KiB, free: 434.3 MiB)
[2025-07-11T14:09:06.530+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO SparkContext: Created broadcast 39 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:09:06.905+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO Executor: Finished task 1.0 in stage 45.0 (TID 81). 2031 bytes result sent to driver
[2025-07-11T14:09:06.907+0200] {subprocess.py:93} INFO - 25/07/11 14:09:06 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 81) in 1196 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:09:07.709+0200] {subprocess.py:93} INFO - 25/07/11 14:09:07 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 138.4.31.23:43033 in memory (size: 4.2 KiB, free: 434.3 MiB)
[2025-07-11T14:09:12.208+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO Executor: Finished task 0.0 in stage 45.0 (TID 80). 2074 bytes result sent to driver
[2025-07-11T14:09:12.208+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 80) in 6498 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:09:12.208+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool
[2025-07-11T14:09:12.212+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: ShuffleMapStage 45 (collect at StringIndexer.scala:204) finished in 6,505 s
[2025-07-11T14:09:12.212+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:09:12.212+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: running: Set()
[2025-07-11T14:09:12.212+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:09:12.212+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: failed: Set()
[2025-07-11T14:09:12.215+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:09:12.254+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO CodeGenerator: Code generated in 17.231506 ms
[2025-07-11T14:09:12.257+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Registering RDD 102 (collect at StringIndexer.scala:204) as input to shuffle 16
[2025-07-11T14:09:12.257+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Got map stage job 31 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-11T14:09:12.258+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Final stage: ShuffleMapStage 50 (collect at StringIndexer.scala:204)
[2025-07-11T14:09:12.258+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 49)
[2025-07-11T14:09:12.258+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:12.258+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[102] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:09:12.262+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 51.4 KiB, free 429.7 MiB)
[2025-07-11T14:09:12.263+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 429.7 MiB)
[2025-07-11T14:09:12.263+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 138.4.31.23:43033 (size: 24.3 KiB, free: 434.2 MiB)
[2025-07-11T14:09:12.264+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:12.264+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[102] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:09:12.264+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks resource profile 0
[2025-07-11T14:09:12.265+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 96) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14833 bytes)
[2025-07-11T14:09:12.266+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO Executor: Running task 0.0 in stage 50.0 (TID 96)
[2025-07-11T14:09:12.272+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO ShuffleBlockFetcherIterator: Getting 2 (1220.4 KiB) non-empty blocks including 2 (1220.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:12.272+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-11T14:09:12.281+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO CodeGenerator: Code generated in 6.938872 ms
[2025-07-11T14:09:12.315+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 138.4.31.23:43033 in memory (size: 9.0 KiB, free: 434.2 MiB)
[2025-07-11T14:09:12.574+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO Executor: Finished task 0.0 in stage 50.0 (TID 96). 6500 bytes result sent to driver
[2025-07-11T14:09:12.574+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 96) in 309 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:09:12.574+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool
[2025-07-11T14:09:12.575+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: ShuffleMapStage 50 (collect at StringIndexer.scala:204) finished in 0,317 s
[2025-07-11T14:09:12.575+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:09:12.575+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: running: Set()
[2025-07-11T14:09:12.575+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:09:12.575+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: failed: Set()
[2025-07-11T14:09:12.588+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
[2025-07-11T14:09:12.590+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Got job 32 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-11T14:09:12.590+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Final stage: ResultStage 53 (collect at StringIndexer.scala:204)
[2025-07-11T14:09:12.590+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
[2025-07-11T14:09:12.591+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:12.591+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[105] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:09:12.592+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 50.5 KiB, free 429.7 MiB)
[2025-07-11T14:09:12.594+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 429.6 MiB)
[2025-07-11T14:09:12.594+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 138.4.31.23:43033 (size: 24.0 KiB, free: 434.2 MiB)
[2025-07-11T14:09:12.594+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:12.594+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[105] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:09:12.594+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0
[2025-07-11T14:09:12.595+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 97) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:09:12.595+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO Executor: Running task 0.0 in stage 53.0 (TID 97)
[2025-07-11T14:09:12.599+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO ShuffleBlockFetcherIterator: Getting 1 (46.5 KiB) non-empty blocks including 1 (46.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:12.599+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:12.621+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO Executor: Finished task 0.0 in stage 53.0 (TID 97). 53379 bytes result sent to driver
[2025-07-11T14:09:12.622+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 97) in 27 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:09:12.622+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool
[2025-07-11T14:09:12.622+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: ResultStage 53 (collect at StringIndexer.scala:204) finished in 0,031 s
[2025-07-11T14:09:12.622+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:09:12.622+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
[2025-07-11T14:09:12.622+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Job 32 finished: collect at StringIndexer.scala:204, took 0,033853 s
[2025-07-11T14:09:12.683+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO FileSystemOverwrite: Path /home/monica.fernandez/practica_creativa/models/string_indexer_model_Route.bin already exists. It will be overwritten.
[2025-07-11T14:09:12.698+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:09:12.698+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:09:12.698+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:09:12.724+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-11T14:09:12.724+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Got job 33 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-11T14:09:12.724+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Final stage: ResultStage 54 (runJob at SparkHadoopWriter.scala:83)
[2025-07-11T14:09:12.725+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:09:12.725+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:12.725+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[107] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-11T14:09:12.731+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 101.3 KiB, free 429.5 MiB)
[2025-07-11T14:09:12.732+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 36.6 KiB, free 429.5 MiB)
[2025-07-11T14:09:12.732+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 138.4.31.23:43033 (size: 36.6 KiB, free: 434.2 MiB)
[2025-07-11T14:09:12.732+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:12.732+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[107] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:09:12.732+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks resource profile 0
[2025-07-11T14:09:12.733+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 98) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15154 bytes)
[2025-07-11T14:09:12.734+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO Executor: Running task 0.0 in stage 54.0 (TID 98)
[2025-07-11T14:09:12.739+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:09:12.739+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:09:12.739+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:09:12.764+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO FileOutputCommitter: Saved output of task 'attempt_20250711140912711268378381030433_0107_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Route.bin/metadata/_temporary/0/task_20250711140912711268378381030433_0107_m_000000
[2025-07-11T14:09:12.764+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO SparkHadoopMapRedUtil: attempt_20250711140912711268378381030433_0107_m_000000_0: Committed. Elapsed time: 1 ms.
[2025-07-11T14:09:12.764+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO Executor: Finished task 0.0 in stage 54.0 (TID 98). 1170 bytes result sent to driver
[2025-07-11T14:09:12.765+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 98) in 32 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:09:12.765+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool
[2025-07-11T14:09:12.765+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: ResultStage 54 (runJob at SparkHadoopWriter.scala:83) finished in 0,040 s
[2025-07-11T14:09:12.765+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:09:12.765+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished
[2025-07-11T14:09:12.767+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Job 33 finished: runJob at SparkHadoopWriter.scala:83, took 0,041334 s
[2025-07-11T14:09:12.767+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO SparkHadoopWriter: Start to commit write Job job_20250711140912711268378381030433_0107.
[2025-07-11T14:09:12.785+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO SparkHadoopWriter: Write Job job_20250711140912711268378381030433_0107 committed. Elapsed time: 19 ms.
[2025-07-11T14:09:12.816+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Registering RDD 110 (parquet at StringIndexer.scala:499) as input to shuffle 17
[2025-07-11T14:09:12.816+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Got map stage job 34 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-11T14:09:12.816+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Final stage: ShuffleMapStage 55 (parquet at StringIndexer.scala:499)
[2025-07-11T14:09:12.816+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:09:12.817+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:12.817+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Submitting ShuffleMapStage 55 (MapPartitionsRDD[110] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-11T14:09:12.817+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 8.1 KiB, free 429.5 MiB)
[2025-07-11T14:09:12.817+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 429.5 MiB)
[2025-07-11T14:09:12.817+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 138.4.31.23:43033 (size: 4.4 KiB, free: 434.2 MiB)
[2025-07-11T14:09:12.818+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:12.818+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 55 (MapPartitionsRDD[110] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:09:12.818+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0
[2025-07-11T14:09:12.819+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 99) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 82517 bytes)
[2025-07-11T14:09:12.819+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO Executor: Running task 0.0 in stage 55.0 (TID 99)
[2025-07-11T14:09:12.826+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO Executor: Finished task 0.0 in stage 55.0 (TID 99). 1628 bytes result sent to driver
[2025-07-11T14:09:12.827+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 99) in 9 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:09:12.828+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool
[2025-07-11T14:09:12.829+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: ShuffleMapStage 55 (parquet at StringIndexer.scala:499) finished in 0,016 s
[2025-07-11T14:09:12.829+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:09:12.829+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: running: Set()
[2025-07-11T14:09:12.829+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:09:12.829+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: failed: Set()
[2025-07-11T14:09:12.833+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:09:12.834+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:09:12.834+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:09:12.834+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:09:12.834+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:09:12.834+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:09:12.834+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:09:12.860+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO SparkContext: Starting job: parquet at StringIndexer.scala:499
[2025-07-11T14:09:12.860+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Got job 35 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-11T14:09:12.860+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Final stage: ResultStage 57 (parquet at StringIndexer.scala:499)
[2025-07-11T14:09:12.860+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
[2025-07-11T14:09:12.860+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:12.860+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[112] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-11T14:09:12.876+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 239.5 KiB, free 429.3 MiB)
[2025-07-11T14:09:12.877+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 83.7 KiB, free 429.2 MiB)
[2025-07-11T14:09:12.881+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 138.4.31.23:43033 (size: 83.7 KiB, free: 434.1 MiB)
[2025-07-11T14:09:12.882+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:12.882+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[112] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:09:12.882+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0
[2025-07-11T14:09:12.883+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 100) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:09:12.883+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO Executor: Running task 0.0 in stage 57.0 (TID 100)
[2025-07-11T14:09:12.893+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO ShuffleBlockFetcherIterator: Getting 1 (42.2 KiB) non-empty blocks including 1 (42.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:12.893+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:12.893+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:09:12.894+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:09:12.894+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:09:12.894+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:09:12.894+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:09:12.894+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:09:12.894+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:09:12.894+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:09:12.895+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-11T14:09:12.896+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-11T14:09:12.896+0200] {subprocess.py:93} INFO - {
[2025-07-11T14:09:12.896+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-11T14:09:12.896+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-11T14:09:12.896+0200] {subprocess.py:93} INFO -     "name" : "labelsArray",
[2025-07-11T14:09:12.896+0200] {subprocess.py:93} INFO -     "type" : {
[2025-07-11T14:09:12.896+0200] {subprocess.py:93} INFO -       "type" : "array",
[2025-07-11T14:09:12.896+0200] {subprocess.py:93} INFO -       "elementType" : {
[2025-07-11T14:09:12.896+0200] {subprocess.py:93} INFO -         "type" : "array",
[2025-07-11T14:09:12.896+0200] {subprocess.py:93} INFO -         "elementType" : "string",
[2025-07-11T14:09:12.896+0200] {subprocess.py:93} INFO -         "containsNull" : true
[2025-07-11T14:09:12.896+0200] {subprocess.py:93} INFO -       },
[2025-07-11T14:09:12.897+0200] {subprocess.py:93} INFO -       "containsNull" : true
[2025-07-11T14:09:12.897+0200] {subprocess.py:93} INFO -     },
[2025-07-11T14:09:12.897+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-11T14:09:12.897+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:09:12.897+0200] {subprocess.py:93} INFO -   } ]
[2025-07-11T14:09:12.897+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:09:12.897+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-11T14:09:12.897+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-11T14:09:12.897+0200] {subprocess.py:93} INFO -   optional group labelsArray (LIST) {
[2025-07-11T14:09:12.897+0200] {subprocess.py:93} INFO -     repeated group list {
[2025-07-11T14:09:12.897+0200] {subprocess.py:93} INFO -       optional group element (LIST) {
[2025-07-11T14:09:12.897+0200] {subprocess.py:93} INFO -         repeated group list {
[2025-07-11T14:09:12.897+0200] {subprocess.py:93} INFO -           optional binary element (STRING);
[2025-07-11T14:09:12.897+0200] {subprocess.py:93} INFO -         }
[2025-07-11T14:09:12.897+0200] {subprocess.py:93} INFO -       }
[2025-07-11T14:09:12.897+0200] {subprocess.py:93} INFO -     }
[2025-07-11T14:09:12.897+0200] {subprocess.py:93} INFO -   }
[2025-07-11T14:09:12.898+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:09:12.898+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:09:12.898+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:09:12.955+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO FileOutputCommitter: Saved output of task 'attempt_202507111409126013370768196029601_0057_m_000000_100' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Route.bin/data/_temporary/0/task_202507111409126013370768196029601_0057_m_000000
[2025-07-11T14:09:12.955+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO SparkHadoopMapRedUtil: attempt_202507111409126013370768196029601_0057_m_000000_100: Committed. Elapsed time: 1 ms.
[2025-07-11T14:09:12.959+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO Executor: Finished task 0.0 in stage 57.0 (TID 100). 4740 bytes result sent to driver
[2025-07-11T14:09:12.960+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 100) in 77 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:09:12.960+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool
[2025-07-11T14:09:12.960+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: ResultStage 57 (parquet at StringIndexer.scala:499) finished in 0,099 s
[2025-07-11T14:09:12.960+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:09:12.960+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
[2025-07-11T14:09:12.961+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO DAGScheduler: Job 35 finished: parquet at StringIndexer.scala:499, took 0,101112 s
[2025-07-11T14:09:12.961+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO FileFormatWriter: Start to commit write Job 21e775ee-dbea-4291-bae7-bcabf20fdf9a.
[2025-07-11T14:09:12.983+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO FileFormatWriter: Write Job 21e775ee-dbea-4291-bae7-bcabf20fdf9a committed. Elapsed time: 21 ms.
[2025-07-11T14:09:12.983+0200] {subprocess.py:93} INFO - 25/07/11 14:09:12 INFO FileFormatWriter: Finished processing stats for write job 21e775ee-dbea-4291-bae7-bcabf20fdf9a.
[2025-07-11T14:09:13.047+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO FileSystemOverwrite: Path /home/monica.fernandez/practica_creativa/models/numeric_vector_assembler.bin already exists. It will be overwritten.
[2025-07-11T14:09:13.061+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:09:13.061+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:09:13.061+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:09:13.089+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-11T14:09:13.091+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Got job 36 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-11T14:09:13.091+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Final stage: ResultStage 58 (runJob at SparkHadoopWriter.scala:83)
[2025-07-11T14:09:13.091+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:09:13.091+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:13.091+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[114] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-11T14:09:13.100+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 101.3 KiB, free 429.1 MiB)
[2025-07-11T14:09:13.102+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 429.0 MiB)
[2025-07-11T14:09:13.102+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 138.4.31.23:43033 (size: 36.5 KiB, free: 434.1 MiB)
[2025-07-11T14:09:13.102+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:13.103+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[114] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:09:13.103+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0
[2025-07-11T14:09:13.105+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 101) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15234 bytes)
[2025-07-11T14:09:13.106+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Running task 0.0 in stage 58.0 (TID 101)
[2025-07-11T14:09:13.111+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:09:13.111+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:09:13.112+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:09:13.137+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO FileOutputCommitter: Saved output of task 'attempt_202507111409135260084412515586656_0114_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/numeric_vector_assembler.bin/metadata/_temporary/0/task_202507111409135260084412515586656_0114_m_000000
[2025-07-11T14:09:13.137+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO SparkHadoopMapRedUtil: attempt_202507111409135260084412515586656_0114_m_000000_0: Committed. Elapsed time: 1 ms.
[2025-07-11T14:09:13.139+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Finished task 0.0 in stage 58.0 (TID 101). 1170 bytes result sent to driver
[2025-07-11T14:09:13.139+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 101) in 35 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:09:13.139+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool
[2025-07-11T14:09:13.139+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: ResultStage 58 (runJob at SparkHadoopWriter.scala:83) finished in 0,048 s
[2025-07-11T14:09:13.139+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:09:13.139+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 58: Stage finished
[2025-07-11T14:09:13.139+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Job 36 finished: runJob at SparkHadoopWriter.scala:83, took 0,049718 s
[2025-07-11T14:09:13.139+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO SparkHadoopWriter: Start to commit write Job job_202507111409135260084412515586656_0114.
[2025-07-11T14:09:13.160+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO SparkHadoopWriter: Write Job job_202507111409135260084412515586656_0114 committed. Elapsed time: 20 ms.
[2025-07-11T14:09:13.265+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO V2ScanRelationPushDown:
[2025-07-11T14:09:13.266+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:09:13.266+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:09:13.266+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:09:13.266+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:09:13.275+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO V2ScanRelationPushDown:
[2025-07-11T14:09:13.275+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-11T14:09:13.275+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:09:13.309+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:09:13.309+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:09:13.351+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO CodeGenerator: Code generated in 9.367481 ms
[2025-07-11T14:09:13.354+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 214.5 KiB, free 428.8 MiB)
[2025-07-11T14:09:13.360+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 428.8 MiB)
[2025-07-11T14:09:13.361+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 138.4.31.23:43033 (size: 38.9 KiB, free: 434.0 MiB)
[2025-07-11T14:09:13.361+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO SparkContext: Created broadcast 46 from showString at NativeMethodAccessorImpl.java:0
[2025-07-11T14:09:13.362+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:09:13.365+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Registering RDD 118 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 18
[2025-07-11T14:09:13.365+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Got map stage job 37 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-07-11T14:09:13.366+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Final stage: ShuffleMapStage 59 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:09:13.366+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:09:13.366+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:13.366+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Submitting ShuffleMapStage 59 (MapPartitionsRDD[118] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:09:13.368+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 22.8 KiB, free 428.8 MiB)
[2025-07-11T14:09:13.369+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 428.8 MiB)
[2025-07-11T14:09:13.369+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 138.4.31.23:43033 (size: 9.9 KiB, free: 434.0 MiB)
[2025-07-11T14:09:13.369+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:13.370+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 59 (MapPartitionsRDD[118] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:09:13.370+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSchedulerImpl: Adding task set 59.0 with 2 tasks resource profile 0
[2025-07-11T14:09:13.370+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 102) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:09:13.371+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Starting task 1.0 in stage 59.0 (TID 103) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:09:13.371+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Running task 0.0 in stage 59.0 (TID 102)
[2025-07-11T14:09:13.371+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Running task 1.0 in stage 59.0 (TID 103)
[2025-07-11T14:09:13.375+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Registering RDD 122 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 19
[2025-07-11T14:09:13.376+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Got map stage job 38 (showString at NativeMethodAccessorImpl.java:0) with 13 output partitions
[2025-07-11T14:09:13.376+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Final stage: ShuffleMapStage 60 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:09:13.376+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:09:13.376+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:13.377+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[122] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:09:13.379+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 18.7 KiB, free 428.7 MiB)
[2025-07-11T14:09:13.380+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 428.7 MiB)
[2025-07-11T14:09:13.380+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 138.4.31.23:43033 (size: 9.2 KiB, free: 434.0 MiB)
[2025-07-11T14:09:13.381+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:13.381+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[122] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-11T14:09:13.381+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSchedulerImpl: Adding task set 60.0 with 13 tasks resource profile 0
[2025-07-11T14:09:13.382+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 104) (138.4.31.23, executor driver, partition 0, ANY, 16719 bytes)
[2025-07-11T14:09:13.382+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 105) (138.4.31.23, executor driver, partition 1, ANY, 16715 bytes)
[2025-07-11T14:09:13.383+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Running task 1.0 in stage 60.0 (TID 105)
[2025-07-11T14:09:13.389+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Running task 0.0 in stage 60.0 (TID 104)
[2025-07-11T14:09:13.389+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO CodeGenerator: Code generated in 9.842672 ms
[2025-07-11T14:09:13.394+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO CodeGenerator: Code generated in 8.392172 ms
[2025-07-11T14:09:13.395+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:09:13.397+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:09:13.419+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Finished task 1.0 in stage 60.0 (TID 105). 1945 bytes result sent to driver
[2025-07-11T14:09:13.419+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Starting task 2.0 in stage 60.0 (TID 106) (138.4.31.23, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-11T14:09:13.420+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Running task 2.0 in stage 60.0 (TID 106)
[2025-07-11T14:09:13.420+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 105) in 38 ms on 138.4.31.23 (executor driver) (1/13)
[2025-07-11T14:09:13.422+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO CodeGenerator: Code generated in 18.257124 ms
[2025-07-11T14:09:13.438+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Finished task 0.0 in stage 60.0 (TID 104). 1945 bytes result sent to driver
[2025-07-11T14:09:13.439+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Starting task 3.0 in stage 60.0 (TID 107) (138.4.31.23, executor driver, partition 3, ANY, 16839 bytes)
[2025-07-11T14:09:13.439+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Running task 3.0 in stage 60.0 (TID 107)
[2025-07-11T14:09:13.439+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 104) in 58 ms on 138.4.31.23 (executor driver) (2/13)
[2025-07-11T14:09:13.465+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 138.4.31.23:43033 in memory (size: 83.7 KiB, free: 434.1 MiB)
[2025-07-11T14:09:13.466+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 138.4.31.23:43033 in memory (size: 36.5 KiB, free: 434.1 MiB)
[2025-07-11T14:09:13.482+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 138.4.31.23:43033 in memory (size: 24.3 KiB, free: 434.1 MiB)
[2025-07-11T14:09:13.483+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 138.4.31.23:43033 in memory (size: 24.0 KiB, free: 434.2 MiB)
[2025-07-11T14:09:13.486+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 138.4.31.23:43033 in memory (size: 36.6 KiB, free: 434.2 MiB)
[2025-07-11T14:09:13.487+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 138.4.31.23:43033 in memory (size: 4.4 KiB, free: 434.2 MiB)
[2025-07-11T14:09:13.519+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Finished task 2.0 in stage 60.0 (TID 106). 1988 bytes result sent to driver
[2025-07-11T14:09:13.519+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Starting task 4.0 in stage 60.0 (TID 108) (138.4.31.23, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-11T14:09:13.520+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Running task 4.0 in stage 60.0 (TID 108)
[2025-07-11T14:09:13.520+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Finished task 2.0 in stage 60.0 (TID 106) in 101 ms on 138.4.31.23 (executor driver) (3/13)
[2025-07-11T14:09:13.531+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Finished task 3.0 in stage 60.0 (TID 107). 1988 bytes result sent to driver
[2025-07-11T14:09:13.532+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Starting task 5.0 in stage 60.0 (TID 109) (138.4.31.23, executor driver, partition 5, ANY, 16719 bytes)
[2025-07-11T14:09:13.533+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Running task 5.0 in stage 60.0 (TID 109)
[2025-07-11T14:09:13.533+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Finished task 3.0 in stage 60.0 (TID 107) in 94 ms on 138.4.31.23 (executor driver) (4/13)
[2025-07-11T14:09:13.576+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Finished task 4.0 in stage 60.0 (TID 108). 1945 bytes result sent to driver
[2025-07-11T14:09:13.578+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Starting task 6.0 in stage 60.0 (TID 110) (138.4.31.23, executor driver, partition 6, ANY, 16839 bytes)
[2025-07-11T14:09:13.578+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Finished task 4.0 in stage 60.0 (TID 108) in 59 ms on 138.4.31.23 (executor driver) (5/13)
[2025-07-11T14:09:13.579+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Running task 6.0 in stage 60.0 (TID 110)
[2025-07-11T14:09:13.608+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Finished task 5.0 in stage 60.0 (TID 109). 1945 bytes result sent to driver
[2025-07-11T14:09:13.609+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Starting task 7.0 in stage 60.0 (TID 111) (138.4.31.23, executor driver, partition 7, ANY, 16839 bytes)
[2025-07-11T14:09:13.609+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Running task 7.0 in stage 60.0 (TID 111)
[2025-07-11T14:09:13.609+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Finished task 5.0 in stage 60.0 (TID 109) in 78 ms on 138.4.31.23 (executor driver) (6/13)
[2025-07-11T14:09:13.660+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Finished task 6.0 in stage 60.0 (TID 110). 1945 bytes result sent to driver
[2025-07-11T14:09:13.670+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Starting task 8.0 in stage 60.0 (TID 112) (138.4.31.23, executor driver, partition 8, ANY, 16719 bytes)
[2025-07-11T14:09:13.670+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Running task 8.0 in stage 60.0 (TID 112)
[2025-07-11T14:09:13.670+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Finished task 6.0 in stage 60.0 (TID 110) in 93 ms on 138.4.31.23 (executor driver) (7/13)
[2025-07-11T14:09:13.684+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Finished task 7.0 in stage 60.0 (TID 111). 1945 bytes result sent to driver
[2025-07-11T14:09:13.685+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Starting task 9.0 in stage 60.0 (TID 113) (138.4.31.23, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-11T14:09:13.685+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Finished task 7.0 in stage 60.0 (TID 111) in 77 ms on 138.4.31.23 (executor driver) (8/13)
[2025-07-11T14:09:13.686+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Running task 9.0 in stage 60.0 (TID 113)
[2025-07-11T14:09:13.716+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Finished task 9.0 in stage 60.0 (TID 113). 1945 bytes result sent to driver
[2025-07-11T14:09:13.725+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Starting task 10.0 in stage 60.0 (TID 114) (138.4.31.23, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-11T14:09:13.725+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Finished task 9.0 in stage 60.0 (TID 113) in 41 ms on 138.4.31.23 (executor driver) (9/13)
[2025-07-11T14:09:13.725+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Running task 10.0 in stage 60.0 (TID 114)
[2025-07-11T14:09:13.750+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Finished task 8.0 in stage 60.0 (TID 112). 1945 bytes result sent to driver
[2025-07-11T14:09:13.752+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Starting task 11.0 in stage 60.0 (TID 115) (138.4.31.23, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-11T14:09:13.752+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Finished task 8.0 in stage 60.0 (TID 112) in 82 ms on 138.4.31.23 (executor driver) (10/13)
[2025-07-11T14:09:13.752+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Running task 11.0 in stage 60.0 (TID 115)
[2025-07-11T14:09:13.777+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Finished task 10.0 in stage 60.0 (TID 114). 1945 bytes result sent to driver
[2025-07-11T14:09:13.785+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Starting task 12.0 in stage 60.0 (TID 116) (138.4.31.23, executor driver, partition 12, ANY, 16719 bytes)
[2025-07-11T14:09:13.785+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Finished task 10.0 in stage 60.0 (TID 114) in 60 ms on 138.4.31.23 (executor driver) (11/13)
[2025-07-11T14:09:13.785+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Running task 12.0 in stage 60.0 (TID 116)
[2025-07-11T14:09:13.834+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Finished task 11.0 in stage 60.0 (TID 115). 2031 bytes result sent to driver
[2025-07-11T14:09:13.835+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Finished task 11.0 in stage 60.0 (TID 115) in 84 ms on 138.4.31.23 (executor driver) (12/13)
[2025-07-11T14:09:13.846+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Finished task 12.0 in stage 60.0 (TID 116). 1988 bytes result sent to driver
[2025-07-11T14:09:13.847+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Finished task 12.0 in stage 60.0 (TID 116) in 62 ms on 138.4.31.23 (executor driver) (13/13)
[2025-07-11T14:09:13.847+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool
[2025-07-11T14:09:13.847+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: ShuffleMapStage 60 (showString at NativeMethodAccessorImpl.java:0) finished in 0,470 s
[2025-07-11T14:09:13.847+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:09:13.847+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: running: Set(ShuffleMapStage 59)
[2025-07-11T14:09:13.847+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:09:13.847+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: failed: Set()
[2025-07-11T14:09:13.894+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO ShufflePartitionsUtil: For shuffle(19), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:09:13.937+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:09:13.937+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Got job 39 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-11T14:09:13.938+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Final stage: ResultStage 62 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-11T14:09:13.938+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)
[2025-07-11T14:09:13.938+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:13.938+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[124] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-11T14:09:13.940+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 8.2 KiB, free 429.5 MiB)
[2025-07-11T14:09:13.941+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 429.5 MiB)
[2025-07-11T14:09:13.941+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 138.4.31.23:43033 (size: 4.2 KiB, free: 434.2 MiB)
[2025-07-11T14:09:13.941+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:13.942+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[124] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:09:13.942+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0
[2025-07-11T14:09:13.943+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 117) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-11T14:09:13.945+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO Executor: Running task 0.0 in stage 62.0 (TID 117)
[2025-07-11T14:09:13.947+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO ShuffleBlockFetcherIterator: Getting 13 (221.8 KiB) non-empty blocks including 13 (221.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:13.948+0200] {subprocess.py:93} INFO - 25/07/11 14:09:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-11T14:09:14.022+0200] {subprocess.py:93} INFO - 25/07/11 14:09:14 INFO Executor: Finished task 0.0 in stage 62.0 (TID 117). 51463 bytes result sent to driver
[2025-07-11T14:09:14.026+0200] {subprocess.py:93} INFO - 25/07/11 14:09:14 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 138.4.31.23:43033 in memory (size: 89.7 KiB, free: 434.3 MiB)
[2025-07-11T14:09:14.026+0200] {subprocess.py:93} INFO - 25/07/11 14:09:14 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 117) in 84 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:09:14.026+0200] {subprocess.py:93} INFO - 25/07/11 14:09:14 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool
[2025-07-11T14:09:14.030+0200] {subprocess.py:93} INFO - 25/07/11 14:09:14 INFO DAGScheduler: ResultStage 62 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,092 s
[2025-07-11T14:09:14.030+0200] {subprocess.py:93} INFO - 25/07/11 14:09:14 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:09:14.030+0200] {subprocess.py:93} INFO - 25/07/11 14:09:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 62: Stage finished
[2025-07-11T14:09:14.030+0200] {subprocess.py:93} INFO - 25/07/11 14:09:14 INFO DAGScheduler: Job 39 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,093270 s
[2025-07-11T14:09:14.031+0200] {subprocess.py:93} INFO - 25/07/11 14:09:14 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 138.4.31.23:43033 in memory (size: 8.7 KiB, free: 434.3 MiB)
[2025-07-11T14:09:14.040+0200] {subprocess.py:93} INFO - 25/07/11 14:09:14 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 138.4.31.23:43033 in memory (size: 38.9 KiB, free: 434.3 MiB)
[2025-07-11T14:09:14.059+0200] {subprocess.py:93} INFO - 25/07/11 14:09:14 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 4.3 MiB, free 429.8 MiB)
[2025-07-11T14:09:14.070+0200] {subprocess.py:93} INFO - 25/07/11 14:09:14 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 109.4 KiB, free 429.7 MiB)
[2025-07-11T14:09:14.071+0200] {subprocess.py:93} INFO - 25/07/11 14:09:14 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 138.4.31.23:43033 (size: 109.4 KiB, free: 434.2 MiB)
[2025-07-11T14:09:14.071+0200] {subprocess.py:93} INFO - 25/07/11 14:09:14 INFO SparkContext: Created broadcast 50 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:09:14.525+0200] {subprocess.py:93} INFO - 25/07/11 14:09:14 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 138.4.31.23:43033 in memory (size: 4.2 KiB, free: 434.2 MiB)
[2025-07-11T14:09:15.076+0200] {subprocess.py:93} INFO - 25/07/11 14:09:15 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 138.4.31.23:43033 in memory (size: 9.2 KiB, free: 434.2 MiB)
[2025-07-11T14:09:15.433+0200] {subprocess.py:93} INFO - 25/07/11 14:09:15 INFO Executor: Finished task 1.0 in stage 59.0 (TID 103). 2031 bytes result sent to driver
[2025-07-11T14:09:15.434+0200] {subprocess.py:93} INFO - 25/07/11 14:09:15 INFO TaskSetManager: Finished task 1.0 in stage 59.0 (TID 103) in 2064 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:09:23.834+0200] {subprocess.py:93} INFO - 25/07/11 14:09:23 INFO Executor: Finished task 0.0 in stage 59.0 (TID 102). 2031 bytes result sent to driver
[2025-07-11T14:09:23.834+0200] {subprocess.py:93} INFO - 25/07/11 14:09:23 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 102) in 10464 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:09:23.835+0200] {subprocess.py:93} INFO - 25/07/11 14:09:23 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool
[2025-07-11T14:09:23.837+0200] {subprocess.py:93} INFO - 25/07/11 14:09:23 INFO DAGScheduler: ShuffleMapStage 59 (showString at NativeMethodAccessorImpl.java:0) finished in 10,471 s
[2025-07-11T14:09:23.837+0200] {subprocess.py:93} INFO - 25/07/11 14:09:23 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:09:23.838+0200] {subprocess.py:93} INFO - 25/07/11 14:09:23 INFO DAGScheduler: running: Set()
[2025-07-11T14:09:23.838+0200] {subprocess.py:93} INFO - 25/07/11 14:09:23 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:09:23.838+0200] {subprocess.py:93} INFO - 25/07/11 14:09:23 INFO DAGScheduler: failed: Set()
[2025-07-11T14:09:23.862+0200] {subprocess.py:93} INFO - 25/07/11 14:09:23 INFO ShufflePartitionsUtil: For shuffle(18), advisory target size: 67108864, actual target size 4228400, minimum partition size: 1048576
[2025-07-11T14:09:23.992+0200] {subprocess.py:93} INFO - 25/07/11 14:09:23 INFO CodeGenerator: Code generated in 44.78678 ms
[2025-07-11T14:09:24.051+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2025-07-11T14:09:24.053+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Got job 40 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-07-11T14:09:24.053+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Final stage: ResultStage 64 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:09:24.053+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)
[2025-07-11T14:09:24.053+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:24.053+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[127] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:09:24.067+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 207.0 KiB, free 429.6 MiB)
[2025-07-11T14:09:24.068+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 99.7 KiB, free 429.5 MiB)
[2025-07-11T14:09:24.068+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 138.4.31.23:43033 (size: 99.7 KiB, free: 434.1 MiB)
[2025-07-11T14:09:24.068+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:24.069+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[127] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:09:24.069+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0
[2025-07-11T14:09:24.070+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 118) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14847 bytes)
[2025-07-11T14:09:24.071+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Running task 0.0 in stage 64.0 (TID 118)
[2025-07-11T14:09:24.100+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO ShuffleBlockFetcherIterator: Getting 1 (7.1 MiB) non-empty blocks including 1 (7.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:24.100+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:24.122+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO CodeGenerator: Code generated in 21.697719 ms
[2025-07-11T14:09:24.128+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO CodeGenerator: Code generated in 3.666883 ms
[2025-07-11T14:09:24.148+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO CodeGenerator: Code generated in 6.536584 ms
[2025-07-11T14:09:24.158+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Finished task 0.0 in stage 64.0 (TID 118). 4916 bytes result sent to driver
[2025-07-11T14:09:24.159+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 118) in 89 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:09:24.159+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool
[2025-07-11T14:09:24.159+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: ResultStage 64 (showString at NativeMethodAccessorImpl.java:0) finished in 0,101 s
[2025-07-11T14:09:24.159+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:09:24.159+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished
[2025-07-11T14:09:24.159+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Job 40 finished: showString at NativeMethodAccessorImpl.java:0, took 0,108278 s
[2025-07-11T14:09:24.170+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO CodeGenerator: Code generated in 7.151724 ms
[2025-07-11T14:09:24.173+0200] {subprocess.py:93} INFO - +--------+-------------------+-------------------+----------+---------+---------+--------+----------+---------+--------+--------------+--------------------+
[2025-07-11T14:09:24.174+0200] {subprocess.py:93} INFO - |ArrDelay|         CRSArrTime|         CRSDepTime|DayOfMonth|DayOfWeek|DayOfYear|DepDelay|FlightDate|FlightNum|Distance|ArrDelayBucket|        Features_vec|
[2025-07-11T14:09:24.174+0200] {subprocess.py:93} INFO - +--------+-------------------+-------------------+----------+---------+---------+--------+----------+---------+--------+--------------+--------------------+
[2025-07-11T14:09:24.174+0200] {subprocess.py:93} INFO - |   -19.0|2015-01-01 19:25:00|2015-01-01 16:50:00|         1|        4|        1|     3.0|2015-01-01|       99|  1739.0|           0.0|[3.0,1739.0,1.0,4...|
[2025-07-11T14:09:24.174+0200] {subprocess.py:93} INFO - |    -3.0|2015-01-01 19:40:00|2015-01-01 17:25:00|         1|        4|        1|    -4.0|2015-01-01|     1576|   338.0|           1.0|[-4.0,338.0,1.0,4...|
[2025-07-11T14:09:24.174+0200] {subprocess.py:93} INFO - |   -30.0|2015-01-01 21:20:00|2015-01-01 18:30:00|         1|        4|        1|    -7.0|2015-01-01|      675|  1739.0|           0.0|[-7.0,1739.0,1.0,...|
[2025-07-11T14:09:24.174+0200] {subprocess.py:93} INFO - |    20.0|2015-01-01 06:00:00|2015-01-01 04:07:00|         1|        4|        1|    -3.0|2015-01-01|     1030|  1129.0|           2.0|[-3.0,1129.0,1.0,...|
[2025-07-11T14:09:24.174+0200] {subprocess.py:93} INFO - |    -7.0|2015-01-01 07:13:00|2015-01-01 05:19:00|         1|        4|        1|     4.0|2015-01-01|      730|  1129.0|           1.0|[4.0,1129.0,1.0,4...|
[2025-07-11T14:09:24.174+0200] {subprocess.py:93} INFO - |   -10.0|2015-01-01 14:20:00|2015-01-01 12:05:00|         1|        4|        1|   -12.0|2015-01-01|      634|   857.0|           1.0|[-12.0,857.0,1.0,...|
[2025-07-11T14:09:24.174+0200] {subprocess.py:93} INFO - |    -4.0|2015-01-01 18:45:00|2015-01-01 16:29:00|         1|        4|        1|    -4.0|2015-01-01|      934|   857.0|           1.0|[-4.0,857.0,1.0,4...|
[2025-07-11T14:09:24.174+0200] {subprocess.py:93} INFO - |   -10.0|2015-01-01 21:33:00|2015-01-01 20:35:00|         1|        4|        1|    -5.0|2015-01-01|     1209|   153.0|           1.0|[-5.0,153.0,1.0,4...|
[2025-07-11T14:09:24.174+0200] {subprocess.py:93} INFO - |    -4.0|2015-01-01 15:35:00|2015-01-01 14:41:00|         1|        4|        1|    -2.0|2015-01-01|     1341|   153.0|           1.0|[-2.0,153.0,1.0,4...|
[2025-07-11T14:09:24.174+0200] {subprocess.py:93} INFO - |   -14.0|2015-01-01 12:19:00|2015-01-01 11:25:00|         1|        4|        1|    -4.0|2015-01-01|     5107|   153.0|           1.0|[-4.0,153.0,1.0,4...|
[2025-07-11T14:09:24.174+0200] {subprocess.py:93} INFO - |   -10.0|2015-01-01 18:31:00|2015-01-01 17:36:00|         1|        4|        1|    -5.0|2015-01-01|     5248|   153.0|           1.0|[-5.0,153.0,1.0,4...|
[2025-07-11T14:09:24.174+0200] {subprocess.py:93} INFO - |    86.0|2015-01-01 19:42:00|2015-01-01 19:08:00|         1|        4|        1|    91.0|2015-01-01|     4601|   456.0|           3.0|[91.0,456.0,1.0,4...|
[2025-07-11T14:09:24.174+0200] {subprocess.py:93} INFO - |   152.0|2015-01-01 15:36:00|2015-01-01 15:01:00|         1|        4|        1|   151.0|2015-01-01|     5997|   456.0|           3.0|[151.0,456.0,1.0,...|
[2025-07-11T14:09:24.175+0200] {subprocess.py:93} INFO - |    20.0|2015-01-01 10:08:00|2015-01-01 09:31:00|         1|        4|        1|     5.0|2015-01-01|     6184|   456.0|           2.0|[5.0,456.0,1.0,4....|
[2025-07-11T14:09:24.175+0200] {subprocess.py:93} INFO - |    -9.0|2015-01-01 10:30:00|2015-01-01 08:15:00|         1|        4|        1|    -7.0|2015-01-01|     4134|   643.0|           1.0|[-7.0,643.0,1.0,4...|
[2025-07-11T14:09:24.175+0200] {subprocess.py:93} INFO - |    18.0|2015-01-01 17:02:00|2015-01-01 14:55:00|         1|        4|        1|    -5.0|2015-01-01|     4178|   643.0|           2.0|[-5.0,643.0,1.0,4...|
[2025-07-11T14:09:24.175+0200] {subprocess.py:93} INFO - |     8.0|2015-01-01 13:10:00|2015-01-01 11:00:00|         1|        4|        1|    -5.0|2015-01-01|     4497|   643.0|           2.0|[-5.0,643.0,1.0,4...|
[2025-07-11T14:09:24.175+0200] {subprocess.py:93} INFO - |    10.0|2015-01-01 19:12:00|2015-01-01 17:06:00|         1|        4|        1|    -6.0|2015-01-01|     4550|   643.0|           2.0|[-6.0,643.0,1.0,4...|
[2025-07-11T14:09:24.175+0200] {subprocess.py:93} INFO - |     1.0|2015-01-01 09:05:00|2015-01-01 06:50:00|         1|        4|        1|    -2.0|2015-01-01|     4555|   643.0|           2.0|[-2.0,643.0,1.0,4...|
[2025-07-11T14:09:24.175+0200] {subprocess.py:93} INFO - |     4.0|2015-01-01 21:50:00|2015-01-01 19:10:00|         1|        4|        1|     2.0|2015-01-01|     1277|   861.0|           2.0|[2.0,861.0,1.0,4....|
[2025-07-11T14:09:24.175+0200] {subprocess.py:93} INFO - +--------+-------------------+-------------------+----------+---------+---------+--------+----------+---------+--------+--------------+--------------------+
[2025-07-11T14:09:24.175+0200] {subprocess.py:93} INFO - only showing top 20 rows
[2025-07-11T14:09:24.175+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:09:24.265+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Instrumentation: [d7c1ea9d] Stage class: RandomForestClassifier
[2025-07-11T14:09:24.265+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Instrumentation: [d7c1ea9d] Stage uid: RandomForestClassifier_6425afc2c8a8
[2025-07-11T14:09:24.298+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO V2ScanRelationPushDown:
[2025-07-11T14:09:24.298+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:09:24.298+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:09:24.298+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:09:24.298+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:09:24.305+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO V2ScanRelationPushDown:
[2025-07-11T14:09:24.305+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-11T14:09:24.306+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:09:24.331+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:09:24.331+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:09:24.352+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 214.5 KiB, free 429.3 MiB)
[2025-07-11T14:09:24.360+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 429.2 MiB)
[2025-07-11T14:09:24.360+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 138.4.31.23:43033 (size: 38.9 KiB, free: 434.1 MiB)
[2025-07-11T14:09:24.361+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO SparkContext: Created broadcast 52 from rdd at Instrumentation.scala:62
[2025-07-11T14:09:24.362+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:09:24.367+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Registering RDD 131 (rdd at Instrumentation.scala:62) as input to shuffle 20
[2025-07-11T14:09:24.368+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Got map stage job 41 (rdd at Instrumentation.scala:62) with 2 output partitions
[2025-07-11T14:09:24.368+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Final stage: ShuffleMapStage 65 (rdd at Instrumentation.scala:62)
[2025-07-11T14:09:24.368+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:09:24.368+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:24.368+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[131] at rdd at Instrumentation.scala:62), which has no missing parents
[2025-07-11T14:09:24.370+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 22.8 KiB, free 429.2 MiB)
[2025-07-11T14:09:24.371+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 429.2 MiB)
[2025-07-11T14:09:24.371+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 138.4.31.23:43033 (size: 9.9 KiB, free: 434.1 MiB)
[2025-07-11T14:09:24.372+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:24.372+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[131] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:09:24.372+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSchedulerImpl: Adding task set 65.0 with 2 tasks resource profile 0
[2025-07-11T14:09:24.374+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 119) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:09:24.374+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Starting task 1.0 in stage 65.0 (TID 120) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:09:24.374+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Running task 0.0 in stage 65.0 (TID 119)
[2025-07-11T14:09:24.374+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Registering RDD 135 (rdd at Instrumentation.scala:62) as input to shuffle 21
[2025-07-11T14:09:24.374+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Running task 1.0 in stage 65.0 (TID 120)
[2025-07-11T14:09:24.374+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Got map stage job 42 (rdd at Instrumentation.scala:62) with 13 output partitions
[2025-07-11T14:09:24.374+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Final stage: ShuffleMapStage 66 (rdd at Instrumentation.scala:62)
[2025-07-11T14:09:24.374+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:09:24.375+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:24.375+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Submitting ShuffleMapStage 66 (MapPartitionsRDD[135] at rdd at Instrumentation.scala:62), which has no missing parents
[2025-07-11T14:09:24.377+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 18.7 KiB, free 429.2 MiB)
[2025-07-11T14:09:24.379+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:09:24.379+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:09:24.381+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 429.2 MiB)
[2025-07-11T14:09:24.382+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 138.4.31.23:43033 (size: 9.2 KiB, free: 434.1 MiB)
[2025-07-11T14:09:24.382+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:24.383+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[135] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-11T14:09:24.383+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSchedulerImpl: Adding task set 66.0 with 13 tasks resource profile 0
[2025-07-11T14:09:24.385+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 121) (138.4.31.23, executor driver, partition 0, ANY, 16719 bytes)
[2025-07-11T14:09:24.385+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Starting task 1.0 in stage 66.0 (TID 122) (138.4.31.23, executor driver, partition 1, ANY, 16719 bytes)
[2025-07-11T14:09:24.386+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Running task 1.0 in stage 66.0 (TID 122)
[2025-07-11T14:09:24.386+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Running task 0.0 in stage 66.0 (TID 121)
[2025-07-11T14:09:24.412+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 138.4.31.23:43033 in memory (size: 99.7 KiB, free: 434.2 MiB)
[2025-07-11T14:09:24.460+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Finished task 1.0 in stage 66.0 (TID 122). 1988 bytes result sent to driver
[2025-07-11T14:09:24.470+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Starting task 2.0 in stage 66.0 (TID 123) (138.4.31.23, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-11T14:09:24.470+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Running task 2.0 in stage 66.0 (TID 123)
[2025-07-11T14:09:24.470+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Finished task 1.0 in stage 66.0 (TID 122) in 85 ms on 138.4.31.23 (executor driver) (1/13)
[2025-07-11T14:09:24.472+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Finished task 0.0 in stage 66.0 (TID 121). 1988 bytes result sent to driver
[2025-07-11T14:09:24.473+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Starting task 3.0 in stage 66.0 (TID 124) (138.4.31.23, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-11T14:09:24.473+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 121) in 89 ms on 138.4.31.23 (executor driver) (2/13)
[2025-07-11T14:09:24.474+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Running task 3.0 in stage 66.0 (TID 124)
[2025-07-11T14:09:24.538+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Finished task 2.0 in stage 66.0 (TID 123). 1945 bytes result sent to driver
[2025-07-11T14:09:24.544+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Starting task 4.0 in stage 66.0 (TID 125) (138.4.31.23, executor driver, partition 4, ANY, 16839 bytes)
[2025-07-11T14:09:24.544+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Finished task 2.0 in stage 66.0 (TID 123) in 75 ms on 138.4.31.23 (executor driver) (3/13)
[2025-07-11T14:09:24.545+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Running task 4.0 in stage 66.0 (TID 125)
[2025-07-11T14:09:24.545+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Finished task 3.0 in stage 66.0 (TID 124). 1945 bytes result sent to driver
[2025-07-11T14:09:24.546+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Starting task 5.0 in stage 66.0 (TID 126) (138.4.31.23, executor driver, partition 5, ANY, 16839 bytes)
[2025-07-11T14:09:24.547+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Finished task 3.0 in stage 66.0 (TID 124) in 74 ms on 138.4.31.23 (executor driver) (4/13)
[2025-07-11T14:09:24.547+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Running task 5.0 in stage 66.0 (TID 126)
[2025-07-11T14:09:24.604+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Finished task 4.0 in stage 66.0 (TID 125). 1945 bytes result sent to driver
[2025-07-11T14:09:24.606+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Starting task 6.0 in stage 66.0 (TID 127) (138.4.31.23, executor driver, partition 6, ANY, 16719 bytes)
[2025-07-11T14:09:24.607+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Finished task 4.0 in stage 66.0 (TID 125) in 64 ms on 138.4.31.23 (executor driver) (5/13)
[2025-07-11T14:09:24.608+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Finished task 5.0 in stage 66.0 (TID 126). 1945 bytes result sent to driver
[2025-07-11T14:09:24.609+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Running task 6.0 in stage 66.0 (TID 127)
[2025-07-11T14:09:24.610+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Starting task 7.0 in stage 66.0 (TID 128) (138.4.31.23, executor driver, partition 7, ANY, 16715 bytes)
[2025-07-11T14:09:24.610+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Finished task 5.0 in stage 66.0 (TID 126) in 63 ms on 138.4.31.23 (executor driver) (6/13)
[2025-07-11T14:09:24.610+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Running task 7.0 in stage 66.0 (TID 128)
[2025-07-11T14:09:24.692+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Finished task 7.0 in stage 66.0 (TID 128). 2031 bytes result sent to driver
[2025-07-11T14:09:24.693+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Starting task 8.0 in stage 66.0 (TID 129) (138.4.31.23, executor driver, partition 8, ANY, 16719 bytes)
[2025-07-11T14:09:24.693+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Running task 8.0 in stage 66.0 (TID 129)
[2025-07-11T14:09:24.694+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Finished task 7.0 in stage 66.0 (TID 128) in 86 ms on 138.4.31.23 (executor driver) (7/13)
[2025-07-11T14:09:24.697+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Finished task 6.0 in stage 66.0 (TID 127). 1988 bytes result sent to driver
[2025-07-11T14:09:24.699+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Starting task 9.0 in stage 66.0 (TID 130) (138.4.31.23, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-11T14:09:24.699+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Finished task 6.0 in stage 66.0 (TID 127) in 93 ms on 138.4.31.23 (executor driver) (8/13)
[2025-07-11T14:09:24.699+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Running task 9.0 in stage 66.0 (TID 130)
[2025-07-11T14:09:24.750+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Finished task 9.0 in stage 66.0 (TID 130). 1945 bytes result sent to driver
[2025-07-11T14:09:24.751+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Starting task 10.0 in stage 66.0 (TID 131) (138.4.31.23, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-11T14:09:24.751+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Finished task 9.0 in stage 66.0 (TID 130) in 54 ms on 138.4.31.23 (executor driver) (9/13)
[2025-07-11T14:09:24.751+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Running task 10.0 in stage 66.0 (TID 131)
[2025-07-11T14:09:24.762+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Finished task 8.0 in stage 66.0 (TID 129). 1945 bytes result sent to driver
[2025-07-11T14:09:24.764+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Starting task 11.0 in stage 66.0 (TID 132) (138.4.31.23, executor driver, partition 11, ANY, 16839 bytes)
[2025-07-11T14:09:24.765+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Finished task 8.0 in stage 66.0 (TID 129) in 71 ms on 138.4.31.23 (executor driver) (10/13)
[2025-07-11T14:09:24.766+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Running task 11.0 in stage 66.0 (TID 132)
[2025-07-11T14:09:24.842+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Finished task 10.0 in stage 66.0 (TID 131). 1988 bytes result sent to driver
[2025-07-11T14:09:24.844+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Starting task 12.0 in stage 66.0 (TID 133) (138.4.31.23, executor driver, partition 12, ANY, 16719 bytes)
[2025-07-11T14:09:24.844+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Finished task 10.0 in stage 66.0 (TID 131) in 93 ms on 138.4.31.23 (executor driver) (11/13)
[2025-07-11T14:09:24.847+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Running task 12.0 in stage 66.0 (TID 133)
[2025-07-11T14:09:24.862+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Finished task 11.0 in stage 66.0 (TID 132). 1945 bytes result sent to driver
[2025-07-11T14:09:24.863+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Finished task 11.0 in stage 66.0 (TID 132) in 100 ms on 138.4.31.23 (executor driver) (12/13)
[2025-07-11T14:09:24.898+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Finished task 12.0 in stage 66.0 (TID 133). 1945 bytes result sent to driver
[2025-07-11T14:09:24.899+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Finished task 12.0 in stage 66.0 (TID 133) in 55 ms on 138.4.31.23 (executor driver) (13/13)
[2025-07-11T14:09:24.899+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool
[2025-07-11T14:09:24.900+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: ShuffleMapStage 66 (rdd at Instrumentation.scala:62) finished in 0,523 s
[2025-07-11T14:09:24.900+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:09:24.900+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: running: Set(ShuffleMapStage 65)
[2025-07-11T14:09:24.900+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:09:24.900+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: failed: Set()
[2025-07-11T14:09:24.919+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 138.4.31.23:43033 in memory (size: 109.4 KiB, free: 434.3 MiB)
[2025-07-11T14:09:24.921+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 138.4.31.23:43033 in memory (size: 38.9 KiB, free: 434.3 MiB)
[2025-07-11T14:09:24.923+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 138.4.31.23:43033 in memory (size: 9.9 KiB, free: 434.3 MiB)
[2025-07-11T14:09:24.938+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:09:24.973+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:09:24.974+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Got job 43 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-11T14:09:24.975+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Final stage: ResultStage 68 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-11T14:09:24.975+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67)
[2025-07-11T14:09:24.975+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:24.975+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[137] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-11T14:09:24.976+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 8.2 KiB, free 434.1 MiB)
[2025-07-11T14:09:24.977+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 434.1 MiB)
[2025-07-11T14:09:24.977+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 138.4.31.23:43033 (size: 4.2 KiB, free: 434.3 MiB)
[2025-07-11T14:09:24.978+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:24.978+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[137] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:09:24.978+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks resource profile 0
[2025-07-11T14:09:24.979+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 134) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-11T14:09:24.986+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO Executor: Running task 0.0 in stage 68.0 (TID 134)
[2025-07-11T14:09:24.989+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO ShuffleBlockFetcherIterator: Getting 13 (221.8 KiB) non-empty blocks including 13 (221.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:24.990+0200] {subprocess.py:93} INFO - 25/07/11 14:09:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-11T14:09:25.013+0200] {subprocess.py:93} INFO - 25/07/11 14:09:25 INFO Executor: Finished task 0.0 in stage 68.0 (TID 134). 51149 bytes result sent to driver
[2025-07-11T14:09:25.014+0200] {subprocess.py:93} INFO - 25/07/11 14:09:25 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 134) in 34 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:09:25.014+0200] {subprocess.py:93} INFO - 25/07/11 14:09:25 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool
[2025-07-11T14:09:25.014+0200] {subprocess.py:93} INFO - 25/07/11 14:09:25 INFO DAGScheduler: ResultStage 68 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,039 s
[2025-07-11T14:09:25.015+0200] {subprocess.py:93} INFO - 25/07/11 14:09:25 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:09:25.015+0200] {subprocess.py:93} INFO - 25/07/11 14:09:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 68: Stage finished
[2025-07-11T14:09:25.020+0200] {subprocess.py:93} INFO - 25/07/11 14:09:25 INFO DAGScheduler: Job 43 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,044334 s
[2025-07-11T14:09:25.026+0200] {subprocess.py:93} INFO - 25/07/11 14:09:25 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 138.4.31.23:43033 in memory (size: 4.2 KiB, free: 434.3 MiB)
[2025-07-11T14:09:25.027+0200] {subprocess.py:93} INFO - 25/07/11 14:09:25 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 4.3 MiB, free 429.8 MiB)
[2025-07-11T14:09:25.030+0200] {subprocess.py:93} INFO - 25/07/11 14:09:25 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 109.4 KiB, free 429.7 MiB)
[2025-07-11T14:09:25.031+0200] {subprocess.py:93} INFO - 25/07/11 14:09:25 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 138.4.31.23:43033 (size: 109.4 KiB, free: 434.2 MiB)
[2025-07-11T14:09:25.031+0200] {subprocess.py:93} INFO - 25/07/11 14:09:25 INFO SparkContext: Created broadcast 56 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:09:25.963+0200] {subprocess.py:93} INFO - 25/07/11 14:09:25 INFO Executor: Finished task 1.0 in stage 65.0 (TID 120). 2074 bytes result sent to driver
[2025-07-11T14:09:25.965+0200] {subprocess.py:93} INFO - 25/07/11 14:09:25 INFO TaskSetManager: Finished task 1.0 in stage 65.0 (TID 120) in 1591 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:09:26.064+0200] {subprocess.py:93} INFO - 25/07/11 14:09:26 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 138.4.31.23:43033 in memory (size: 9.2 KiB, free: 434.2 MiB)
[2025-07-11T14:09:34.292+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Finished task 0.0 in stage 65.0 (TID 119). 2031 bytes result sent to driver
[2025-07-11T14:09:34.293+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 119) in 9919 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:09:34.293+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool
[2025-07-11T14:09:34.293+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO DAGScheduler: ShuffleMapStage 65 (rdd at Instrumentation.scala:62) finished in 9,926 s
[2025-07-11T14:09:34.293+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:09:34.293+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO DAGScheduler: running: Set()
[2025-07-11T14:09:34.293+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:09:34.293+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO DAGScheduler: failed: Set()
[2025-07-11T14:09:34.304+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 4228400, minimum partition size: 1048576
[2025-07-11T14:09:34.338+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO CodeGenerator: Code generated in 18.887325 ms
[2025-07-11T14:09:34.349+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Instrumentation: [d7c1ea9d] training: numPartitions=4 storageLevel=StorageLevel(1 replicas)
[2025-07-11T14:09:34.419+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO V2ScanRelationPushDown:
[2025-07-11T14:09:34.419+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:09:34.419+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:09:34.419+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:09:34.419+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:09:34.425+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO V2ScanRelationPushDown:
[2025-07-11T14:09:34.425+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-11T14:09:34.425+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:09:34.451+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:09:34.451+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:09:34.475+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO CodeGenerator: Code generated in 8.339749 ms
[2025-07-11T14:09:34.479+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 214.5 KiB, free 429.6 MiB)
[2025-07-11T14:09:34.488+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 429.5 MiB)
[2025-07-11T14:09:34.488+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 138.4.31.23:43033 (size: 38.9 KiB, free: 434.2 MiB)
[2025-07-11T14:09:34.488+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO SparkContext: Created broadcast 57 from rdd at RandomForestClassifier.scala:155
[2025-07-11T14:09:34.490+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:09:34.495+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO DAGScheduler: Registering RDD 146 (rdd at RandomForestClassifier.scala:155) as input to shuffle 22
[2025-07-11T14:09:34.495+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO DAGScheduler: Got map stage job 44 (rdd at RandomForestClassifier.scala:155) with 2 output partitions
[2025-07-11T14:09:34.495+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO DAGScheduler: Final stage: ShuffleMapStage 69 (rdd at RandomForestClassifier.scala:155)
[2025-07-11T14:09:34.495+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:09:34.495+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:34.495+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO DAGScheduler: Submitting ShuffleMapStage 69 (MapPartitionsRDD[146] at rdd at RandomForestClassifier.scala:155), which has no missing parents
[2025-07-11T14:09:34.496+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 20.7 KiB, free 429.5 MiB)
[2025-07-11T14:09:34.498+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 9.3 KiB, free 429.5 MiB)
[2025-07-11T14:09:34.498+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 138.4.31.23:43033 (size: 9.3 KiB, free: 434.2 MiB)
[2025-07-11T14:09:34.500+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:34.501+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 69 (MapPartitionsRDD[146] at rdd at RandomForestClassifier.scala:155) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:09:34.501+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSchedulerImpl: Adding task set 69.0 with 2 tasks resource profile 0
[2025-07-11T14:09:34.501+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 135) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:09:34.501+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 136) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:09:34.501+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Running task 1.0 in stage 69.0 (TID 136)
[2025-07-11T14:09:34.501+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Running task 0.0 in stage 69.0 (TID 135)
[2025-07-11T14:09:34.502+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO DAGScheduler: Registering RDD 150 (rdd at RandomForestClassifier.scala:155) as input to shuffle 23
[2025-07-11T14:09:34.503+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO DAGScheduler: Got map stage job 45 (rdd at RandomForestClassifier.scala:155) with 13 output partitions
[2025-07-11T14:09:34.503+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO DAGScheduler: Final stage: ShuffleMapStage 70 (rdd at RandomForestClassifier.scala:155)
[2025-07-11T14:09:34.504+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:09:34.504+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:34.505+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO DAGScheduler: Submitting ShuffleMapStage 70 (MapPartitionsRDD[150] at rdd at RandomForestClassifier.scala:155), which has no missing parents
[2025-07-11T14:09:34.507+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 18.7 KiB, free 429.5 MiB)
[2025-07-11T14:09:34.508+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 429.5 MiB)
[2025-07-11T14:09:34.508+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 138.4.31.23:43033 (size: 9.2 KiB, free: 434.2 MiB)
[2025-07-11T14:09:34.509+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:34.509+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[150] at rdd at RandomForestClassifier.scala:155) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-11T14:09:34.509+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSchedulerImpl: Adding task set 70.0 with 13 tasks resource profile 0
[2025-07-11T14:09:34.512+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 137) (138.4.31.23, executor driver, partition 0, ANY, 16715 bytes)
[2025-07-11T14:09:34.513+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO CodeGenerator: Code generated in 7.288761 ms
[2025-07-11T14:09:34.513+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Starting task 1.0 in stage 70.0 (TID 138) (138.4.31.23, executor driver, partition 1, ANY, 16719 bytes)
[2025-07-11T14:09:34.513+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Running task 0.0 in stage 70.0 (TID 137)
[2025-07-11T14:09:34.513+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Running task 1.0 in stage 70.0 (TID 138)
[2025-07-11T14:09:34.549+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO CodeGenerator: Code generated in 33.859612 ms
[2025-07-11T14:09:34.551+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:09:34.553+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:09:34.566+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Finished task 0.0 in stage 70.0 (TID 137). 2031 bytes result sent to driver
[2025-07-11T14:09:34.567+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO CodeGenerator: Code generated in 12.74917 ms
[2025-07-11T14:09:34.567+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Starting task 2.0 in stage 70.0 (TID 139) (138.4.31.23, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-11T14:09:34.568+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 137) in 57 ms on 138.4.31.23 (executor driver) (1/13)
[2025-07-11T14:09:34.577+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Running task 2.0 in stage 70.0 (TID 139)
[2025-07-11T14:09:34.583+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Finished task 1.0 in stage 70.0 (TID 138). 1988 bytes result sent to driver
[2025-07-11T14:09:34.584+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Starting task 3.0 in stage 70.0 (TID 140) (138.4.31.23, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-11T14:09:34.584+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Finished task 1.0 in stage 70.0 (TID 138) in 72 ms on 138.4.31.23 (executor driver) (2/13)
[2025-07-11T14:09:34.584+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Running task 3.0 in stage 70.0 (TID 140)
[2025-07-11T14:09:34.640+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Finished task 2.0 in stage 70.0 (TID 139). 1945 bytes result sent to driver
[2025-07-11T14:09:34.641+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Starting task 4.0 in stage 70.0 (TID 141) (138.4.31.23, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-11T14:09:34.642+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Finished task 2.0 in stage 70.0 (TID 139) in 75 ms on 138.4.31.23 (executor driver) (3/13)
[2025-07-11T14:09:34.642+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Running task 4.0 in stage 70.0 (TID 141)
[2025-07-11T14:09:34.681+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Finished task 3.0 in stage 70.0 (TID 140). 1945 bytes result sent to driver
[2025-07-11T14:09:34.682+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Starting task 5.0 in stage 70.0 (TID 142) (138.4.31.23, executor driver, partition 5, ANY, 16719 bytes)
[2025-07-11T14:09:34.682+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Running task 5.0 in stage 70.0 (TID 142)
[2025-07-11T14:09:34.682+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Finished task 3.0 in stage 70.0 (TID 140) in 99 ms on 138.4.31.23 (executor driver) (4/13)
[2025-07-11T14:09:34.748+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Finished task 4.0 in stage 70.0 (TID 141). 1945 bytes result sent to driver
[2025-07-11T14:09:34.749+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Starting task 6.0 in stage 70.0 (TID 143) (138.4.31.23, executor driver, partition 6, ANY, 16839 bytes)
[2025-07-11T14:09:34.750+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Running task 6.0 in stage 70.0 (TID 143)
[2025-07-11T14:09:34.750+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Finished task 4.0 in stage 70.0 (TID 141) in 109 ms on 138.4.31.23 (executor driver) (5/13)
[2025-07-11T14:09:34.750+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Finished task 5.0 in stage 70.0 (TID 142). 1945 bytes result sent to driver
[2025-07-11T14:09:34.751+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Starting task 7.0 in stage 70.0 (TID 144) (138.4.31.23, executor driver, partition 7, ANY, 16839 bytes)
[2025-07-11T14:09:34.751+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Running task 7.0 in stage 70.0 (TID 144)
[2025-07-11T14:09:34.752+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Finished task 5.0 in stage 70.0 (TID 142) in 70 ms on 138.4.31.23 (executor driver) (6/13)
[2025-07-11T14:09:34.815+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 138.4.31.23:43033 in memory (size: 9.9 KiB, free: 434.2 MiB)
[2025-07-11T14:09:34.823+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Finished task 6.0 in stage 70.0 (TID 143). 1945 bytes result sent to driver
[2025-07-11T14:09:34.825+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Starting task 8.0 in stage 70.0 (TID 145) (138.4.31.23, executor driver, partition 8, ANY, 16839 bytes)
[2025-07-11T14:09:34.825+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Finished task 6.0 in stage 70.0 (TID 143) in 77 ms on 138.4.31.23 (executor driver) (7/13)
[2025-07-11T14:09:34.829+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Running task 8.0 in stage 70.0 (TID 145)
[2025-07-11T14:09:34.849+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Finished task 7.0 in stage 70.0 (TID 144). 1988 bytes result sent to driver
[2025-07-11T14:09:34.850+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Starting task 9.0 in stage 70.0 (TID 146) (138.4.31.23, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-11T14:09:34.851+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Finished task 7.0 in stage 70.0 (TID 144) in 101 ms on 138.4.31.23 (executor driver) (8/13)
[2025-07-11T14:09:34.851+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Running task 9.0 in stage 70.0 (TID 146)
[2025-07-11T14:09:34.913+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Finished task 8.0 in stage 70.0 (TID 145). 1945 bytes result sent to driver
[2025-07-11T14:09:34.915+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Starting task 10.0 in stage 70.0 (TID 147) (138.4.31.23, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-11T14:09:34.915+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Running task 10.0 in stage 70.0 (TID 147)
[2025-07-11T14:09:34.916+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Finished task 8.0 in stage 70.0 (TID 145) in 90 ms on 138.4.31.23 (executor driver) (9/13)
[2025-07-11T14:09:34.924+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Finished task 9.0 in stage 70.0 (TID 146). 1945 bytes result sent to driver
[2025-07-11T14:09:34.934+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Starting task 11.0 in stage 70.0 (TID 148) (138.4.31.23, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-11T14:09:34.934+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO Executor: Running task 11.0 in stage 70.0 (TID 148)
[2025-07-11T14:09:34.934+0200] {subprocess.py:93} INFO - 25/07/11 14:09:34 INFO TaskSetManager: Finished task 9.0 in stage 70.0 (TID 146) in 72 ms on 138.4.31.23 (executor driver) (10/13)
[2025-07-11T14:09:35.150+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO Executor: Finished task 10.0 in stage 70.0 (TID 147). 1945 bytes result sent to driver
[2025-07-11T14:09:35.150+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO Executor: Finished task 11.0 in stage 70.0 (TID 148). 1945 bytes result sent to driver
[2025-07-11T14:09:35.155+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO TaskSetManager: Starting task 12.0 in stage 70.0 (TID 149) (138.4.31.23, executor driver, partition 12, ANY, 16719 bytes)
[2025-07-11T14:09:35.156+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO TaskSetManager: Finished task 10.0 in stage 70.0 (TID 147) in 242 ms on 138.4.31.23 (executor driver) (11/13)
[2025-07-11T14:09:35.157+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO TaskSetManager: Finished task 11.0 in stage 70.0 (TID 148) in 235 ms on 138.4.31.23 (executor driver) (12/13)
[2025-07-11T14:09:35.160+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO Executor: Running task 12.0 in stage 70.0 (TID 149)
[2025-07-11T14:09:35.271+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO Executor: Finished task 12.0 in stage 70.0 (TID 149). 1988 bytes result sent to driver
[2025-07-11T14:09:35.272+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO TaskSetManager: Finished task 12.0 in stage 70.0 (TID 149) in 121 ms on 138.4.31.23 (executor driver) (13/13)
[2025-07-11T14:09:35.272+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool
[2025-07-11T14:09:35.272+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO DAGScheduler: ShuffleMapStage 70 (rdd at RandomForestClassifier.scala:155) finished in 0,766 s
[2025-07-11T14:09:35.272+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:09:35.272+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO DAGScheduler: running: Set(ShuffleMapStage 69)
[2025-07-11T14:09:35.272+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:09:35.272+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO DAGScheduler: failed: Set()
[2025-07-11T14:09:35.340+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO ShufflePartitionsUtil: For shuffle(23), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:09:35.352+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:09:35.352+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO DAGScheduler: Got job 46 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-11T14:09:35.352+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO DAGScheduler: Final stage: ResultStage 72 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-11T14:09:35.352+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 71)
[2025-07-11T14:09:35.352+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:35.352+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[152] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-11T14:09:35.353+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 8.2 KiB, free 429.5 MiB)
[2025-07-11T14:09:35.355+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 429.5 MiB)
[2025-07-11T14:09:35.356+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 138.4.31.23:43033 (size: 4.2 KiB, free: 434.2 MiB)
[2025-07-11T14:09:35.356+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:35.356+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[152] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:09:35.356+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks resource profile 0
[2025-07-11T14:09:35.356+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 150) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-11T14:09:35.356+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO Executor: Running task 0.0 in stage 72.0 (TID 150)
[2025-07-11T14:09:35.364+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO ShuffleBlockFetcherIterator: Getting 13 (221.8 KiB) non-empty blocks including 13 (221.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:35.365+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-11T14:09:35.392+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO Executor: Finished task 0.0 in stage 72.0 (TID 150). 51242 bytes result sent to driver
[2025-07-11T14:09:35.392+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 150) in 36 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:09:35.393+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool
[2025-07-11T14:09:35.395+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO DAGScheduler: ResultStage 72 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,043 s
[2025-07-11T14:09:35.395+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:09:35.396+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished
[2025-07-11T14:09:35.396+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO DAGScheduler: Job 46 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,045086 s
[2025-07-11T14:09:35.414+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 4.3 MiB, free 425.2 MiB)
[2025-07-11T14:09:35.419+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 109.4 KiB, free 425.1 MiB)
[2025-07-11T14:09:35.419+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 138.4.31.23:43033 (size: 109.4 KiB, free: 434.1 MiB)
[2025-07-11T14:09:35.420+0200] {subprocess.py:93} INFO - 25/07/11 14:09:35 INFO SparkContext: Created broadcast 61 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:09:36.059+0200] {subprocess.py:93} INFO - 25/07/11 14:09:36 INFO Executor: Finished task 1.0 in stage 69.0 (TID 136). 2031 bytes result sent to driver
[2025-07-11T14:09:36.061+0200] {subprocess.py:93} INFO - 25/07/11 14:09:36 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 136) in 1560 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:09:36.445+0200] {subprocess.py:93} INFO - 25/07/11 14:09:36 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 138.4.31.23:43033 in memory (size: 4.2 KiB, free: 434.1 MiB)
[2025-07-11T14:09:40.035+0200] {subprocess.py:93} INFO - 25/07/11 14:09:40 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 138.4.31.23:43033 in memory (size: 9.2 KiB, free: 434.1 MiB)
[2025-07-11T14:09:42.475+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO Executor: Finished task 0.0 in stage 69.0 (TID 135). 2031 bytes result sent to driver
[2025-07-11T14:09:42.476+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 135) in 7977 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:09:42.476+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool
[2025-07-11T14:09:42.476+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO DAGScheduler: ShuffleMapStage 69 (rdd at RandomForestClassifier.scala:155) finished in 7,981 s
[2025-07-11T14:09:42.476+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:09:42.476+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO DAGScheduler: running: Set()
[2025-07-11T14:09:42.477+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:09:42.477+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO DAGScheduler: failed: Set()
[2025-07-11T14:09:42.487+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1923052, minimum partition size: 1048576
[2025-07-11T14:09:42.541+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO CodeGenerator: Code generated in 30.938508 ms
[2025-07-11T14:09:42.559+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO Instrumentation: [d7c1ea9d] {"featuresCol":"Features_vec","labelCol":"ArrDelayBucket","predictionCol":"Prediction","maxMemoryInMB":1024,"maxBins":4657,"numTrees":10}
[2025-07-11T14:09:42.593+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:119
[2025-07-11T14:09:42.593+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO DAGScheduler: Got job 47 (take at DecisionTreeMetadata.scala:119) with 1 output partitions
[2025-07-11T14:09:42.593+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO DAGScheduler: Final stage: ResultStage 74 (take at DecisionTreeMetadata.scala:119)
[2025-07-11T14:09:42.593+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)
[2025-07-11T14:09:42.593+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:42.593+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[160] at map at DecisionTreeMetadata.scala:119), which has no missing parents
[2025-07-11T14:09:42.598+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 278.1 KiB, free 424.9 MiB)
[2025-07-11T14:09:42.599+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 126.8 KiB, free 424.8 MiB)
[2025-07-11T14:09:42.600+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 138.4.31.23:43033 (size: 126.8 KiB, free: 434.0 MiB)
[2025-07-11T14:09:42.600+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:42.601+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[160] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:09:42.601+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0
[2025-07-11T14:09:42.602+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 151) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14847 bytes)
[2025-07-11T14:09:42.603+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO Executor: Running task 0.0 in stage 74.0 (TID 151)
[2025-07-11T14:09:42.639+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO ShuffleBlockFetcherIterator: Getting 1 (3.2 MiB) non-empty blocks including 1 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:42.639+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:42.681+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO CodeGenerator: Code generated in 41.195742 ms
[2025-07-11T14:09:42.695+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO CodeGenerator: Code generated in 11.188603 ms
[2025-07-11T14:09:42.714+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO CodeGenerator: Code generated in 6.782046 ms
[2025-07-11T14:09:42.716+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO Executor: Finished task 0.0 in stage 74.0 (TID 151). 5038 bytes result sent to driver
[2025-07-11T14:09:42.717+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 151) in 115 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:09:42.717+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool
[2025-07-11T14:09:42.718+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO DAGScheduler: ResultStage 74 (take at DecisionTreeMetadata.scala:119) finished in 0,123 s
[2025-07-11T14:09:42.719+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:09:42.722+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished
[2025-07-11T14:09:42.722+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO DAGScheduler: Job 47 finished: take at DecisionTreeMetadata.scala:119, took 0,125336 s
[2025-07-11T14:09:42.729+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125
[2025-07-11T14:09:42.731+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO DAGScheduler: Got job 48 (aggregate at DecisionTreeMetadata.scala:125) with 4 output partitions
[2025-07-11T14:09:42.731+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO DAGScheduler: Final stage: ResultStage 76 (aggregate at DecisionTreeMetadata.scala:125)
[2025-07-11T14:09:42.732+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)
[2025-07-11T14:09:42.732+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:42.732+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[159] at retag at RandomForest.scala:274), which has no missing parents
[2025-07-11T14:09:42.737+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 278.2 KiB, free 424.5 MiB)
[2025-07-11T14:09:42.739+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 126.9 KiB, free 424.4 MiB)
[2025-07-11T14:09:42.740+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 138.4.31.23:43033 (size: 126.9 KiB, free: 433.9 MiB)
[2025-07-11T14:09:42.740+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:42.741+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 76 (MapPartitionsRDD[159] at retag at RandomForest.scala:274) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:09:42.741+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO TaskSchedulerImpl: Adding task set 76.0 with 4 tasks resource profile 0
[2025-07-11T14:09:42.743+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 152) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14847 bytes)
[2025-07-11T14:09:42.743+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO TaskSetManager: Starting task 1.0 in stage 76.0 (TID 153) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14847 bytes)
[2025-07-11T14:09:42.743+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO TaskSetManager: Starting task 2.0 in stage 76.0 (TID 154) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14847 bytes)
[2025-07-11T14:09:42.743+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO TaskSetManager: Starting task 3.0 in stage 76.0 (TID 155) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14847 bytes)
[2025-07-11T14:09:42.743+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO Executor: Running task 1.0 in stage 76.0 (TID 153)
[2025-07-11T14:09:42.743+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO Executor: Running task 2.0 in stage 76.0 (TID 154)
[2025-07-11T14:09:42.743+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO Executor: Running task 0.0 in stage 76.0 (TID 152)
[2025-07-11T14:09:42.744+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO Executor: Running task 3.0 in stage 76.0 (TID 155)
[2025-07-11T14:09:42.755+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO ShuffleBlockFetcherIterator: Getting 1 (384.6 KiB) non-empty blocks including 1 (384.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:42.755+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:42.760+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO ShuffleBlockFetcherIterator: Getting 1 (3.4 MiB) non-empty blocks including 1 (3.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:42.760+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:42.760+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO ShuffleBlockFetcherIterator: Getting 1 (3.2 MiB) non-empty blocks including 1 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:42.761+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:42.763+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO ShuffleBlockFetcherIterator: Getting 1 (366.2 KiB) non-empty blocks including 1 (366.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:42.763+0200] {subprocess.py:93} INFO - 25/07/11 14:09:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:43.072+0200] {subprocess.py:93} INFO - 25/07/11 14:09:43 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 138.4.31.23:43033 in memory (size: 126.8 KiB, free: 434.0 MiB)
[2025-07-11T14:09:43.294+0200] {subprocess.py:93} INFO - 25/07/11 14:09:43 INFO Executor: Finished task 3.0 in stage 76.0 (TID 155). 5927 bytes result sent to driver
[2025-07-11T14:09:43.294+0200] {subprocess.py:93} INFO - 25/07/11 14:09:43 INFO Executor: Finished task 2.0 in stage 76.0 (TID 154). 5970 bytes result sent to driver
[2025-07-11T14:09:43.296+0200] {subprocess.py:93} INFO - 25/07/11 14:09:43 INFO TaskSetManager: Finished task 3.0 in stage 76.0 (TID 155) in 553 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:09:43.296+0200] {subprocess.py:93} INFO - 25/07/11 14:09:43 INFO TaskSetManager: Finished task 2.0 in stage 76.0 (TID 154) in 554 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:09:43.387+0200] {subprocess.py:93} INFO - 25/07/11 14:09:43 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 138.4.31.23:43033 in memory (size: 9.3 KiB, free: 434.0 MiB)
[2025-07-11T14:09:43.976+0200] {subprocess.py:93} INFO - 25/07/11 14:09:43 INFO Executor: Finished task 0.0 in stage 76.0 (TID 152). 5970 bytes result sent to driver
[2025-07-11T14:09:43.977+0200] {subprocess.py:93} INFO - 25/07/11 14:09:43 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 152) in 1235 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:09:43.997+0200] {subprocess.py:93} INFO - 25/07/11 14:09:43 INFO Executor: Finished task 1.0 in stage 76.0 (TID 153). 5927 bytes result sent to driver
[2025-07-11T14:09:43.998+0200] {subprocess.py:93} INFO - 25/07/11 14:09:43 INFO TaskSetManager: Finished task 1.0 in stage 76.0 (TID 153) in 1256 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:09:43.998+0200] {subprocess.py:93} INFO - 25/07/11 14:09:43 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool
[2025-07-11T14:09:43.999+0200] {subprocess.py:93} INFO - 25/07/11 14:09:43 INFO DAGScheduler: ResultStage 76 (aggregate at DecisionTreeMetadata.scala:125) finished in 1,266 s
[2025-07-11T14:09:43.999+0200] {subprocess.py:93} INFO - 25/07/11 14:09:43 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:09:43.999+0200] {subprocess.py:93} INFO - 25/07/11 14:09:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 76: Stage finished
[2025-07-11T14:09:43.999+0200] {subprocess.py:93} INFO - 25/07/11 14:09:43 INFO DAGScheduler: Job 48 finished: aggregate at DecisionTreeMetadata.scala:125, took 1,269830 s
[2025-07-11T14:09:44.156+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:1054
[2025-07-11T14:09:44.158+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO DAGScheduler: Registering RDD 162 (flatMap at RandomForest.scala:1039) as input to shuffle 24
[2025-07-11T14:09:44.158+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO DAGScheduler: Got job 49 (collectAsMap at RandomForest.scala:1054) with 4 output partitions
[2025-07-11T14:09:44.158+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO DAGScheduler: Final stage: ResultStage 79 (collectAsMap at RandomForest.scala:1054)
[2025-07-11T14:09:44.158+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78)
[2025-07-11T14:09:44.158+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 78)
[2025-07-11T14:09:44.159+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO DAGScheduler: Submitting ShuffleMapStage 78 (MapPartitionsRDD[162] at flatMap at RandomForest.scala:1039), which has no missing parents
[2025-07-11T14:09:44.168+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 281.5 KiB, free 424.5 MiB)
[2025-07-11T14:09:44.169+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 128.0 KiB, free 424.4 MiB)
[2025-07-11T14:09:44.170+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 138.4.31.23:43033 (size: 128.0 KiB, free: 433.9 MiB)
[2025-07-11T14:09:44.170+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:44.173+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[162] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:09:44.173+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO TaskSchedulerImpl: Adding task set 78.0 with 4 tasks resource profile 0
[2025-07-11T14:09:44.174+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 156) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:09:44.176+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 157) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:09:44.176+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO TaskSetManager: Starting task 2.0 in stage 78.0 (TID 158) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:09:44.176+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO TaskSetManager: Starting task 3.0 in stage 78.0 (TID 159) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:09:44.177+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO Executor: Running task 0.0 in stage 78.0 (TID 156)
[2025-07-11T14:09:44.178+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO Executor: Running task 1.0 in stage 78.0 (TID 157)
[2025-07-11T14:09:44.178+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO Executor: Running task 2.0 in stage 78.0 (TID 158)
[2025-07-11T14:09:44.178+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO Executor: Running task 3.0 in stage 78.0 (TID 159)
[2025-07-11T14:09:44.234+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO ShuffleBlockFetcherIterator: Getting 1 (366.2 KiB) non-empty blocks including 1 (366.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:44.238+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:44.238+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO ShuffleBlockFetcherIterator: Getting 1 (384.6 KiB) non-empty blocks including 1 (384.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:44.238+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:44.238+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO ShuffleBlockFetcherIterator: Getting 1 (3.2 MiB) non-empty blocks including 1 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:44.238+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:44.238+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO ShuffleBlockFetcherIterator: Getting 1 (3.4 MiB) non-empty blocks including 1 (3.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:44.238+0200] {subprocess.py:93} INFO - 25/07/11 14:09:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:45.091+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO Executor: Finished task 3.0 in stage 78.0 (TID 159). 6108 bytes result sent to driver
[2025-07-11T14:09:45.091+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO TaskSetManager: Finished task 3.0 in stage 78.0 (TID 159) in 916 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:09:45.166+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO Executor: Finished task 2.0 in stage 78.0 (TID 158). 6151 bytes result sent to driver
[2025-07-11T14:09:45.166+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO TaskSetManager: Finished task 2.0 in stage 78.0 (TID 158) in 991 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:09:45.610+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 138.4.31.23:43033 in memory (size: 126.9 KiB, free: 434.0 MiB)
[2025-07-11T14:09:45.879+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO Executor: Finished task 1.0 in stage 78.0 (TID 157). 6108 bytes result sent to driver
[2025-07-11T14:09:45.879+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 157) in 1705 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:09:45.910+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO Executor: Finished task 0.0 in stage 78.0 (TID 156). 6108 bytes result sent to driver
[2025-07-11T14:09:45.911+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 156) in 1738 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:09:45.911+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool
[2025-07-11T14:09:45.913+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO DAGScheduler: ShuffleMapStage 78 (flatMap at RandomForest.scala:1039) finished in 1,752 s
[2025-07-11T14:09:45.913+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:09:45.913+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO DAGScheduler: running: Set()
[2025-07-11T14:09:45.913+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO DAGScheduler: waiting: Set(ResultStage 79)
[2025-07-11T14:09:45.913+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO DAGScheduler: failed: Set()
[2025-07-11T14:09:45.913+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[164] at map at RandomForest.scala:1054), which has no missing parents
[2025-07-11T14:09:45.915+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 9.9 KiB, free 424.8 MiB)
[2025-07-11T14:09:45.916+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 424.8 MiB)
[2025-07-11T14:09:45.916+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 138.4.31.23:43033 (size: 4.6 KiB, free: 434.0 MiB)
[2025-07-11T14:09:45.917+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:45.917+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 79 (MapPartitionsRDD[164] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:09:45.917+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO TaskSchedulerImpl: Adding task set 79.0 with 4 tasks resource profile 0
[2025-07-11T14:09:45.922+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 160) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:45.923+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 161) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:45.923+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO TaskSetManager: Starting task 2.0 in stage 79.0 (TID 162) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:45.923+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO TaskSetManager: Starting task 3.0 in stage 79.0 (TID 163) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:45.923+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO Executor: Running task 0.0 in stage 79.0 (TID 160)
[2025-07-11T14:09:45.923+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO Executor: Running task 2.0 in stage 79.0 (TID 162)
[2025-07-11T14:09:45.929+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO ShuffleBlockFetcherIterator: Getting 4 (5.0 KiB) non-empty blocks including 4 (5.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:45.929+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO Executor: Running task 3.0 in stage 79.0 (TID 163)
[2025-07-11T14:09:45.931+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:45.934+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO Executor: Running task 1.0 in stage 79.0 (TID 161)
[2025-07-11T14:09:45.935+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO ShuffleBlockFetcherIterator: Getting 4 (50.2 KiB) non-empty blocks including 4 (50.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:45.935+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:45.937+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO ShuffleBlockFetcherIterator: Getting 4 (22.4 KiB) non-empty blocks including 4 (22.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:45.940+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:45.940+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO ShuffleBlockFetcherIterator: Getting 4 (4.5 KiB) non-empty blocks including 4 (4.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:45.940+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:45.981+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO Executor: Finished task 3.0 in stage 79.0 (TID 163). 2176 bytes result sent to driver
[2025-07-11T14:09:45.982+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO TaskSetManager: Finished task 3.0 in stage 79.0 (TID 163) in 59 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:09:45.982+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO Executor: Finished task 2.0 in stage 79.0 (TID 162). 2608 bytes result sent to driver
[2025-07-11T14:09:45.986+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO TaskSetManager: Finished task 2.0 in stage 79.0 (TID 162) in 66 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:09:45.994+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO Executor: Finished task 1.0 in stage 79.0 (TID 161). 25393 bytes result sent to driver
[2025-07-11T14:09:45.995+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO Executor: Finished task 0.0 in stage 79.0 (TID 160). 14394 bytes result sent to driver
[2025-07-11T14:09:45.998+0200] {subprocess.py:93} INFO - 25/07/11 14:09:45 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 161) in 78 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:09:46.003+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 160) in 85 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:09:46.003+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool
[2025-07-11T14:09:46.003+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO DAGScheduler: ResultStage 79 (collectAsMap at RandomForest.scala:1054) finished in 0,090 s
[2025-07-11T14:09:46.003+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:09:46.003+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 79: Stage finished
[2025-07-11T14:09:46.004+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO DAGScheduler: Job 49 finished: collectAsMap at RandomForest.scala:1054, took 1,847145 s
[2025-07-11T14:09:46.013+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 51.8 KiB, free 424.7 MiB)
[2025-07-11T14:09:46.014+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 424.7 MiB)
[2025-07-11T14:09:46.015+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 138.4.31.23:43033 (size: 9.0 KiB, free: 434.0 MiB)
[2025-07-11T14:09:46.015+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO SparkContext: Created broadcast 66 from broadcast at RandomForest.scala:293
[2025-07-11T14:09:46.028+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO Instrumentation: [d7c1ea9d] {"numFeatures":9}
[2025-07-11T14:09:46.028+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO Instrumentation: [d7c1ea9d] {"numClasses":4}
[2025-07-11T14:09:46.028+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO Instrumentation: [d7c1ea9d] {"numExamples":457013}
[2025-07-11T14:09:46.029+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO Instrumentation: [d7c1ea9d] {"sumOfWeights":457013.0}
[2025-07-11T14:09:46.041+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 1160.0 B, free 424.7 MiB)
[2025-07-11T14:09:46.044+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 412.0 B, free 424.7 MiB)
[2025-07-11T14:09:46.044+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 138.4.31.23:43033 (size: 412.0 B, free: 434.0 MiB)
[2025-07-11T14:09:46.046+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO SparkContext: Created broadcast 67 from broadcast at RandomForest.scala:622
[2025-07-11T14:09:46.080+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
[2025-07-11T14:09:46.081+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO DAGScheduler: Registering RDD 167 (mapPartitions at RandomForest.scala:644) as input to shuffle 25
[2025-07-11T14:09:46.081+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO DAGScheduler: Got job 50 (collectAsMap at RandomForest.scala:663) with 4 output partitions
[2025-07-11T14:09:46.081+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO DAGScheduler: Final stage: ResultStage 82 (collectAsMap at RandomForest.scala:663)
[2025-07-11T14:09:46.081+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 81)
[2025-07-11T14:09:46.081+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 81)
[2025-07-11T14:09:46.084+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[167] at mapPartitions at RandomForest.scala:644), which has no missing parents
[2025-07-11T14:09:46.095+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 298.0 KiB, free 424.4 MiB)
[2025-07-11T14:09:46.097+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 136.6 KiB, free 424.3 MiB)
[2025-07-11T14:09:46.097+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 138.4.31.23:43033 (size: 136.6 KiB, free: 433.8 MiB)
[2025-07-11T14:09:46.098+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:46.099+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[167] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:09:46.099+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO TaskSchedulerImpl: Adding task set 81.0 with 4 tasks resource profile 0
[2025-07-11T14:09:46.100+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 164) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:09:46.101+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 165) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:09:46.101+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO TaskSetManager: Starting task 2.0 in stage 81.0 (TID 166) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:09:46.101+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO TaskSetManager: Starting task 3.0 in stage 81.0 (TID 167) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:09:46.101+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO Executor: Running task 1.0 in stage 81.0 (TID 165)
[2025-07-11T14:09:46.105+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO Executor: Running task 2.0 in stage 81.0 (TID 166)
[2025-07-11T14:09:46.106+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO Executor: Running task 0.0 in stage 81.0 (TID 164)
[2025-07-11T14:09:46.109+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO Executor: Running task 3.0 in stage 81.0 (TID 167)
[2025-07-11T14:09:46.155+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO ShuffleBlockFetcherIterator: Getting 1 (366.2 KiB) non-empty blocks including 1 (366.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:46.155+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:46.158+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO ShuffleBlockFetcherIterator: Getting 1 (3.4 MiB) non-empty blocks including 1 (3.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:46.158+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:46.159+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO ShuffleBlockFetcherIterator: Getting 1 (3.2 MiB) non-empty blocks including 1 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:46.159+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:46.162+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO ShuffleBlockFetcherIterator: Getting 1 (384.6 KiB) non-empty blocks including 1 (384.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:46.162+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:46.788+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 138.4.31.23:43033 in memory (size: 4.6 KiB, free: 433.8 MiB)
[2025-07-11T14:09:46.868+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO MemoryStore: Block rdd_166_3 stored as values in memory (estimated size 3.9 MiB, free 420.4 MiB)
[2025-07-11T14:09:46.868+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO BlockManagerInfo: Added rdd_166_3 in memory on 138.4.31.23:43033 (size: 3.9 MiB, free: 429.9 MiB)
[2025-07-11T14:09:46.943+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO MemoryStore: Block rdd_166_2 stored as values in memory (estimated size 3.8 MiB, free 416.6 MiB)
[2025-07-11T14:09:46.944+0200] {subprocess.py:93} INFO - 25/07/11 14:09:46 INFO BlockManagerInfo: Added rdd_166_2 in memory on 138.4.31.23:43033 (size: 3.8 MiB, free: 426.2 MiB)
[2025-07-11T14:09:47.173+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO Executor: Finished task 2.0 in stage 81.0 (TID 166). 6108 bytes result sent to driver
[2025-07-11T14:09:47.174+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO TaskSetManager: Finished task 2.0 in stage 81.0 (TID 166) in 1074 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:09:47.211+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO Executor: Finished task 3.0 in stage 81.0 (TID 167). 6108 bytes result sent to driver
[2025-07-11T14:09:47.212+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO TaskSetManager: Finished task 3.0 in stage 81.0 (TID 167) in 1111 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:09:47.689+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 138.4.31.23:43033 in memory (size: 128.0 KiB, free: 426.3 MiB)
[2025-07-11T14:09:47.838+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO MemoryStore: Block rdd_166_1 stored as values in memory (estimated size 36.2 MiB, free 380.9 MiB)
[2025-07-11T14:09:47.838+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO BlockManagerInfo: Added rdd_166_1 in memory on 138.4.31.23:43033 (size: 36.2 MiB, free: 390.1 MiB)
[2025-07-11T14:09:47.882+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO MemoryStore: Block rdd_166_0 stored as values in memory (estimated size 34.6 MiB, free 346.3 MiB)
[2025-07-11T14:09:47.882+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO BlockManagerInfo: Added rdd_166_0 in memory on 138.4.31.23:43033 (size: 34.6 MiB, free: 355.6 MiB)
[2025-07-11T14:09:47.966+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO Executor: Finished task 1.0 in stage 81.0 (TID 165). 6108 bytes result sent to driver
[2025-07-11T14:09:47.966+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 165) in 1866 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:09:47.993+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO Executor: Finished task 0.0 in stage 81.0 (TID 164). 6108 bytes result sent to driver
[2025-07-11T14:09:47.994+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 164) in 1894 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:09:47.994+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool
[2025-07-11T14:09:47.995+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO DAGScheduler: ShuffleMapStage 81 (mapPartitions at RandomForest.scala:644) finished in 1,910 s
[2025-07-11T14:09:47.995+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:09:47.995+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO DAGScheduler: running: Set()
[2025-07-11T14:09:47.995+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO DAGScheduler: waiting: Set(ResultStage 82)
[2025-07-11T14:09:47.995+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO DAGScheduler: failed: Set()
[2025-07-11T14:09:47.995+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[169] at map at RandomForest.scala:663), which has no missing parents
[2025-07-11T14:09:47.998+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 7.2 KiB, free 346.3 MiB)
[2025-07-11T14:09:47.998+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 346.3 MiB)
[2025-07-11T14:09:47.998+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 138.4.31.23:43033 (size: 3.8 KiB, free: 355.5 MiB)
[2025-07-11T14:09:47.999+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:47.999+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 82 (MapPartitionsRDD[169] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:09:47.999+0200] {subprocess.py:93} INFO - 25/07/11 14:09:47 INFO TaskSchedulerImpl: Adding task set 82.0 with 4 tasks resource profile 0
[2025-07-11T14:09:48.000+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 168) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:48.001+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSetManager: Starting task 1.0 in stage 82.0 (TID 169) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:48.001+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSetManager: Starting task 2.0 in stage 82.0 (TID 170) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:48.001+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSetManager: Starting task 3.0 in stage 82.0 (TID 171) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:48.001+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO Executor: Running task 2.0 in stage 82.0 (TID 170)
[2025-07-11T14:09:48.001+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO Executor: Running task 0.0 in stage 82.0 (TID 168)
[2025-07-11T14:09:48.001+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO Executor: Running task 1.0 in stage 82.0 (TID 169)
[2025-07-11T14:09:48.001+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO Executor: Running task 3.0 in stage 82.0 (TID 171)
[2025-07-11T14:09:48.005+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO ShuffleBlockFetcherIterator: Getting 4 (179.0 KiB) non-empty blocks including 4 (179.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:48.005+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO ShuffleBlockFetcherIterator: Getting 4 (267.7 KiB) non-empty blocks including 4 (267.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:48.005+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:48.005+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:48.005+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO ShuffleBlockFetcherIterator: Getting 4 (232.1 KiB) non-empty blocks including 4 (232.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:48.005+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:48.006+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO ShuffleBlockFetcherIterator: Getting 4 (323.9 KiB) non-empty blocks including 4 (323.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:48.006+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-11T14:09:48.462+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO Executor: Finished task 2.0 in stage 82.0 (TID 170). 2814 bytes result sent to driver
[2025-07-11T14:09:48.464+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSetManager: Finished task 2.0 in stage 82.0 (TID 170) in 464 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:09:48.480+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO Executor: Finished task 1.0 in stage 82.0 (TID 169). 6583 bytes result sent to driver
[2025-07-11T14:09:48.481+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO Executor: Finished task 3.0 in stage 82.0 (TID 171). 6334 bytes result sent to driver
[2025-07-11T14:09:48.481+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSetManager: Finished task 1.0 in stage 82.0 (TID 169) in 481 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:09:48.482+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSetManager: Finished task 3.0 in stage 82.0 (TID 171) in 482 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:09:48.530+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO Executor: Finished task 0.0 in stage 82.0 (TID 168). 6576 bytes result sent to driver
[2025-07-11T14:09:48.530+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 168) in 531 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:09:48.530+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool
[2025-07-11T14:09:48.531+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO DAGScheduler: ResultStage 82 (collectAsMap at RandomForest.scala:663) finished in 0,534 s
[2025-07-11T14:09:48.531+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:09:48.531+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 82: Stage finished
[2025-07-11T14:09:48.531+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO DAGScheduler: Job 50 finished: collectAsMap at RandomForest.scala:663, took 2,451400 s
[2025-07-11T14:09:48.532+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TorrentBroadcast: Destroying Broadcast(67) (from destroy at RandomForest.scala:674)
[2025-07-11T14:09:48.534+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 138.4.31.23:43033 in memory (size: 412.0 B, free: 355.5 MiB)
[2025-07-11T14:09:48.536+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 2.2 KiB, free 346.3 MiB)
[2025-07-11T14:09:48.536+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 537.0 B, free 346.3 MiB)
[2025-07-11T14:09:48.536+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 138.4.31.23:43033 (size: 537.0 B, free: 355.5 MiB)
[2025-07-11T14:09:48.537+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO SparkContext: Created broadcast 70 from broadcast at RandomForest.scala:622
[2025-07-11T14:09:48.551+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
[2025-07-11T14:09:48.552+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO DAGScheduler: Registering RDD 170 (mapPartitions at RandomForest.scala:644) as input to shuffle 26
[2025-07-11T14:09:48.553+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO DAGScheduler: Got job 51 (collectAsMap at RandomForest.scala:663) with 4 output partitions
[2025-07-11T14:09:48.553+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO DAGScheduler: Final stage: ResultStage 85 (collectAsMap at RandomForest.scala:663)
[2025-07-11T14:09:48.553+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 84)
[2025-07-11T14:09:48.553+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 84)
[2025-07-11T14:09:48.553+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO DAGScheduler: Submitting ShuffleMapStage 84 (MapPartitionsRDD[170] at mapPartitions at RandomForest.scala:644), which has no missing parents
[2025-07-11T14:09:48.557+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 311.7 KiB, free 346.0 MiB)
[2025-07-11T14:09:48.558+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 141.8 KiB, free 345.8 MiB)
[2025-07-11T14:09:48.558+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 138.4.31.23:43033 (size: 141.8 KiB, free: 355.4 MiB)
[2025-07-11T14:09:48.559+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:48.559+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 84 (MapPartitionsRDD[170] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:09:48.559+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSchedulerImpl: Adding task set 84.0 with 4 tasks resource profile 0
[2025-07-11T14:09:48.562+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 172) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:09:48.562+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSetManager: Starting task 1.0 in stage 84.0 (TID 173) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:09:48.562+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSetManager: Starting task 2.0 in stage 84.0 (TID 174) (138.4.31.23, executor driver, partition 2, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:09:48.567+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSetManager: Starting task 3.0 in stage 84.0 (TID 175) (138.4.31.23, executor driver, partition 3, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:09:48.567+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO Executor: Running task 3.0 in stage 84.0 (TID 175)
[2025-07-11T14:09:48.567+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO Executor: Running task 2.0 in stage 84.0 (TID 174)
[2025-07-11T14:09:48.567+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO Executor: Running task 1.0 in stage 84.0 (TID 173)
[2025-07-11T14:09:48.567+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO Executor: Running task 0.0 in stage 84.0 (TID 172)
[2025-07-11T14:09:48.574+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO BlockManager: Found block rdd_166_1 locally
[2025-07-11T14:09:48.576+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO BlockManager: Found block rdd_166_2 locally
[2025-07-11T14:09:48.576+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO BlockManager: Found block rdd_166_3 locally
[2025-07-11T14:09:48.578+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO BlockManager: Found block rdd_166_0 locally
[2025-07-11T14:09:48.698+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO Executor: Finished task 2.0 in stage 84.0 (TID 174). 5420 bytes result sent to driver
[2025-07-11T14:09:48.699+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSetManager: Finished task 2.0 in stage 84.0 (TID 174) in 139 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:09:48.717+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO Executor: Finished task 3.0 in stage 84.0 (TID 175). 5420 bytes result sent to driver
[2025-07-11T14:09:48.717+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSetManager: Finished task 3.0 in stage 84.0 (TID 175) in 157 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:09:48.860+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO Executor: Finished task 0.0 in stage 84.0 (TID 172). 5420 bytes result sent to driver
[2025-07-11T14:09:48.862+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 172) in 301 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:09:48.877+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO Executor: Finished task 1.0 in stage 84.0 (TID 173). 5420 bytes result sent to driver
[2025-07-11T14:09:48.877+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSetManager: Finished task 1.0 in stage 84.0 (TID 173) in 317 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:09:48.878+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool
[2025-07-11T14:09:48.882+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO DAGScheduler: ShuffleMapStage 84 (mapPartitions at RandomForest.scala:644) finished in 0,325 s
[2025-07-11T14:09:48.882+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:09:48.882+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO DAGScheduler: running: Set()
[2025-07-11T14:09:48.882+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO DAGScheduler: waiting: Set(ResultStage 85)
[2025-07-11T14:09:48.882+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO DAGScheduler: failed: Set()
[2025-07-11T14:09:48.882+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[172] at map at RandomForest.scala:663), which has no missing parents
[2025-07-11T14:09:48.884+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 9.4 KiB, free 345.8 MiB)
[2025-07-11T14:09:48.884+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 345.8 MiB)
[2025-07-11T14:09:48.884+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 138.4.31.23:43033 (size: 4.9 KiB, free: 355.4 MiB)
[2025-07-11T14:09:48.885+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:48.885+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 85 (MapPartitionsRDD[172] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:09:48.885+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSchedulerImpl: Adding task set 85.0 with 4 tasks resource profile 0
[2025-07-11T14:09:48.885+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 176) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:48.885+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSetManager: Starting task 1.0 in stage 85.0 (TID 177) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:48.886+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSetManager: Starting task 2.0 in stage 85.0 (TID 178) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:48.886+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO TaskSetManager: Starting task 3.0 in stage 85.0 (TID 179) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:48.886+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO Executor: Running task 2.0 in stage 85.0 (TID 178)
[2025-07-11T14:09:48.886+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO Executor: Running task 0.0 in stage 85.0 (TID 176)
[2025-07-11T14:09:48.887+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO Executor: Running task 3.0 in stage 85.0 (TID 179)
[2025-07-11T14:09:48.888+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO ShuffleBlockFetcherIterator: Getting 4 (170.9 KiB) non-empty blocks including 4 (170.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:48.888+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO ShuffleBlockFetcherIterator: Getting 4 (373.7 KiB) non-empty blocks including 4 (373.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:48.888+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:48.888+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:48.889+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO Executor: Running task 1.0 in stage 85.0 (TID 177)
[2025-07-11T14:09:48.889+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO ShuffleBlockFetcherIterator: Getting 4 (433.2 KiB) non-empty blocks including 4 (433.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:48.889+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:48.892+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO ShuffleBlockFetcherIterator: Getting 4 (375.9 KiB) non-empty blocks including 4 (375.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:48.892+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:48.910+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 138.4.31.23:43033 in memory (size: 3.8 KiB, free: 355.4 MiB)
[2025-07-11T14:09:48.912+0200] {subprocess.py:93} INFO - 25/07/11 14:09:48 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 138.4.31.23:43033 in memory (size: 141.8 KiB, free: 355.5 MiB)
[2025-07-11T14:09:49.049+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO Executor: Finished task 2.0 in stage 85.0 (TID 178). 10754 bytes result sent to driver
[2025-07-11T14:09:49.052+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSetManager: Finished task 2.0 in stage 85.0 (TID 178) in 167 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:09:49.155+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO Executor: Finished task 1.0 in stage 85.0 (TID 177). 43293 bytes result sent to driver
[2025-07-11T14:09:49.156+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSetManager: Finished task 1.0 in stage 85.0 (TID 177) in 271 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:09:49.184+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO Executor: Finished task 0.0 in stage 85.0 (TID 176). 89325 bytes result sent to driver
[2025-07-11T14:09:49.187+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 176) in 302 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:09:49.206+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO Executor: Finished task 3.0 in stage 85.0 (TID 179). 113450 bytes result sent to driver
[2025-07-11T14:09:49.210+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSetManager: Finished task 3.0 in stage 85.0 (TID 179) in 323 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:09:49.210+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool
[2025-07-11T14:09:49.210+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO DAGScheduler: ResultStage 85 (collectAsMap at RandomForest.scala:663) finished in 0,331 s
[2025-07-11T14:09:49.212+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:09:49.212+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 85: Stage finished
[2025-07-11T14:09:49.212+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO DAGScheduler: Job 51 finished: collectAsMap at RandomForest.scala:663, took 0,660611 s
[2025-07-11T14:09:49.212+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TorrentBroadcast: Destroying Broadcast(70) (from destroy at RandomForest.scala:674)
[2025-07-11T14:09:49.213+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 138.4.31.23:43033 in memory (size: 537.0 B, free: 355.5 MiB)
[2025-07-11T14:09:49.214+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 4.8 KiB, free 346.3 MiB)
[2025-07-11T14:09:49.215+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 755.0 B, free 346.3 MiB)
[2025-07-11T14:09:49.215+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 138.4.31.23:43033 (size: 755.0 B, free: 355.5 MiB)
[2025-07-11T14:09:49.216+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO SparkContext: Created broadcast 73 from broadcast at RandomForest.scala:622
[2025-07-11T14:09:49.236+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
[2025-07-11T14:09:49.237+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO DAGScheduler: Registering RDD 173 (mapPartitions at RandomForest.scala:644) as input to shuffle 27
[2025-07-11T14:09:49.237+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO DAGScheduler: Got job 52 (collectAsMap at RandomForest.scala:663) with 4 output partitions
[2025-07-11T14:09:49.237+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO DAGScheduler: Final stage: ResultStage 88 (collectAsMap at RandomForest.scala:663)
[2025-07-11T14:09:49.238+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 87)
[2025-07-11T14:09:49.238+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 87)
[2025-07-11T14:09:49.240+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO DAGScheduler: Submitting ShuffleMapStage 87 (MapPartitionsRDD[173] at mapPartitions at RandomForest.scala:644), which has no missing parents
[2025-07-11T14:09:49.258+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 138.4.31.23:43033 in memory (size: 136.6 KiB, free: 355.7 MiB)
[2025-07-11T14:09:49.259+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 553.0 KiB, free 346.2 MiB)
[2025-07-11T14:09:49.261+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 246.2 KiB, free 345.9 MiB)
[2025-07-11T14:09:49.262+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 138.4.31.23:43033 (size: 246.2 KiB, free: 355.4 MiB)
[2025-07-11T14:09:49.262+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:49.262+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 87 (MapPartitionsRDD[173] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:09:49.262+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSchedulerImpl: Adding task set 87.0 with 4 tasks resource profile 0
[2025-07-11T14:09:49.263+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 180) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:09:49.263+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSetManager: Starting task 1.0 in stage 87.0 (TID 181) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:09:49.263+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSetManager: Starting task 2.0 in stage 87.0 (TID 182) (138.4.31.23, executor driver, partition 2, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:09:49.264+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSetManager: Starting task 3.0 in stage 87.0 (TID 183) (138.4.31.23, executor driver, partition 3, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:09:49.264+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO Executor: Running task 0.0 in stage 87.0 (TID 180)
[2025-07-11T14:09:49.264+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO Executor: Running task 1.0 in stage 87.0 (TID 181)
[2025-07-11T14:09:49.264+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO Executor: Running task 3.0 in stage 87.0 (TID 183)
[2025-07-11T14:09:49.264+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO Executor: Running task 2.0 in stage 87.0 (TID 182)
[2025-07-11T14:09:49.282+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO BlockManager: Found block rdd_166_2 locally
[2025-07-11T14:09:49.300+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO BlockManager: Found block rdd_166_0 locally
[2025-07-11T14:09:49.303+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO BlockManager: Found block rdd_166_3 locally
[2025-07-11T14:09:49.306+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO BlockManager: Found block rdd_166_1 locally
[2025-07-11T14:09:49.468+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO Executor: Finished task 3.0 in stage 87.0 (TID 183). 5420 bytes result sent to driver
[2025-07-11T14:09:49.470+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSetManager: Finished task 3.0 in stage 87.0 (TID 183) in 206 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:09:49.475+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO Executor: Finished task 2.0 in stage 87.0 (TID 182). 5420 bytes result sent to driver
[2025-07-11T14:09:49.475+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSetManager: Finished task 2.0 in stage 87.0 (TID 182) in 212 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:09:49.721+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO Executor: Finished task 0.0 in stage 87.0 (TID 180). 5420 bytes result sent to driver
[2025-07-11T14:09:49.722+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 180) in 460 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:09:49.732+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO Executor: Finished task 1.0 in stage 87.0 (TID 181). 5420 bytes result sent to driver
[2025-07-11T14:09:49.733+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSetManager: Finished task 1.0 in stage 87.0 (TID 181) in 470 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:09:49.733+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool
[2025-07-11T14:09:49.733+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO DAGScheduler: ShuffleMapStage 87 (mapPartitions at RandomForest.scala:644) finished in 0,493 s
[2025-07-11T14:09:49.733+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:09:49.733+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO DAGScheduler: running: Set()
[2025-07-11T14:09:49.733+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO DAGScheduler: waiting: Set(ResultStage 88)
[2025-07-11T14:09:49.734+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO DAGScheduler: failed: Set()
[2025-07-11T14:09:49.734+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[175] at map at RandomForest.scala:663), which has no missing parents
[2025-07-11T14:09:49.735+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 11.5 KiB, free 345.9 MiB)
[2025-07-11T14:09:49.736+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 345.9 MiB)
[2025-07-11T14:09:49.736+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 138.4.31.23:43033 (size: 5.7 KiB, free: 355.4 MiB)
[2025-07-11T14:09:49.737+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:49.737+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 88 (MapPartitionsRDD[175] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:09:49.738+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSchedulerImpl: Adding task set 88.0 with 4 tasks resource profile 0
[2025-07-11T14:09:49.739+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 184) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:49.739+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSetManager: Starting task 1.0 in stage 88.0 (TID 185) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:49.739+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSetManager: Starting task 2.0 in stage 88.0 (TID 186) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:49.741+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSetManager: Starting task 3.0 in stage 88.0 (TID 187) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:49.742+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO Executor: Running task 3.0 in stage 88.0 (TID 187)
[2025-07-11T14:09:49.742+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO Executor: Running task 1.0 in stage 88.0 (TID 185)
[2025-07-11T14:09:49.742+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO Executor: Running task 2.0 in stage 88.0 (TID 186)
[2025-07-11T14:09:49.742+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO Executor: Running task 0.0 in stage 88.0 (TID 184)
[2025-07-11T14:09:49.742+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO ShuffleBlockFetcherIterator: Getting 4 (342.8 KiB) non-empty blocks including 4 (342.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:49.742+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO ShuffleBlockFetcherIterator: Getting 4 (459.4 KiB) non-empty blocks including 4 (459.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:49.742+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO ShuffleBlockFetcherIterator: Getting 4 (431.1 KiB) non-empty blocks including 4 (431.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:49.742+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO ShuffleBlockFetcherIterator: Getting 4 (577.0 KiB) non-empty blocks including 4 (577.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:49.742+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:49.742+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:49.745+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:49.751+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2025-07-11T14:09:49.876+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 138.4.31.23:43033 in memory (size: 246.2 KiB, free: 355.7 MiB)
[2025-07-11T14:09:49.877+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 138.4.31.23:43033 in memory (size: 4.9 KiB, free: 355.7 MiB)
[2025-07-11T14:09:49.952+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO Executor: Finished task 0.0 in stage 88.0 (TID 184). 4990 bytes result sent to driver
[2025-07-11T14:09:49.953+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 184) in 214 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:09:49.972+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO Executor: Finished task 2.0 in stage 88.0 (TID 186). 28033 bytes result sent to driver
[2025-07-11T14:09:49.974+0200] {subprocess.py:93} INFO - 25/07/11 14:09:49 INFO TaskSetManager: Finished task 2.0 in stage 88.0 (TID 186) in 235 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:09:50.037+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO Executor: Finished task 3.0 in stage 88.0 (TID 187). 11338 bytes result sent to driver
[2025-07-11T14:09:50.038+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO TaskSetManager: Finished task 3.0 in stage 88.0 (TID 187) in 298 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:09:50.068+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO Executor: Finished task 1.0 in stage 88.0 (TID 185). 172614 bytes result sent to driver
[2025-07-11T14:09:50.068+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO TaskSetManager: Finished task 1.0 in stage 88.0 (TID 185) in 329 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:09:50.068+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool
[2025-07-11T14:09:50.068+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO DAGScheduler: ResultStage 88 (collectAsMap at RandomForest.scala:663) finished in 0,333 s
[2025-07-11T14:09:50.068+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:09:50.068+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 88: Stage finished
[2025-07-11T14:09:50.069+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO DAGScheduler: Job 52 finished: collectAsMap at RandomForest.scala:663, took 0,832209 s
[2025-07-11T14:09:50.069+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO TorrentBroadcast: Destroying Broadcast(73) (from destroy at RandomForest.scala:674)
[2025-07-11T14:09:50.072+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 138.4.31.23:43033 in memory (size: 755.0 B, free: 355.7 MiB)
[2025-07-11T14:09:50.074+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 9.7 KiB, free 346.7 MiB)
[2025-07-11T14:09:50.074+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 1216.0 B, free 346.7 MiB)
[2025-07-11T14:09:50.074+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 138.4.31.23:43033 (size: 1216.0 B, free: 355.7 MiB)
[2025-07-11T14:09:50.075+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO SparkContext: Created broadcast 76 from broadcast at RandomForest.scala:622
[2025-07-11T14:09:50.096+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
[2025-07-11T14:09:50.097+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO DAGScheduler: Registering RDD 176 (mapPartitions at RandomForest.scala:644) as input to shuffle 28
[2025-07-11T14:09:50.097+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO DAGScheduler: Got job 53 (collectAsMap at RandomForest.scala:663) with 4 output partitions
[2025-07-11T14:09:50.097+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO DAGScheduler: Final stage: ResultStage 91 (collectAsMap at RandomForest.scala:663)
[2025-07-11T14:09:50.097+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)
[2025-07-11T14:09:50.097+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 90)
[2025-07-11T14:09:50.098+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO DAGScheduler: Submitting ShuffleMapStage 90 (MapPartitionsRDD[176] at mapPartitions at RandomForest.scala:644), which has no missing parents
[2025-07-11T14:09:50.111+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 757.7 KiB, free 345.9 MiB)
[2025-07-11T14:09:50.113+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 329.9 KiB, free 345.6 MiB)
[2025-07-11T14:09:50.113+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 138.4.31.23:43033 (size: 329.9 KiB, free: 355.4 MiB)
[2025-07-11T14:09:50.114+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:50.114+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 90 (MapPartitionsRDD[176] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:09:50.114+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO TaskSchedulerImpl: Adding task set 90.0 with 4 tasks resource profile 0
[2025-07-11T14:09:50.118+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 188) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:09:50.119+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO TaskSetManager: Starting task 1.0 in stage 90.0 (TID 189) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:09:50.119+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO TaskSetManager: Starting task 2.0 in stage 90.0 (TID 190) (138.4.31.23, executor driver, partition 2, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:09:50.119+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO TaskSetManager: Starting task 3.0 in stage 90.0 (TID 191) (138.4.31.23, executor driver, partition 3, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:09:50.119+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO Executor: Running task 0.0 in stage 90.0 (TID 188)
[2025-07-11T14:09:50.119+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO Executor: Running task 2.0 in stage 90.0 (TID 190)
[2025-07-11T14:09:50.119+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO Executor: Running task 3.0 in stage 90.0 (TID 191)
[2025-07-11T14:09:50.119+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO Executor: Running task 1.0 in stage 90.0 (TID 189)
[2025-07-11T14:09:50.136+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO BlockManager: Found block rdd_166_2 locally
[2025-07-11T14:09:50.142+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO BlockManager: Found block rdd_166_0 locally
[2025-07-11T14:09:50.151+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO BlockManager: Found block rdd_166_1 locally
[2025-07-11T14:09:50.154+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO BlockManager: Found block rdd_166_3 locally
[2025-07-11T14:09:50.512+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO Executor: Finished task 2.0 in stage 90.0 (TID 190). 5420 bytes result sent to driver
[2025-07-11T14:09:50.513+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO TaskSetManager: Finished task 2.0 in stage 90.0 (TID 190) in 398 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:09:50.559+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO Executor: Finished task 3.0 in stage 90.0 (TID 191). 5420 bytes result sent to driver
[2025-07-11T14:09:50.560+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO TaskSetManager: Finished task 3.0 in stage 90.0 (TID 191) in 445 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:09:50.905+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO Executor: Finished task 1.0 in stage 90.0 (TID 189). 5420 bytes result sent to driver
[2025-07-11T14:09:50.906+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO TaskSetManager: Finished task 1.0 in stage 90.0 (TID 189) in 790 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:09:50.923+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO Executor: Finished task 0.0 in stage 90.0 (TID 188). 5420 bytes result sent to driver
[2025-07-11T14:09:50.924+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 188) in 809 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:09:50.924+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool
[2025-07-11T14:09:50.924+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO DAGScheduler: ShuffleMapStage 90 (mapPartitions at RandomForest.scala:644) finished in 0,826 s
[2025-07-11T14:09:50.925+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:09:50.925+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO DAGScheduler: running: Set()
[2025-07-11T14:09:50.925+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO DAGScheduler: waiting: Set(ResultStage 91)
[2025-07-11T14:09:50.925+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO DAGScheduler: failed: Set()
[2025-07-11T14:09:50.925+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[178] at map at RandomForest.scala:663), which has no missing parents
[2025-07-11T14:09:50.926+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 15.6 KiB, free 345.6 MiB)
[2025-07-11T14:09:50.926+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 345.6 MiB)
[2025-07-11T14:09:50.927+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 138.4.31.23:43033 (size: 7.3 KiB, free: 355.3 MiB)
[2025-07-11T14:09:50.927+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:50.927+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 91 (MapPartitionsRDD[178] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:09:50.927+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO TaskSchedulerImpl: Adding task set 91.0 with 4 tasks resource profile 0
[2025-07-11T14:09:50.928+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 192) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:50.928+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 193) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:50.928+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO TaskSetManager: Starting task 2.0 in stage 91.0 (TID 194) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:50.928+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO TaskSetManager: Starting task 3.0 in stage 91.0 (TID 195) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:50.930+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO Executor: Running task 1.0 in stage 91.0 (TID 193)
[2025-07-11T14:09:50.930+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO Executor: Running task 2.0 in stage 91.0 (TID 194)
[2025-07-11T14:09:50.930+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO Executor: Running task 0.0 in stage 91.0 (TID 192)
[2025-07-11T14:09:50.931+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO ShuffleBlockFetcherIterator: Getting 4 (619.3 KiB) non-empty blocks including 4 (619.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:50.931+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:50.931+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO Executor: Running task 3.0 in stage 91.0 (TID 195)
[2025-07-11T14:09:50.931+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO ShuffleBlockFetcherIterator: Getting 4 (784.8 KiB) non-empty blocks including 4 (784.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:50.932+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:50.933+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO ShuffleBlockFetcherIterator: Getting 4 (666.0 KiB) non-empty blocks including 4 (666.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:50.935+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-11T14:09:50.937+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO ShuffleBlockFetcherIterator: Getting 4 (578.3 KiB) non-empty blocks including 4 (578.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:50.937+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-11T14:09:50.959+0200] {subprocess.py:93} INFO - 25/07/11 14:09:50 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 138.4.31.23:43033 in memory (size: 329.9 KiB, free: 355.7 MiB)
[2025-07-11T14:09:51.422+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO Executor: Finished task 3.0 in stage 91.0 (TID 195). 117379 bytes result sent to driver
[2025-07-11T14:09:51.425+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO TaskSetManager: Finished task 3.0 in stage 91.0 (TID 195) in 497 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:09:51.459+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO Executor: Finished task 0.0 in stage 91.0 (TID 192). 79045 bytes result sent to driver
[2025-07-11T14:09:51.461+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 192) in 533 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:09:51.627+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 138.4.31.23:43033 in memory (size: 5.7 KiB, free: 355.7 MiB)
[2025-07-11T14:09:51.692+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO Executor: Finished task 1.0 in stage 91.0 (TID 193). 97189 bytes result sent to driver
[2025-07-11T14:09:51.701+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 193) in 773 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:09:51.773+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO Executor: Finished task 2.0 in stage 91.0 (TID 194). 79382 bytes result sent to driver
[2025-07-11T14:09:51.775+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO TaskSetManager: Finished task 2.0 in stage 91.0 (TID 194) in 847 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:09:51.775+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool
[2025-07-11T14:09:51.776+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO DAGScheduler: ResultStage 91 (collectAsMap at RandomForest.scala:663) finished in 0,850 s
[2025-07-11T14:09:51.776+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:09:51.776+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 91: Stage finished
[2025-07-11T14:09:51.776+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO DAGScheduler: Job 53 finished: collectAsMap at RandomForest.scala:663, took 1,679579 s
[2025-07-11T14:09:51.778+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO TorrentBroadcast: Destroying Broadcast(76) (from destroy at RandomForest.scala:674)
[2025-07-11T14:09:51.778+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 138.4.31.23:43033 in memory (size: 1216.0 B, free: 355.7 MiB)
[2025-07-11T14:09:51.785+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 18.9 KiB, free 346.7 MiB)
[2025-07-11T14:09:51.785+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 2.1 KiB, free 346.7 MiB)
[2025-07-11T14:09:51.785+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 138.4.31.23:43033 (size: 2.1 KiB, free: 355.7 MiB)
[2025-07-11T14:09:51.787+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO SparkContext: Created broadcast 79 from broadcast at RandomForest.scala:622
[2025-07-11T14:09:51.819+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
[2025-07-11T14:09:51.820+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO DAGScheduler: Registering RDD 179 (mapPartitions at RandomForest.scala:644) as input to shuffle 29
[2025-07-11T14:09:51.821+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO DAGScheduler: Got job 54 (collectAsMap at RandomForest.scala:663) with 4 output partitions
[2025-07-11T14:09:51.821+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO DAGScheduler: Final stage: ResultStage 94 (collectAsMap at RandomForest.scala:663)
[2025-07-11T14:09:51.821+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 93)
[2025-07-11T14:09:51.821+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 93)
[2025-07-11T14:09:51.823+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO DAGScheduler: Submitting ShuffleMapStage 93 (MapPartitionsRDD[179] at mapPartitions at RandomForest.scala:644), which has no missing parents
[2025-07-11T14:09:51.840+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 WARN DAGScheduler: Broadcasting large task binary with size 1118.1 KiB
[2025-07-11T14:09:51.840+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 1118.1 KiB, free 345.6 MiB)
[2025-07-11T14:09:51.844+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 479.7 KiB, free 345.1 MiB)
[2025-07-11T14:09:51.844+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 138.4.31.23:43033 (size: 479.7 KiB, free: 355.2 MiB)
[2025-07-11T14:09:51.844+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:51.844+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 93 (MapPartitionsRDD[179] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:09:51.844+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO TaskSchedulerImpl: Adding task set 93.0 with 4 tasks resource profile 0
[2025-07-11T14:09:51.846+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 196) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:09:51.846+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO TaskSetManager: Starting task 1.0 in stage 93.0 (TID 197) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:09:51.846+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO TaskSetManager: Starting task 2.0 in stage 93.0 (TID 198) (138.4.31.23, executor driver, partition 2, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:09:51.846+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO TaskSetManager: Starting task 3.0 in stage 93.0 (TID 199) (138.4.31.23, executor driver, partition 3, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:09:51.847+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO Executor: Running task 0.0 in stage 93.0 (TID 196)
[2025-07-11T14:09:51.849+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO Executor: Running task 1.0 in stage 93.0 (TID 197)
[2025-07-11T14:09:51.849+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO Executor: Running task 2.0 in stage 93.0 (TID 198)
[2025-07-11T14:09:51.850+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO Executor: Running task 3.0 in stage 93.0 (TID 199)
[2025-07-11T14:09:51.886+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO BlockManager: Found block rdd_166_3 locally
[2025-07-11T14:09:51.917+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO BlockManager: Found block rdd_166_1 locally
[2025-07-11T14:09:51.932+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO BlockManager: Found block rdd_166_2 locally
[2025-07-11T14:09:51.934+0200] {subprocess.py:93} INFO - 25/07/11 14:09:51 INFO BlockManager: Found block rdd_166_0 locally
[2025-07-11T14:09:52.220+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO Executor: Finished task 3.0 in stage 93.0 (TID 199). 5420 bytes result sent to driver
[2025-07-11T14:09:52.221+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO TaskSetManager: Finished task 3.0 in stage 93.0 (TID 199) in 375 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:09:52.343+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO Executor: Finished task 2.0 in stage 93.0 (TID 198). 5420 bytes result sent to driver
[2025-07-11T14:09:52.345+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO TaskSetManager: Finished task 2.0 in stage 93.0 (TID 198) in 499 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:09:52.572+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 138.4.31.23:43033 in memory (size: 7.3 KiB, free: 355.2 MiB)
[2025-07-11T14:09:52.891+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO Executor: Finished task 0.0 in stage 93.0 (TID 196). 5463 bytes result sent to driver
[2025-07-11T14:09:52.893+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 196) in 1048 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:09:52.910+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO Executor: Finished task 1.0 in stage 93.0 (TID 197). 5463 bytes result sent to driver
[2025-07-11T14:09:52.911+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO TaskSetManager: Finished task 1.0 in stage 93.0 (TID 197) in 1065 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:09:52.911+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool
[2025-07-11T14:09:52.916+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO DAGScheduler: ShuffleMapStage 93 (mapPartitions at RandomForest.scala:644) finished in 1,094 s
[2025-07-11T14:09:52.916+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:09:52.916+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO DAGScheduler: running: Set()
[2025-07-11T14:09:52.916+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO DAGScheduler: waiting: Set(ResultStage 94)
[2025-07-11T14:09:52.916+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO DAGScheduler: failed: Set()
[2025-07-11T14:09:52.916+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[181] at map at RandomForest.scala:663), which has no missing parents
[2025-07-11T14:09:52.918+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 24.0 KiB, free 345.1 MiB)
[2025-07-11T14:09:52.919+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 345.1 MiB)
[2025-07-11T14:09:52.919+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 138.4.31.23:43033 (size: 10.3 KiB, free: 355.2 MiB)
[2025-07-11T14:09:52.920+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:52.921+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 94 (MapPartitionsRDD[181] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:09:52.921+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO TaskSchedulerImpl: Adding task set 94.0 with 4 tasks resource profile 0
[2025-07-11T14:09:52.922+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 200) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:52.922+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO TaskSetManager: Starting task 1.0 in stage 94.0 (TID 201) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:52.922+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO TaskSetManager: Starting task 2.0 in stage 94.0 (TID 202) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:52.922+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO TaskSetManager: Starting task 3.0 in stage 94.0 (TID 203) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:09:52.923+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO Executor: Running task 0.0 in stage 94.0 (TID 200)
[2025-07-11T14:09:52.923+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO Executor: Running task 2.0 in stage 94.0 (TID 202)
[2025-07-11T14:09:52.923+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO Executor: Running task 3.0 in stage 94.0 (TID 203)
[2025-07-11T14:09:52.924+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO Executor: Running task 1.0 in stage 94.0 (TID 201)
[2025-07-11T14:09:52.927+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO ShuffleBlockFetcherIterator: Getting 4 (757.6 KiB) non-empty blocks including 4 (757.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:52.927+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:52.927+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO ShuffleBlockFetcherIterator: Getting 4 (861.8 KiB) non-empty blocks including 4 (861.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:52.927+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO ShuffleBlockFetcherIterator: Getting 4 (897.4 KiB) non-empty blocks including 4 (897.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:52.927+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:52.927+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:52.933+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO ShuffleBlockFetcherIterator: Getting 4 (749.4 KiB) non-empty blocks including 4 (749.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:52.933+0200] {subprocess.py:93} INFO - 25/07/11 14:09:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:09:54.027+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO Executor: Finished task 1.0 in stage 94.0 (TID 201). 163209 bytes result sent to driver
[2025-07-11T14:09:54.033+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO TaskSetManager: Finished task 1.0 in stage 94.0 (TID 201) in 1111 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:09:54.035+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO Executor: Finished task 0.0 in stage 94.0 (TID 200). 102018 bytes result sent to driver
[2025-07-11T14:09:54.040+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 200) in 1118 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:09:54.129+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO Executor: Finished task 3.0 in stage 94.0 (TID 203). 132045 bytes result sent to driver
[2025-07-11T14:09:54.133+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO TaskSetManager: Finished task 3.0 in stage 94.0 (TID 203) in 1210 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:09:54.284+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 138.4.31.23:43033 in memory (size: 479.7 KiB, free: 355.7 MiB)
[2025-07-11T14:09:54.461+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO Executor: Finished task 2.0 in stage 94.0 (TID 202). 327296 bytes result sent to driver
[2025-07-11T14:09:54.466+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO TaskSetManager: Finished task 2.0 in stage 94.0 (TID 202) in 1544 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:09:54.467+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO DAGScheduler: ResultStage 94 (collectAsMap at RandomForest.scala:663) finished in 1,549 s
[2025-07-11T14:09:54.468+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:09:54.468+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool
[2025-07-11T14:09:54.469+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 94: Stage finished
[2025-07-11T14:09:54.469+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO DAGScheduler: Job 54 finished: collectAsMap at RandomForest.scala:663, took 2,650178 s
[2025-07-11T14:09:54.470+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO TorrentBroadcast: Destroying Broadcast(79) (from destroy at RandomForest.scala:674)
[2025-07-11T14:09:54.471+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO RandomForest: Internal timing for DecisionTree:
[2025-07-11T14:09:54.471+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO RandomForest:   init: 0.001967103
[2025-07-11T14:09:54.472+0200] {subprocess.py:93} INFO -   total: 8.443425231
[2025-07-11T14:09:54.472+0200] {subprocess.py:93} INFO -   findBestSplits: 8.428000844
[2025-07-11T14:09:54.472+0200] {subprocess.py:93} INFO -   chooseSplits: 8.422715414
[2025-07-11T14:09:54.472+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 138.4.31.23:43033 in memory (size: 2.1 KiB, free: 355.7 MiB)
[2025-07-11T14:09:54.483+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO MapPartitionsRDD: Removing RDD 166 from persistence list
[2025-07-11T14:09:54.489+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO TorrentBroadcast: Destroying Broadcast(66) (from destroy at RandomForest.scala:305)
[2025-07-11T14:09:54.493+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO BlockManager: Removing RDD 166
[2025-07-11T14:09:54.497+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO Instrumentation: [d7c1ea9d] {"numClasses":4}
[2025-07-11T14:09:54.497+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO Instrumentation: [d7c1ea9d] {"numFeatures":9}
[2025-07-11T14:09:54.531+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 138.4.31.23:43033 in memory (size: 9.0 KiB, free: 434.1 MiB)
[2025-07-11T14:09:54.849+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO V2ScanRelationPushDown:
[2025-07-11T14:09:54.849+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:09:54.849+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:09:54.849+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:09:54.849+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:09:54.856+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO V2ScanRelationPushDown:
[2025-07-11T14:09:54.856+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-11T14:09:54.856+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:09:54.895+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:09:54.895+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:09:54.918+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 214.5 KiB, free 424.9 MiB)
[2025-07-11T14:09:54.927+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 424.9 MiB)
[2025-07-11T14:09:54.927+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 138.4.31.23:43033 (size: 38.9 KiB, free: 434.1 MiB)
[2025-07-11T14:09:54.928+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO SparkContext: Created broadcast 82 from rdd at ClassificationSummary.scala:58
[2025-07-11T14:09:54.928+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:09:54.932+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO DAGScheduler: Registering RDD 185 (rdd at ClassificationSummary.scala:58) as input to shuffle 30
[2025-07-11T14:09:54.932+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO DAGScheduler: Got map stage job 55 (rdd at ClassificationSummary.scala:58) with 2 output partitions
[2025-07-11T14:09:54.932+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO DAGScheduler: Final stage: ShuffleMapStage 95 (rdd at ClassificationSummary.scala:58)
[2025-07-11T14:09:54.932+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:09:54.933+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:54.933+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO DAGScheduler: Submitting ShuffleMapStage 95 (MapPartitionsRDD[185] at rdd at ClassificationSummary.scala:58), which has no missing parents
[2025-07-11T14:09:54.936+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 20.7 KiB, free 424.9 MiB)
[2025-07-11T14:09:54.938+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 9.3 KiB, free 424.9 MiB)
[2025-07-11T14:09:54.938+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 138.4.31.23:43033 (size: 9.3 KiB, free: 434.1 MiB)
[2025-07-11T14:09:54.938+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:54.938+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 95 (MapPartitionsRDD[185] at rdd at ClassificationSummary.scala:58) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:09:54.938+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO TaskSchedulerImpl: Adding task set 95.0 with 2 tasks resource profile 0
[2025-07-11T14:09:54.941+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 204) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:09:54.941+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO TaskSetManager: Starting task 1.0 in stage 95.0 (TID 205) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:09:54.941+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO Executor: Running task 0.0 in stage 95.0 (TID 204)
[2025-07-11T14:09:54.941+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO Executor: Running task 1.0 in stage 95.0 (TID 205)
[2025-07-11T14:09:54.943+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO DAGScheduler: Registering RDD 189 (rdd at ClassificationSummary.scala:58) as input to shuffle 31
[2025-07-11T14:09:54.943+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO DAGScheduler: Got map stage job 56 (rdd at ClassificationSummary.scala:58) with 13 output partitions
[2025-07-11T14:09:54.943+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO DAGScheduler: Final stage: ShuffleMapStage 96 (rdd at ClassificationSummary.scala:58)
[2025-07-11T14:09:54.943+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:09:54.943+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:54.944+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO DAGScheduler: Submitting ShuffleMapStage 96 (MapPartitionsRDD[189] at rdd at ClassificationSummary.scala:58), which has no missing parents
[2025-07-11T14:09:54.947+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 18.7 KiB, free 424.9 MiB)
[2025-07-11T14:09:54.948+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 424.9 MiB)
[2025-07-11T14:09:54.949+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 138.4.31.23:43033 (size: 9.2 KiB, free: 434.0 MiB)
[2025-07-11T14:09:54.949+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:54.949+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 96 (MapPartitionsRDD[189] at rdd at ClassificationSummary.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-11T14:09:54.949+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO TaskSchedulerImpl: Adding task set 96.0 with 13 tasks resource profile 0
[2025-07-11T14:09:54.950+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 206) (138.4.31.23, executor driver, partition 0, ANY, 16839 bytes)
[2025-07-11T14:09:54.950+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO TaskSetManager: Starting task 1.0 in stage 96.0 (TID 207) (138.4.31.23, executor driver, partition 1, ANY, 16719 bytes)
[2025-07-11T14:09:54.951+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:09:54.951+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO Executor: Running task 0.0 in stage 96.0 (TID 206)
[2025-07-11T14:09:54.951+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:09:54.957+0200] {subprocess.py:93} INFO - 25/07/11 14:09:54 INFO Executor: Running task 1.0 in stage 96.0 (TID 207)
[2025-07-11T14:09:55.028+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Finished task 0.0 in stage 96.0 (TID 206). 1945 bytes result sent to driver
[2025-07-11T14:09:55.029+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Starting task 2.0 in stage 96.0 (TID 208) (138.4.31.23, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-11T14:09:55.029+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 206) in 79 ms on 138.4.31.23 (executor driver) (1/13)
[2025-07-11T14:09:55.029+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Running task 2.0 in stage 96.0 (TID 208)
[2025-07-11T14:09:55.033+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Finished task 1.0 in stage 96.0 (TID 207). 1945 bytes result sent to driver
[2025-07-11T14:09:55.033+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Starting task 3.0 in stage 96.0 (TID 209) (138.4.31.23, executor driver, partition 3, ANY, 16715 bytes)
[2025-07-11T14:09:55.033+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Finished task 1.0 in stage 96.0 (TID 207) in 83 ms on 138.4.31.23 (executor driver) (2/13)
[2025-07-11T14:09:55.046+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Running task 3.0 in stage 96.0 (TID 209)
[2025-07-11T14:09:55.118+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Finished task 3.0 in stage 96.0 (TID 209). 1945 bytes result sent to driver
[2025-07-11T14:09:55.118+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Finished task 2.0 in stage 96.0 (TID 208). 1945 bytes result sent to driver
[2025-07-11T14:09:55.120+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Starting task 4.0 in stage 96.0 (TID 210) (138.4.31.23, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-11T14:09:55.120+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Starting task 5.0 in stage 96.0 (TID 211) (138.4.31.23, executor driver, partition 5, ANY, 16719 bytes)
[2025-07-11T14:09:55.121+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Running task 4.0 in stage 96.0 (TID 210)
[2025-07-11T14:09:55.121+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Finished task 3.0 in stage 96.0 (TID 209) in 88 ms on 138.4.31.23 (executor driver) (3/13)
[2025-07-11T14:09:55.121+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Finished task 2.0 in stage 96.0 (TID 208) in 92 ms on 138.4.31.23 (executor driver) (4/13)
[2025-07-11T14:09:55.121+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Running task 5.0 in stage 96.0 (TID 211)
[2025-07-11T14:09:55.206+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Finished task 5.0 in stage 96.0 (TID 211). 1945 bytes result sent to driver
[2025-07-11T14:09:55.206+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Starting task 6.0 in stage 96.0 (TID 212) (138.4.31.23, executor driver, partition 6, ANY, 16719 bytes)
[2025-07-11T14:09:55.207+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Finished task 5.0 in stage 96.0 (TID 211) in 88 ms on 138.4.31.23 (executor driver) (5/13)
[2025-07-11T14:09:55.210+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Finished task 4.0 in stage 96.0 (TID 210). 1945 bytes result sent to driver
[2025-07-11T14:09:55.210+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Running task 6.0 in stage 96.0 (TID 212)
[2025-07-11T14:09:55.211+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Starting task 7.0 in stage 96.0 (TID 213) (138.4.31.23, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-11T14:09:55.211+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Finished task 4.0 in stage 96.0 (TID 210) in 92 ms on 138.4.31.23 (executor driver) (6/13)
[2025-07-11T14:09:55.214+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Running task 7.0 in stage 96.0 (TID 213)
[2025-07-11T14:09:55.291+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Finished task 7.0 in stage 96.0 (TID 213). 1945 bytes result sent to driver
[2025-07-11T14:09:55.292+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Starting task 8.0 in stage 96.0 (TID 214) (138.4.31.23, executor driver, partition 8, ANY, 16839 bytes)
[2025-07-11T14:09:55.292+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Finished task 7.0 in stage 96.0 (TID 213) in 82 ms on 138.4.31.23 (executor driver) (7/13)
[2025-07-11T14:09:55.302+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Running task 8.0 in stage 96.0 (TID 214)
[2025-07-11T14:09:55.314+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Finished task 6.0 in stage 96.0 (TID 212). 1945 bytes result sent to driver
[2025-07-11T14:09:55.314+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Starting task 9.0 in stage 96.0 (TID 215) (138.4.31.23, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-11T14:09:55.315+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Finished task 6.0 in stage 96.0 (TID 212) in 109 ms on 138.4.31.23 (executor driver) (8/13)
[2025-07-11T14:09:55.315+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Running task 9.0 in stage 96.0 (TID 215)
[2025-07-11T14:09:55.412+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 138.4.31.23:43033 in memory (size: 10.3 KiB, free: 434.1 MiB)
[2025-07-11T14:09:55.440+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Finished task 9.0 in stage 96.0 (TID 215). 1988 bytes result sent to driver
[2025-07-11T14:09:55.441+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Starting task 10.0 in stage 96.0 (TID 216) (138.4.31.23, executor driver, partition 10, ANY, 16839 bytes)
[2025-07-11T14:09:55.441+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Finished task 9.0 in stage 96.0 (TID 215) in 127 ms on 138.4.31.23 (executor driver) (9/13)
[2025-07-11T14:09:55.451+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Running task 10.0 in stage 96.0 (TID 216)
[2025-07-11T14:09:55.467+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Finished task 8.0 in stage 96.0 (TID 214). 1988 bytes result sent to driver
[2025-07-11T14:09:55.467+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Starting task 11.0 in stage 96.0 (TID 217) (138.4.31.23, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-11T14:09:55.467+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Finished task 8.0 in stage 96.0 (TID 214) in 170 ms on 138.4.31.23 (executor driver) (10/13)
[2025-07-11T14:09:55.467+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Running task 11.0 in stage 96.0 (TID 217)
[2025-07-11T14:09:55.556+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Finished task 10.0 in stage 96.0 (TID 216). 1945 bytes result sent to driver
[2025-07-11T14:09:55.557+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Starting task 12.0 in stage 96.0 (TID 218) (138.4.31.23, executor driver, partition 12, ANY, 16719 bytes)
[2025-07-11T14:09:55.558+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Finished task 10.0 in stage 96.0 (TID 216) in 117 ms on 138.4.31.23 (executor driver) (11/13)
[2025-07-11T14:09:55.561+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Running task 12.0 in stage 96.0 (TID 218)
[2025-07-11T14:09:55.581+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Finished task 11.0 in stage 96.0 (TID 217). 1945 bytes result sent to driver
[2025-07-11T14:09:55.583+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Finished task 11.0 in stage 96.0 (TID 217) in 122 ms on 138.4.31.23 (executor driver) (12/13)
[2025-07-11T14:09:55.605+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Finished task 12.0 in stage 96.0 (TID 218). 1945 bytes result sent to driver
[2025-07-11T14:09:55.606+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Finished task 12.0 in stage 96.0 (TID 218) in 49 ms on 138.4.31.23 (executor driver) (13/13)
[2025-07-11T14:09:55.606+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool
[2025-07-11T14:09:55.606+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO DAGScheduler: ShuffleMapStage 96 (rdd at ClassificationSummary.scala:58) finished in 0,660 s
[2025-07-11T14:09:55.606+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:09:55.606+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO DAGScheduler: running: Set(ShuffleMapStage 95)
[2025-07-11T14:09:55.607+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:09:55.607+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO DAGScheduler: failed: Set()
[2025-07-11T14:09:55.625+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO ShufflePartitionsUtil: For shuffle(31), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:09:55.640+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:09:55.641+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO DAGScheduler: Got job 57 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-11T14:09:55.641+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO DAGScheduler: Final stage: ResultStage 98 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-11T14:09:55.641+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 97)
[2025-07-11T14:09:55.641+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:09:55.641+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[191] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-11T14:09:55.644+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 8.2 KiB, free 424.9 MiB)
[2025-07-11T14:09:55.644+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 424.9 MiB)
[2025-07-11T14:09:55.645+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 138.4.31.23:43033 (size: 4.2 KiB, free: 434.1 MiB)
[2025-07-11T14:09:55.646+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:09:55.648+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[191] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:09:55.648+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks resource profile 0
[2025-07-11T14:09:55.648+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 219) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-11T14:09:55.648+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Running task 0.0 in stage 98.0 (TID 219)
[2025-07-11T14:09:55.654+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO ShuffleBlockFetcherIterator: Getting 13 (221.8 KiB) non-empty blocks including 13 (221.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:09:55.655+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-11T14:09:55.678+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO Executor: Finished task 0.0 in stage 98.0 (TID 219). 51220 bytes result sent to driver
[2025-07-11T14:09:55.679+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 219) in 32 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:09:55.679+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool
[2025-07-11T14:09:55.679+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO DAGScheduler: ResultStage 98 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,037 s
[2025-07-11T14:09:55.679+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:09:55.679+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 98: Stage finished
[2025-07-11T14:09:55.679+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO DAGScheduler: Job 57 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,038713 s
[2025-07-11T14:09:55.689+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 4.3 MiB, free 420.6 MiB)
[2025-07-11T14:09:55.691+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 109.5 KiB, free 420.5 MiB)
[2025-07-11T14:09:55.694+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 138.4.31.23:43033 (size: 109.5 KiB, free: 433.9 MiB)
[2025-07-11T14:09:55.695+0200] {subprocess.py:93} INFO - 25/07/11 14:09:55 INFO SparkContext: Created broadcast 86 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:09:56.268+0200] {subprocess.py:93} INFO - 25/07/11 14:09:56 INFO Executor: Finished task 1.0 in stage 95.0 (TID 205). 2031 bytes result sent to driver
[2025-07-11T14:09:56.269+0200] {subprocess.py:93} INFO - 25/07/11 14:09:56 INFO TaskSetManager: Finished task 1.0 in stage 95.0 (TID 205) in 1328 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:09:56.439+0200] {subprocess.py:93} INFO - 25/07/11 14:09:56 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 138.4.31.23:43033 in memory (size: 4.2 KiB, free: 433.9 MiB)
[2025-07-11T14:10:02.253+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO Executor: Finished task 0.0 in stage 95.0 (TID 204). 2074 bytes result sent to driver
[2025-07-11T14:10:02.254+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 204) in 7314 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:10:02.254+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool
[2025-07-11T14:10:02.255+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: ShuffleMapStage 95 (rdd at ClassificationSummary.scala:58) finished in 7,321 s
[2025-07-11T14:10:02.255+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:10:02.255+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: running: Set()
[2025-07-11T14:10:02.255+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:10:02.255+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: failed: Set()
[2025-07-11T14:10:02.265+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO ShufflePartitionsUtil: For shuffle(30), advisory target size: 67108864, actual target size 1923052, minimum partition size: 1048576
[2025-07-11T14:10:02.321+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO CodeGenerator: Code generated in 24.901744 ms
[2025-07-11T14:10:02.361+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO Instrumentation: [d7c1ea9d] training finished
[2025-07-11T14:10:02.434+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO BlockManager: Removing RDD 166
[2025-07-11T14:10:02.439+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 138.4.31.23:43033 in memory (size: 9.2 KiB, free: 434.0 MiB)
[2025-07-11T14:10:02.452+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileSystemOverwrite: Path /home/monica.fernandez/practica_creativa/models/spark_random_forest_classifier.flight_delays.5.0.bin already exists. It will be overwritten.
[2025-07-11T14:10:02.485+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:10:02.485+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:02.489+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:02.532+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-11T14:10:02.533+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Got job 58 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-11T14:10:02.534+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Final stage: ResultStage 99 (runJob at SparkHadoopWriter.scala:83)
[2025-07-11T14:10:02.534+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:10:02.534+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:02.534+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[199] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-11T14:10:02.540+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 101.4 KiB, free 420.5 MiB)
[2025-07-11T14:10:02.541+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 420.4 MiB)
[2025-07-11T14:10:02.542+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 138.4.31.23:43033 (size: 36.5 KiB, free: 433.9 MiB)
[2025-07-11T14:10:02.542+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:02.542+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[199] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:10:02.542+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks resource profile 0
[2025-07-11T14:10:02.543+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 220) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15042 bytes)
[2025-07-11T14:10:02.543+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO Executor: Running task 0.0 in stage 99.0 (TID 220)
[2025-07-11T14:10:02.548+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:10:02.548+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:02.548+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:02.605+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileOutputCommitter: Saved output of task 'attempt_202507111410028634995958041768066_0199_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/spark_random_forest_classifier.flight_delays.5.0.bin/metadata/_temporary/0/task_202507111410028634995958041768066_0199_m_000000
[2025-07-11T14:10:02.605+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO SparkHadoopMapRedUtil: attempt_202507111410028634995958041768066_0199_m_000000_0: Committed. Elapsed time: 1 ms.
[2025-07-11T14:10:02.605+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO Executor: Finished task 0.0 in stage 99.0 (TID 220). 1170 bytes result sent to driver
[2025-07-11T14:10:02.606+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 220) in 63 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:10:02.607+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool
[2025-07-11T14:10:02.608+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: ResultStage 99 (runJob at SparkHadoopWriter.scala:83) finished in 0,074 s
[2025-07-11T14:10:02.608+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:10:02.608+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 99: Stage finished
[2025-07-11T14:10:02.608+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Job 58 finished: runJob at SparkHadoopWriter.scala:83, took 0,075165 s
[2025-07-11T14:10:02.608+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO SparkHadoopWriter: Start to commit write Job job_202507111410028634995958041768066_0199.
[2025-07-11T14:10:02.635+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO SparkHadoopWriter: Write Job job_202507111410028634995958041768066_0199 committed. Elapsed time: 27 ms.
[2025-07-11T14:10:02.652+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:10:02.652+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:02.652+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:02.684+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-11T14:10:02.686+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Got job 59 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-11T14:10:02.686+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Final stage: ResultStage 100 (runJob at SparkHadoopWriter.scala:83)
[2025-07-11T14:10:02.686+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:10:02.686+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:02.686+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[201] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-11T14:10:02.691+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 101.5 KiB, free 420.3 MiB)
[2025-07-11T14:10:02.692+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 36.6 KiB, free 420.3 MiB)
[2025-07-11T14:10:02.693+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 138.4.31.23:43033 (size: 36.6 KiB, free: 433.9 MiB)
[2025-07-11T14:10:02.693+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:02.693+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[201] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:10:02.693+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks resource profile 0
[2025-07-11T14:10:02.694+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 221) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15658 bytes)
[2025-07-11T14:10:02.695+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO Executor: Running task 0.0 in stage 100.0 (TID 221)
[2025-07-11T14:10:02.699+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:10:02.699+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:02.699+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:02.725+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileOutputCommitter: Saved output of task 'attempt_202507111410025098066809060240060_0201_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/spark_random_forest_classifier.flight_delays.5.0.bin/stages/0_RandomForestClassifier_6425afc2c8a8/metadata/_temporary/0/task_202507111410025098066809060240060_0201_m_000000
[2025-07-11T14:10:02.725+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO SparkHadoopMapRedUtil: attempt_202507111410025098066809060240060_0201_m_000000_0: Committed. Elapsed time: 1 ms.
[2025-07-11T14:10:02.725+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO Executor: Finished task 0.0 in stage 100.0 (TID 221). 1170 bytes result sent to driver
[2025-07-11T14:10:02.726+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 221) in 32 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:10:02.726+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool
[2025-07-11T14:10:02.726+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: ResultStage 100 (runJob at SparkHadoopWriter.scala:83) finished in 0,041 s
[2025-07-11T14:10:02.726+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:10:02.726+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 100: Stage finished
[2025-07-11T14:10:02.726+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Job 59 finished: runJob at SparkHadoopWriter.scala:83, took 0,042272 s
[2025-07-11T14:10:02.727+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO SparkHadoopWriter: Start to commit write Job job_202507111410025098066809060240060_0201.
[2025-07-11T14:10:02.748+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO SparkHadoopWriter: Write Job job_202507111410025098066809060240060_0201 committed. Elapsed time: 21 ms.
[2025-07-11T14:10:02.810+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO CodeGenerator: Code generated in 5.04307 ms
[2025-07-11T14:10:02.815+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Registering RDD 204 (parquet at treeModels.scala:483) as input to shuffle 32
[2025-07-11T14:10:02.815+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Got map stage job 60 (parquet at treeModels.scala:483) with 4 output partitions
[2025-07-11T14:10:02.815+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Final stage: ShuffleMapStage 101 (parquet at treeModels.scala:483)
[2025-07-11T14:10:02.815+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:10:02.815+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:02.815+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Submitting ShuffleMapStage 101 (MapPartitionsRDD[204] at parquet at treeModels.scala:483), which has no missing parents
[2025-07-11T14:10:02.819+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 8.3 KiB, free 420.3 MiB)
[2025-07-11T14:10:02.819+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 420.3 MiB)
[2025-07-11T14:10:02.820+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 138.4.31.23:43033 (size: 4.5 KiB, free: 433.9 MiB)
[2025-07-11T14:10:02.820+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:02.820+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 101 (MapPartitionsRDD[204] at parquet at treeModels.scala:483) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:10:02.820+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSchedulerImpl: Adding task set 101.0 with 4 tasks resource profile 0
[2025-07-11T14:10:02.820+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 222) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 16404 bytes)
[2025-07-11T14:10:02.820+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSetManager: Starting task 1.0 in stage 101.0 (TID 223) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 17128 bytes)
[2025-07-11T14:10:02.820+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSetManager: Starting task 2.0 in stage 101.0 (TID 224) (138.4.31.23, executor driver, partition 2, PROCESS_LOCAL, 16404 bytes)
[2025-07-11T14:10:02.820+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSetManager: Starting task 3.0 in stage 101.0 (TID 225) (138.4.31.23, executor driver, partition 3, PROCESS_LOCAL, 17128 bytes)
[2025-07-11T14:10:02.820+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO Executor: Running task 0.0 in stage 101.0 (TID 222)
[2025-07-11T14:10:02.822+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO Executor: Running task 1.0 in stage 101.0 (TID 223)
[2025-07-11T14:10:02.822+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO Executor: Running task 3.0 in stage 101.0 (TID 225)
[2025-07-11T14:10:02.822+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO Executor: Running task 2.0 in stage 101.0 (TID 224)
[2025-07-11T14:10:02.828+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO Executor: Finished task 1.0 in stage 101.0 (TID 223). 1628 bytes result sent to driver
[2025-07-11T14:10:02.828+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSetManager: Finished task 1.0 in stage 101.0 (TID 223) in 5 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:10:02.828+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO Executor: Finished task 2.0 in stage 101.0 (TID 224). 1628 bytes result sent to driver
[2025-07-11T14:10:02.828+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO Executor: Finished task 0.0 in stage 101.0 (TID 222). 1628 bytes result sent to driver
[2025-07-11T14:10:02.828+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO Executor: Finished task 3.0 in stage 101.0 (TID 225). 1628 bytes result sent to driver
[2025-07-11T14:10:02.828+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 222) in 8 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:10:02.828+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSetManager: Finished task 2.0 in stage 101.0 (TID 224) in 8 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:10:02.828+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSetManager: Finished task 3.0 in stage 101.0 (TID 225) in 8 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:10:02.828+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool
[2025-07-11T14:10:02.828+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: ShuffleMapStage 101 (parquet at treeModels.scala:483) finished in 0,011 s
[2025-07-11T14:10:02.828+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:10:02.828+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: running: Set()
[2025-07-11T14:10:02.829+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:10:02.829+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: failed: Set()
[2025-07-11T14:10:02.833+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:10:02.834+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:02.834+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:02.834+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:10:02.834+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:02.834+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:02.834+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:10:02.851+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO SparkContext: Starting job: parquet at treeModels.scala:483
[2025-07-11T14:10:02.852+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Got job 61 (parquet at treeModels.scala:483) with 1 output partitions
[2025-07-11T14:10:02.852+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Final stage: ResultStage 103 (parquet at treeModels.scala:483)
[2025-07-11T14:10:02.852+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 102)
[2025-07-11T14:10:02.852+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:02.852+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[206] at parquet at treeModels.scala:483), which has no missing parents
[2025-07-11T14:10:02.865+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 239.9 KiB, free 420.0 MiB)
[2025-07-11T14:10:02.866+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 84.1 KiB, free 420.0 MiB)
[2025-07-11T14:10:02.866+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 138.4.31.23:43033 (size: 84.1 KiB, free: 433.8 MiB)
[2025-07-11T14:10:02.866+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:02.867+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[206] at parquet at treeModels.scala:483) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:10:02.867+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks resource profile 0
[2025-07-11T14:10:02.867+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 226) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:10:02.868+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO Executor: Running task 0.0 in stage 103.0 (TID 226)
[2025-07-11T14:10:02.876+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:02.876+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:10:02.877+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:02.877+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:02.877+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:10:02.877+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:02.877+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:02.877+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:10:02.877+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:10:02.877+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:10:02.878+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-11T14:10:02.879+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-11T14:10:02.879+0200] {subprocess.py:93} INFO - {
[2025-07-11T14:10:02.879+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-11T14:10:02.879+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-11T14:10:02.879+0200] {subprocess.py:93} INFO -     "name" : "treeID",
[2025-07-11T14:10:02.879+0200] {subprocess.py:93} INFO -     "type" : "integer",
[2025-07-11T14:10:02.880+0200] {subprocess.py:93} INFO -     "nullable" : false,
[2025-07-11T14:10:02.880+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:10:02.880+0200] {subprocess.py:93} INFO -   }, {
[2025-07-11T14:10:02.880+0200] {subprocess.py:93} INFO -     "name" : "metadata",
[2025-07-11T14:10:02.880+0200] {subprocess.py:93} INFO -     "type" : "string",
[2025-07-11T14:10:02.880+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-11T14:10:02.880+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:10:02.880+0200] {subprocess.py:93} INFO -   }, {
[2025-07-11T14:10:02.880+0200] {subprocess.py:93} INFO -     "name" : "weights",
[2025-07-11T14:10:02.880+0200] {subprocess.py:93} INFO -     "type" : "double",
[2025-07-11T14:10:02.880+0200] {subprocess.py:93} INFO -     "nullable" : false,
[2025-07-11T14:10:02.880+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:10:02.880+0200] {subprocess.py:93} INFO -   } ]
[2025-07-11T14:10:02.880+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:10:02.880+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-11T14:10:02.880+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-11T14:10:02.880+0200] {subprocess.py:93} INFO -   required int32 treeID;
[2025-07-11T14:10:02.880+0200] {subprocess.py:93} INFO -   optional binary metadata (STRING);
[2025-07-11T14:10:02.880+0200] {subprocess.py:93} INFO -   required double weights;
[2025-07-11T14:10:02.881+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:10:02.881+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:10:02.881+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:10:02.934+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileOutputCommitter: Saved output of task 'attempt_202507111410025529094433720955989_0103_m_000000_226' to file:/home/monica.fernandez/practica_creativa/models/spark_random_forest_classifier.flight_delays.5.0.bin/stages/0_RandomForestClassifier_6425afc2c8a8/treesMetadata/_temporary/0/task_202507111410025529094433720955989_0103_m_000000
[2025-07-11T14:10:02.934+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO SparkHadoopMapRedUtil: attempt_202507111410025529094433720955989_0103_m_000000_226: Committed. Elapsed time: 1 ms.
[2025-07-11T14:10:02.935+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO Executor: Finished task 0.0 in stage 103.0 (TID 226). 4740 bytes result sent to driver
[2025-07-11T14:10:02.935+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 226) in 68 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:10:02.935+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool
[2025-07-11T14:10:02.935+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: ResultStage 103 (parquet at treeModels.scala:483) finished in 0,083 s
[2025-07-11T14:10:02.936+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:10:02.936+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 103: Stage finished
[2025-07-11T14:10:02.936+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO DAGScheduler: Job 61 finished: parquet at treeModels.scala:483, took 0,084303 s
[2025-07-11T14:10:02.936+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileFormatWriter: Start to commit write Job 35f17559-802a-45e5-9cba-36cd6898f7eb.
[2025-07-11T14:10:02.958+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileFormatWriter: Write Job 35f17559-802a-45e5-9cba-36cd6898f7eb committed. Elapsed time: 21 ms.
[2025-07-11T14:10:02.958+0200] {subprocess.py:93} INFO - 25/07/11 14:10:02 INFO FileFormatWriter: Finished processing stats for write job 35f17559-802a-45e5-9cba-36cd6898f7eb.
[2025-07-11T14:10:03.047+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO CodeGenerator: Code generated in 23.114521 ms
[2025-07-11T14:10:03.050+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Registering RDD 211 (parquet at treeModels.scala:491) as input to shuffle 33
[2025-07-11T14:10:03.051+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Got map stage job 62 (parquet at treeModels.scala:491) with 4 output partitions
[2025-07-11T14:10:03.051+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Final stage: ShuffleMapStage 104 (parquet at treeModels.scala:491)
[2025-07-11T14:10:03.051+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:10:03.051+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:03.051+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Submitting ShuffleMapStage 104 (MapPartitionsRDD[211] at parquet at treeModels.scala:491), which has no missing parents
[2025-07-11T14:10:03.054+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 41.5 KiB, free 419.9 MiB)
[2025-07-11T14:10:03.055+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 12.3 KiB, free 419.9 MiB)
[2025-07-11T14:10:03.055+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 138.4.31.23:43033 (size: 12.3 KiB, free: 433.8 MiB)
[2025-07-11T14:10:03.056+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:03.056+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 104 (MapPartitionsRDD[211] at parquet at treeModels.scala:491) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:10:03.056+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSchedulerImpl: Adding task set 104.0 with 4 tasks resource profile 0
[2025-07-11T14:10:03.059+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 227) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 140337 bytes)
[2025-07-11T14:10:03.063+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Starting task 1.0 in stage 104.0 (TID 228) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 386293 bytes)
[2025-07-11T14:10:03.065+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Starting task 2.0 in stage 104.0 (TID 229) (138.4.31.23, executor driver, partition 2, PROCESS_LOCAL, 128364 bytes)
[2025-07-11T14:10:03.068+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Starting task 3.0 in stage 104.0 (TID 230) (138.4.31.23, executor driver, partition 3, PROCESS_LOCAL, 208919 bytes)
[2025-07-11T14:10:03.069+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Running task 0.0 in stage 104.0 (TID 227)
[2025-07-11T14:10:03.069+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Running task 1.0 in stage 104.0 (TID 228)
[2025-07-11T14:10:03.069+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Running task 3.0 in stage 104.0 (TID 230)
[2025-07-11T14:10:03.070+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Running task 2.0 in stage 104.0 (TID 229)
[2025-07-11T14:10:03.105+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO CodeGenerator: Code generated in 21.340535 ms
[2025-07-11T14:10:03.119+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Finished task 2.0 in stage 104.0 (TID 229). 1700 bytes result sent to driver
[2025-07-11T14:10:03.119+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Finished task 2.0 in stage 104.0 (TID 229) in 56 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:10:03.134+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Finished task 0.0 in stage 104.0 (TID 227). 1700 bytes result sent to driver
[2025-07-11T14:10:03.135+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 227) in 79 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:10:03.140+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Finished task 3.0 in stage 104.0 (TID 230). 1700 bytes result sent to driver
[2025-07-11T14:10:03.141+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Finished task 3.0 in stage 104.0 (TID 230) in 76 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:10:03.155+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Finished task 1.0 in stage 104.0 (TID 228). 1700 bytes result sent to driver
[2025-07-11T14:10:03.156+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Finished task 1.0 in stage 104.0 (TID 228) in 98 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:10:03.156+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool
[2025-07-11T14:10:03.156+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: ShuffleMapStage 104 (parquet at treeModels.scala:491) finished in 0,105 s
[2025-07-11T14:10:03.156+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:10:03.156+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: running: Set()
[2025-07-11T14:10:03.156+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:10:03.157+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: failed: Set()
[2025-07-11T14:10:03.164+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:10:03.165+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:03.165+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:03.165+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:10:03.165+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:03.166+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:03.166+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:10:03.186+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO SparkContext: Starting job: parquet at treeModels.scala:491
[2025-07-11T14:10:03.188+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Got job 63 (parquet at treeModels.scala:491) with 1 output partitions
[2025-07-11T14:10:03.188+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Final stage: ResultStage 106 (parquet at treeModels.scala:491)
[2025-07-11T14:10:03.188+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 105)
[2025-07-11T14:10:03.188+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:03.188+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[213] at parquet at treeModels.scala:491), which has no missing parents
[2025-07-11T14:10:03.207+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 241.5 KiB, free 419.7 MiB)
[2025-07-11T14:10:03.207+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 84.8 KiB, free 419.6 MiB)
[2025-07-11T14:10:03.208+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 138.4.31.23:43033 (size: 84.8 KiB, free: 433.7 MiB)
[2025-07-11T14:10:03.208+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:03.208+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[213] at parquet at treeModels.scala:491) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:10:03.208+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks resource profile 0
[2025-07-11T14:10:03.209+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 231) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:10:03.209+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Running task 0.0 in stage 106.0 (TID 231)
[2025-07-11T14:10:03.219+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO ShuffleBlockFetcherIterator: Getting 4 (176.9 KiB) non-empty blocks including 4 (176.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:03.219+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:10:03.221+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:03.222+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:03.222+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:10:03.222+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:03.222+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:03.223+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:10:03.223+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:10:03.223+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:10:03.224+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-11T14:10:03.230+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-11T14:10:03.230+0200] {subprocess.py:93} INFO - {
[2025-07-11T14:10:03.230+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-11T14:10:03.230+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-11T14:10:03.230+0200] {subprocess.py:93} INFO -     "name" : "treeID",
[2025-07-11T14:10:03.230+0200] {subprocess.py:93} INFO -     "type" : "integer",
[2025-07-11T14:10:03.230+0200] {subprocess.py:93} INFO -     "nullable" : false,
[2025-07-11T14:10:03.230+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:10:03.230+0200] {subprocess.py:93} INFO -   }, {
[2025-07-11T14:10:03.231+0200] {subprocess.py:93} INFO -     "name" : "nodeData",
[2025-07-11T14:10:03.231+0200] {subprocess.py:93} INFO -     "type" : {
[2025-07-11T14:10:03.231+0200] {subprocess.py:93} INFO -       "type" : "struct",
[2025-07-11T14:10:03.231+0200] {subprocess.py:93} INFO -       "fields" : [ {
[2025-07-11T14:10:03.231+0200] {subprocess.py:93} INFO -         "name" : "id",
[2025-07-11T14:10:03.231+0200] {subprocess.py:93} INFO -         "type" : "integer",
[2025-07-11T14:10:03.231+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:10:03.231+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:10:03.231+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:10:03.231+0200] {subprocess.py:93} INFO -         "name" : "prediction",
[2025-07-11T14:10:03.231+0200] {subprocess.py:93} INFO -         "type" : "double",
[2025-07-11T14:10:03.231+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:10:03.231+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:10:03.232+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:10:03.232+0200] {subprocess.py:93} INFO -         "name" : "impurity",
[2025-07-11T14:10:03.232+0200] {subprocess.py:93} INFO -         "type" : "double",
[2025-07-11T14:10:03.232+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:10:03.232+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:10:03.232+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:10:03.232+0200] {subprocess.py:93} INFO -         "name" : "impurityStats",
[2025-07-11T14:10:03.232+0200] {subprocess.py:93} INFO -         "type" : {
[2025-07-11T14:10:03.232+0200] {subprocess.py:93} INFO -           "type" : "array",
[2025-07-11T14:10:03.232+0200] {subprocess.py:93} INFO -           "elementType" : "double",
[2025-07-11T14:10:03.232+0200] {subprocess.py:93} INFO -           "containsNull" : false
[2025-07-11T14:10:03.232+0200] {subprocess.py:93} INFO -         },
[2025-07-11T14:10:03.232+0200] {subprocess.py:93} INFO -         "nullable" : true,
[2025-07-11T14:10:03.232+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:10:03.232+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:10:03.232+0200] {subprocess.py:93} INFO -         "name" : "rawCount",
[2025-07-11T14:10:03.233+0200] {subprocess.py:93} INFO -         "type" : "long",
[2025-07-11T14:10:03.233+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:10:03.233+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:10:03.233+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:10:03.233+0200] {subprocess.py:93} INFO -         "name" : "gain",
[2025-07-11T14:10:03.233+0200] {subprocess.py:93} INFO -         "type" : "double",
[2025-07-11T14:10:03.233+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:10:03.233+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:10:03.233+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:10:03.233+0200] {subprocess.py:93} INFO -         "name" : "leftChild",
[2025-07-11T14:10:03.233+0200] {subprocess.py:93} INFO -         "type" : "integer",
[2025-07-11T14:10:03.233+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:10:03.233+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:10:03.233+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:10:03.233+0200] {subprocess.py:93} INFO -         "name" : "rightChild",
[2025-07-11T14:10:03.233+0200] {subprocess.py:93} INFO -         "type" : "integer",
[2025-07-11T14:10:03.233+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:10:03.234+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:10:03.234+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:10:03.234+0200] {subprocess.py:93} INFO -         "name" : "split",
[2025-07-11T14:10:03.234+0200] {subprocess.py:93} INFO -         "type" : {
[2025-07-11T14:10:03.234+0200] {subprocess.py:93} INFO -           "type" : "struct",
[2025-07-11T14:10:03.234+0200] {subprocess.py:93} INFO -           "fields" : [ {
[2025-07-11T14:10:03.234+0200] {subprocess.py:93} INFO -             "name" : "featureIndex",
[2025-07-11T14:10:03.234+0200] {subprocess.py:93} INFO -             "type" : "integer",
[2025-07-11T14:10:03.234+0200] {subprocess.py:93} INFO -             "nullable" : false,
[2025-07-11T14:10:03.234+0200] {subprocess.py:93} INFO -             "metadata" : { }
[2025-07-11T14:10:03.234+0200] {subprocess.py:93} INFO -           }, {
[2025-07-11T14:10:03.234+0200] {subprocess.py:93} INFO -             "name" : "leftCategoriesOrThreshold",
[2025-07-11T14:10:03.234+0200] {subprocess.py:93} INFO -             "type" : {
[2025-07-11T14:10:03.234+0200] {subprocess.py:93} INFO -               "type" : "array",
[2025-07-11T14:10:03.234+0200] {subprocess.py:93} INFO -               "elementType" : "double",
[2025-07-11T14:10:03.234+0200] {subprocess.py:93} INFO -               "containsNull" : false
[2025-07-11T14:10:03.234+0200] {subprocess.py:93} INFO -             },
[2025-07-11T14:10:03.235+0200] {subprocess.py:93} INFO -             "nullable" : true,
[2025-07-11T14:10:03.235+0200] {subprocess.py:93} INFO -             "metadata" : { }
[2025-07-11T14:10:03.235+0200] {subprocess.py:93} INFO -           }, {
[2025-07-11T14:10:03.235+0200] {subprocess.py:93} INFO -             "name" : "numCategories",
[2025-07-11T14:10:03.235+0200] {subprocess.py:93} INFO -             "type" : "integer",
[2025-07-11T14:10:03.235+0200] {subprocess.py:93} INFO -             "nullable" : false,
[2025-07-11T14:10:03.235+0200] {subprocess.py:93} INFO -             "metadata" : { }
[2025-07-11T14:10:03.235+0200] {subprocess.py:93} INFO -           } ]
[2025-07-11T14:10:03.235+0200] {subprocess.py:93} INFO -         },
[2025-07-11T14:10:03.235+0200] {subprocess.py:93} INFO -         "nullable" : true,
[2025-07-11T14:10:03.235+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:10:03.235+0200] {subprocess.py:93} INFO -       } ]
[2025-07-11T14:10:03.235+0200] {subprocess.py:93} INFO -     },
[2025-07-11T14:10:03.235+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-11T14:10:03.235+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:10:03.235+0200] {subprocess.py:93} INFO -   } ]
[2025-07-11T14:10:03.235+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:10:03.236+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-11T14:10:03.236+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-11T14:10:03.236+0200] {subprocess.py:93} INFO -   required int32 treeID;
[2025-07-11T14:10:03.236+0200] {subprocess.py:93} INFO -   optional group nodeData {
[2025-07-11T14:10:03.236+0200] {subprocess.py:93} INFO -     required int32 id;
[2025-07-11T14:10:03.236+0200] {subprocess.py:93} INFO -     required double prediction;
[2025-07-11T14:10:03.236+0200] {subprocess.py:93} INFO -     required double impurity;
[2025-07-11T14:10:03.236+0200] {subprocess.py:93} INFO -     optional group impurityStats (LIST) {
[2025-07-11T14:10:03.236+0200] {subprocess.py:93} INFO -       repeated group list {
[2025-07-11T14:10:03.236+0200] {subprocess.py:93} INFO -         required double element;
[2025-07-11T14:10:03.236+0200] {subprocess.py:93} INFO -       }
[2025-07-11T14:10:03.236+0200] {subprocess.py:93} INFO -     }
[2025-07-11T14:10:03.236+0200] {subprocess.py:93} INFO -     required int64 rawCount;
[2025-07-11T14:10:03.236+0200] {subprocess.py:93} INFO -     required double gain;
[2025-07-11T14:10:03.236+0200] {subprocess.py:93} INFO -     required int32 leftChild;
[2025-07-11T14:10:03.237+0200] {subprocess.py:93} INFO -     required int32 rightChild;
[2025-07-11T14:10:03.237+0200] {subprocess.py:93} INFO -     optional group split {
[2025-07-11T14:10:03.237+0200] {subprocess.py:93} INFO -       required int32 featureIndex;
[2025-07-11T14:10:03.237+0200] {subprocess.py:93} INFO -       optional group leftCategoriesOrThreshold (LIST) {
[2025-07-11T14:10:03.237+0200] {subprocess.py:93} INFO -         repeated group list {
[2025-07-11T14:10:03.237+0200] {subprocess.py:93} INFO -           required double element;
[2025-07-11T14:10:03.237+0200] {subprocess.py:93} INFO -         }
[2025-07-11T14:10:03.237+0200] {subprocess.py:93} INFO -       }
[2025-07-11T14:10:03.237+0200] {subprocess.py:93} INFO -       required int32 numCategories;
[2025-07-11T14:10:03.237+0200] {subprocess.py:93} INFO -     }
[2025-07-11T14:10:03.239+0200] {subprocess.py:93} INFO -   }
[2025-07-11T14:10:03.239+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:10:03.239+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:10:03.239+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:10:03.342+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO FileOutputCommitter: Saved output of task 'attempt_202507111410033706176379383122757_0106_m_000000_231' to file:/home/monica.fernandez/practica_creativa/models/spark_random_forest_classifier.flight_delays.5.0.bin/stages/0_RandomForestClassifier_6425afc2c8a8/data/_temporary/0/task_202507111410033706176379383122757_0106_m_000000
[2025-07-11T14:10:03.342+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO SparkHadoopMapRedUtil: attempt_202507111410033706176379383122757_0106_m_000000_231: Committed. Elapsed time: 1 ms.
[2025-07-11T14:10:03.343+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Finished task 0.0 in stage 106.0 (TID 231). 4740 bytes result sent to driver
[2025-07-11T14:10:03.343+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 231) in 134 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:10:03.343+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool
[2025-07-11T14:10:03.344+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: ResultStage 106 (parquet at treeModels.scala:491) finished in 0,155 s
[2025-07-11T14:10:03.344+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:10:03.345+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 106: Stage finished
[2025-07-11T14:10:03.345+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Job 63 finished: parquet at treeModels.scala:491, took 0,157608 s
[2025-07-11T14:10:03.345+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO FileFormatWriter: Start to commit write Job 519eff1b-47e0-4c1e-be12-a9bcb97d87ab.
[2025-07-11T14:10:03.371+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO FileFormatWriter: Write Job 519eff1b-47e0-4c1e-be12-a9bcb97d87ab committed. Elapsed time: 26 ms.
[2025-07-11T14:10:03.371+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO FileFormatWriter: Finished processing stats for write job 519eff1b-47e0-4c1e-be12-a9bcb97d87ab.
[2025-07-11T14:10:03.376+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Instrumentation: [ba31128e] training finished
[2025-07-11T14:10:03.376+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Instrumentation: [201f6e4e] training finished
[2025-07-11T14:10:03.479+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO V2ScanRelationPushDown:
[2025-07-11T14:10:03.479+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:10:03.479+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:10:03.479+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:10:03.479+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:10:03.488+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO V2ScanRelationPushDown:
[2025-07-11T14:10:03.488+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-11T14:10:03.488+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:10:03.536+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:10:03.536+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:10:03.552+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 214.5 KiB, free 419.4 MiB)
[2025-07-11T14:10:03.559+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 419.3 MiB)
[2025-07-11T14:10:03.560+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 138.4.31.23:43033 (size: 38.9 KiB, free: 433.7 MiB)
[2025-07-11T14:10:03.561+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO SparkContext: Created broadcast 93 from rdd at MulticlassClassificationEvaluator.scala:191
[2025-07-11T14:10:03.562+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:10:03.569+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Registering RDD 217 (rdd at MulticlassClassificationEvaluator.scala:191) as input to shuffle 34
[2025-07-11T14:10:03.570+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Got map stage job 64 (rdd at MulticlassClassificationEvaluator.scala:191) with 2 output partitions
[2025-07-11T14:10:03.570+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Final stage: ShuffleMapStage 107 (rdd at MulticlassClassificationEvaluator.scala:191)
[2025-07-11T14:10:03.570+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:10:03.570+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:03.571+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Submitting ShuffleMapStage 107 (MapPartitionsRDD[217] at rdd at MulticlassClassificationEvaluator.scala:191), which has no missing parents
[2025-07-11T14:10:03.573+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 20.7 KiB, free 419.3 MiB)
[2025-07-11T14:10:03.573+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 9.3 KiB, free 419.3 MiB)
[2025-07-11T14:10:03.573+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 138.4.31.23:43033 (size: 9.3 KiB, free: 433.7 MiB)
[2025-07-11T14:10:03.576+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:03.576+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 107 (MapPartitionsRDD[217] at rdd at MulticlassClassificationEvaluator.scala:191) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:10:03.576+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSchedulerImpl: Adding task set 107.0 with 2 tasks resource profile 0
[2025-07-11T14:10:03.576+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 232) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:10:03.576+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Starting task 1.0 in stage 107.0 (TID 233) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:10:03.576+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Running task 1.0 in stage 107.0 (TID 233)
[2025-07-11T14:10:03.576+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Running task 0.0 in stage 107.0 (TID 232)
[2025-07-11T14:10:03.580+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:10:03.580+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:10:03.593+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Registering RDD 221 (rdd at MulticlassClassificationEvaluator.scala:191) as input to shuffle 35
[2025-07-11T14:10:03.593+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Got map stage job 65 (rdd at MulticlassClassificationEvaluator.scala:191) with 13 output partitions
[2025-07-11T14:10:03.593+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Final stage: ShuffleMapStage 108 (rdd at MulticlassClassificationEvaluator.scala:191)
[2025-07-11T14:10:03.593+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:10:03.593+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:03.594+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Submitting ShuffleMapStage 108 (MapPartitionsRDD[221] at rdd at MulticlassClassificationEvaluator.scala:191), which has no missing parents
[2025-07-11T14:10:03.595+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 18.7 KiB, free 419.3 MiB)
[2025-07-11T14:10:03.596+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 419.3 MiB)
[2025-07-11T14:10:03.596+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 138.4.31.23:43033 (size: 9.2 KiB, free: 433.6 MiB)
[2025-07-11T14:10:03.598+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:03.629+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 108 (MapPartitionsRDD[221] at rdd at MulticlassClassificationEvaluator.scala:191) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-11T14:10:03.630+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSchedulerImpl: Adding task set 108.0 with 13 tasks resource profile 0
[2025-07-11T14:10:03.630+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 234) (138.4.31.23, executor driver, partition 0, ANY, 16839 bytes)
[2025-07-11T14:10:03.630+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Starting task 1.0 in stage 108.0 (TID 235) (138.4.31.23, executor driver, partition 1, ANY, 16719 bytes)
[2025-07-11T14:10:03.630+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Running task 0.0 in stage 108.0 (TID 234)
[2025-07-11T14:10:03.630+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Running task 1.0 in stage 108.0 (TID 235)
[2025-07-11T14:10:03.717+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Finished task 0.0 in stage 108.0 (TID 234). 1945 bytes result sent to driver
[2025-07-11T14:10:03.718+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Starting task 2.0 in stage 108.0 (TID 236) (138.4.31.23, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-11T14:10:03.719+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Running task 2.0 in stage 108.0 (TID 236)
[2025-07-11T14:10:03.719+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 234) in 119 ms on 138.4.31.23 (executor driver) (1/13)
[2025-07-11T14:10:03.719+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Finished task 1.0 in stage 108.0 (TID 235). 1945 bytes result sent to driver
[2025-07-11T14:10:03.727+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Starting task 3.0 in stage 108.0 (TID 237) (138.4.31.23, executor driver, partition 3, ANY, 16715 bytes)
[2025-07-11T14:10:03.728+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Finished task 1.0 in stage 108.0 (TID 235) in 128 ms on 138.4.31.23 (executor driver) (2/13)
[2025-07-11T14:10:03.729+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Running task 3.0 in stage 108.0 (TID 237)
[2025-07-11T14:10:03.787+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Finished task 2.0 in stage 108.0 (TID 236). 1945 bytes result sent to driver
[2025-07-11T14:10:03.788+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Starting task 4.0 in stage 108.0 (TID 238) (138.4.31.23, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-11T14:10:03.789+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Running task 4.0 in stage 108.0 (TID 238)
[2025-07-11T14:10:03.789+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Finished task 2.0 in stage 108.0 (TID 236) in 70 ms on 138.4.31.23 (executor driver) (3/13)
[2025-07-11T14:10:03.807+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Finished task 3.0 in stage 108.0 (TID 237). 1988 bytes result sent to driver
[2025-07-11T14:10:03.809+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Starting task 5.0 in stage 108.0 (TID 239) (138.4.31.23, executor driver, partition 5, ANY, 16719 bytes)
[2025-07-11T14:10:03.809+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Finished task 3.0 in stage 108.0 (TID 237) in 82 ms on 138.4.31.23 (executor driver) (4/13)
[2025-07-11T14:10:03.810+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Running task 5.0 in stage 108.0 (TID 239)
[2025-07-11T14:10:03.857+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Finished task 4.0 in stage 108.0 (TID 238). 1945 bytes result sent to driver
[2025-07-11T14:10:03.858+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Starting task 6.0 in stage 108.0 (TID 240) (138.4.31.23, executor driver, partition 6, ANY, 16719 bytes)
[2025-07-11T14:10:03.858+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Finished task 4.0 in stage 108.0 (TID 238) in 70 ms on 138.4.31.23 (executor driver) (5/13)
[2025-07-11T14:10:03.858+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Running task 6.0 in stage 108.0 (TID 240)
[2025-07-11T14:10:03.894+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Finished task 5.0 in stage 108.0 (TID 239). 1988 bytes result sent to driver
[2025-07-11T14:10:03.896+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Starting task 7.0 in stage 108.0 (TID 241) (138.4.31.23, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-11T14:10:03.896+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Finished task 5.0 in stage 108.0 (TID 239) in 88 ms on 138.4.31.23 (executor driver) (6/13)
[2025-07-11T14:10:03.896+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Running task 7.0 in stage 108.0 (TID 241)
[2025-07-11T14:10:03.908+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Finished task 6.0 in stage 108.0 (TID 240). 1945 bytes result sent to driver
[2025-07-11T14:10:03.910+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Starting task 8.0 in stage 108.0 (TID 242) (138.4.31.23, executor driver, partition 8, ANY, 16839 bytes)
[2025-07-11T14:10:03.911+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Finished task 6.0 in stage 108.0 (TID 240) in 54 ms on 138.4.31.23 (executor driver) (7/13)
[2025-07-11T14:10:03.912+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Running task 8.0 in stage 108.0 (TID 242)
[2025-07-11T14:10:03.962+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 138.4.31.23:43033 in memory (size: 4.5 KiB, free: 433.7 MiB)
[2025-07-11T14:10:03.963+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Finished task 7.0 in stage 108.0 (TID 241). 1988 bytes result sent to driver
[2025-07-11T14:10:03.964+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Starting task 9.0 in stage 108.0 (TID 243) (138.4.31.23, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-11T14:10:03.965+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO Executor: Running task 9.0 in stage 108.0 (TID 243)
[2025-07-11T14:10:03.978+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO TaskSetManager: Finished task 7.0 in stage 108.0 (TID 241) in 83 ms on 138.4.31.23 (executor driver) (8/13)
[2025-07-11T14:10:03.997+0200] {subprocess.py:93} INFO - 25/07/11 14:10:03 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 138.4.31.23:43033 in memory (size: 36.5 KiB, free: 433.7 MiB)
[2025-07-11T14:10:04.000+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO Executor: Finished task 8.0 in stage 108.0 (TID 242). 1988 bytes result sent to driver
[2025-07-11T14:10:04.001+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO TaskSetManager: Starting task 10.0 in stage 108.0 (TID 244) (138.4.31.23, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-11T14:10:04.002+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO TaskSetManager: Finished task 8.0 in stage 108.0 (TID 242) in 92 ms on 138.4.31.23 (executor driver) (9/13)
[2025-07-11T14:10:04.003+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO Executor: Running task 10.0 in stage 108.0 (TID 244)
[2025-07-11T14:10:04.015+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 138.4.31.23:43033 in memory (size: 84.8 KiB, free: 433.8 MiB)
[2025-07-11T14:10:04.017+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 138.4.31.23:43033 in memory (size: 84.1 KiB, free: 433.9 MiB)
[2025-07-11T14:10:04.018+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 138.4.31.23:43033 in memory (size: 12.3 KiB, free: 433.9 MiB)
[2025-07-11T14:10:04.019+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 138.4.31.23:43033 in memory (size: 36.6 KiB, free: 433.9 MiB)
[2025-07-11T14:10:04.056+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO Executor: Finished task 9.0 in stage 108.0 (TID 243). 1988 bytes result sent to driver
[2025-07-11T14:10:04.058+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO TaskSetManager: Starting task 11.0 in stage 108.0 (TID 245) (138.4.31.23, executor driver, partition 11, ANY, 16839 bytes)
[2025-07-11T14:10:04.059+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO TaskSetManager: Finished task 9.0 in stage 108.0 (TID 243) in 94 ms on 138.4.31.23 (executor driver) (10/13)
[2025-07-11T14:10:04.059+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO Executor: Running task 11.0 in stage 108.0 (TID 245)
[2025-07-11T14:10:04.098+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO Executor: Finished task 10.0 in stage 108.0 (TID 244). 1988 bytes result sent to driver
[2025-07-11T14:10:04.101+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO TaskSetManager: Starting task 12.0 in stage 108.0 (TID 246) (138.4.31.23, executor driver, partition 12, ANY, 16719 bytes)
[2025-07-11T14:10:04.103+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO TaskSetManager: Finished task 10.0 in stage 108.0 (TID 244) in 101 ms on 138.4.31.23 (executor driver) (11/13)
[2025-07-11T14:10:04.106+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO Executor: Running task 12.0 in stage 108.0 (TID 246)
[2025-07-11T14:10:04.163+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO Executor: Finished task 11.0 in stage 108.0 (TID 245). 1945 bytes result sent to driver
[2025-07-11T14:10:04.164+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO TaskSetManager: Finished task 11.0 in stage 108.0 (TID 245) in 108 ms on 138.4.31.23 (executor driver) (12/13)
[2025-07-11T14:10:04.166+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO Executor: Finished task 12.0 in stage 108.0 (TID 246). 1945 bytes result sent to driver
[2025-07-11T14:10:04.168+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO TaskSetManager: Finished task 12.0 in stage 108.0 (TID 246) in 66 ms on 138.4.31.23 (executor driver) (13/13)
[2025-07-11T14:10:04.168+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool
[2025-07-11T14:10:04.168+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO DAGScheduler: ShuffleMapStage 108 (rdd at MulticlassClassificationEvaluator.scala:191) finished in 0,573 s
[2025-07-11T14:10:04.169+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:10:04.169+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO DAGScheduler: running: Set(ShuffleMapStage 107)
[2025-07-11T14:10:04.169+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:10:04.169+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO DAGScheduler: failed: Set()
[2025-07-11T14:10:04.183+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO ShufflePartitionsUtil: For shuffle(35), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:10:04.214+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:10:04.218+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO DAGScheduler: Got job 66 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-11T14:10:04.218+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO DAGScheduler: Final stage: ResultStage 110 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-11T14:10:04.218+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 109)
[2025-07-11T14:10:04.218+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:04.218+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO DAGScheduler: Submitting ResultStage 110 (MapPartitionsRDD[223] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-11T14:10:04.218+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 8.2 KiB, free 420.2 MiB)
[2025-07-11T14:10:04.218+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 420.2 MiB)
[2025-07-11T14:10:04.218+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 138.4.31.23:43033 (size: 4.2 KiB, free: 433.9 MiB)
[2025-07-11T14:10:04.219+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:04.220+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 110 (MapPartitionsRDD[223] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:10:04.220+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO TaskSchedulerImpl: Adding task set 110.0 with 1 tasks resource profile 0
[2025-07-11T14:10:04.229+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 247) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-11T14:10:04.229+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO Executor: Running task 0.0 in stage 110.0 (TID 247)
[2025-07-11T14:10:04.229+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO ShuffleBlockFetcherIterator: Getting 13 (221.8 KiB) non-empty blocks including 13 (221.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:04.229+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-11T14:10:04.249+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO Executor: Finished task 0.0 in stage 110.0 (TID 247). 51171 bytes result sent to driver
[2025-07-11T14:10:04.257+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 247) in 37 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:10:04.257+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool
[2025-07-11T14:10:04.257+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO DAGScheduler: ResultStage 110 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,042 s
[2025-07-11T14:10:04.258+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:10:04.258+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 110: Stage finished
[2025-07-11T14:10:04.259+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO DAGScheduler: Job 66 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,045350 s
[2025-07-11T14:10:04.265+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 4.3 MiB, free 416.0 MiB)
[2025-07-11T14:10:04.268+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 109.4 KiB, free 415.9 MiB)
[2025-07-11T14:10:04.269+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 138.4.31.23:43033 (size: 109.4 KiB, free: 433.8 MiB)
[2025-07-11T14:10:04.269+0200] {subprocess.py:93} INFO - 25/07/11 14:10:04 INFO SparkContext: Created broadcast 97 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:10:05.035+0200] {subprocess.py:93} INFO - 25/07/11 14:10:05 INFO Executor: Finished task 1.0 in stage 107.0 (TID 233). 2031 bytes result sent to driver
[2025-07-11T14:10:05.036+0200] {subprocess.py:93} INFO - 25/07/11 14:10:05 INFO TaskSetManager: Finished task 1.0 in stage 107.0 (TID 233) in 1459 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:10:05.734+0200] {subprocess.py:93} INFO - 25/07/11 14:10:05 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 138.4.31.23:43033 in memory (size: 4.2 KiB, free: 433.8 MiB)
[2025-07-11T14:10:11.246+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 138.4.31.23:43033 in memory (size: 109.4 KiB, free: 433.9 MiB)
[2025-07-11T14:10:11.253+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 138.4.31.23:43033 in memory (size: 38.9 KiB, free: 433.9 MiB)
[2025-07-11T14:10:11.259+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 138.4.31.23:43033 in memory (size: 38.9 KiB, free: 434.0 MiB)
[2025-07-11T14:10:11.266+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 138.4.31.23:43033 in memory (size: 9.2 KiB, free: 434.0 MiB)
[2025-07-11T14:10:11.269+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 138.4.31.23:43033 in memory (size: 109.4 KiB, free: 434.1 MiB)
[2025-07-11T14:10:11.270+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 138.4.31.23:43033 in memory (size: 9.3 KiB, free: 434.1 MiB)
[2025-07-11T14:10:11.435+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO Executor: Finished task 0.0 in stage 107.0 (TID 232). 2031 bytes result sent to driver
[2025-07-11T14:10:11.436+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 232) in 7861 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:10:11.436+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool
[2025-07-11T14:10:11.437+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO DAGScheduler: ShuffleMapStage 107 (rdd at MulticlassClassificationEvaluator.scala:191) finished in 7,865 s
[2025-07-11T14:10:11.437+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:10:11.437+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO DAGScheduler: running: Set()
[2025-07-11T14:10:11.437+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:10:11.437+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO DAGScheduler: failed: Set()
[2025-07-11T14:10:11.449+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO ShufflePartitionsUtil: For shuffle(34), advisory target size: 67108864, actual target size 1923052, minimum partition size: 1048576
[2025-07-11T14:10:11.488+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO CodeGenerator: Code generated in 24.263378 ms
[2025-07-11T14:10:11.523+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO SparkContext: Starting job: collectAsMap at MulticlassMetrics.scala:61
[2025-07-11T14:10:11.524+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO DAGScheduler: Registering RDD 230 (map at MulticlassMetrics.scala:52) as input to shuffle 36
[2025-07-11T14:10:11.524+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO DAGScheduler: Got job 67 (collectAsMap at MulticlassMetrics.scala:61) with 4 output partitions
[2025-07-11T14:10:11.524+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO DAGScheduler: Final stage: ResultStage 113 (collectAsMap at MulticlassMetrics.scala:61)
[2025-07-11T14:10:11.525+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 112)
[2025-07-11T14:10:11.525+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 112)
[2025-07-11T14:10:11.525+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO DAGScheduler: Submitting ShuffleMapStage 112 (MapPartitionsRDD[230] at map at MulticlassMetrics.scala:52), which has no missing parents
[2025-07-11T14:10:11.546+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 WARN DAGScheduler: Broadcasting large task binary with size 1043.2 KiB
[2025-07-11T14:10:11.546+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 1043.3 KiB, free 424.1 MiB)
[2025-07-11T14:10:11.556+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 454.2 KiB, free 423.7 MiB)
[2025-07-11T14:10:11.556+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 138.4.31.23:43033 (size: 454.2 KiB, free: 433.7 MiB)
[2025-07-11T14:10:11.557+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:11.558+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 112 (MapPartitionsRDD[230] at map at MulticlassMetrics.scala:52) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:10:11.558+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO TaskSchedulerImpl: Adding task set 112.0 with 4 tasks resource profile 0
[2025-07-11T14:10:11.559+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 248) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:10:11.559+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO TaskSetManager: Starting task 1.0 in stage 112.0 (TID 249) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:10:11.559+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO TaskSetManager: Starting task 2.0 in stage 112.0 (TID 250) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:10:11.560+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO TaskSetManager: Starting task 3.0 in stage 112.0 (TID 251) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:10:11.560+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO Executor: Running task 1.0 in stage 112.0 (TID 249)
[2025-07-11T14:10:11.560+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO Executor: Running task 2.0 in stage 112.0 (TID 250)
[2025-07-11T14:10:11.560+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO Executor: Running task 0.0 in stage 112.0 (TID 248)
[2025-07-11T14:10:11.561+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO Executor: Running task 3.0 in stage 112.0 (TID 251)
[2025-07-11T14:10:11.590+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO ShuffleBlockFetcherIterator: Getting 1 (384.6 KiB) non-empty blocks including 1 (384.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:11.590+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:10:11.608+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO ShuffleBlockFetcherIterator: Getting 1 (3.4 MiB) non-empty blocks including 1 (3.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:11.609+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:10:11.609+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO ShuffleBlockFetcherIterator: Getting 1 (3.2 MiB) non-empty blocks including 1 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:11.610+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:10:11.616+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO ShuffleBlockFetcherIterator: Getting 1 (366.2 KiB) non-empty blocks including 1 (366.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:11.616+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-11T14:10:11.627+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO CodeGenerator: Code generated in 35.470796 ms
[2025-07-11T14:10:11.639+0200] {subprocess.py:93} INFO - 25/07/11 14:10:11 INFO CodeGenerator: Code generated in 9.792858 ms
[2025-07-11T14:10:12.386+0200] {subprocess.py:93} INFO - 25/07/11 14:10:12 INFO Executor: Finished task 2.0 in stage 112.0 (TID 250). 6108 bytes result sent to driver
[2025-07-11T14:10:12.389+0200] {subprocess.py:93} INFO - 25/07/11 14:10:12 INFO TaskSetManager: Finished task 2.0 in stage 112.0 (TID 250) in 828 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:10:12.464+0200] {subprocess.py:93} INFO - 25/07/11 14:10:12 INFO Executor: Finished task 3.0 in stage 112.0 (TID 251). 6108 bytes result sent to driver
[2025-07-11T14:10:12.466+0200] {subprocess.py:93} INFO - 25/07/11 14:10:12 INFO TaskSetManager: Finished task 3.0 in stage 112.0 (TID 251) in 907 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:10:13.302+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 138.4.31.23:43033 in memory (size: 9.3 KiB, free: 433.7 MiB)
[2025-07-11T14:10:13.928+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO Executor: Finished task 1.0 in stage 112.0 (TID 249). 6108 bytes result sent to driver
[2025-07-11T14:10:13.931+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO TaskSetManager: Finished task 1.0 in stage 112.0 (TID 249) in 2372 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:10:13.974+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO Executor: Finished task 0.0 in stage 112.0 (TID 248). 6108 bytes result sent to driver
[2025-07-11T14:10:13.975+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 248) in 2415 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:10:13.975+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool
[2025-07-11T14:10:13.975+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO DAGScheduler: ShuffleMapStage 112 (map at MulticlassMetrics.scala:52) finished in 2,449 s
[2025-07-11T14:10:13.975+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:10:13.975+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO DAGScheduler: running: Set()
[2025-07-11T14:10:13.975+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO DAGScheduler: waiting: Set(ResultStage 113)
[2025-07-11T14:10:13.975+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO DAGScheduler: failed: Set()
[2025-07-11T14:10:13.975+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO DAGScheduler: Submitting ResultStage 113 (ShuffledRDD[231] at reduceByKey at MulticlassMetrics.scala:61), which has no missing parents
[2025-07-11T14:10:13.976+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 4.7 KiB, free 423.7 MiB)
[2025-07-11T14:10:13.976+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 2.8 KiB, free 423.7 MiB)
[2025-07-11T14:10:13.976+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 138.4.31.23:43033 (size: 2.8 KiB, free: 433.7 MiB)
[2025-07-11T14:10:13.977+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:13.977+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 113 (ShuffledRDD[231] at reduceByKey at MulticlassMetrics.scala:61) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:10:13.978+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO TaskSchedulerImpl: Adding task set 113.0 with 4 tasks resource profile 0
[2025-07-11T14:10:13.979+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 252) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:10:13.979+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO TaskSetManager: Starting task 1.0 in stage 113.0 (TID 253) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:10:13.979+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO TaskSetManager: Starting task 2.0 in stage 113.0 (TID 254) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:10:13.979+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO TaskSetManager: Starting task 3.0 in stage 113.0 (TID 255) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:10:13.979+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO Executor: Running task 3.0 in stage 113.0 (TID 255)
[2025-07-11T14:10:13.980+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO Executor: Running task 2.0 in stage 113.0 (TID 254)
[2025-07-11T14:10:13.980+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO Executor: Running task 0.0 in stage 113.0 (TID 252)
[2025-07-11T14:10:13.980+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO Executor: Running task 1.0 in stage 113.0 (TID 253)
[2025-07-11T14:10:13.981+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO ShuffleBlockFetcherIterator: Getting 4 (1370.0 B) non-empty blocks including 4 (1370.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:13.981+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:10:13.981+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO ShuffleBlockFetcherIterator: Getting 4 (1104.0 B) non-empty blocks including 4 (1104.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:13.981+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:10:13.983+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO Executor: Finished task 3.0 in stage 113.0 (TID 255). 2156 bytes result sent to driver
[2025-07-11T14:10:13.983+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO Executor: Finished task 1.0 in stage 113.0 (TID 253). 1937 bytes result sent to driver
[2025-07-11T14:10:13.984+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO TaskSetManager: Finished task 1.0 in stage 113.0 (TID 253) in 5 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:10:13.984+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO ShuffleBlockFetcherIterator: Getting 4 (1472.0 B) non-empty blocks including 4 (1472.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:13.984+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO ShuffleBlockFetcherIterator: Getting 4 (1054.0 B) non-empty blocks including 4 (1054.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:13.984+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:10:13.985+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:10:13.986+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO Executor: Finished task 2.0 in stage 113.0 (TID 254). 2156 bytes result sent to driver
[2025-07-11T14:10:13.986+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO Executor: Finished task 0.0 in stage 113.0 (TID 252). 1980 bytes result sent to driver
[2025-07-11T14:10:13.986+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO TaskSetManager: Finished task 2.0 in stage 113.0 (TID 254) in 7 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:10:13.987+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO TaskSetManager: Finished task 3.0 in stage 113.0 (TID 255) in 7 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:10:13.987+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 252) in 9 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:10:13.987+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool
[2025-07-11T14:10:13.988+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO DAGScheduler: ResultStage 113 (collectAsMap at MulticlassMetrics.scala:61) finished in 0,012 s
[2025-07-11T14:10:13.988+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:10:13.988+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 113: Stage finished
[2025-07-11T14:10:13.988+0200] {subprocess.py:93} INFO - 25/07/11 14:10:13 INFO DAGScheduler: Job 67 finished: collectAsMap at MulticlassMetrics.scala:61, took 2,463890 s
[2025-07-11T14:10:13.991+0200] {subprocess.py:93} INFO - Accuracy: 0.5919
[2025-07-11T14:10:14.249+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO V2ScanRelationPushDown:
[2025-07-11T14:10:14.249+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:10:14.249+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:10:14.249+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:10:14.249+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:10:14.259+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO V2ScanRelationPushDown:
[2025-07-11T14:10:14.259+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-11T14:10:14.259+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:10:14.296+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:10:14.297+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:10:14.385+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO CodeGenerator: Code generated in 11.144937 ms
[2025-07-11T14:10:14.385+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 214.5 KiB, free 423.5 MiB)
[2025-07-11T14:10:14.394+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 423.5 MiB)
[2025-07-11T14:10:14.394+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 138.4.31.23:43033 (size: 38.9 KiB, free: 433.6 MiB)
[2025-07-11T14:10:14.394+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO SparkContext: Created broadcast 100 from showString at NativeMethodAccessorImpl.java:0
[2025-07-11T14:10:14.405+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:10:14.406+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO DAGScheduler: Registering RDD 235 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 37
[2025-07-11T14:10:14.406+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO DAGScheduler: Got map stage job 68 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-07-11T14:10:14.407+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO DAGScheduler: Final stage: ShuffleMapStage 114 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:10:14.407+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:10:14.407+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:14.407+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO DAGScheduler: Submitting ShuffleMapStage 114 (MapPartitionsRDD[235] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:10:14.407+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 20.2 KiB, free 423.5 MiB)
[2025-07-11T14:10:14.413+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 423.4 MiB)
[2025-07-11T14:10:14.413+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 138.4.31.23:43033 (size: 9.2 KiB, free: 433.6 MiB)
[2025-07-11T14:10:14.415+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:14.415+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 114 (MapPartitionsRDD[235] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:10:14.415+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO TaskSchedulerImpl: Adding task set 114.0 with 2 tasks resource profile 0
[2025-07-11T14:10:14.415+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO DAGScheduler: Registering RDD 239 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 38
[2025-07-11T14:10:14.415+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO DAGScheduler: Got map stage job 69 (showString at NativeMethodAccessorImpl.java:0) with 13 output partitions
[2025-07-11T14:10:14.415+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO DAGScheduler: Final stage: ShuffleMapStage 115 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:10:14.415+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:10:14.415+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 256) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:10:14.415+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 138.4.31.23:43033 in memory (size: 2.8 KiB, free: 433.6 MiB)
[2025-07-11T14:10:14.415+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO TaskSetManager: Starting task 1.0 in stage 114.0 (TID 257) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:10:14.415+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO Executor: Running task 0.0 in stage 114.0 (TID 256)
[2025-07-11T14:10:14.419+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO Executor: Running task 1.0 in stage 114.0 (TID 257)
[2025-07-11T14:10:14.423+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:14.423+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO DAGScheduler: Submitting ShuffleMapStage 115 (MapPartitionsRDD[239] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:10:14.423+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 18.7 KiB, free 423.4 MiB)
[2025-07-11T14:10:14.427+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 423.4 MiB)
[2025-07-11T14:10:14.428+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 138.4.31.23:43033 (size: 9.2 KiB, free: 433.6 MiB)
[2025-07-11T14:10:14.428+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:14.429+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 115 (MapPartitionsRDD[239] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-11T14:10:14.429+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO TaskSchedulerImpl: Adding task set 115.0 with 13 tasks resource profile 0
[2025-07-11T14:10:14.430+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO CodeGenerator: Code generated in 11.651305 ms
[2025-07-11T14:10:14.430+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 258) (138.4.31.23, executor driver, partition 0, ANY, 16719 bytes)
[2025-07-11T14:10:14.431+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO TaskSetManager: Starting task 1.0 in stage 115.0 (TID 259) (138.4.31.23, executor driver, partition 1, ANY, 16719 bytes)
[2025-07-11T14:10:14.431+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO Executor: Running task 1.0 in stage 115.0 (TID 259)
[2025-07-11T14:10:14.431+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO Executor: Running task 0.0 in stage 115.0 (TID 258)
[2025-07-11T14:10:14.452+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO CodeGenerator: Code generated in 13.933188 ms
[2025-07-11T14:10:14.453+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:10:14.459+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:10:14.474+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO CodeGenerator: Code generated in 20.051311 ms
[2025-07-11T14:10:14.596+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO Executor: Finished task 1.0 in stage 115.0 (TID 259). 1945 bytes result sent to driver
[2025-07-11T14:10:14.600+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO TaskSetManager: Starting task 2.0 in stage 115.0 (TID 260) (138.4.31.23, executor driver, partition 2, ANY, 16839 bytes)
[2025-07-11T14:10:14.600+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO TaskSetManager: Finished task 1.0 in stage 115.0 (TID 259) in 170 ms on 138.4.31.23 (executor driver) (1/13)
[2025-07-11T14:10:14.606+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO Executor: Running task 2.0 in stage 115.0 (TID 260)
[2025-07-11T14:10:14.638+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO Executor: Finished task 0.0 in stage 115.0 (TID 258). 1988 bytes result sent to driver
[2025-07-11T14:10:14.640+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO TaskSetManager: Starting task 3.0 in stage 115.0 (TID 261) (138.4.31.23, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-11T14:10:14.640+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 258) in 210 ms on 138.4.31.23 (executor driver) (2/13)
[2025-07-11T14:10:14.655+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO Executor: Running task 3.0 in stage 115.0 (TID 261)
[2025-07-11T14:10:14.710+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO Executor: Finished task 2.0 in stage 115.0 (TID 260). 2031 bytes result sent to driver
[2025-07-11T14:10:14.711+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO TaskSetManager: Starting task 4.0 in stage 115.0 (TID 262) (138.4.31.23, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-11T14:10:14.711+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO TaskSetManager: Finished task 2.0 in stage 115.0 (TID 260) in 115 ms on 138.4.31.23 (executor driver) (3/13)
[2025-07-11T14:10:14.711+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO Executor: Running task 4.0 in stage 115.0 (TID 262)
[2025-07-11T14:10:14.785+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO Executor: Finished task 3.0 in stage 115.0 (TID 261). 1988 bytes result sent to driver
[2025-07-11T14:10:14.785+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO Executor: Finished task 4.0 in stage 115.0 (TID 262). 1945 bytes result sent to driver
[2025-07-11T14:10:14.788+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO TaskSetManager: Starting task 5.0 in stage 115.0 (TID 263) (138.4.31.23, executor driver, partition 5, ANY, 16719 bytes)
[2025-07-11T14:10:14.788+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO TaskSetManager: Starting task 6.0 in stage 115.0 (TID 264) (138.4.31.23, executor driver, partition 6, ANY, 16719 bytes)
[2025-07-11T14:10:14.788+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO TaskSetManager: Finished task 3.0 in stage 115.0 (TID 261) in 148 ms on 138.4.31.23 (executor driver) (4/13)
[2025-07-11T14:10:14.788+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO TaskSetManager: Finished task 4.0 in stage 115.0 (TID 262) in 77 ms on 138.4.31.23 (executor driver) (5/13)
[2025-07-11T14:10:14.788+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO Executor: Running task 6.0 in stage 115.0 (TID 264)
[2025-07-11T14:10:14.789+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO Executor: Running task 5.0 in stage 115.0 (TID 263)
[2025-07-11T14:10:14.890+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO Executor: Finished task 6.0 in stage 115.0 (TID 264). 1945 bytes result sent to driver
[2025-07-11T14:10:14.898+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO TaskSetManager: Starting task 7.0 in stage 115.0 (TID 265) (138.4.31.23, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-11T14:10:14.898+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO Executor: Running task 7.0 in stage 115.0 (TID 265)
[2025-07-11T14:10:14.898+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO TaskSetManager: Finished task 6.0 in stage 115.0 (TID 264) in 111 ms on 138.4.31.23 (executor driver) (6/13)
[2025-07-11T14:10:14.952+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO Executor: Finished task 5.0 in stage 115.0 (TID 263). 1945 bytes result sent to driver
[2025-07-11T14:10:14.954+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO TaskSetManager: Starting task 8.0 in stage 115.0 (TID 266) (138.4.31.23, executor driver, partition 8, ANY, 16839 bytes)
[2025-07-11T14:10:14.954+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO TaskSetManager: Finished task 5.0 in stage 115.0 (TID 263) in 167 ms on 138.4.31.23 (executor driver) (7/13)
[2025-07-11T14:10:14.957+0200] {subprocess.py:93} INFO - 25/07/11 14:10:14 INFO Executor: Running task 8.0 in stage 115.0 (TID 266)
[2025-07-11T14:10:15.023+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO Executor: Finished task 7.0 in stage 115.0 (TID 265). 1945 bytes result sent to driver
[2025-07-11T14:10:15.025+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO TaskSetManager: Starting task 9.0 in stage 115.0 (TID 267) (138.4.31.23, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-11T14:10:15.027+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO TaskSetManager: Finished task 7.0 in stage 115.0 (TID 265) in 134 ms on 138.4.31.23 (executor driver) (8/13)
[2025-07-11T14:10:15.035+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO Executor: Running task 9.0 in stage 115.0 (TID 267)
[2025-07-11T14:10:15.125+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO Executor: Finished task 8.0 in stage 115.0 (TID 266). 1945 bytes result sent to driver
[2025-07-11T14:10:15.129+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO TaskSetManager: Starting task 10.0 in stage 115.0 (TID 268) (138.4.31.23, executor driver, partition 10, ANY, 16839 bytes)
[2025-07-11T14:10:15.129+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO TaskSetManager: Finished task 8.0 in stage 115.0 (TID 266) in 177 ms on 138.4.31.23 (executor driver) (9/13)
[2025-07-11T14:10:15.136+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO Executor: Running task 10.0 in stage 115.0 (TID 268)
[2025-07-11T14:10:15.253+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO Executor: Finished task 9.0 in stage 115.0 (TID 267). 2031 bytes result sent to driver
[2025-07-11T14:10:15.258+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO TaskSetManager: Starting task 11.0 in stage 115.0 (TID 269) (138.4.31.23, executor driver, partition 11, ANY, 16715 bytes)
[2025-07-11T14:10:15.258+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO TaskSetManager: Finished task 9.0 in stage 115.0 (TID 267) in 233 ms on 138.4.31.23 (executor driver) (10/13)
[2025-07-11T14:10:15.266+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO Executor: Running task 11.0 in stage 115.0 (TID 269)
[2025-07-11T14:10:15.295+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO Executor: Finished task 10.0 in stage 115.0 (TID 268). 1988 bytes result sent to driver
[2025-07-11T14:10:15.297+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO TaskSetManager: Starting task 12.0 in stage 115.0 (TID 270) (138.4.31.23, executor driver, partition 12, ANY, 16719 bytes)
[2025-07-11T14:10:15.297+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO TaskSetManager: Finished task 10.0 in stage 115.0 (TID 268) in 168 ms on 138.4.31.23 (executor driver) (11/13)
[2025-07-11T14:10:15.299+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO Executor: Running task 12.0 in stage 115.0 (TID 270)
[2025-07-11T14:10:15.461+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO Executor: Finished task 12.0 in stage 115.0 (TID 270). 1945 bytes result sent to driver
[2025-07-11T14:10:15.462+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO TaskSetManager: Finished task 12.0 in stage 115.0 (TID 270) in 167 ms on 138.4.31.23 (executor driver) (12/13)
[2025-07-11T14:10:15.467+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO Executor: Finished task 11.0 in stage 115.0 (TID 269). 1988 bytes result sent to driver
[2025-07-11T14:10:15.469+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO TaskSetManager: Finished task 11.0 in stage 115.0 (TID 269) in 215 ms on 138.4.31.23 (executor driver) (13/13)
[2025-07-11T14:10:15.469+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool
[2025-07-11T14:10:15.469+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO DAGScheduler: ShuffleMapStage 115 (showString at NativeMethodAccessorImpl.java:0) finished in 1,047 s
[2025-07-11T14:10:15.469+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:10:15.470+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO DAGScheduler: running: Set(ShuffleMapStage 114)
[2025-07-11T14:10:15.470+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:10:15.470+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO DAGScheduler: failed: Set()
[2025-07-11T14:10:15.565+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO ShufflePartitionsUtil: For shuffle(38), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:10:15.660+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:10:15.677+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO DAGScheduler: Got job 70 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-11T14:10:15.678+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO DAGScheduler: Final stage: ResultStage 117 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-11T14:10:15.678+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 116)
[2025-07-11T14:10:15.678+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:15.678+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[241] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-11T14:10:15.678+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 8.2 KiB, free 423.4 MiB)
[2025-07-11T14:10:15.678+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 423.4 MiB)
[2025-07-11T14:10:15.689+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 138.4.31.23:43033 (size: 4.2 KiB, free: 433.6 MiB)
[2025-07-11T14:10:15.689+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:15.689+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[241] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:10:15.689+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO TaskSchedulerImpl: Adding task set 117.0 with 1 tasks resource profile 0
[2025-07-11T14:10:15.689+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 271) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-11T14:10:15.689+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO Executor: Running task 0.0 in stage 117.0 (TID 271)
[2025-07-11T14:10:15.689+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO ShuffleBlockFetcherIterator: Getting 13 (221.8 KiB) non-empty blocks including 13 (221.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:15.690+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-11T14:10:15.752+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO Executor: Finished task 0.0 in stage 117.0 (TID 271). 51232 bytes result sent to driver
[2025-07-11T14:10:15.753+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 271) in 68 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:10:15.754+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool
[2025-07-11T14:10:15.754+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO DAGScheduler: ResultStage 117 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,077 s
[2025-07-11T14:10:15.754+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:10:15.754+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 117: Stage finished
[2025-07-11T14:10:15.754+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO DAGScheduler: Job 70 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,084016 s
[2025-07-11T14:10:15.767+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 4.3 MiB, free 419.2 MiB)
[2025-07-11T14:10:15.770+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 109.7 KiB, free 419.1 MiB)
[2025-07-11T14:10:15.773+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 138.4.31.23:43033 (size: 109.7 KiB, free: 433.5 MiB)
[2025-07-11T14:10:15.773+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO SparkContext: Created broadcast 104 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:10:15.914+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 138.4.31.23:43033 in memory (size: 38.9 KiB, free: 433.5 MiB)
[2025-07-11T14:10:15.963+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 138.4.31.23:43033 in memory (size: 109.4 KiB, free: 433.6 MiB)
[2025-07-11T14:10:15.965+0200] {subprocess.py:93} INFO - 25/07/11 14:10:15 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 138.4.31.23:43033 in memory (size: 454.2 KiB, free: 434.1 MiB)
[2025-07-11T14:10:16.587+0200] {subprocess.py:93} INFO - 25/07/11 14:10:16 INFO Executor: Finished task 1.0 in stage 114.0 (TID 257). 2031 bytes result sent to driver
[2025-07-11T14:10:16.588+0200] {subprocess.py:93} INFO - 25/07/11 14:10:16 INFO TaskSetManager: Finished task 1.0 in stage 114.0 (TID 257) in 2173 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:10:17.382+0200] {subprocess.py:93} INFO - 25/07/11 14:10:17 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 138.4.31.23:43033 in memory (size: 4.2 KiB, free: 434.1 MiB)
[2025-07-11T14:10:24.141+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO Executor: Finished task 0.0 in stage 114.0 (TID 256). 2074 bytes result sent to driver
[2025-07-11T14:10:24.141+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 256) in 9727 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:10:24.142+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool
[2025-07-11T14:10:24.142+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO DAGScheduler: ShuffleMapStage 114 (showString at NativeMethodAccessorImpl.java:0) finished in 9,736 s
[2025-07-11T14:10:24.142+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:10:24.142+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO DAGScheduler: running: Set()
[2025-07-11T14:10:24.143+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:10:24.143+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO DAGScheduler: failed: Set()
[2025-07-11T14:10:24.151+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO ShufflePartitionsUtil: For shuffle(37), advisory target size: 67108864, actual target size 1399865, minimum partition size: 1048576
[2025-07-11T14:10:24.281+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 138.4.31.23:43033 in memory (size: 9.2 KiB, free: 434.1 MiB)
[2025-07-11T14:10:24.319+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO CodeGenerator: Code generated in 108.288791 ms
[2025-07-11T14:10:24.345+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO DAGScheduler: Registering RDD 244 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 39
[2025-07-11T14:10:24.345+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO DAGScheduler: Got map stage job 71 (showString at NativeMethodAccessorImpl.java:0) with 4 output partitions
[2025-07-11T14:10:24.346+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO DAGScheduler: Final stage: ShuffleMapStage 119 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:10:24.347+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 118)
[2025-07-11T14:10:24.347+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:24.349+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO DAGScheduler: Submitting ShuffleMapStage 119 (MapPartitionsRDD[244] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:10:24.366+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 WARN DAGScheduler: Broadcasting large task binary with size 1020.3 KiB
[2025-07-11T14:10:24.366+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 1020.4 KiB, free 424.2 MiB)
[2025-07-11T14:10:24.370+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 452.5 KiB, free 423.7 MiB)
[2025-07-11T14:10:24.371+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 138.4.31.23:43033 (size: 452.5 KiB, free: 433.7 MiB)
[2025-07-11T14:10:24.372+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:24.372+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 119 (MapPartitionsRDD[244] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:10:24.372+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO TaskSchedulerImpl: Adding task set 119.0 with 4 tasks resource profile 0
[2025-07-11T14:10:24.374+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 272) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:10:24.374+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO TaskSetManager: Starting task 1.0 in stage 119.0 (TID 273) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:10:24.374+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO TaskSetManager: Starting task 2.0 in stage 119.0 (TID 274) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:10:24.374+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO TaskSetManager: Starting task 3.0 in stage 119.0 (TID 275) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:10:24.374+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO Executor: Running task 0.0 in stage 119.0 (TID 272)
[2025-07-11T14:10:24.374+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO Executor: Running task 1.0 in stage 119.0 (TID 273)
[2025-07-11T14:10:24.374+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO Executor: Running task 2.0 in stage 119.0 (TID 274)
[2025-07-11T14:10:24.374+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO Executor: Running task 3.0 in stage 119.0 (TID 275)
[2025-07-11T14:10:24.404+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO ShuffleBlockFetcherIterator: Getting 1 (2.3 MiB) non-empty blocks including 1 (2.3 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:24.404+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-11T14:10:24.412+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO ShuffleBlockFetcherIterator: Getting 1 (283.3 KiB) non-empty blocks including 1 (283.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:24.412+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:10:24.430+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO ShuffleBlockFetcherIterator: Getting 1 (268.8 KiB) non-empty blocks including 1 (268.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:24.436+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:10:24.448+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO ShuffleBlockFetcherIterator: Getting 1 (2.5 MiB) non-empty blocks including 1 (2.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:24.451+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-11T14:10:24.461+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO CodeGenerator: Code generated in 57.463823 ms
[2025-07-11T14:10:24.474+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO CodeGenerator: Code generated in 9.995372 ms
[2025-07-11T14:10:24.479+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO CodeGenerator: Code generated in 3.385898 ms
[2025-07-11T14:10:24.489+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO CodeGenerator: Code generated in 3.250121 ms
[2025-07-11T14:10:24.499+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO CodeGenerator: Code generated in 8.959555 ms
[2025-07-11T14:10:24.908+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO Executor: Finished task 2.0 in stage 119.0 (TID 274). 6904 bytes result sent to driver
[2025-07-11T14:10:24.909+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO TaskSetManager: Finished task 2.0 in stage 119.0 (TID 274) in 535 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:10:24.999+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO Executor: Finished task 3.0 in stage 119.0 (TID 275). 6947 bytes result sent to driver
[2025-07-11T14:10:24.999+0200] {subprocess.py:93} INFO - 25/07/11 14:10:24 INFO TaskSetManager: Finished task 3.0 in stage 119.0 (TID 275) in 624 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:10:25.247+0200] {subprocess.py:93} INFO - 25/07/11 14:10:25 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 138.4.31.23:43033 in memory (size: 9.2 KiB, free: 433.7 MiB)
[2025-07-11T14:10:26.122+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO Executor: Finished task 0.0 in stage 119.0 (TID 272). 6904 bytes result sent to driver
[2025-07-11T14:10:26.125+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 272) in 1751 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:10:26.260+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO Executor: Finished task 1.0 in stage 119.0 (TID 273). 6904 bytes result sent to driver
[2025-07-11T14:10:26.261+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO TaskSetManager: Finished task 1.0 in stage 119.0 (TID 273) in 1888 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:10:26.262+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool
[2025-07-11T14:10:26.262+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO DAGScheduler: ShuffleMapStage 119 (showString at NativeMethodAccessorImpl.java:0) finished in 1,914 s
[2025-07-11T14:10:26.262+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:10:26.262+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO DAGScheduler: running: Set()
[2025-07-11T14:10:26.262+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:10:26.263+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO DAGScheduler: failed: Set()
[2025-07-11T14:10:26.266+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO ShufflePartitionsUtil: For shuffle(39), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:10:26.277+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-07-11T14:10:26.312+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO CodeGenerator: Code generated in 30.3469 ms
[2025-07-11T14:10:26.377+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2025-07-11T14:10:26.384+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO DAGScheduler: Got job 72 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-07-11T14:10:26.384+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO DAGScheduler: Final stage: ResultStage 122 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:10:26.384+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 121)
[2025-07-11T14:10:26.384+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:26.384+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO DAGScheduler: Submitting ResultStage 122 (MapPartitionsRDD[247] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:10:26.395+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 WARN DAGScheduler: Broadcasting large task binary with size 1004.9 KiB
[2025-07-11T14:10:26.396+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 1004.9 KiB, free 422.8 MiB)
[2025-07-11T14:10:26.399+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 446.3 KiB, free 422.3 MiB)
[2025-07-11T14:10:26.400+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 138.4.31.23:43033 (size: 446.3 KiB, free: 433.2 MiB)
[2025-07-11T14:10:26.400+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:26.400+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 122 (MapPartitionsRDD[247] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:10:26.401+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO TaskSchedulerImpl: Adding task set 122.0 with 1 tasks resource profile 0
[2025-07-11T14:10:26.402+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 276) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:10:26.404+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO Executor: Running task 0.0 in stage 122.0 (TID 276)
[2025-07-11T14:10:26.423+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO ShuffleBlockFetcherIterator: Getting 4 (1008.0 B) non-empty blocks including 4 (1008.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:26.424+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:10:26.433+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO CodeGenerator: Code generated in 8.611568 ms
[2025-07-11T14:10:26.451+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO Executor: Finished task 0.0 in stage 122.0 (TID 276). 8218 bytes result sent to driver
[2025-07-11T14:10:26.461+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 276) in 50 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:10:26.461+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool
[2025-07-11T14:10:26.461+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO DAGScheduler: ResultStage 122 (showString at NativeMethodAccessorImpl.java:0) finished in 0,072 s
[2025-07-11T14:10:26.461+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:10:26.461+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 122: Stage finished
[2025-07-11T14:10:26.461+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO DAGScheduler: Job 72 finished: showString at NativeMethodAccessorImpl.java:0, took 0,075227 s
[2025-07-11T14:10:26.462+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO CodeGenerator: Code generated in 8.170303 ms
[2025-07-11T14:10:26.485+0200] {subprocess.py:93} INFO - +----------+------+
[2025-07-11T14:10:26.485+0200] {subprocess.py:93} INFO - |Prediction| count|
[2025-07-11T14:10:26.485+0200] {subprocess.py:93} INFO - +----------+------+
[2025-07-11T14:10:26.485+0200] {subprocess.py:93} INFO - |       0.0|  6192|
[2025-07-11T14:10:26.485+0200] {subprocess.py:93} INFO - |       1.0|315771|
[2025-07-11T14:10:26.485+0200] {subprocess.py:93} INFO - |       3.0| 51427|
[2025-07-11T14:10:26.485+0200] {subprocess.py:93} INFO - |       2.0| 83623|
[2025-07-11T14:10:26.486+0200] {subprocess.py:93} INFO - +----------+------+
[2025-07-11T14:10:26.486+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:10:26.637+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO V2ScanRelationPushDown:
[2025-07-11T14:10:26.637+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:10:26.637+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:10:26.637+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:10:26.637+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:10:26.659+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO V2ScanRelationPushDown:
[2025-07-11T14:10:26.659+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-11T14:10:26.659+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:10:26.776+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:10:26.776+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:10:26.964+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 214.5 KiB, free 422.1 MiB)
[2025-07-11T14:10:26.983+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 422.1 MiB)
[2025-07-11T14:10:26.983+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 138.4.31.23:43033 (size: 38.9 KiB, free: 433.2 MiB)
[2025-07-11T14:10:26.983+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO SparkContext: Created broadcast 107 from showString at NativeMethodAccessorImpl.java:0
[2025-07-11T14:10:26.983+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:10:27.002+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO DAGScheduler: Registering RDD 251 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 40
[2025-07-11T14:10:27.002+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO DAGScheduler: Got map stage job 73 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-07-11T14:10:27.002+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO DAGScheduler: Final stage: ShuffleMapStage 123 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:10:27.002+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:10:27.002+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:27.002+0200] {subprocess.py:93} INFO - 25/07/11 14:10:26 INFO DAGScheduler: Submitting ShuffleMapStage 123 (MapPartitionsRDD[251] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:10:27.002+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 22.8 KiB, free 422.1 MiB)
[2025-07-11T14:10:27.002+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 422.1 MiB)
[2025-07-11T14:10:27.002+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 138.4.31.23:43033 (size: 9.9 KiB, free: 433.2 MiB)
[2025-07-11T14:10:27.002+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:27.003+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 123 (MapPartitionsRDD[251] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:10:27.003+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSchedulerImpl: Adding task set 123.0 with 2 tasks resource profile 0
[2025-07-11T14:10:27.004+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 277) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:10:27.004+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Starting task 1.0 in stage 123.0 (TID 278) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:10:27.004+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Running task 1.0 in stage 123.0 (TID 278)
[2025-07-11T14:10:27.009+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO DAGScheduler: Registering RDD 255 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 41
[2025-07-11T14:10:27.009+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO DAGScheduler: Got map stage job 74 (showString at NativeMethodAccessorImpl.java:0) with 13 output partitions
[2025-07-11T14:10:27.009+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO DAGScheduler: Final stage: ShuffleMapStage 124 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:10:27.009+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Running task 0.0 in stage 123.0 (TID 277)
[2025-07-11T14:10:27.009+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:10:27.009+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:27.010+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO DAGScheduler: Submitting ShuffleMapStage 124 (MapPartitionsRDD[255] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:10:27.012+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 18.7 KiB, free 422.0 MiB)
[2025-07-11T14:10:27.012+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 422.0 MiB)
[2025-07-11T14:10:27.016+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 138.4.31.23:43033 (size: 9.2 KiB, free: 433.2 MiB)
[2025-07-11T14:10:27.019+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:10:27.021+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:10:27.023+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:27.024+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 124 (MapPartitionsRDD[255] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-11T14:10:27.026+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSchedulerImpl: Adding task set 124.0 with 13 tasks resource profile 0
[2025-07-11T14:10:27.027+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 279) (138.4.31.23, executor driver, partition 0, ANY, 16719 bytes)
[2025-07-11T14:10:27.027+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Starting task 1.0 in stage 124.0 (TID 280) (138.4.31.23, executor driver, partition 1, ANY, 16719 bytes)
[2025-07-11T14:10:27.029+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Running task 1.0 in stage 124.0 (TID 280)
[2025-07-11T14:10:27.029+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Running task 0.0 in stage 124.0 (TID 279)
[2025-07-11T14:10:27.219+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Finished task 1.0 in stage 124.0 (TID 280). 1945 bytes result sent to driver
[2025-07-11T14:10:27.220+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Starting task 2.0 in stage 124.0 (TID 281) (138.4.31.23, executor driver, partition 2, ANY, 16839 bytes)
[2025-07-11T14:10:27.221+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Finished task 1.0 in stage 124.0 (TID 280) in 193 ms on 138.4.31.23 (executor driver) (1/13)
[2025-07-11T14:10:27.225+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Running task 2.0 in stage 124.0 (TID 281)
[2025-07-11T14:10:27.245+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Finished task 0.0 in stage 124.0 (TID 279). 1945 bytes result sent to driver
[2025-07-11T14:10:27.247+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Starting task 3.0 in stage 124.0 (TID 282) (138.4.31.23, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-11T14:10:27.248+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 279) in 220 ms on 138.4.31.23 (executor driver) (2/13)
[2025-07-11T14:10:27.253+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Running task 3.0 in stage 124.0 (TID 282)
[2025-07-11T14:10:27.603+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Finished task 3.0 in stage 124.0 (TID 282). 1945 bytes result sent to driver
[2025-07-11T14:10:27.605+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Starting task 4.0 in stage 124.0 (TID 283) (138.4.31.23, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-11T14:10:27.605+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Running task 4.0 in stage 124.0 (TID 283)
[2025-07-11T14:10:27.606+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Finished task 3.0 in stage 124.0 (TID 282) in 360 ms on 138.4.31.23 (executor driver) (3/13)
[2025-07-11T14:10:27.620+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Finished task 2.0 in stage 124.0 (TID 281). 1945 bytes result sent to driver
[2025-07-11T14:10:27.623+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Starting task 5.0 in stage 124.0 (TID 284) (138.4.31.23, executor driver, partition 5, ANY, 16839 bytes)
[2025-07-11T14:10:27.623+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Running task 5.0 in stage 124.0 (TID 284)
[2025-07-11T14:10:27.624+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Finished task 2.0 in stage 124.0 (TID 281) in 401 ms on 138.4.31.23 (executor driver) (4/13)
[2025-07-11T14:10:27.644+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Finished task 4.0 in stage 124.0 (TID 283). 1945 bytes result sent to driver
[2025-07-11T14:10:27.645+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Starting task 6.0 in stage 124.0 (TID 285) (138.4.31.23, executor driver, partition 6, ANY, 16715 bytes)
[2025-07-11T14:10:27.648+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Running task 6.0 in stage 124.0 (TID 285)
[2025-07-11T14:10:27.649+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Finished task 4.0 in stage 124.0 (TID 283) in 41 ms on 138.4.31.23 (executor driver) (5/13)
[2025-07-11T14:10:27.674+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Finished task 5.0 in stage 124.0 (TID 284). 1945 bytes result sent to driver
[2025-07-11T14:10:27.675+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Starting task 7.0 in stage 124.0 (TID 286) (138.4.31.23, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-11T14:10:27.675+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Running task 7.0 in stage 124.0 (TID 286)
[2025-07-11T14:10:27.676+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Finished task 5.0 in stage 124.0 (TID 284) in 55 ms on 138.4.31.23 (executor driver) (6/13)
[2025-07-11T14:10:27.727+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 138.4.31.23:43033 in memory (size: 446.3 KiB, free: 433.6 MiB)
[2025-07-11T14:10:27.749+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Finished task 6.0 in stage 124.0 (TID 285). 1988 bytes result sent to driver
[2025-07-11T14:10:27.753+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Starting task 8.0 in stage 124.0 (TID 287) (138.4.31.23, executor driver, partition 8, ANY, 16719 bytes)
[2025-07-11T14:10:27.753+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Running task 8.0 in stage 124.0 (TID 287)
[2025-07-11T14:10:27.754+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Finished task 6.0 in stage 124.0 (TID 285) in 109 ms on 138.4.31.23 (executor driver) (7/13)
[2025-07-11T14:10:27.769+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Finished task 7.0 in stage 124.0 (TID 286). 1988 bytes result sent to driver
[2025-07-11T14:10:27.770+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Starting task 9.0 in stage 124.0 (TID 288) (138.4.31.23, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-11T14:10:27.771+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Running task 9.0 in stage 124.0 (TID 288)
[2025-07-11T14:10:27.771+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Finished task 7.0 in stage 124.0 (TID 286) in 96 ms on 138.4.31.23 (executor driver) (8/13)
[2025-07-11T14:10:27.835+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Finished task 8.0 in stage 124.0 (TID 287). 1945 bytes result sent to driver
[2025-07-11T14:10:27.841+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Starting task 10.0 in stage 124.0 (TID 289) (138.4.31.23, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-11T14:10:27.843+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Finished task 8.0 in stage 124.0 (TID 287) in 91 ms on 138.4.31.23 (executor driver) (9/13)
[2025-07-11T14:10:27.844+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Running task 10.0 in stage 124.0 (TID 289)
[2025-07-11T14:10:27.848+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Finished task 9.0 in stage 124.0 (TID 288). 1945 bytes result sent to driver
[2025-07-11T14:10:27.850+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Starting task 11.0 in stage 124.0 (TID 290) (138.4.31.23, executor driver, partition 11, ANY, 16839 bytes)
[2025-07-11T14:10:27.851+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Finished task 9.0 in stage 124.0 (TID 288) in 80 ms on 138.4.31.23 (executor driver) (10/13)
[2025-07-11T14:10:27.851+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Running task 11.0 in stage 124.0 (TID 290)
[2025-07-11T14:10:27.906+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Finished task 10.0 in stage 124.0 (TID 289). 1945 bytes result sent to driver
[2025-07-11T14:10:27.906+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Starting task 12.0 in stage 124.0 (TID 291) (138.4.31.23, executor driver, partition 12, ANY, 16719 bytes)
[2025-07-11T14:10:27.907+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Finished task 10.0 in stage 124.0 (TID 289) in 66 ms on 138.4.31.23 (executor driver) (11/13)
[2025-07-11T14:10:27.908+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Running task 12.0 in stage 124.0 (TID 291)
[2025-07-11T14:10:27.941+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Finished task 11.0 in stage 124.0 (TID 290). 1945 bytes result sent to driver
[2025-07-11T14:10:27.952+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Finished task 11.0 in stage 124.0 (TID 290) in 103 ms on 138.4.31.23 (executor driver) (12/13)
[2025-07-11T14:10:27.967+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO Executor: Finished task 12.0 in stage 124.0 (TID 291). 1945 bytes result sent to driver
[2025-07-11T14:10:27.972+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSetManager: Finished task 12.0 in stage 124.0 (TID 291) in 66 ms on 138.4.31.23 (executor driver) (13/13)
[2025-07-11T14:10:27.972+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool
[2025-07-11T14:10:27.973+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO DAGScheduler: ShuffleMapStage 124 (showString at NativeMethodAccessorImpl.java:0) finished in 0,962 s
[2025-07-11T14:10:27.974+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:10:27.974+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO DAGScheduler: running: Set(ShuffleMapStage 123)
[2025-07-11T14:10:27.974+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:10:27.974+0200] {subprocess.py:93} INFO - 25/07/11 14:10:27 INFO DAGScheduler: failed: Set()
[2025-07-11T14:10:28.061+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO ShufflePartitionsUtil: For shuffle(41), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:10:28.132+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:10:28.133+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO DAGScheduler: Got job 75 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-11T14:10:28.134+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO DAGScheduler: Final stage: ResultStage 126 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-11T14:10:28.134+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 125)
[2025-07-11T14:10:28.134+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:28.136+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[257] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-11T14:10:28.138+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 8.2 KiB, free 423.4 MiB)
[2025-07-11T14:10:28.138+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 423.4 MiB)
[2025-07-11T14:10:28.138+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 138.4.31.23:43033 (size: 4.2 KiB, free: 433.6 MiB)
[2025-07-11T14:10:28.141+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:28.141+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 126 (MapPartitionsRDD[257] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:10:28.142+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO TaskSchedulerImpl: Adding task set 126.0 with 1 tasks resource profile 0
[2025-07-11T14:10:28.145+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 292) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-11T14:10:28.146+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO Executor: Running task 0.0 in stage 126.0 (TID 292)
[2025-07-11T14:10:28.148+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO ShuffleBlockFetcherIterator: Getting 13 (221.8 KiB) non-empty blocks including 13 (221.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:28.149+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-11T14:10:28.197+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO Executor: Finished task 0.0 in stage 126.0 (TID 292). 51133 bytes result sent to driver
[2025-07-11T14:10:28.199+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 292) in 54 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:10:28.199+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool
[2025-07-11T14:10:28.201+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO DAGScheduler: ResultStage 126 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,065 s
[2025-07-11T14:10:28.204+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:10:28.204+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 126: Stage finished
[2025-07-11T14:10:28.205+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO DAGScheduler: Job 75 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,069965 s
[2025-07-11T14:10:28.209+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 4.3 MiB, free 419.2 MiB)
[2025-07-11T14:10:28.212+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 109.2 KiB, free 419.1 MiB)
[2025-07-11T14:10:28.215+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 138.4.31.23:43033 (size: 109.2 KiB, free: 433.5 MiB)
[2025-07-11T14:10:28.215+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO SparkContext: Created broadcast 111 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:10:28.444+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 138.4.31.23:43033 in memory (size: 4.2 KiB, free: 433.5 MiB)
[2025-07-11T14:10:28.957+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO Executor: Finished task 1.0 in stage 123.0 (TID 278). 2031 bytes result sent to driver
[2025-07-11T14:10:28.958+0200] {subprocess.py:93} INFO - 25/07/11 14:10:28 INFO TaskSetManager: Finished task 1.0 in stage 123.0 (TID 278) in 1955 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:10:37.147+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO Executor: Finished task 0.0 in stage 123.0 (TID 277). 2031 bytes result sent to driver
[2025-07-11T14:10:37.148+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 277) in 10145 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:10:37.148+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool
[2025-07-11T14:10:37.148+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO DAGScheduler: ShuffleMapStage 123 (showString at NativeMethodAccessorImpl.java:0) finished in 10,149 s
[2025-07-11T14:10:37.148+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:10:37.148+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO DAGScheduler: running: Set()
[2025-07-11T14:10:37.148+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:10:37.148+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO DAGScheduler: failed: Set()
[2025-07-11T14:10:37.158+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO ShufflePartitionsUtil: For shuffle(40), advisory target size: 67108864, actual target size 4228400, minimum partition size: 1048576
[2025-07-11T14:10:37.169+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO CodeGenerator: Code generated in 3.497394 ms
[2025-07-11T14:10:37.217+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO CodeGenerator: Code generated in 31.231098 ms
[2025-07-11T14:10:37.286+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2025-07-11T14:10:37.288+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO DAGScheduler: Got job 76 (showString at NativeMethodAccessorImpl.java:0) with 4 output partitions
[2025-07-11T14:10:37.289+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO DAGScheduler: Final stage: ResultStage 128 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:10:37.289+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 127)
[2025-07-11T14:10:37.289+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:37.289+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO DAGScheduler: Submitting ResultStage 128 (MapPartitionsRDD[261] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:10:37.305+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 WARN DAGScheduler: Broadcasting large task binary with size 1009.3 KiB
[2025-07-11T14:10:37.306+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 1009.4 KiB, free 418.1 MiB)
[2025-07-11T14:10:37.310+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 439.9 KiB, free 417.7 MiB)
[2025-07-11T14:10:37.312+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 138.4.31.23:43033 (size: 439.9 KiB, free: 433.1 MiB)
[2025-07-11T14:10:37.312+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:37.313+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 128 (MapPartitionsRDD[261] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:10:37.313+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO TaskSchedulerImpl: Adding task set 128.0 with 4 tasks resource profile 0
[2025-07-11T14:10:37.314+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 293) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14847 bytes)
[2025-07-11T14:10:37.314+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO TaskSetManager: Starting task 1.0 in stage 128.0 (TID 294) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14847 bytes)
[2025-07-11T14:10:37.314+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO TaskSetManager: Starting task 2.0 in stage 128.0 (TID 295) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14847 bytes)
[2025-07-11T14:10:37.314+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO TaskSetManager: Starting task 3.0 in stage 128.0 (TID 296) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14847 bytes)
[2025-07-11T14:10:37.315+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO Executor: Running task 0.0 in stage 128.0 (TID 293)
[2025-07-11T14:10:37.315+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO Executor: Running task 2.0 in stage 128.0 (TID 295)
[2025-07-11T14:10:37.315+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO Executor: Running task 3.0 in stage 128.0 (TID 296)
[2025-07-11T14:10:37.320+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO Executor: Running task 1.0 in stage 128.0 (TID 294)
[2025-07-11T14:10:37.357+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO CodeGenerator: Code generated in 9.473898 ms
[2025-07-11T14:10:37.359+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO ShuffleBlockFetcherIterator: Getting 1 (7.1 MiB) non-empty blocks including 1 (7.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:37.360+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:10:37.361+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO ShuffleBlockFetcherIterator: Getting 1 (7.4 MiB) non-empty blocks including 1 (7.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:37.361+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:10:37.365+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO ShuffleBlockFetcherIterator: Getting 1 (840.2 KiB) non-empty blocks including 1 (840.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:37.365+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:10:37.366+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO ShuffleBlockFetcherIterator: Getting 1 (802.7 KiB) non-empty blocks including 1 (802.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:37.366+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:10:37.413+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO CodeGenerator: Code generated in 50.825983 ms
[2025-07-11T14:10:37.680+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO Executor: Finished task 3.0 in stage 128.0 (TID 296). 7241 bytes result sent to driver
[2025-07-11T14:10:37.682+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO TaskSetManager: Finished task 3.0 in stage 128.0 (TID 296) in 368 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:10:37.727+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO Executor: Finished task 2.0 in stage 128.0 (TID 295). 7241 bytes result sent to driver
[2025-07-11T14:10:37.728+0200] {subprocess.py:93} INFO - 25/07/11 14:10:37 INFO TaskSetManager: Finished task 2.0 in stage 128.0 (TID 295) in 414 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:10:38.787+0200] {subprocess.py:93} INFO - 25/07/11 14:10:38 INFO Executor: Finished task 0.0 in stage 128.0 (TID 293). 7241 bytes result sent to driver
[2025-07-11T14:10:38.788+0200] {subprocess.py:93} INFO - 25/07/11 14:10:38 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 293) in 1474 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:10:38.814+0200] {subprocess.py:93} INFO - 25/07/11 14:10:38 INFO Executor: Finished task 1.0 in stage 128.0 (TID 294). 7241 bytes result sent to driver
[2025-07-11T14:10:38.815+0200] {subprocess.py:93} INFO - 25/07/11 14:10:38 INFO TaskSetManager: Finished task 1.0 in stage 128.0 (TID 294) in 1500 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:10:38.815+0200] {subprocess.py:93} INFO - 25/07/11 14:10:38 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool
[2025-07-11T14:10:38.815+0200] {subprocess.py:93} INFO - 25/07/11 14:10:38 INFO DAGScheduler: ResultStage 128 (showString at NativeMethodAccessorImpl.java:0) finished in 1,526 s
[2025-07-11T14:10:38.815+0200] {subprocess.py:93} INFO - 25/07/11 14:10:38 INFO DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:10:38.815+0200] {subprocess.py:93} INFO - 25/07/11 14:10:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 128: Stage finished
[2025-07-11T14:10:38.816+0200] {subprocess.py:93} INFO - 25/07/11 14:10:38 INFO DAGScheduler: Job 76 finished: showString at NativeMethodAccessorImpl.java:0, took 1,528631 s
[2025-07-11T14:10:38.826+0200] {subprocess.py:93} INFO - 25/07/11 14:10:38 INFO CodeGenerator: Code generated in 7.48043 ms
[2025-07-11T14:10:38.835+0200] {subprocess.py:93} INFO - 25/07/11 14:10:38 INFO CodeGenerator: Code generated in 4.870042 ms
[2025-07-11T14:10:38.837+0200] {subprocess.py:93} INFO - +--------+-------------------+-------------------+----------+---------+---------+--------+----------+---------+-----------------+--------------+--------------------+--------------------+--------------------+----------+
[2025-07-11T14:10:38.837+0200] {subprocess.py:93} INFO - |ArrDelay|         CRSArrTime|         CRSDepTime|DayOfMonth|DayOfWeek|DayOfYear|DepDelay|FlightDate|FlightNum|         Distance|ArrDelayBucket|        Features_vec|       rawPrediction|         probability|Prediction|
[2025-07-11T14:10:38.837+0200] {subprocess.py:93} INFO - +--------+-------------------+-------------------+----------+---------+---------+--------+----------+---------+-----------------+--------------+--------------------+--------------------+--------------------+----------+
[2025-07-11T14:10:38.839+0200] {subprocess.py:93} INFO - |   -22.0|2015-01-01 10:11:00|2015-01-01 07:00:00|         1|        4|        1|    -2.0|2015-01-01|     2282|            946.0|           0.0|[-2.0,946.0,1.0,4...|[2.80066385023886...|[0.28006638502388...|       1.0|
[2025-07-11T14:10:38.839+0200] {subprocess.py:93} INFO - |    -7.0|2015-01-01 12:42:00|2015-01-01 11:25:00|         1|        4|        1|    -6.0|2015-01-01|      626|            369.0|           1.0|[-6.0,369.0,1.0,4...|[1.53803424467514...|[0.15380342446751...|       1.0|
[2025-07-11T14:10:38.839+0200] {subprocess.py:93} INFO - |    -7.0|2015-01-01 17:09:00|2015-01-01 14:11:00|         1|        4|        1|    10.0|2015-01-01|     1236|588.7860861334595|           1.0|[10.0,588.7860861...|[1.29589735250055...|[0.12958973525005...|       2.0|
[2025-07-11T14:10:38.839+0200] {subprocess.py:93} INFO - |     8.0|2015-01-01 16:38:00|2015-01-01 15:45:00|         1|        4|        1|    -3.0|2015-01-01|     6603|            160.0|           2.0|[-3.0,160.0,1.0,4...|[0.96674469553972...|[0.09667446955397...|       1.0|
[2025-07-11T14:10:38.839+0200] {subprocess.py:93} INFO - |   -28.0|2015-01-01 19:10:00|2015-01-01 17:05:00|         1|        4|        1|    -8.0|2015-01-01|     3101|            693.0|           0.0|[-8.0,693.0,1.0,4...|[1.61008925327684...|[0.16100892532768...|       1.0|
[2025-07-11T14:10:38.839+0200] {subprocess.py:93} INFO - |    53.0|2015-01-01 21:18:00|2015-01-01 18:15:00|         1|        4|        1|    53.0|2015-01-01|     5159|            946.0|           3.0|[53.0,946.0,1.0,4...|[0.24994993756609...|[0.02499499375660...|       3.0|
[2025-07-11T14:10:38.839+0200] {subprocess.py:93} INFO - +--------+-------------------+-------------------+----------+---------+---------+--------+----------+---------+-----------------+--------------+--------------------+--------------------+--------------------+----------+
[2025-07-11T14:10:38.839+0200] {subprocess.py:93} INFO - only showing top 6 rows
[2025-07-11T14:10:38.839+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:10:38.958+0200] {subprocess.py:93} INFO - 25/07/11 14:10:38 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:10:38.958+0200] {subprocess.py:93} INFO - 25/07/11 14:10:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:38.958+0200] {subprocess.py:93} INFO - 25/07/11 14:10:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:39.087+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-11T14:10:39.088+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Got job 77 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-11T14:10:39.088+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Final stage: ResultStage 129 (runJob at SparkHadoopWriter.scala:83)
[2025-07-11T14:10:39.088+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:10:39.089+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:39.089+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Submitting ResultStage 129 (MapPartitionsRDD[263] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-11T14:10:39.098+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 101.3 KiB, free 417.6 MiB)
[2025-07-11T14:10:39.099+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 417.5 MiB)
[2025-07-11T14:10:39.100+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 138.4.31.23:43033 (size: 36.4 KiB, free: 433.0 MiB)
[2025-07-11T14:10:39.100+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:39.101+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 129 (MapPartitionsRDD[263] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:10:39.101+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSchedulerImpl: Adding task set 129.0 with 1 tasks resource profile 0
[2025-07-11T14:10:39.106+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 297) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15042 bytes)
[2025-07-11T14:10:39.109+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Running task 0.0 in stage 129.0 (TID 297)
[2025-07-11T14:10:39.120+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:10:39.120+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:39.120+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:39.186+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: Saved output of task 'attempt_202507111410387340324836062664806_0263_m_000000_0' to file:/tmp/mlflow/671f37e3-d98b-4b5b-8193-df4827ff52e9/metadata/_temporary/0/task_202507111410387340324836062664806_0263_m_000000
[2025-07-11T14:10:39.186+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SparkHadoopMapRedUtil: attempt_202507111410387340324836062664806_0263_m_000000_0: Committed. Elapsed time: 0 ms.
[2025-07-11T14:10:39.187+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Finished task 0.0 in stage 129.0 (TID 297). 1170 bytes result sent to driver
[2025-07-11T14:10:39.187+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 297) in 82 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:10:39.188+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool
[2025-07-11T14:10:39.188+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: ResultStage 129 (runJob at SparkHadoopWriter.scala:83) finished in 0,099 s
[2025-07-11T14:10:39.188+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Job 77 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:10:39.188+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 129: Stage finished
[2025-07-11T14:10:39.188+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Job 77 finished: runJob at SparkHadoopWriter.scala:83, took 0,100205 s
[2025-07-11T14:10:39.188+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SparkHadoopWriter: Start to commit write Job job_202507111410387340324836062664806_0263.
[2025-07-11T14:10:39.202+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SparkHadoopWriter: Write Job job_202507111410387340324836062664806_0263 committed. Elapsed time: 14 ms.
[2025-07-11T14:10:39.217+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:10:39.217+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:39.217+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:39.258+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-11T14:10:39.262+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Got job 78 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-11T14:10:39.262+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Final stage: ResultStage 130 (runJob at SparkHadoopWriter.scala:83)
[2025-07-11T14:10:39.262+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:10:39.262+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:39.262+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Submitting ResultStage 130 (MapPartitionsRDD[265] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-11T14:10:39.269+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 101.4 KiB, free 417.4 MiB)
[2025-07-11T14:10:39.271+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 417.4 MiB)
[2025-07-11T14:10:39.271+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 138.4.31.23:43033 (size: 36.5 KiB, free: 433.0 MiB)
[2025-07-11T14:10:39.271+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:39.271+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 130 (MapPartitionsRDD[265] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:10:39.271+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSchedulerImpl: Adding task set 130.0 with 1 tasks resource profile 0
[2025-07-11T14:10:39.272+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 298) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15658 bytes)
[2025-07-11T14:10:39.273+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Running task 0.0 in stage 130.0 (TID 298)
[2025-07-11T14:10:39.277+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:10:39.277+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:39.277+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:39.298+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: Saved output of task 'attempt_202507111410392975037504359899386_0265_m_000000_0' to file:/tmp/mlflow/671f37e3-d98b-4b5b-8193-df4827ff52e9/stages/0_RandomForestClassifier_6425afc2c8a8/metadata/_temporary/0/task_202507111410392975037504359899386_0265_m_000000
[2025-07-11T14:10:39.298+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SparkHadoopMapRedUtil: attempt_202507111410392975037504359899386_0265_m_000000_0: Committed. Elapsed time: 0 ms.
[2025-07-11T14:10:39.298+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Finished task 0.0 in stage 130.0 (TID 298). 1170 bytes result sent to driver
[2025-07-11T14:10:39.299+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 298) in 27 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:10:39.299+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool
[2025-07-11T14:10:39.299+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: ResultStage 130 (runJob at SparkHadoopWriter.scala:83) finished in 0,037 s
[2025-07-11T14:10:39.300+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:10:39.300+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 130: Stage finished
[2025-07-11T14:10:39.300+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Job 78 finished: runJob at SparkHadoopWriter.scala:83, took 0,041408 s
[2025-07-11T14:10:39.300+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SparkHadoopWriter: Start to commit write Job job_202507111410392975037504359899386_0265.
[2025-07-11T14:10:39.313+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SparkHadoopWriter: Write Job job_202507111410392975037504359899386_0265 committed. Elapsed time: 13 ms.
[2025-07-11T14:10:39.358+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Registering RDD 268 (parquet at treeModels.scala:483) as input to shuffle 42
[2025-07-11T14:10:39.359+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Got map stage job 79 (parquet at treeModels.scala:483) with 4 output partitions
[2025-07-11T14:10:39.359+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Final stage: ShuffleMapStage 131 (parquet at treeModels.scala:483)
[2025-07-11T14:10:39.359+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:10:39.359+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:39.359+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Submitting ShuffleMapStage 131 (MapPartitionsRDD[268] at parquet at treeModels.scala:483), which has no missing parents
[2025-07-11T14:10:39.361+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 8.3 KiB, free 417.4 MiB)
[2025-07-11T14:10:39.362+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 417.4 MiB)
[2025-07-11T14:10:39.362+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 138.4.31.23:43033 (size: 4.5 KiB, free: 433.0 MiB)
[2025-07-11T14:10:39.363+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:39.364+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 131 (MapPartitionsRDD[268] at parquet at treeModels.scala:483) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:10:39.364+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSchedulerImpl: Adding task set 131.0 with 4 tasks resource profile 0
[2025-07-11T14:10:39.371+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 299) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 16404 bytes)
[2025-07-11T14:10:39.371+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Starting task 1.0 in stage 131.0 (TID 300) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 17128 bytes)
[2025-07-11T14:10:39.371+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Starting task 2.0 in stage 131.0 (TID 301) (138.4.31.23, executor driver, partition 2, PROCESS_LOCAL, 16404 bytes)
[2025-07-11T14:10:39.371+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Starting task 3.0 in stage 131.0 (TID 302) (138.4.31.23, executor driver, partition 3, PROCESS_LOCAL, 17128 bytes)
[2025-07-11T14:10:39.371+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Running task 0.0 in stage 131.0 (TID 299)
[2025-07-11T14:10:39.371+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Running task 1.0 in stage 131.0 (TID 300)
[2025-07-11T14:10:39.371+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Running task 2.0 in stage 131.0 (TID 301)
[2025-07-11T14:10:39.371+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Running task 3.0 in stage 131.0 (TID 302)
[2025-07-11T14:10:39.371+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Finished task 2.0 in stage 131.0 (TID 301). 1585 bytes result sent to driver
[2025-07-11T14:10:39.371+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Finished task 0.0 in stage 131.0 (TID 299). 1585 bytes result sent to driver
[2025-07-11T14:10:39.371+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Finished task 1.0 in stage 131.0 (TID 300). 1585 bytes result sent to driver
[2025-07-11T14:10:39.379+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Finished task 2.0 in stage 131.0 (TID 301) in 13 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:10:39.380+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 299) in 15 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:10:39.380+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Finished task 1.0 in stage 131.0 (TID 300) in 15 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:10:39.384+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Finished task 3.0 in stage 131.0 (TID 302). 1671 bytes result sent to driver
[2025-07-11T14:10:39.384+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 138.4.31.23:43033 in memory (size: 36.5 KiB, free: 433.0 MiB)
[2025-07-11T14:10:39.385+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Finished task 3.0 in stage 131.0 (TID 302) in 19 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:10:39.385+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool
[2025-07-11T14:10:39.385+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 138.4.31.23:43033 in memory (size: 36.4 KiB, free: 433.1 MiB)
[2025-07-11T14:10:39.385+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: ShuffleMapStage 131 (parquet at treeModels.scala:483) finished in 0,026 s
[2025-07-11T14:10:39.385+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:10:39.386+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: running: Set()
[2025-07-11T14:10:39.386+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:10:39.386+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: failed: Set()
[2025-07-11T14:10:39.389+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:10:39.389+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:39.389+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:39.389+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 138.4.31.23:43033 in memory (size: 439.9 KiB, free: 433.5 MiB)
[2025-07-11T14:10:39.390+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:10:39.390+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:39.390+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:39.390+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:10:39.408+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SparkContext: Starting job: parquet at treeModels.scala:483
[2025-07-11T14:10:39.409+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Got job 80 (parquet at treeModels.scala:483) with 1 output partitions
[2025-07-11T14:10:39.409+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Final stage: ResultStage 133 (parquet at treeModels.scala:483)
[2025-07-11T14:10:39.409+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 132)
[2025-07-11T14:10:39.409+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:39.409+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Submitting ResultStage 133 (MapPartitionsRDD[270] at parquet at treeModels.scala:483), which has no missing parents
[2025-07-11T14:10:39.424+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 239.7 KiB, free 418.8 MiB)
[2025-07-11T14:10:39.427+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 83.9 KiB, free 418.8 MiB)
[2025-07-11T14:10:39.428+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 138.4.31.23:43033 (size: 83.9 KiB, free: 433.4 MiB)
[2025-07-11T14:10:39.428+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:39.428+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 133 (MapPartitionsRDD[270] at parquet at treeModels.scala:483) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:10:39.428+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSchedulerImpl: Adding task set 133.0 with 1 tasks resource profile 0
[2025-07-11T14:10:39.429+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 303) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:10:39.429+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Running task 0.0 in stage 133.0 (TID 303)
[2025-07-11T14:10:39.438+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:39.438+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:10:39.439+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:39.439+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:39.440+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:10:39.440+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:39.440+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:39.440+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:10:39.440+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:10:39.441+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:10:39.442+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-11T14:10:39.443+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-11T14:10:39.443+0200] {subprocess.py:93} INFO - {
[2025-07-11T14:10:39.443+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-11T14:10:39.443+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-11T14:10:39.443+0200] {subprocess.py:93} INFO -     "name" : "treeID",
[2025-07-11T14:10:39.444+0200] {subprocess.py:93} INFO -     "type" : "integer",
[2025-07-11T14:10:39.444+0200] {subprocess.py:93} INFO -     "nullable" : false,
[2025-07-11T14:10:39.444+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:10:39.444+0200] {subprocess.py:93} INFO -   }, {
[2025-07-11T14:10:39.444+0200] {subprocess.py:93} INFO -     "name" : "metadata",
[2025-07-11T14:10:39.444+0200] {subprocess.py:93} INFO -     "type" : "string",
[2025-07-11T14:10:39.444+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-11T14:10:39.444+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:10:39.444+0200] {subprocess.py:93} INFO -   }, {
[2025-07-11T14:10:39.444+0200] {subprocess.py:93} INFO -     "name" : "weights",
[2025-07-11T14:10:39.444+0200] {subprocess.py:93} INFO -     "type" : "double",
[2025-07-11T14:10:39.444+0200] {subprocess.py:93} INFO -     "nullable" : false,
[2025-07-11T14:10:39.444+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:10:39.444+0200] {subprocess.py:93} INFO -   } ]
[2025-07-11T14:10:39.444+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:10:39.444+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-11T14:10:39.444+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-11T14:10:39.444+0200] {subprocess.py:93} INFO -   required int32 treeID;
[2025-07-11T14:10:39.445+0200] {subprocess.py:93} INFO -   optional binary metadata (STRING);
[2025-07-11T14:10:39.445+0200] {subprocess.py:93} INFO -   required double weights;
[2025-07-11T14:10:39.445+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:10:39.445+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:10:39.445+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:10:39.464+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: Saved output of task 'attempt_202507111410397433974642094190486_0133_m_000000_303' to file:/tmp/mlflow/671f37e3-d98b-4b5b-8193-df4827ff52e9/stages/0_RandomForestClassifier_6425afc2c8a8/treesMetadata/_temporary/0/task_202507111410397433974642094190486_0133_m_000000
[2025-07-11T14:10:39.464+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SparkHadoopMapRedUtil: attempt_202507111410397433974642094190486_0133_m_000000_303: Committed. Elapsed time: 0 ms.
[2025-07-11T14:10:39.464+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Finished task 0.0 in stage 133.0 (TID 303). 4740 bytes result sent to driver
[2025-07-11T14:10:39.465+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 303) in 36 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:10:39.465+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool
[2025-07-11T14:10:39.466+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: ResultStage 133 (parquet at treeModels.scala:483) finished in 0,057 s
[2025-07-11T14:10:39.466+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:10:39.466+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 133: Stage finished
[2025-07-11T14:10:39.467+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Job 80 finished: parquet at treeModels.scala:483, took 0,059187 s
[2025-07-11T14:10:39.467+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileFormatWriter: Start to commit write Job a8397214-ed7c-4eba-aaf0-cfc20900a513.
[2025-07-11T14:10:39.483+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileFormatWriter: Write Job a8397214-ed7c-4eba-aaf0-cfc20900a513 committed. Elapsed time: 15 ms.
[2025-07-11T14:10:39.484+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileFormatWriter: Finished processing stats for write job a8397214-ed7c-4eba-aaf0-cfc20900a513.
[2025-07-11T14:10:39.554+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Registering RDD 275 (parquet at treeModels.scala:491) as input to shuffle 43
[2025-07-11T14:10:39.554+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Got map stage job 81 (parquet at treeModels.scala:491) with 4 output partitions
[2025-07-11T14:10:39.554+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Final stage: ShuffleMapStage 134 (parquet at treeModels.scala:491)
[2025-07-11T14:10:39.554+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:10:39.554+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:39.554+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Submitting ShuffleMapStage 134 (MapPartitionsRDD[275] at parquet at treeModels.scala:491), which has no missing parents
[2025-07-11T14:10:39.556+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 41.5 KiB, free 418.7 MiB)
[2025-07-11T14:10:39.556+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 12.3 KiB, free 418.7 MiB)
[2025-07-11T14:10:39.556+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 138.4.31.23:43033 (size: 12.3 KiB, free: 433.4 MiB)
[2025-07-11T14:10:39.556+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:39.557+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 134 (MapPartitionsRDD[275] at parquet at treeModels.scala:491) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:10:39.557+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSchedulerImpl: Adding task set 134.0 with 4 tasks resource profile 0
[2025-07-11T14:10:39.559+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 304) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 140337 bytes)
[2025-07-11T14:10:39.564+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Starting task 1.0 in stage 134.0 (TID 305) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 386293 bytes)
[2025-07-11T14:10:39.566+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Starting task 2.0 in stage 134.0 (TID 306) (138.4.31.23, executor driver, partition 2, PROCESS_LOCAL, 128364 bytes)
[2025-07-11T14:10:39.568+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Starting task 3.0 in stage 134.0 (TID 307) (138.4.31.23, executor driver, partition 3, PROCESS_LOCAL, 208919 bytes)
[2025-07-11T14:10:39.569+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Running task 0.0 in stage 134.0 (TID 304)
[2025-07-11T14:10:39.569+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Running task 1.0 in stage 134.0 (TID 305)
[2025-07-11T14:10:39.570+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Running task 2.0 in stage 134.0 (TID 306)
[2025-07-11T14:10:39.573+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Running task 3.0 in stage 134.0 (TID 307)
[2025-07-11T14:10:39.585+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Finished task 0.0 in stage 134.0 (TID 304). 1700 bytes result sent to driver
[2025-07-11T14:10:39.585+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 304) in 28 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:10:39.599+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Finished task 1.0 in stage 134.0 (TID 305). 1700 bytes result sent to driver
[2025-07-11T14:10:39.600+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Finished task 1.0 in stage 134.0 (TID 305) in 41 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:10:39.610+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Finished task 2.0 in stage 134.0 (TID 306). 1700 bytes result sent to driver
[2025-07-11T14:10:39.613+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Finished task 2.0 in stage 134.0 (TID 306) in 48 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:10:39.620+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Finished task 3.0 in stage 134.0 (TID 307). 1700 bytes result sent to driver
[2025-07-11T14:10:39.622+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Finished task 3.0 in stage 134.0 (TID 307) in 55 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:10:39.623+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool
[2025-07-11T14:10:39.624+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: ShuffleMapStage 134 (parquet at treeModels.scala:491) finished in 0,068 s
[2025-07-11T14:10:39.624+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:10:39.624+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: running: Set()
[2025-07-11T14:10:39.624+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:10:39.624+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: failed: Set()
[2025-07-11T14:10:39.631+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:10:39.632+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:39.632+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:39.632+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:10:39.632+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:39.632+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:39.632+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:10:39.655+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SparkContext: Starting job: parquet at treeModels.scala:491
[2025-07-11T14:10:39.655+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Got job 82 (parquet at treeModels.scala:491) with 1 output partitions
[2025-07-11T14:10:39.655+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Final stage: ResultStage 136 (parquet at treeModels.scala:491)
[2025-07-11T14:10:39.655+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 135)
[2025-07-11T14:10:39.655+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:10:39.655+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Submitting ResultStage 136 (MapPartitionsRDD[277] at parquet at treeModels.scala:491), which has no missing parents
[2025-07-11T14:10:39.670+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 241.4 KiB, free 418.5 MiB)
[2025-07-11T14:10:39.671+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 84.8 KiB, free 418.4 MiB)
[2025-07-11T14:10:39.672+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 138.4.31.23:43033 (size: 84.8 KiB, free: 433.3 MiB)
[2025-07-11T14:10:39.673+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:10:39.673+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 136 (MapPartitionsRDD[277] at parquet at treeModels.scala:491) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:10:39.673+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSchedulerImpl: Adding task set 136.0 with 1 tasks resource profile 0
[2025-07-11T14:10:39.674+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 308) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:10:39.674+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Running task 0.0 in stage 136.0 (TID 308)
[2025-07-11T14:10:39.683+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO ShuffleBlockFetcherIterator: Getting 4 (176.9 KiB) non-empty blocks including 4 (176.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:10:39.684+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:10:39.685+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:39.685+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:39.685+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:10:39.685+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:10:39.685+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:10:39.685+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:10:39.685+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:10:39.686+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:10:39.686+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-11T14:10:39.689+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-11T14:10:39.689+0200] {subprocess.py:93} INFO - {
[2025-07-11T14:10:39.689+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-11T14:10:39.690+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-11T14:10:39.690+0200] {subprocess.py:93} INFO -     "name" : "treeID",
[2025-07-11T14:10:39.690+0200] {subprocess.py:93} INFO -     "type" : "integer",
[2025-07-11T14:10:39.690+0200] {subprocess.py:93} INFO -     "nullable" : false,
[2025-07-11T14:10:39.690+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:10:39.690+0200] {subprocess.py:93} INFO -   }, {
[2025-07-11T14:10:39.690+0200] {subprocess.py:93} INFO -     "name" : "nodeData",
[2025-07-11T14:10:39.690+0200] {subprocess.py:93} INFO -     "type" : {
[2025-07-11T14:10:39.690+0200] {subprocess.py:93} INFO -       "type" : "struct",
[2025-07-11T14:10:39.690+0200] {subprocess.py:93} INFO -       "fields" : [ {
[2025-07-11T14:10:39.690+0200] {subprocess.py:93} INFO -         "name" : "id",
[2025-07-11T14:10:39.690+0200] {subprocess.py:93} INFO -         "type" : "integer",
[2025-07-11T14:10:39.690+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:10:39.690+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:10:39.690+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:10:39.690+0200] {subprocess.py:93} INFO -         "name" : "prediction",
[2025-07-11T14:10:39.690+0200] {subprocess.py:93} INFO -         "type" : "double",
[2025-07-11T14:10:39.690+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:10:39.691+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:10:39.691+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:10:39.691+0200] {subprocess.py:93} INFO -         "name" : "impurity",
[2025-07-11T14:10:39.691+0200] {subprocess.py:93} INFO -         "type" : "double",
[2025-07-11T14:10:39.691+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:10:39.691+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:10:39.691+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:10:39.691+0200] {subprocess.py:93} INFO -         "name" : "impurityStats",
[2025-07-11T14:10:39.691+0200] {subprocess.py:93} INFO -         "type" : {
[2025-07-11T14:10:39.691+0200] {subprocess.py:93} INFO -           "type" : "array",
[2025-07-11T14:10:39.691+0200] {subprocess.py:93} INFO -           "elementType" : "double",
[2025-07-11T14:10:39.691+0200] {subprocess.py:93} INFO -           "containsNull" : false
[2025-07-11T14:10:39.691+0200] {subprocess.py:93} INFO -         },
[2025-07-11T14:10:39.691+0200] {subprocess.py:93} INFO -         "nullable" : true,
[2025-07-11T14:10:39.691+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:10:39.691+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:10:39.691+0200] {subprocess.py:93} INFO -         "name" : "rawCount",
[2025-07-11T14:10:39.691+0200] {subprocess.py:93} INFO -         "type" : "long",
[2025-07-11T14:10:39.691+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:10:39.692+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:10:39.692+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:10:39.692+0200] {subprocess.py:93} INFO -         "name" : "gain",
[2025-07-11T14:10:39.692+0200] {subprocess.py:93} INFO -         "type" : "double",
[2025-07-11T14:10:39.692+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:10:39.692+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:10:39.692+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:10:39.692+0200] {subprocess.py:93} INFO -         "name" : "leftChild",
[2025-07-11T14:10:39.692+0200] {subprocess.py:93} INFO -         "type" : "integer",
[2025-07-11T14:10:39.692+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:10:39.692+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:10:39.692+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:10:39.692+0200] {subprocess.py:93} INFO -         "name" : "rightChild",
[2025-07-11T14:10:39.692+0200] {subprocess.py:93} INFO -         "type" : "integer",
[2025-07-11T14:10:39.692+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:10:39.692+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:10:39.692+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:10:39.692+0200] {subprocess.py:93} INFO -         "name" : "split",
[2025-07-11T14:10:39.693+0200] {subprocess.py:93} INFO -         "type" : {
[2025-07-11T14:10:39.693+0200] {subprocess.py:93} INFO -           "type" : "struct",
[2025-07-11T14:10:39.693+0200] {subprocess.py:93} INFO -           "fields" : [ {
[2025-07-11T14:10:39.693+0200] {subprocess.py:93} INFO -             "name" : "featureIndex",
[2025-07-11T14:10:39.693+0200] {subprocess.py:93} INFO -             "type" : "integer",
[2025-07-11T14:10:39.693+0200] {subprocess.py:93} INFO -             "nullable" : false,
[2025-07-11T14:10:39.693+0200] {subprocess.py:93} INFO -             "metadata" : { }
[2025-07-11T14:10:39.693+0200] {subprocess.py:93} INFO -           }, {
[2025-07-11T14:10:39.693+0200] {subprocess.py:93} INFO -             "name" : "leftCategoriesOrThreshold",
[2025-07-11T14:10:39.693+0200] {subprocess.py:93} INFO -             "type" : {
[2025-07-11T14:10:39.693+0200] {subprocess.py:93} INFO -               "type" : "array",
[2025-07-11T14:10:39.693+0200] {subprocess.py:93} INFO -               "elementType" : "double",
[2025-07-11T14:10:39.693+0200] {subprocess.py:93} INFO -               "containsNull" : false
[2025-07-11T14:10:39.693+0200] {subprocess.py:93} INFO -             },
[2025-07-11T14:10:39.693+0200] {subprocess.py:93} INFO -             "nullable" : true,
[2025-07-11T14:10:39.693+0200] {subprocess.py:93} INFO -             "metadata" : { }
[2025-07-11T14:10:39.693+0200] {subprocess.py:93} INFO -           }, {
[2025-07-11T14:10:39.693+0200] {subprocess.py:93} INFO -             "name" : "numCategories",
[2025-07-11T14:10:39.694+0200] {subprocess.py:93} INFO -             "type" : "integer",
[2025-07-11T14:10:39.694+0200] {subprocess.py:93} INFO -             "nullable" : false,
[2025-07-11T14:10:39.694+0200] {subprocess.py:93} INFO -             "metadata" : { }
[2025-07-11T14:10:39.694+0200] {subprocess.py:93} INFO -           } ]
[2025-07-11T14:10:39.694+0200] {subprocess.py:93} INFO -         },
[2025-07-11T14:10:39.694+0200] {subprocess.py:93} INFO -         "nullable" : true,
[2025-07-11T14:10:39.694+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:10:39.694+0200] {subprocess.py:93} INFO -       } ]
[2025-07-11T14:10:39.694+0200] {subprocess.py:93} INFO -     },
[2025-07-11T14:10:39.694+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-11T14:10:39.694+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:10:39.694+0200] {subprocess.py:93} INFO -   } ]
[2025-07-11T14:10:39.694+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:10:39.694+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-11T14:10:39.694+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-11T14:10:39.694+0200] {subprocess.py:93} INFO -   required int32 treeID;
[2025-07-11T14:10:39.694+0200] {subprocess.py:93} INFO -   optional group nodeData {
[2025-07-11T14:10:39.694+0200] {subprocess.py:93} INFO -     required int32 id;
[2025-07-11T14:10:39.695+0200] {subprocess.py:93} INFO -     required double prediction;
[2025-07-11T14:10:39.695+0200] {subprocess.py:93} INFO -     required double impurity;
[2025-07-11T14:10:39.695+0200] {subprocess.py:93} INFO -     optional group impurityStats (LIST) {
[2025-07-11T14:10:39.695+0200] {subprocess.py:93} INFO -       repeated group list {
[2025-07-11T14:10:39.695+0200] {subprocess.py:93} INFO -         required double element;
[2025-07-11T14:10:39.695+0200] {subprocess.py:93} INFO -       }
[2025-07-11T14:10:39.695+0200] {subprocess.py:93} INFO -     }
[2025-07-11T14:10:39.695+0200] {subprocess.py:93} INFO -     required int64 rawCount;
[2025-07-11T14:10:39.695+0200] {subprocess.py:93} INFO -     required double gain;
[2025-07-11T14:10:39.695+0200] {subprocess.py:93} INFO -     required int32 leftChild;
[2025-07-11T14:10:39.695+0200] {subprocess.py:93} INFO -     required int32 rightChild;
[2025-07-11T14:10:39.695+0200] {subprocess.py:93} INFO -     optional group split {
[2025-07-11T14:10:39.695+0200] {subprocess.py:93} INFO -       required int32 featureIndex;
[2025-07-11T14:10:39.695+0200] {subprocess.py:93} INFO -       optional group leftCategoriesOrThreshold (LIST) {
[2025-07-11T14:10:39.695+0200] {subprocess.py:93} INFO -         repeated group list {
[2025-07-11T14:10:39.695+0200] {subprocess.py:93} INFO -           required double element;
[2025-07-11T14:10:39.695+0200] {subprocess.py:93} INFO -         }
[2025-07-11T14:10:39.695+0200] {subprocess.py:93} INFO -       }
[2025-07-11T14:10:39.695+0200] {subprocess.py:93} INFO -       required int32 numCategories;
[2025-07-11T14:10:39.696+0200] {subprocess.py:93} INFO -     }
[2025-07-11T14:10:39.696+0200] {subprocess.py:93} INFO -   }
[2025-07-11T14:10:39.696+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:10:39.696+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:10:39.696+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:10:39.713+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 138.4.31.23:43033 in memory (size: 4.5 KiB, free: 433.3 MiB)
[2025-07-11T14:10:39.714+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 138.4.31.23:43033 in memory (size: 83.9 KiB, free: 433.4 MiB)
[2025-07-11T14:10:39.717+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 138.4.31.23:43033 in memory (size: 12.3 KiB, free: 433.4 MiB)
[2025-07-11T14:10:39.756+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileOutputCommitter: Saved output of task 'attempt_202507111410397404911837827564967_0136_m_000000_308' to file:/tmp/mlflow/671f37e3-d98b-4b5b-8193-df4827ff52e9/stages/0_RandomForestClassifier_6425afc2c8a8/data/_temporary/0/task_202507111410397404911837827564967_0136_m_000000
[2025-07-11T14:10:39.756+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO SparkHadoopMapRedUtil: attempt_202507111410397404911837827564967_0136_m_000000_308: Committed. Elapsed time: 0 ms.
[2025-07-11T14:10:39.757+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Executor: Finished task 0.0 in stage 136.0 (TID 308). 4783 bytes result sent to driver
[2025-07-11T14:10:39.758+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 308) in 85 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:10:39.758+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool
[2025-07-11T14:10:39.758+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: ResultStage 136 (parquet at treeModels.scala:491) finished in 0,102 s
[2025-07-11T14:10:39.758+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:10:39.758+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 136: Stage finished
[2025-07-11T14:10:39.758+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO DAGScheduler: Job 82 finished: parquet at treeModels.scala:491, took 0,103637 s
[2025-07-11T14:10:39.758+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileFormatWriter: Start to commit write Job f6a0cf14-e3e5-4c7c-b46e-a78d4b41a94e.
[2025-07-11T14:10:39.769+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileFormatWriter: Write Job f6a0cf14-e3e5-4c7c-b46e-a78d4b41a94e committed. Elapsed time: 9 ms.
[2025-07-11T14:10:39.769+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO FileFormatWriter: Finished processing stats for write job f6a0cf14-e3e5-4c7c-b46e-a78d4b41a94e.
[2025-07-11T14:10:39.769+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Instrumentation: [1e9076c2] training finished
[2025-07-11T14:10:39.769+0200] {subprocess.py:93} INFO - 25/07/11 14:10:39 INFO Instrumentation: [810a9f90] training finished
[2025-07-11T14:11:11.833+0200] {subprocess.py:93} INFO - 2025/07/11 14:11:11 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp2izq29qk/model, flavor: spark). Fall back to return ['pyspark==3.5.3']. Set logging level to DEBUG to see the full traceback.
[2025-07-11T14:11:11.847+0200] {subprocess.py:93} INFO - [31m2025/07/11 14:11:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
[2025-07-11T14:11:11.964+0200] {subprocess.py:93} INFO - MLflow: Model and metrics logged successfully.
[2025-07-11T14:11:11.979+0200] {subprocess.py:93} INFO - 25/07/11 14:11:11 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2025-07-11T14:11:11.989+0200] {subprocess.py:93} INFO - 25/07/11 14:11:11 INFO SparkUI: Stopped Spark web UI at http://138.4.31.23:4041
[2025-07-11T14:11:12.005+0200] {subprocess.py:93} INFO - 25/07/11 14:11:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-07-11T14:11:12.035+0200] {subprocess.py:93} INFO - 25/07/11 14:11:12 INFO MemoryStore: MemoryStore cleared
[2025-07-11T14:11:12.036+0200] {subprocess.py:93} INFO - 25/07/11 14:11:12 INFO BlockManager: BlockManager stopped
[2025-07-11T14:11:12.049+0200] {subprocess.py:93} INFO - 25/07/11 14:11:12 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-07-11T14:11:12.049+0200] {subprocess.py:93} INFO - 25/07/11 14:11:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-07-11T14:11:12.074+0200] {subprocess.py:93} INFO - 25/07/11 14:11:12 INFO SparkContext: Successfully stopped SparkContext
[2025-07-11T14:11:12.650+0200] {subprocess.py:93} INFO - 25/07/11 14:11:12 INFO ShutdownHookManager: Shutdown hook called
[2025-07-11T14:11:12.651+0200] {subprocess.py:93} INFO - 25/07/11 14:11:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365
[2025-07-11T14:11:12.655+0200] {subprocess.py:93} INFO - 25/07/11 14:11:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-6c0c64f3-295b-4849-895c-2ca4a44e7365/pyspark-a7a5597d-77a8-483c-ba8b-2127d70035e4
[2025-07-11T14:11:12.659+0200] {subprocess.py:93} INFO - 25/07/11 14:11:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-8903d192-5c27-42da-837f-8b08ea94d499
[2025-07-11T14:11:12.671+0200] {subprocess.py:93} INFO - 25/07/11 14:11:12 INFO CassandraConnector: Disconnected from Cassandra cluster.
[2025-07-11T14:11:12.674+0200] {subprocess.py:93} INFO - 25/07/11 14:11:12 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
[2025-07-11T14:11:12.827+0200] {subprocess.py:97} INFO - Command exited with return code 0
[2025-07-11T14:11:12.870+0200] {taskinstance.py:1318} INFO - Marking task as SUCCESS. dag_id=agile_data_science_batch_prediction_model_training, task_id=pyspark_train_classifier_model, execution_date=20250711T120810, start_date=20250711T120818, end_date=20250711T121112
[2025-07-11T14:11:12.906+0200] {local_task_job.py:208} INFO - Task exited with return code 0
[2025-07-11T14:11:12.926+0200] {taskinstance.py:2578} INFO - 0 downstream tasks scheduled from follow-on schedule check
