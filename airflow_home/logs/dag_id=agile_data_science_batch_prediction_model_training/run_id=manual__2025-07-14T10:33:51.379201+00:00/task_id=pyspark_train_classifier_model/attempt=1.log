[2025-07-14T12:33:54.608+0200] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: agile_data_science_batch_prediction_model_training.pyspark_train_classifier_model manual__2025-07-14T10:33:51.379201+00:00 [queued]>
[2025-07-14T12:33:54.628+0200] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: agile_data_science_batch_prediction_model_training.pyspark_train_classifier_model manual__2025-07-14T10:33:51.379201+00:00 [queued]>
[2025-07-14T12:33:54.628+0200] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2025-07-14T12:33:54.629+0200] {taskinstance.py:1280} INFO - Starting attempt 1 of 4
[2025-07-14T12:33:54.629+0200] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2025-07-14T12:33:54.654+0200] {taskinstance.py:1300} INFO - Executing <Task(BashOperator): pyspark_train_classifier_model> on 2025-07-14 10:33:51.379201+00:00
[2025-07-14T12:33:54.657+0200] {standard_task_runner.py:55} INFO - Started process 27262 to run task
[2025-07-14T12:33:54.661+0200] {standard_task_runner.py:82} INFO - Running: ['airflow', 'tasks', 'run', 'agile_data_science_batch_prediction_model_training', 'pyspark_train_classifier_model', 'manual__2025-07-14T10:33:51.379201+00:00', '--job-id', '191', '--raw', '--subdir', 'DAGS_FOLDER/setup.py', '--cfg-path', '/tmp/tmpa8srsebf']
[2025-07-14T12:33:54.662+0200] {standard_task_runner.py:83} INFO - Job 191: Subtask pyspark_train_classifier_model
[2025-07-14T12:33:54.755+0200] {task_command.py:388} INFO - Running <TaskInstance: agile_data_science_batch_prediction_model_training.pyspark_train_classifier_model manual__2025-07-14T10:33:51.379201+00:00 [running]> on host l089.lab.dit.upm.es
[2025-07-14T12:33:54.850+0200] {taskinstance.py:1507} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=agile_data_science_batch_prediction_model_training
AIRFLOW_CTX_TASK_ID=pyspark_train_classifier_model
AIRFLOW_CTX_EXECUTION_DATE=2025-07-14T10:33:51.379201+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2025-07-14T10:33:51.379201+00:00
[2025-07-14T12:33:54.852+0200] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-14T12:33:54.852+0200] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', '\nsource /home/monica.fernandez/practica_creativa/venv-airflow/bin/activate && export PYSPARK_PYTHON=/home/monica.fernandez/practica_creativa/venv-airflow/bin/python && spark-submit   --master local[4]   --packages com.datastax.spark:spark-cassandra-connector_2.12:3.5.0,com.github.jnr:jnr-posix:3.1.15   /home/monica.fernandez/practica_creativa/resources/train_spark_mllib_model.py   /home/monica.fernandez/practica_creativa']
[2025-07-14T12:33:54.860+0200] {subprocess.py:86} INFO - Output:
[2025-07-14T12:33:57.504+0200] {subprocess.py:93} INFO - 25/07/14 12:33:57 WARN Utils: Your hostname, l089 resolves to a loopback address: 127.0.1.1; using 138.4.31.89 instead (on interface eno1)
[2025-07-14T12:33:57.505+0200] {subprocess.py:93} INFO - 25/07/14 12:33:57 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
[2025-07-14T12:33:57.705+0200] {subprocess.py:93} INFO - :: loading settings :: url = jar:file:/home/monica.fernandez/.sdkman/candidates/spark/3.5.3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-07-14T12:33:57.800+0200] {subprocess.py:93} INFO - Ivy Default Cache set to: /home/monica.fernandez/.ivy2/cache
[2025-07-14T12:33:57.800+0200] {subprocess.py:93} INFO - The jars for the packages stored in: /home/monica.fernandez/.ivy2/jars
[2025-07-14T12:33:57.802+0200] {subprocess.py:93} INFO - com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency
[2025-07-14T12:33:57.802+0200] {subprocess.py:93} INFO - com.github.jnr#jnr-posix added as a dependency
[2025-07-14T12:33:57.803+0200] {subprocess.py:93} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-ebdcd806-e5cc-4a0b-98ca-6b77d3edcbcb;1.0
[2025-07-14T12:33:57.803+0200] {subprocess.py:93} INFO - 	confs: [default]
[2025-07-14T12:33:57.947+0200] {subprocess.py:93} INFO - 	found com.datastax.spark#spark-cassandra-connector_2.12;3.5.0 in central
[2025-07-14T12:33:57.967+0200] {subprocess.py:93} INFO - 	found com.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.0 in central
[2025-07-14T12:33:57.987+0200] {subprocess.py:93} INFO - 	found org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 in central
[2025-07-14T12:33:58.008+0200] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-core-shaded;4.13.0 in central
[2025-07-14T12:33:58.025+0200] {subprocess.py:93} INFO - 	found com.datastax.oss#native-protocol;1.5.0 in central
[2025-07-14T12:33:58.039+0200] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central
[2025-07-14T12:33:58.054+0200] {subprocess.py:93} INFO - 	found com.typesafe#config;1.4.1 in central
[2025-07-14T12:33:58.068+0200] {subprocess.py:93} INFO - 	found org.slf4j#slf4j-api;1.7.26 in central
[2025-07-14T12:33:58.082+0200] {subprocess.py:93} INFO - 	found io.dropwizard.metrics#metrics-core;4.1.18 in central
[2025-07-14T12:33:58.099+0200] {subprocess.py:93} INFO - 	found org.hdrhistogram#HdrHistogram;2.1.12 in central
[2025-07-14T12:33:58.112+0200] {subprocess.py:93} INFO - 	found org.reactivestreams#reactive-streams;1.0.3 in central
[2025-07-14T12:33:58.125+0200] {subprocess.py:93} INFO - 	found com.github.stephenc.jcip#jcip-annotations;1.0-1 in central
[2025-07-14T12:33:58.137+0200] {subprocess.py:93} INFO - 	found com.github.spotbugs#spotbugs-annotations;3.1.12 in central
[2025-07-14T12:33:58.150+0200] {subprocess.py:93} INFO - 	found com.google.code.findbugs#jsr305;3.0.2 in central
[2025-07-14T12:33:58.163+0200] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central
[2025-07-14T12:33:58.176+0200] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-query-builder;4.13.0 in central
[2025-07-14T12:33:58.189+0200] {subprocess.py:93} INFO - 	found org.apache.commons#commons-lang3;3.10 in central
[2025-07-14T12:33:58.200+0200] {subprocess.py:93} INFO - 	found com.thoughtworks.paranamer#paranamer;2.8 in central
[2025-07-14T12:33:58.211+0200] {subprocess.py:93} INFO - 	found org.scala-lang#scala-reflect;2.12.11 in central
[2025-07-14T12:33:58.223+0200] {subprocess.py:93} INFO - 	found com.github.jnr#jnr-posix;3.1.15 in central
[2025-07-14T12:33:58.233+0200] {subprocess.py:93} INFO - 	found com.github.jnr#jnr-ffi;2.2.11 in central
[2025-07-14T12:33:58.243+0200] {subprocess.py:93} INFO - 	found com.github.jnr#jffi;1.3.9 in central
[2025-07-14T12:33:58.253+0200] {subprocess.py:93} INFO - 	found org.ow2.asm#asm;9.2 in central
[2025-07-14T12:33:58.262+0200] {subprocess.py:93} INFO - 	found org.ow2.asm#asm-commons;9.2 in central
[2025-07-14T12:33:58.279+0200] {subprocess.py:93} INFO - 	found org.ow2.asm#asm-tree;9.2 in central
[2025-07-14T12:33:58.288+0200] {subprocess.py:93} INFO - 	found org.ow2.asm#asm-analysis;9.2 in central
[2025-07-14T12:33:58.298+0200] {subprocess.py:93} INFO - 	found org.ow2.asm#asm-util;9.2 in central
[2025-07-14T12:33:58.310+0200] {subprocess.py:93} INFO - 	found com.github.jnr#jnr-a64asm;1.0.0 in central
[2025-07-14T12:33:58.320+0200] {subprocess.py:93} INFO - 	found com.github.jnr#jnr-x86asm;1.0.2 in central
[2025-07-14T12:33:58.330+0200] {subprocess.py:93} INFO - 	found com.github.jnr#jnr-constants;0.10.3 in central
[2025-07-14T12:33:58.382+0200] {subprocess.py:93} INFO - :: resolution report :: resolve 535ms :: artifacts dl 44ms
[2025-07-14T12:33:58.382+0200] {subprocess.py:93} INFO - 	:: modules in use:
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	com.datastax.oss#native-protocol;1.5.0 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	com.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.0 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	com.datastax.spark#spark-cassandra-connector_2.12;3.5.0 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	com.github.jnr#jffi;1.3.9 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	com.github.jnr#jnr-a64asm;1.0.0 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	com.github.jnr#jnr-constants;0.10.3 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	com.github.jnr#jnr-ffi;2.2.11 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	com.github.jnr#jnr-posix;3.1.15 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	com.github.jnr#jnr-x86asm;1.0.2 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	com.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	com.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	com.google.code.findbugs#jsr305;3.0.2 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	com.thoughtworks.paranamer#paranamer;2.8 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	com.typesafe#config;1.4.1 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	io.dropwizard.metrics#metrics-core;4.1.18 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	org.apache.commons#commons-lang3;3.10 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	org.hdrhistogram#HdrHistogram;2.1.12 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	org.ow2.asm#asm;9.2 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	org.ow2.asm#asm-analysis;9.2 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	org.ow2.asm#asm-commons;9.2 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	org.ow2.asm#asm-tree;9.2 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	org.ow2.asm#asm-util;9.2 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	org.reactivestreams#reactive-streams;1.0.3 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	org.scala-lang#scala-reflect;2.12.11 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	org.slf4j#slf4j-api;1.7.26 from central in [default]
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	|                  |            modules            ||   artifacts   |
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	|      default     |   30  |   0   |   0   |   0   ||   30  |   0   |
[2025-07-14T12:33:58.383+0200] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-07-14T12:33:58.390+0200] {subprocess.py:93} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-ebdcd806-e5cc-4a0b-98ca-6b77d3edcbcb
[2025-07-14T12:33:58.390+0200] {subprocess.py:93} INFO - 	confs: [default]
[2025-07-14T12:33:58.406+0200] {subprocess.py:93} INFO - 	0 artifacts copied, 30 already retrieved (0kB/15ms)
[2025-07-14T12:33:58.619+0200] {subprocess.py:93} INFO - 25/07/14 12:33:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-07-14T12:34:03.853+0200] {subprocess.py:93} INFO - 25/07/14 12:34:03 INFO SparkContext: Running Spark version 3.5.3
[2025-07-14T12:34:03.854+0200] {subprocess.py:93} INFO - 25/07/14 12:34:03 INFO SparkContext: OS info Linux, 6.1.0-35-amd64, amd64
[2025-07-14T12:34:03.854+0200] {subprocess.py:93} INFO - 25/07/14 12:34:03 INFO SparkContext: Java version 17.0.14
[2025-07-14T12:34:03.868+0200] {subprocess.py:93} INFO - 25/07/14 12:34:03 INFO ResourceUtils: ==============================================================
[2025-07-14T12:34:03.869+0200] {subprocess.py:93} INFO - 25/07/14 12:34:03 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-07-14T12:34:03.869+0200] {subprocess.py:93} INFO - 25/07/14 12:34:03 INFO ResourceUtils: ==============================================================
[2025-07-14T12:34:03.869+0200] {subprocess.py:93} INFO - 25/07/14 12:34:03 INFO SparkContext: Submitted application: train_spark_mllib_model.py
[2025-07-14T12:34:03.887+0200] {subprocess.py:93} INFO - 25/07/14 12:34:03 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-07-14T12:34:03.891+0200] {subprocess.py:93} INFO - 25/07/14 12:34:03 INFO ResourceProfile: Limiting resource is cpu
[2025-07-14T12:34:03.891+0200] {subprocess.py:93} INFO - 25/07/14 12:34:03 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-07-14T12:34:03.957+0200] {subprocess.py:93} INFO - 25/07/14 12:34:03 INFO SecurityManager: Changing view acls to: monica.fernandez
[2025-07-14T12:34:03.957+0200] {subprocess.py:93} INFO - 25/07/14 12:34:03 INFO SecurityManager: Changing modify acls to: monica.fernandez
[2025-07-14T12:34:03.958+0200] {subprocess.py:93} INFO - 25/07/14 12:34:03 INFO SecurityManager: Changing view acls groups to:
[2025-07-14T12:34:03.958+0200] {subprocess.py:93} INFO - 25/07/14 12:34:03 INFO SecurityManager: Changing modify acls groups to:
[2025-07-14T12:34:03.958+0200] {subprocess.py:93} INFO - 25/07/14 12:34:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: monica.fernandez; groups with view permissions: EMPTY; users with modify permissions: monica.fernandez; groups with modify permissions: EMPTY
[2025-07-14T12:34:04.153+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Successfully started service 'sparkDriver' on port 44139.
[2025-07-14T12:34:04.187+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkEnv: Registering MapOutputTracker
[2025-07-14T12:34:04.215+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkEnv: Registering BlockManagerMaster
[2025-07-14T12:34:04.233+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-07-14T12:34:04.233+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-07-14T12:34:04.236+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-07-14T12:34:04.262+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-29ddd1d1-b3a4-43fb-8876-eae306dbdfb4
[2025-07-14T12:34:04.274+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-07-14T12:34:04.283+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-07-14T12:34:04.406+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-07-14T12:34:04.452+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[2025-07-14T12:34:04.458+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Successfully started service 'SparkUI' on port 4041.
[2025-07-14T12:34:04.482+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar at spark://138.4.31.89:44139/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.482+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-posix-3.1.15.jar at spark://138.4.31.89:44139/jars/com.github.jnr_jnr-posix-3.1.15.jar with timestamp 1752489243847
[2025-07-14T12:34:04.483+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar at spark://138.4.31.89:44139/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.483+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar at spark://138.4.31.89:44139/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.484+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar at spark://138.4.31.89:44139/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.484+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar at spark://138.4.31.89:44139/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.484+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar at spark://138.4.31.89:44139/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1752489243847
[2025-07-14T12:34:04.484+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar at spark://138.4.31.89:44139/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1752489243847
[2025-07-14T12:34:04.485+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar at spark://138.4.31.89:44139/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1752489243847
[2025-07-14T12:34:04.485+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar at spark://138.4.31.89:44139/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.485+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar at spark://138.4.31.89:44139/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1752489243847
[2025-07-14T12:34:04.486+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.typesafe_config-1.4.1.jar at spark://138.4.31.89:44139/jars/com.typesafe_config-1.4.1.jar with timestamp 1752489243847
[2025-07-14T12:34:04.486+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.slf4j_slf4j-api-1.7.26.jar at spark://138.4.31.89:44139/jars/org.slf4j_slf4j-api-1.7.26.jar with timestamp 1752489243847
[2025-07-14T12:34:04.486+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar at spark://138.4.31.89:44139/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1752489243847
[2025-07-14T12:34:04.487+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar at spark://138.4.31.89:44139/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1752489243847
[2025-07-14T12:34:04.487+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar at spark://138.4.31.89:44139/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1752489243847
[2025-07-14T12:34:04.487+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar at spark://138.4.31.89:44139/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1752489243847
[2025-07-14T12:34:04.488+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar at spark://138.4.31.89:44139/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1752489243847
[2025-07-14T12:34:04.488+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar at spark://138.4.31.89:44139/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.488+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar at spark://138.4.31.89:44139/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.488+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-ffi-2.2.11.jar at spark://138.4.31.89:44139/jars/com.github.jnr_jnr-ffi-2.2.11.jar with timestamp 1752489243847
[2025-07-14T12:34:04.489+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-constants-0.10.3.jar at spark://138.4.31.89:44139/jars/com.github.jnr_jnr-constants-0.10.3.jar with timestamp 1752489243847
[2025-07-14T12:34:04.489+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jffi-1.3.9-native.jar at spark://138.4.31.89:44139/jars/com.github.jnr_jffi-1.3.9-native.jar with timestamp 1752489243847
[2025-07-14T12:34:04.489+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-9.2.jar at spark://138.4.31.89:44139/jars/org.ow2.asm_asm-9.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.489+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-commons-9.2.jar at spark://138.4.31.89:44139/jars/org.ow2.asm_asm-commons-9.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.490+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-analysis-9.2.jar at spark://138.4.31.89:44139/jars/org.ow2.asm_asm-analysis-9.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.490+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-tree-9.2.jar at spark://138.4.31.89:44139/jars/org.ow2.asm_asm-tree-9.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.490+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-util-9.2.jar at spark://138.4.31.89:44139/jars/org.ow2.asm_asm-util-9.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.491+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-a64asm-1.0.0.jar at spark://138.4.31.89:44139/jars/com.github.jnr_jnr-a64asm-1.0.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.491+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-x86asm-1.0.2.jar at spark://138.4.31.89:44139/jars/com.github.jnr_jnr-x86asm-1.0.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.492+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar at file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.493+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar
[2025-07-14T12:34:04.518+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-posix-3.1.15.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-posix-3.1.15.jar with timestamp 1752489243847
[2025-07-14T12:34:04.518+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-posix-3.1.15.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jnr-posix-3.1.15.jar
[2025-07-14T12:34:04.522+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar at file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.522+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar
[2025-07-14T12:34:04.533+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar at file:///home/monica.fernandez/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.533+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar
[2025-07-14T12:34:04.538+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar at file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.538+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.oss_java-driver-core-shaded-4.13.0.jar
[2025-07-14T12:34:04.601+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar at file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.601+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar
[2025-07-14T12:34:04.605+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar at file:///home/monica.fernandez/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1752489243847
[2025-07-14T12:34:04.605+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.apache.commons_commons-lang3-3.10.jar
[2025-07-14T12:34:04.614+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar at file:///home/monica.fernandez/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1752489243847
[2025-07-14T12:34:04.614+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.thoughtworks.paranamer_paranamer-2.8.jar
[2025-07-14T12:34:04.618+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar at file:///home/monica.fernandez/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1752489243847
[2025-07-14T12:34:04.618+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.scala-lang_scala-reflect-2.12.11.jar
[2025-07-14T12:34:04.655+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar at file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.655+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.oss_native-protocol-1.5.0.jar
[2025-07-14T12:34:04.663+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar at file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1752489243847
[2025-07-14T12:34:04.663+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar
[2025-07-14T12:34:04.692+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.typesafe_config-1.4.1.jar at file:///home/monica.fernandez/.ivy2/jars/com.typesafe_config-1.4.1.jar with timestamp 1752489243847
[2025-07-14T12:34:04.692+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.typesafe_config-1.4.1.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.typesafe_config-1.4.1.jar
[2025-07-14T12:34:04.699+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.slf4j_slf4j-api-1.7.26.jar at file:///home/monica.fernandez/.ivy2/jars/org.slf4j_slf4j-api-1.7.26.jar with timestamp 1752489243847
[2025-07-14T12:34:04.699+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.slf4j_slf4j-api-1.7.26.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.slf4j_slf4j-api-1.7.26.jar
[2025-07-14T12:34:04.704+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar at file:///home/monica.fernandez/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1752489243847
[2025-07-14T12:34:04.704+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/io.dropwizard.metrics_metrics-core-4.1.18.jar
[2025-07-14T12:34:04.710+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar at file:///home/monica.fernandez/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1752489243847
[2025-07-14T12:34:04.710+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.hdrhistogram_HdrHistogram-2.1.12.jar
[2025-07-14T12:34:04.716+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar at file:///home/monica.fernandez/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1752489243847
[2025-07-14T12:34:04.716+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.reactivestreams_reactive-streams-1.0.3.jar
[2025-07-14T12:34:04.719+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1752489243847
[2025-07-14T12:34:04.719+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar
[2025-07-14T12:34:04.723+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1752489243847
[2025-07-14T12:34:04.723+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.spotbugs_spotbugs-annotations-3.1.12.jar
[2025-07-14T12:34:04.727+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar at file:///home/monica.fernandez/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.727+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.google.code.findbugs_jsr305-3.0.2.jar
[2025-07-14T12:34:04.730+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar at file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.731+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.oss_java-driver-query-builder-4.13.0.jar
[2025-07-14T12:34:04.737+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-ffi-2.2.11.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-ffi-2.2.11.jar with timestamp 1752489243847
[2025-07-14T12:34:04.737+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-ffi-2.2.11.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jnr-ffi-2.2.11.jar
[2025-07-14T12:34:04.745+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-constants-0.10.3.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-constants-0.10.3.jar with timestamp 1752489243847
[2025-07-14T12:34:04.745+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-constants-0.10.3.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jnr-constants-0.10.3.jar
[2025-07-14T12:34:04.763+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jffi-1.3.9-native.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jffi-1.3.9-native.jar with timestamp 1752489243847
[2025-07-14T12:34:04.763+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.jnr_jffi-1.3.9-native.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jffi-1.3.9-native.jar
[2025-07-14T12:34:04.773+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-9.2.jar at file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-9.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.773+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-9.2.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.ow2.asm_asm-9.2.jar
[2025-07-14T12:34:04.776+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-commons-9.2.jar at file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-commons-9.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.776+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-commons-9.2.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.ow2.asm_asm-commons-9.2.jar
[2025-07-14T12:34:04.778+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-analysis-9.2.jar at file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-analysis-9.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.778+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-analysis-9.2.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.ow2.asm_asm-analysis-9.2.jar
[2025-07-14T12:34:04.780+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-tree-9.2.jar at file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-tree-9.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.780+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-tree-9.2.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.ow2.asm_asm-tree-9.2.jar
[2025-07-14T12:34:04.782+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-util-9.2.jar at file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-util-9.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.782+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-util-9.2.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.ow2.asm_asm-util-9.2.jar
[2025-07-14T12:34:04.785+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-a64asm-1.0.0.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-a64asm-1.0.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.785+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-a64asm-1.0.0.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jnr-a64asm-1.0.0.jar
[2025-07-14T12:34:04.787+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-x86asm-1.0.2.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-x86asm-1.0.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.787+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-x86asm-1.0.2.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jnr-x86asm-1.0.2.jar
[2025-07-14T12:34:04.844+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Starting executor ID driver on host 138.4.31.89
[2025-07-14T12:34:04.844+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: OS info Linux, 6.1.0-35-amd64, amd64
[2025-07-14T12:34:04.844+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Java version 17.0.14
[2025-07-14T12:34:04.849+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-07-14T12:34:04.849+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1f431f29 for default.
[2025-07-14T12:34:04.855+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.872+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar
[2025-07-14T12:34:04.873+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.873+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.google.code.findbugs_jsr305-3.0.2.jar
[2025-07-14T12:34:04.875+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.typesafe_config-1.4.1.jar with timestamp 1752489243847
[2025-07-14T12:34:04.875+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.typesafe_config-1.4.1.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.typesafe_config-1.4.1.jar
[2025-07-14T12:34:04.877+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1752489243847
[2025-07-14T12:34:04.877+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.thoughtworks.paranamer_paranamer-2.8.jar
[2025-07-14T12:34:04.878+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1752489243847
[2025-07-14T12:34:04.879+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.hdrhistogram_HdrHistogram-2.1.12.jar
[2025-07-14T12:34:04.880+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-a64asm-1.0.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.881+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-a64asm-1.0.0.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jnr-a64asm-1.0.0.jar
[2025-07-14T12:34:04.882+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jffi-1.3.9-native.jar with timestamp 1752489243847
[2025-07-14T12:34:04.883+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.jnr_jffi-1.3.9-native.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jffi-1.3.9-native.jar
[2025-07-14T12:34:04.884+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1752489243847
[2025-07-14T12:34:04.884+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.spotbugs_spotbugs-annotations-3.1.12.jar
[2025-07-14T12:34:04.885+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1752489243847
[2025-07-14T12:34:04.886+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.apache.commons_commons-lang3-3.10.jar
[2025-07-14T12:34:04.887+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1752489243847
[2025-07-14T12:34:04.888+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/io.dropwizard.metrics_metrics-core-4.1.18.jar
[2025-07-14T12:34:04.889+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1752489243847
[2025-07-14T12:34:04.891+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar
[2025-07-14T12:34:04.892+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-util-9.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.893+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-util-9.2.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.ow2.asm_asm-util-9.2.jar
[2025-07-14T12:34:04.894+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-9.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.894+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-9.2.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.ow2.asm_asm-9.2.jar
[2025-07-14T12:34:04.895+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.899+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.oss_java-driver-core-shaded-4.13.0.jar
[2025-07-14T12:34:04.901+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.901+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.oss_native-protocol-1.5.0.jar
[2025-07-14T12:34:04.902+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-tree-9.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.903+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-tree-9.2.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.ow2.asm_asm-tree-9.2.jar
[2025-07-14T12:34:04.905+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.slf4j_slf4j-api-1.7.26.jar with timestamp 1752489243847
[2025-07-14T12:34:04.905+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.slf4j_slf4j-api-1.7.26.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.slf4j_slf4j-api-1.7.26.jar
[2025-07-14T12:34:04.906+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-ffi-2.2.11.jar with timestamp 1752489243847
[2025-07-14T12:34:04.907+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-ffi-2.2.11.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jnr-ffi-2.2.11.jar
[2025-07-14T12:34:04.908+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.909+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar
[2025-07-14T12:34:04.910+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.911+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar
[2025-07-14T12:34:04.912+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.913+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.oss_java-driver-query-builder-4.13.0.jar
[2025-07-14T12:34:04.914+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1752489243847
[2025-07-14T12:34:04.914+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar
[2025-07-14T12:34:04.915+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-analysis-9.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.916+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-analysis-9.2.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.ow2.asm_asm-analysis-9.2.jar
[2025-07-14T12:34:04.917+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1752489243847
[2025-07-14T12:34:04.917+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.reactivestreams_reactive-streams-1.0.3.jar
[2025-07-14T12:34:04.918+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-x86asm-1.0.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.919+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-x86asm-1.0.2.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jnr-x86asm-1.0.2.jar
[2025-07-14T12:34:04.920+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.921+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar
[2025-07-14T12:34:04.922+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-commons-9.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.923+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-commons-9.2.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.ow2.asm_asm-commons-9.2.jar
[2025-07-14T12:34:04.924+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1752489243847
[2025-07-14T12:34:04.926+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.scala-lang_scala-reflect-2.12.11.jar
[2025-07-14T12:34:04.928+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-posix-3.1.15.jar with timestamp 1752489243847
[2025-07-14T12:34:04.928+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-posix-3.1.15.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jnr-posix-3.1.15.jar
[2025-07-14T12:34:04.929+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-constants-0.10.3.jar with timestamp 1752489243847
[2025-07-14T12:34:04.930+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-constants-0.10.3.jar has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jnr-constants-0.10.3.jar
[2025-07-14T12:34:04.932+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching spark://138.4.31.89:44139/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.958+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO TransportClientFactory: Successfully created connection to /138.4.31.89:44139 after 16 ms (0 ms spent in bootstraps)
[2025-07-14T12:34:04.961+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Fetching spark://138.4.31.89:44139/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp11673021590698389098.tmp
[2025-07-14T12:34:04.973+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp11673021590698389098.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar
[2025-07-14T12:34:04.975+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar to class loader default
[2025-07-14T12:34:04.975+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching spark://138.4.31.89:44139/jars/com.github.jnr_jnr-x86asm-1.0.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.975+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Fetching spark://138.4.31.89:44139/jars/com.github.jnr_jnr-x86asm-1.0.2.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp15409648168140962035.tmp
[2025-07-14T12:34:04.976+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp15409648168140962035.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jnr-x86asm-1.0.2.jar
[2025-07-14T12:34:04.978+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jnr-x86asm-1.0.2.jar to class loader default
[2025-07-14T12:34:04.978+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching spark://138.4.31.89:44139/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1752489243847
[2025-07-14T12:34:04.978+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Fetching spark://138.4.31.89:44139/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp12215243681797914737.tmp
[2025-07-14T12:34:04.979+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp12215243681797914737.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.hdrhistogram_HdrHistogram-2.1.12.jar
[2025-07-14T12:34:04.980+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.hdrhistogram_HdrHistogram-2.1.12.jar to class loader default
[2025-07-14T12:34:04.980+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching spark://138.4.31.89:44139/jars/com.github.jnr_jffi-1.3.9-native.jar with timestamp 1752489243847
[2025-07-14T12:34:04.980+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Fetching spark://138.4.31.89:44139/jars/com.github.jnr_jffi-1.3.9-native.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp9659355150772792589.tmp
[2025-07-14T12:34:04.982+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp9659355150772792589.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jffi-1.3.9-native.jar
[2025-07-14T12:34:04.983+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jffi-1.3.9-native.jar to class loader default
[2025-07-14T12:34:04.984+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching spark://138.4.31.89:44139/jars/org.ow2.asm_asm-9.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.984+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Fetching spark://138.4.31.89:44139/jars/org.ow2.asm_asm-9.2.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp9246086568541992276.tmp
[2025-07-14T12:34:04.984+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp9246086568541992276.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.ow2.asm_asm-9.2.jar
[2025-07-14T12:34:04.986+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.ow2.asm_asm-9.2.jar to class loader default
[2025-07-14T12:34:04.986+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching spark://138.4.31.89:44139/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1752489243847
[2025-07-14T12:34:04.986+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Fetching spark://138.4.31.89:44139/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp6752918783966838082.tmp
[2025-07-14T12:34:04.986+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp6752918783966838082.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/io.dropwizard.metrics_metrics-core-4.1.18.jar
[2025-07-14T12:34:04.988+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/io.dropwizard.metrics_metrics-core-4.1.18.jar to class loader default
[2025-07-14T12:34:04.988+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching spark://138.4.31.89:44139/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1752489243847
[2025-07-14T12:34:04.988+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Fetching spark://138.4.31.89:44139/jars/com.google.code.findbugs_jsr305-3.0.2.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp17207115966065789500.tmp
[2025-07-14T12:34:04.988+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp17207115966065789500.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.google.code.findbugs_jsr305-3.0.2.jar
[2025-07-14T12:34:04.990+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.google.code.findbugs_jsr305-3.0.2.jar to class loader default
[2025-07-14T12:34:04.990+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching spark://138.4.31.89:44139/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1752489243847
[2025-07-14T12:34:04.990+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Fetching spark://138.4.31.89:44139/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp14584197275351080560.tmp
[2025-07-14T12:34:04.991+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp14584197275351080560.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar
[2025-07-14T12:34:04.992+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar to class loader default
[2025-07-14T12:34:04.992+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching spark://138.4.31.89:44139/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1752489243847
[2025-07-14T12:34:04.992+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Fetching spark://138.4.31.89:44139/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp16935131648926251243.tmp
[2025-07-14T12:34:04.993+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp16935131648926251243.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.oss_java-driver-query-builder-4.13.0.jar
[2025-07-14T12:34:04.994+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.oss_java-driver-query-builder-4.13.0.jar to class loader default
[2025-07-14T12:34:04.994+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching spark://138.4.31.89:44139/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1752489243847
[2025-07-14T12:34:04.995+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Fetching spark://138.4.31.89:44139/jars/com.thoughtworks.paranamer_paranamer-2.8.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp3627696224774253143.tmp
[2025-07-14T12:34:04.995+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp3627696224774253143.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.thoughtworks.paranamer_paranamer-2.8.jar
[2025-07-14T12:34:04.996+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.thoughtworks.paranamer_paranamer-2.8.jar to class loader default
[2025-07-14T12:34:04.996+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching spark://138.4.31.89:44139/jars/com.github.jnr_jnr-ffi-2.2.11.jar with timestamp 1752489243847
[2025-07-14T12:34:04.996+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: Fetching spark://138.4.31.89:44139/jars/com.github.jnr_jnr-ffi-2.2.11.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp6359879602061789093.tmp
[2025-07-14T12:34:04.998+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp6359879602061789093.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jnr-ffi-2.2.11.jar
[2025-07-14T12:34:04.999+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jnr-ffi-2.2.11.jar to class loader default
[2025-07-14T12:34:04.999+0200] {subprocess.py:93} INFO - 25/07/14 12:34:04 INFO Executor: Fetching spark://138.4.31.89:44139/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1752489243847
[2025-07-14T12:34:05.000+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: Fetching spark://138.4.31.89:44139/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp13591827925744081939.tmp
[2025-07-14T12:34:05.003+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp13591827925744081939.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar
[2025-07-14T12:34:05.004+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar to class loader default
[2025-07-14T12:34:05.004+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Fetching spark://138.4.31.89:44139/jars/org.ow2.asm_asm-tree-9.2.jar with timestamp 1752489243847
[2025-07-14T12:34:05.005+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: Fetching spark://138.4.31.89:44139/jars/org.ow2.asm_asm-tree-9.2.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp2987909769110313906.tmp
[2025-07-14T12:34:05.005+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp2987909769110313906.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.ow2.asm_asm-tree-9.2.jar
[2025-07-14T12:34:05.007+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.ow2.asm_asm-tree-9.2.jar to class loader default
[2025-07-14T12:34:05.007+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Fetching spark://138.4.31.89:44139/jars/com.github.jnr_jnr-posix-3.1.15.jar with timestamp 1752489243847
[2025-07-14T12:34:05.007+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: Fetching spark://138.4.31.89:44139/jars/com.github.jnr_jnr-posix-3.1.15.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp4494608681100561442.tmp
[2025-07-14T12:34:05.008+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp4494608681100561442.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jnr-posix-3.1.15.jar
[2025-07-14T12:34:05.009+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jnr-posix-3.1.15.jar to class loader default
[2025-07-14T12:34:05.009+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Fetching spark://138.4.31.89:44139/jars/com.github.jnr_jnr-constants-0.10.3.jar with timestamp 1752489243847
[2025-07-14T12:34:05.009+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: Fetching spark://138.4.31.89:44139/jars/com.github.jnr_jnr-constants-0.10.3.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp6423579343192592485.tmp
[2025-07-14T12:34:05.012+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp6423579343192592485.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jnr-constants-0.10.3.jar
[2025-07-14T12:34:05.013+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jnr-constants-0.10.3.jar to class loader default
[2025-07-14T12:34:05.013+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Fetching spark://138.4.31.89:44139/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1752489243847
[2025-07-14T12:34:05.013+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: Fetching spark://138.4.31.89:44139/jars/com.datastax.oss_native-protocol-1.5.0.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp145849627720304843.tmp
[2025-07-14T12:34:05.014+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp145849627720304843.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.oss_native-protocol-1.5.0.jar
[2025-07-14T12:34:05.015+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.oss_native-protocol-1.5.0.jar to class loader default
[2025-07-14T12:34:05.015+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Fetching spark://138.4.31.89:44139/jars/org.ow2.asm_asm-util-9.2.jar with timestamp 1752489243847
[2025-07-14T12:34:05.015+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: Fetching spark://138.4.31.89:44139/jars/org.ow2.asm_asm-util-9.2.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp11432249913117831062.tmp
[2025-07-14T12:34:05.016+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp11432249913117831062.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.ow2.asm_asm-util-9.2.jar
[2025-07-14T12:34:05.017+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.ow2.asm_asm-util-9.2.jar to class loader default
[2025-07-14T12:34:05.017+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Fetching spark://138.4.31.89:44139/jars/com.github.jnr_jnr-a64asm-1.0.0.jar with timestamp 1752489243847
[2025-07-14T12:34:05.017+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: Fetching spark://138.4.31.89:44139/jars/com.github.jnr_jnr-a64asm-1.0.0.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp394934542212933695.tmp
[2025-07-14T12:34:05.018+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp394934542212933695.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jnr-a64asm-1.0.0.jar
[2025-07-14T12:34:05.019+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.jnr_jnr-a64asm-1.0.0.jar to class loader default
[2025-07-14T12:34:05.019+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Fetching spark://138.4.31.89:44139/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1752489243847
[2025-07-14T12:34:05.019+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: Fetching spark://138.4.31.89:44139/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp6174051967264759982.tmp
[2025-07-14T12:34:05.020+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp6174051967264759982.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar
[2025-07-14T12:34:05.021+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar to class loader default
[2025-07-14T12:34:05.021+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Fetching spark://138.4.31.89:44139/jars/com.typesafe_config-1.4.1.jar with timestamp 1752489243847
[2025-07-14T12:34:05.021+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: Fetching spark://138.4.31.89:44139/jars/com.typesafe_config-1.4.1.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp8993208876578349471.tmp
[2025-07-14T12:34:05.022+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp8993208876578349471.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.typesafe_config-1.4.1.jar
[2025-07-14T12:34:05.023+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.typesafe_config-1.4.1.jar to class loader default
[2025-07-14T12:34:05.023+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Fetching spark://138.4.31.89:44139/jars/org.ow2.asm_asm-commons-9.2.jar with timestamp 1752489243847
[2025-07-14T12:34:05.023+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: Fetching spark://138.4.31.89:44139/jars/org.ow2.asm_asm-commons-9.2.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp1036737906387955492.tmp
[2025-07-14T12:34:05.024+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp1036737906387955492.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.ow2.asm_asm-commons-9.2.jar
[2025-07-14T12:34:05.025+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.ow2.asm_asm-commons-9.2.jar to class loader default
[2025-07-14T12:34:05.025+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Fetching spark://138.4.31.89:44139/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1752489243847
[2025-07-14T12:34:05.025+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: Fetching spark://138.4.31.89:44139/jars/org.apache.commons_commons-lang3-3.10.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp17394184541911066845.tmp
[2025-07-14T12:34:05.026+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp17394184541911066845.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.apache.commons_commons-lang3-3.10.jar
[2025-07-14T12:34:05.028+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.apache.commons_commons-lang3-3.10.jar to class loader default
[2025-07-14T12:34:05.028+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Fetching spark://138.4.31.89:44139/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1752489243847
[2025-07-14T12:34:05.028+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: Fetching spark://138.4.31.89:44139/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp1700065599994330135.tmp
[2025-07-14T12:34:05.043+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp1700065599994330135.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.oss_java-driver-core-shaded-4.13.0.jar
[2025-07-14T12:34:05.045+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.oss_java-driver-core-shaded-4.13.0.jar to class loader default
[2025-07-14T12:34:05.045+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Fetching spark://138.4.31.89:44139/jars/org.ow2.asm_asm-analysis-9.2.jar with timestamp 1752489243847
[2025-07-14T12:34:05.046+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: Fetching spark://138.4.31.89:44139/jars/org.ow2.asm_asm-analysis-9.2.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp14823723032550961832.tmp
[2025-07-14T12:34:05.046+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp14823723032550961832.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.ow2.asm_asm-analysis-9.2.jar
[2025-07-14T12:34:05.048+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.ow2.asm_asm-analysis-9.2.jar to class loader default
[2025-07-14T12:34:05.048+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Fetching spark://138.4.31.89:44139/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1752489243847
[2025-07-14T12:34:05.048+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: Fetching spark://138.4.31.89:44139/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp14301239693423487798.tmp
[2025-07-14T12:34:05.050+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp14301239693423487798.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar
[2025-07-14T12:34:05.052+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar to class loader default
[2025-07-14T12:34:05.052+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Fetching spark://138.4.31.89:44139/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1752489243847
[2025-07-14T12:34:05.052+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: Fetching spark://138.4.31.89:44139/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp13709370009163138645.tmp
[2025-07-14T12:34:05.053+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp13709370009163138645.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.spotbugs_spotbugs-annotations-3.1.12.jar
[2025-07-14T12:34:05.055+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.github.spotbugs_spotbugs-annotations-3.1.12.jar to class loader default
[2025-07-14T12:34:05.055+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Fetching spark://138.4.31.89:44139/jars/org.slf4j_slf4j-api-1.7.26.jar with timestamp 1752489243847
[2025-07-14T12:34:05.055+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: Fetching spark://138.4.31.89:44139/jars/org.slf4j_slf4j-api-1.7.26.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp2201796974564808320.tmp
[2025-07-14T12:34:05.056+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp2201796974564808320.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.slf4j_slf4j-api-1.7.26.jar
[2025-07-14T12:34:05.058+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.slf4j_slf4j-api-1.7.26.jar to class loader default
[2025-07-14T12:34:05.058+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Fetching spark://138.4.31.89:44139/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1752489243847
[2025-07-14T12:34:05.058+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: Fetching spark://138.4.31.89:44139/jars/org.reactivestreams_reactive-streams-1.0.3.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp1703814788938099436.tmp
[2025-07-14T12:34:05.059+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp1703814788938099436.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.reactivestreams_reactive-streams-1.0.3.jar
[2025-07-14T12:34:05.061+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.reactivestreams_reactive-streams-1.0.3.jar to class loader default
[2025-07-14T12:34:05.061+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Fetching spark://138.4.31.89:44139/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1752489243847
[2025-07-14T12:34:05.061+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: Fetching spark://138.4.31.89:44139/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp4172049783394442750.tmp
[2025-07-14T12:34:05.067+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp4172049783394442750.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar
[2025-07-14T12:34:05.068+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar to class loader default
[2025-07-14T12:34:05.069+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Fetching spark://138.4.31.89:44139/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1752489243847
[2025-07-14T12:34:05.069+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: Fetching spark://138.4.31.89:44139/jars/org.scala-lang_scala-reflect-2.12.11.jar to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp12362123404817657959.tmp
[2025-07-14T12:34:05.074+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/fetchFileTemp12362123404817657959.tmp has been previously copied to /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.scala-lang_scala-reflect-2.12.11.jar
[2025-07-14T12:34:05.076+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Executor: Adding file:/tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/userFiles-b059ea2c-d1c4-468a-9326-dc1a716b8f9f/org.scala-lang_scala-reflect-2.12.11.jar to class loader default
[2025-07-14T12:34:05.083+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45589.
[2025-07-14T12:34:05.083+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO NettyBlockTransferService: Server created on 138.4.31.89:45589
[2025-07-14T12:34:05.084+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-07-14T12:34:05.088+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 138.4.31.89, 45589, None)
[2025-07-14T12:34:05.090+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO BlockManagerMasterEndpoint: Registering block manager 138.4.31.89:45589 with 434.4 MiB RAM, BlockManagerId(driver, 138.4.31.89, 45589, None)
[2025-07-14T12:34:05.091+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 138.4.31.89, 45589, None)
[2025-07-14T12:34:05.091+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 138.4.31.89, 45589, None)
[2025-07-14T12:34:05.426+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-07-14T12:34:05.427+0200] {subprocess.py:93} INFO - 25/07/14 12:34:05 INFO SharedState: Warehouse path is 'file:/tmp/airflowtmpafoxw00z/spark-warehouse'.
[2025-07-14T12:34:06.118+0200] {subprocess.py:93} INFO - 25/07/14 12:34:06 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.
[2025-07-14T12:34:07.557+0200] {subprocess.py:93} INFO - MLflow Run ID: 3a76f10e405e429ab683744f070fd452
[2025-07-14T12:34:07.558+0200] {subprocess.py:93} INFO - MLflow Tracking URI: file:///home/monica.fernandez/practica_creativa/mlruns
[2025-07-14T12:34:07.750+0200] {subprocess.py:93} INFO - 25/07/14 12:34:07 INFO InMemoryFileIndex: It took 27 ms to list leaf files for 1 paths.
[2025-07-14T12:34:08.872+0200] {subprocess.py:93} INFO - 25/07/14 12:34:08 INFO DefaultMavenCoordinates: DataStax Java driver for Apache Cassandra(R) (com.datastax.oss:java-driver-core-shaded) version 4.13.0
[2025-07-14T12:34:08.950+0200] {subprocess.py:93} INFO - 25/07/14 12:34:08 INFO Clock: Could not access native clock (see debug logs for details), falling back to Java system clock
[2025-07-14T12:34:09.230+0200] {subprocess.py:93} INFO - 25/07/14 12:34:09 INFO CassandraConnector: Connected to Cassandra cluster.
[2025-07-14T12:34:09.272+0200] {subprocess.py:93} INFO - Columnas tras join con Cassandra: ['origin', 'dest', 'ArrDelay', 'CRSArrTime', 'CRSDepTime', 'Carrier', 'DayOfMonth', 'DayOfWeek', 'DayOfYear', 'DepDelay', 'FlightDate', 'FlightNum', 'Route', 'distance']
[2025-07-14T12:34:09.529+0200] {subprocess.py:93} INFO - 25/07/14 12:34:09 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:09.529+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-14T12:34:09.529+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-14T12:34:09.529+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-14T12:34:09.529+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:09.567+0200] {subprocess.py:93} INFO - 25/07/14 12:34:09 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:09.567+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-14T12:34:09.567+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:09.754+0200] {subprocess.py:93} INFO - 25/07/14 12:34:09 INFO FileSourceStrategy: Pushed Filters:
[2025-07-14T12:34:09.754+0200] {subprocess.py:93} INFO - 25/07/14 12:34:09 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-14T12:34:10.068+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO CodeGenerator: Code generated in 105.517304 ms
[2025-07-14T12:34:10.092+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 214.5 KiB, free 434.2 MiB)
[2025-07-14T12:34:10.125+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.0 KiB, free 434.2 MiB)
[2025-07-14T12:34:10.126+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 138.4.31.89:45589 (size: 39.0 KiB, free: 434.4 MiB)
[2025-07-14T12:34:10.128+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO SparkContext: Created broadcast 0 from showString at NativeMethodAccessorImpl.java:0
[2025-07-14T12:34:10.137+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-14T12:34:10.214+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: Registering RDD 3 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2025-07-14T12:34:10.216+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: Got map stage job 0 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-07-14T12:34:10.216+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-14T12:34:10.217+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:10.217+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:10.218+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-14T12:34:10.219+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO CodeGenerator: Code generated in 6.511651 ms
[2025-07-14T12:34:10.268+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 17.1 KiB, free 434.1 MiB)
[2025-07-14T12:34:10.268+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 434.1 MiB)
[2025-07-14T12:34:10.269+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 138.4.31.89:45589 (size: 8.3 KiB, free: 434.4 MiB)
[2025-07-14T12:34:10.269+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:10.277+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-14T12:34:10.278+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks resource profile 0
[2025-07-14T12:34:10.286+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: Registering RDD 7 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2025-07-14T12:34:10.286+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: Got map stage job 1 (showString at NativeMethodAccessorImpl.java:0) with 13 output partitions
[2025-07-14T12:34:10.286+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-14T12:34:10.287+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:10.287+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:10.287+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-14T12:34:10.296+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:10.298+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (138.4.31.89, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:10.303+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
[2025-07-14T12:34:10.304+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2025-07-14T12:34:10.307+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 18.7 KiB, free 434.1 MiB)
[2025-07-14T12:34:10.308+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 434.1 MiB)
[2025-07-14T12:34:10.309+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 138.4.31.89:45589 (size: 9.2 KiB, free: 434.3 MiB)
[2025-07-14T12:34:10.309+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:10.309+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-14T12:34:10.309+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSchedulerImpl: Adding task set 1.0 with 13 tasks resource profile 0
[2025-07-14T12:34:10.315+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2) (138.4.31.89, executor driver, partition 0, ANY, 16839 bytes)
[2025-07-14T12:34:10.316+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3) (138.4.31.89, executor driver, partition 1, ANY, 16719 bytes)
[2025-07-14T12:34:10.317+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
[2025-07-14T12:34:10.317+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
[2025-07-14T12:34:10.399+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO CodeGenerator: Code generated in 48.6378 ms
[2025-07-14T12:34:10.399+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO CodeGenerator: Code generated in 49.024215 ms
[2025-07-14T12:34:10.419+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO CodeGenerator: Code generated in 10.701345 ms
[2025-07-14T12:34:10.419+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO CodeGenerator: Code generated in 10.791885 ms
[2025-07-14T12:34:10.423+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-14T12:34:10.423+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-14T12:34:10.429+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO CodeGenerator: Code generated in 3.958144 ms
[2025-07-14T12:34:10.461+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO CodecPool: Got brand-new decompressor [.bz2]
[2025-07-14T12:34:10.461+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO CodecPool: Got brand-new decompressor [.bz2]
[2025-07-14T12:34:10.550+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO CodeGenerator: Code generated in 10.80177 ms
[2025-07-14T12:34:10.605+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2074 bytes result sent to driver
[2025-07-14T12:34:10.605+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2074 bytes result sent to driver
[2025-07-14T12:34:10.616+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 4) (138.4.31.89, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-14T12:34:10.617+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Running task 2.0 in stage 1.0 (TID 4)
[2025-07-14T12:34:10.618+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 5) (138.4.31.89, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-14T12:34:10.618+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Running task 3.0 in stage 1.0 (TID 5)
[2025-07-14T12:34:10.620+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 328 ms on 138.4.31.89 (executor driver) (1/2)
[2025-07-14T12:34:10.620+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 323 ms on 138.4.31.89 (executor driver) (2/2)
[2025-07-14T12:34:10.621+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-07-14T12:34:10.626+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: ShuffleMapStage 0 (showString at NativeMethodAccessorImpl.java:0) finished in 0,399 s
[2025-07-14T12:34:10.626+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:10.627+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: running: Set(ShuffleMapStage 1)
[2025-07-14T12:34:10.627+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:10.627+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:10.633+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1988 bytes result sent to driver
[2025-07-14T12:34:10.634+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 6) (138.4.31.89, executor driver, partition 4, ANY, 16839 bytes)
[2025-07-14T12:34:10.635+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1988 bytes result sent to driver
[2025-07-14T12:34:10.635+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 324 ms on 138.4.31.89 (executor driver) (1/13)
[2025-07-14T12:34:10.635+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Running task 4.0 in stage 1.0 (TID 6)
[2025-07-14T12:34:10.636+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 7) (138.4.31.89, executor driver, partition 5, ANY, 16719 bytes)
[2025-07-14T12:34:10.636+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Running task 5.0 in stage 1.0 (TID 7)
[2025-07-14T12:34:10.637+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 320 ms on 138.4.31.89 (executor driver) (2/13)
[2025-07-14T12:34:10.653+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Finished task 3.0 in stage 1.0 (TID 5). 1945 bytes result sent to driver
[2025-07-14T12:34:10.654+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Finished task 2.0 in stage 1.0 (TID 4). 1988 bytes result sent to driver
[2025-07-14T12:34:10.656+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 8) (138.4.31.89, executor driver, partition 6, ANY, 16839 bytes)
[2025-07-14T12:34:10.656+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Running task 6.0 in stage 1.0 (TID 8)
[2025-07-14T12:34:10.656+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 9) (138.4.31.89, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-14T12:34:10.657+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 5) in 39 ms on 138.4.31.89 (executor driver) (3/13)
[2025-07-14T12:34:10.657+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Running task 7.0 in stage 1.0 (TID 9)
[2025-07-14T12:34:10.657+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 4) in 42 ms on 138.4.31.89 (executor driver) (4/13)
[2025-07-14T12:34:10.665+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Finished task 4.0 in stage 1.0 (TID 6). 1988 bytes result sent to driver
[2025-07-14T12:34:10.666+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Finished task 5.0 in stage 1.0 (TID 7). 1988 bytes result sent to driver
[2025-07-14T12:34:10.666+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 10) (138.4.31.89, executor driver, partition 8, ANY, 16719 bytes)
[2025-07-14T12:34:10.666+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 6) in 32 ms on 138.4.31.89 (executor driver) (5/13)
[2025-07-14T12:34:10.666+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Running task 8.0 in stage 1.0 (TID 10)
[2025-07-14T12:34:10.667+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 11) (138.4.31.89, executor driver, partition 9, ANY, 16715 bytes)
[2025-07-14T12:34:10.667+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 7) in 32 ms on 138.4.31.89 (executor driver) (6/13)
[2025-07-14T12:34:10.667+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Running task 9.0 in stage 1.0 (TID 11)
[2025-07-14T12:34:10.694+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Finished task 6.0 in stage 1.0 (TID 8). 1988 bytes result sent to driver
[2025-07-14T12:34:10.694+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 12) (138.4.31.89, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-14T12:34:10.695+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 8) in 41 ms on 138.4.31.89 (executor driver) (7/13)
[2025-07-14T12:34:10.695+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Running task 10.0 in stage 1.0 (TID 12)
[2025-07-14T12:34:10.700+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Finished task 9.0 in stage 1.0 (TID 11). 2031 bytes result sent to driver
[2025-07-14T12:34:10.701+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Starting task 11.0 in stage 1.0 (TID 13) (138.4.31.89, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-14T12:34:10.701+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Running task 11.0 in stage 1.0 (TID 13)
[2025-07-14T12:34:10.701+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 11) in 34 ms on 138.4.31.89 (executor driver) (8/13)
[2025-07-14T12:34:10.704+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Finished task 7.0 in stage 1.0 (TID 9). 2031 bytes result sent to driver
[2025-07-14T12:34:10.705+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Starting task 12.0 in stage 1.0 (TID 14) (138.4.31.89, executor driver, partition 12, ANY, 16719 bytes)
[2025-07-14T12:34:10.706+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 9) in 50 ms on 138.4.31.89 (executor driver) (9/13)
[2025-07-14T12:34:10.706+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Running task 12.0 in stage 1.0 (TID 14)
[2025-07-14T12:34:10.707+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Finished task 8.0 in stage 1.0 (TID 10). 1988 bytes result sent to driver
[2025-07-14T12:34:10.708+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 10) in 42 ms on 138.4.31.89 (executor driver) (10/13)
[2025-07-14T12:34:10.723+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Finished task 10.0 in stage 1.0 (TID 12). 1988 bytes result sent to driver
[2025-07-14T12:34:10.723+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Finished task 12.0 in stage 1.0 (TID 14). 1945 bytes result sent to driver
[2025-07-14T12:34:10.724+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 12) in 30 ms on 138.4.31.89 (executor driver) (11/13)
[2025-07-14T12:34:10.724+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Finished task 12.0 in stage 1.0 (TID 14) in 19 ms on 138.4.31.89 (executor driver) (12/13)
[2025-07-14T12:34:10.725+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Finished task 11.0 in stage 1.0 (TID 13). 1988 bytes result sent to driver
[2025-07-14T12:34:10.725+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Finished task 11.0 in stage 1.0 (TID 13) in 25 ms on 138.4.31.89 (executor driver) (13/13)
[2025-07-14T12:34:10.725+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2025-07-14T12:34:10.726+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 0,438 s
[2025-07-14T12:34:10.726+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:10.726+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:10.726+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:10.726+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:10.740+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO ShufflePartitionsUtil: For shuffle(0, 1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-14T12:34:10.768+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO CodeGenerator: Code generated in 13.420646 ms
[2025-07-14T12:34:10.776+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO CodeGenerator: Code generated in 5.248364 ms
[2025-07-14T12:34:10.794+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO CodeGenerator: Code generated in 4.295857 ms
[2025-07-14T12:34:10.810+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2025-07-14T12:34:10.812+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: Got job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-07-14T12:34:10.812+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: Final stage: ResultStage 4 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-14T12:34:10.812+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2, ShuffleMapStage 3)
[2025-07-14T12:34:10.812+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:10.813+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[14] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-14T12:34:10.821+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 54.2 KiB, free 434.0 MiB)
[2025-07-14T12:34:10.822+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 25.2 KiB, free 434.0 MiB)
[2025-07-14T12:34:10.822+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 138.4.31.89:45589 (size: 25.2 KiB, free: 434.3 MiB)
[2025-07-14T12:34:10.822+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:10.823+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:10.823+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
[2025-07-14T12:34:10.826+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 15) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 15110 bytes)
[2025-07-14T12:34:10.826+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Running task 0.0 in stage 4.0 (TID 15)
[2025-07-14T12:34:10.847+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO ShuffleBlockFetcherIterator: Getting 2 (512.0 B) non-empty blocks including 2 (512.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:10.848+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-14T12:34:10.854+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO CodeGenerator: Code generated in 4.959408 ms
[2025-07-14T12:34:10.862+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO CodeGenerator: Code generated in 4.663765 ms
[2025-07-14T12:34:10.869+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO CodeGenerator: Code generated in 3.678828 ms
[2025-07-14T12:34:10.875+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO ShuffleBlockFetcherIterator: Getting 13 (217.3 KiB) non-empty blocks including 13 (217.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:10.875+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-14T12:34:10.879+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO CodeGenerator: Code generated in 3.86736 ms
[2025-07-14T12:34:10.883+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO CodeGenerator: Code generated in 2.291261 ms
[2025-07-14T12:34:10.887+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO CodeGenerator: Code generated in 3.137663 ms
[2025-07-14T12:34:10.894+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO CodeGenerator: Code generated in 6.888669 ms
[2025-07-14T12:34:10.930+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO Executor: Finished task 0.0 in stage 4.0 (TID 15). 6329 bytes result sent to driver
[2025-07-14T12:34:10.932+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 15) in 107 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:10.932+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2025-07-14T12:34:10.932+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: ResultStage 4 (showString at NativeMethodAccessorImpl.java:0) finished in 0,114 s
[2025-07-14T12:34:10.933+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:10.933+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
[2025-07-14T12:34:10.934+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO DAGScheduler: Job 2 finished: showString at NativeMethodAccessorImpl.java:0, took 0,123892 s
[2025-07-14T12:34:10.958+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 138.4.31.89:45589 in memory (size: 8.3 KiB, free: 434.3 MiB)
[2025-07-14T12:34:10.958+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO CodeGenerator: Code generated in 3.411296 ms
[2025-07-14T12:34:10.960+0200] {subprocess.py:93} INFO - 25/07/14 12:34:10 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 138.4.31.89:45589 in memory (size: 9.2 KiB, free: 434.3 MiB)
[2025-07-14T12:34:10.963+0200] {subprocess.py:93} INFO - +------+----+--------+
[2025-07-14T12:34:10.963+0200] {subprocess.py:93} INFO - |origin|dest|distance|
[2025-07-14T12:34:10.963+0200] {subprocess.py:93} INFO - +------+----+--------+
[2025-07-14T12:34:10.963+0200] {subprocess.py:93} INFO - |   ABQ| DFW|   569.0|
[2025-07-14T12:34:10.963+0200] {subprocess.py:93} INFO - |   ABQ| DFW|   569.0|
[2025-07-14T12:34:10.963+0200] {subprocess.py:93} INFO - |   ABQ| DFW|   569.0|
[2025-07-14T12:34:10.963+0200] {subprocess.py:93} INFO - |   ATL| DFW|   731.0|
[2025-07-14T12:34:10.963+0200] {subprocess.py:93} INFO - |   ATL| DFW|   731.0|
[2025-07-14T12:34:10.963+0200] {subprocess.py:93} INFO - +------+----+--------+
[2025-07-14T12:34:10.963+0200] {subprocess.py:93} INFO - only showing top 5 rows
[2025-07-14T12:34:10.963+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:11.183+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO FileSystemOverwrite: Path /home/monica.fernandez/practica_creativa/models/arrival_bucketizer_2.0.bin already exists. It will be overwritten.
[2025-07-14T12:34:11.211+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
[2025-07-14T12:34:11.212+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-14T12:34:11.213+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:11.213+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:11.233+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-14T12:34:11.234+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Got job 3 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-14T12:34:11.234+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Final stage: ResultStage 5 (runJob at SparkHadoopWriter.scala:83)
[2025-07-14T12:34:11.234+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:11.234+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:11.234+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[16] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-14T12:34:11.240+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 101.3 KiB, free 434.0 MiB)
[2025-07-14T12:34:11.241+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 433.9 MiB)
[2025-07-14T12:34:11.241+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 138.4.31.89:45589 (size: 36.5 KiB, free: 434.3 MiB)
[2025-07-14T12:34:11.241+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:11.242+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[16] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:11.242+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2025-07-14T12:34:11.243+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 16) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15151 bytes)
[2025-07-14T12:34:11.244+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Running task 0.0 in stage 5.0 (TID 16)
[2025-07-14T12:34:11.253+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-14T12:34:11.253+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:11.253+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:11.276+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO FileOutputCommitter: Saved output of task 'attempt_202507141234111618590050078444779_0016_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/arrival_bucketizer_2.0.bin/metadata/_temporary/0/task_202507141234111618590050078444779_0016_m_000000
[2025-07-14T12:34:11.276+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO SparkHadoopMapRedUtil: attempt_202507141234111618590050078444779_0016_m_000000_0: Committed. Elapsed time: 1 ms.
[2025-07-14T12:34:11.278+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Finished task 0.0 in stage 5.0 (TID 16). 1170 bytes result sent to driver
[2025-07-14T12:34:11.278+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 16) in 36 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:11.278+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-07-14T12:34:11.278+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: ResultStage 5 (runJob at SparkHadoopWriter.scala:83) finished in 0,043 s
[2025-07-14T12:34:11.278+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:11.278+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-07-14T12:34:11.279+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Job 3 finished: runJob at SparkHadoopWriter.scala:83, took 0,045127 s
[2025-07-14T12:34:11.279+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO SparkHadoopWriter: Start to commit write Job job_202507141234111618590050078444779_0016.
[2025-07-14T12:34:11.294+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO SparkHadoopWriter: Write Job job_202507141234111618590050078444779_0016 committed. Elapsed time: 14 ms.
[2025-07-14T12:34:11.380+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:11.380+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-14T12:34:11.380+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-14T12:34:11.380+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-14T12:34:11.380+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:11.388+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:11.389+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68
[2025-07-14T12:34:11.389+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:11.419+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO FileSourceStrategy: Pushed Filters:
[2025-07-14T12:34:11.419+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-14T12:34:11.434+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO CodeGenerator: Code generated in 3.002915 ms
[2025-07-14T12:34:11.436+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 214.5 KiB, free 433.7 MiB)
[2025-07-14T12:34:11.442+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 39.0 KiB, free 433.7 MiB)
[2025-07-14T12:34:11.442+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 138.4.31.89:45589 (size: 39.0 KiB, free: 434.3 MiB)
[2025-07-14T12:34:11.443+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO SparkContext: Created broadcast 5 from collect at StringIndexer.scala:204
[2025-07-14T12:34:11.443+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-14T12:34:11.446+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Registering RDD 20 (collect at StringIndexer.scala:204) as input to shuffle 2
[2025-07-14T12:34:11.446+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Got map stage job 4 (collect at StringIndexer.scala:204) with 2 output partitions
[2025-07-14T12:34:11.446+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (collect at StringIndexer.scala:204)
[2025-07-14T12:34:11.446+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:11.446+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:11.446+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[20] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-14T12:34:11.447+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 17.4 KiB, free 433.7 MiB)
[2025-07-14T12:34:11.449+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 433.7 MiB)
[2025-07-14T12:34:11.449+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 138.4.31.89:45589 (size: 8.3 KiB, free: 434.3 MiB)
[2025-07-14T12:34:11.449+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:11.449+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[20] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-14T12:34:11.449+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSchedulerImpl: Adding task set 6.0 with 2 tasks resource profile 0
[2025-07-14T12:34:11.449+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO CodeGenerator: Code generated in 2.690333 ms
[2025-07-14T12:34:11.450+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 17) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:11.450+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 18) (138.4.31.89, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:11.450+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Running task 0.0 in stage 6.0 (TID 17)
[2025-07-14T12:34:11.450+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Running task 1.0 in stage 6.0 (TID 18)
[2025-07-14T12:34:11.452+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Registering RDD 24 (collect at StringIndexer.scala:204) as input to shuffle 3
[2025-07-14T12:34:11.452+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Got map stage job 5 (collect at StringIndexer.scala:204) with 13 output partitions
[2025-07-14T12:34:11.452+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (collect at StringIndexer.scala:204)
[2025-07-14T12:34:11.453+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:11.453+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:11.453+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[24] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-14T12:34:11.454+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 18.2 KiB, free 433.6 MiB)
[2025-07-14T12:34:11.455+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.6 MiB)
[2025-07-14T12:34:11.456+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 138.4.31.89:45589 (size: 9.0 KiB, free: 434.2 MiB)
[2025-07-14T12:34:11.456+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:11.456+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[24] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-14T12:34:11.456+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSchedulerImpl: Adding task set 7.0 with 13 tasks resource profile 0
[2025-07-14T12:34:11.457+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 19) (138.4.31.89, executor driver, partition 0, ANY, 16715 bytes)
[2025-07-14T12:34:11.457+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 20) (138.4.31.89, executor driver, partition 1, ANY, 16839 bytes)
[2025-07-14T12:34:11.457+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Running task 1.0 in stage 7.0 (TID 20)
[2025-07-14T12:34:11.457+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Running task 0.0 in stage 7.0 (TID 19)
[2025-07-14T12:34:11.458+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO CodeGenerator: Code generated in 4.385027 ms
[2025-07-14T12:34:11.461+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO CodeGenerator: Code generated in 2.334524 ms
[2025-07-14T12:34:11.465+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO CodeGenerator: Code generated in 4.458588 ms
[2025-07-14T12:34:11.465+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-14T12:34:11.466+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-14T12:34:11.469+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO CodeGenerator: Code generated in 2.530317 ms
[2025-07-14T12:34:11.489+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Finished task 1.0 in stage 7.0 (TID 20). 1945 bytes result sent to driver
[2025-07-14T12:34:11.490+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 21) (138.4.31.89, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-14T12:34:11.490+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Finished task 0.0 in stage 7.0 (TID 19). 1945 bytes result sent to driver
[2025-07-14T12:34:11.490+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Running task 2.0 in stage 7.0 (TID 21)
[2025-07-14T12:34:11.491+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 22) (138.4.31.89, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-14T12:34:11.491+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 20) in 34 ms on 138.4.31.89 (executor driver) (1/13)
[2025-07-14T12:34:11.492+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 19) in 36 ms on 138.4.31.89 (executor driver) (2/13)
[2025-07-14T12:34:11.492+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Running task 3.0 in stage 7.0 (TID 22)
[2025-07-14T12:34:11.509+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Finished task 2.0 in stage 7.0 (TID 21). 1945 bytes result sent to driver
[2025-07-14T12:34:11.510+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 23) (138.4.31.89, executor driver, partition 4, ANY, 16839 bytes)
[2025-07-14T12:34:11.510+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Running task 4.0 in stage 7.0 (TID 23)
[2025-07-14T12:34:11.510+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 21) in 20 ms on 138.4.31.89 (executor driver) (3/13)
[2025-07-14T12:34:11.520+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Finished task 3.0 in stage 7.0 (TID 22). 1945 bytes result sent to driver
[2025-07-14T12:34:11.521+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 24) (138.4.31.89, executor driver, partition 5, ANY, 16719 bytes)
[2025-07-14T12:34:11.521+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 22) in 30 ms on 138.4.31.89 (executor driver) (4/13)
[2025-07-14T12:34:11.521+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Running task 5.0 in stage 7.0 (TID 24)
[2025-07-14T12:34:11.538+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Finished task 4.0 in stage 7.0 (TID 23). 1945 bytes result sent to driver
[2025-07-14T12:34:11.539+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 25) (138.4.31.89, executor driver, partition 6, ANY, 16839 bytes)
[2025-07-14T12:34:11.540+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Running task 6.0 in stage 7.0 (TID 25)
[2025-07-14T12:34:11.540+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 23) in 30 ms on 138.4.31.89 (executor driver) (5/13)
[2025-07-14T12:34:11.543+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Finished task 5.0 in stage 7.0 (TID 24). 1945 bytes result sent to driver
[2025-07-14T12:34:11.543+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 26) (138.4.31.89, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-14T12:34:11.544+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 24) in 23 ms on 138.4.31.89 (executor driver) (6/13)
[2025-07-14T12:34:11.544+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Running task 7.0 in stage 7.0 (TID 26)
[2025-07-14T12:34:11.564+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 138.4.31.89:45589 in memory (size: 25.2 KiB, free: 434.3 MiB)
[2025-07-14T12:34:11.565+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 138.4.31.89:45589 in memory (size: 36.5 KiB, free: 434.3 MiB)
[2025-07-14T12:34:11.597+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Finished task 7.0 in stage 7.0 (TID 26). 1988 bytes result sent to driver
[2025-07-14T12:34:11.597+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 27) (138.4.31.89, executor driver, partition 8, ANY, 16719 bytes)
[2025-07-14T12:34:11.598+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 26) in 55 ms on 138.4.31.89 (executor driver) (7/13)
[2025-07-14T12:34:11.598+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Running task 8.0 in stage 7.0 (TID 27)
[2025-07-14T12:34:11.602+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Finished task 6.0 in stage 7.0 (TID 25). 1988 bytes result sent to driver
[2025-07-14T12:34:11.602+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 28) (138.4.31.89, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-14T12:34:11.603+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 25) in 63 ms on 138.4.31.89 (executor driver) (8/13)
[2025-07-14T12:34:11.603+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Running task 9.0 in stage 7.0 (TID 28)
[2025-07-14T12:34:11.621+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Finished task 8.0 in stage 7.0 (TID 27). 1945 bytes result sent to driver
[2025-07-14T12:34:11.622+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Starting task 10.0 in stage 7.0 (TID 29) (138.4.31.89, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-14T12:34:11.622+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Finished task 9.0 in stage 7.0 (TID 28). 1945 bytes result sent to driver
[2025-07-14T12:34:11.622+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Running task 10.0 in stage 7.0 (TID 29)
[2025-07-14T12:34:11.622+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Starting task 11.0 in stage 7.0 (TID 30) (138.4.31.89, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-14T12:34:11.622+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 27) in 25 ms on 138.4.31.89 (executor driver) (9/13)
[2025-07-14T12:34:11.622+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Running task 11.0 in stage 7.0 (TID 30)
[2025-07-14T12:34:11.622+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 28) in 20 ms on 138.4.31.89 (executor driver) (10/13)
[2025-07-14T12:34:11.638+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Finished task 11.0 in stage 7.0 (TID 30). 1945 bytes result sent to driver
[2025-07-14T12:34:11.639+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Starting task 12.0 in stage 7.0 (TID 31) (138.4.31.89, executor driver, partition 12, ANY, 16719 bytes)
[2025-07-14T12:34:11.639+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Finished task 11.0 in stage 7.0 (TID 30) in 17 ms on 138.4.31.89 (executor driver) (11/13)
[2025-07-14T12:34:11.640+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Running task 12.0 in stage 7.0 (TID 31)
[2025-07-14T12:34:11.641+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Finished task 10.0 in stage 7.0 (TID 29). 1945 bytes result sent to driver
[2025-07-14T12:34:11.641+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Finished task 10.0 in stage 7.0 (TID 29) in 20 ms on 138.4.31.89 (executor driver) (12/13)
[2025-07-14T12:34:11.653+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Finished task 12.0 in stage 7.0 (TID 31). 1945 bytes result sent to driver
[2025-07-14T12:34:11.654+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Finished task 12.0 in stage 7.0 (TID 31) in 15 ms on 138.4.31.89 (executor driver) (13/13)
[2025-07-14T12:34:11.654+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2025-07-14T12:34:11.654+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: ShuffleMapStage 7 (collect at StringIndexer.scala:204) finished in 0,201 s
[2025-07-14T12:34:11.654+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:11.654+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: running: Set(ShuffleMapStage 6)
[2025-07-14T12:34:11.655+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:11.655+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:11.665+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-14T12:34:11.679+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-14T12:34:11.680+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Got job 6 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-14T12:34:11.680+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Final stage: ResultStage 9 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-14T12:34:11.680+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
[2025-07-14T12:34:11.680+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:11.680+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[26] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-14T12:34:11.682+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 8.2 KiB, free 433.8 MiB)
[2025-07-14T12:34:11.683+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 433.8 MiB)
[2025-07-14T12:34:11.683+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 138.4.31.89:45589 (size: 4.2 KiB, free: 434.3 MiB)
[2025-07-14T12:34:11.684+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:11.684+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[26] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:11.684+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
[2025-07-14T12:34:11.687+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 32) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-14T12:34:11.687+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Running task 0.0 in stage 9.0 (TID 32)
[2025-07-14T12:34:11.690+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO ShuffleBlockFetcherIterator: Getting 13 (195.7 KiB) non-empty blocks including 13 (195.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:11.690+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:11.697+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO Executor: Finished task 0.0 in stage 9.0 (TID 32). 40621 bytes result sent to driver
[2025-07-14T12:34:11.698+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 32) in 12 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:11.698+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-07-14T12:34:11.698+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: ResultStage 9 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,017 s
[2025-07-14T12:34:11.699+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:11.699+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
[2025-07-14T12:34:11.699+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO DAGScheduler: Job 6 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,019483 s
[2025-07-14T12:34:11.706+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO CodeGenerator: Code generated in 2.74378 ms
[2025-07-14T12:34:11.713+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 4.3 MiB, free 429.6 MiB)
[2025-07-14T12:34:11.716+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 89.4 KiB, free 429.5 MiB)
[2025-07-14T12:34:11.717+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 138.4.31.89:45589 (size: 89.4 KiB, free: 434.2 MiB)
[2025-07-14T12:34:11.717+0200] {subprocess.py:93} INFO - 25/07/14 12:34:11 INFO SparkContext: Created broadcast 9 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-14T12:34:12.058+0200] {subprocess.py:93} INFO - 25/07/14 12:34:12 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 138.4.31.89:45589 in memory (size: 4.2 KiB, free: 434.2 MiB)
[2025-07-14T12:34:12.075+0200] {subprocess.py:93} INFO - 25/07/14 12:34:12 INFO Executor: Finished task 1.0 in stage 6.0 (TID 18). 2031 bytes result sent to driver
[2025-07-14T12:34:12.076+0200] {subprocess.py:93} INFO - 25/07/14 12:34:12 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 18) in 626 ms on 138.4.31.89 (executor driver) (1/2)
[2025-07-14T12:34:14.403+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO Executor: Finished task 0.0 in stage 6.0 (TID 17). 2074 bytes result sent to driver
[2025-07-14T12:34:14.403+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 17) in 2953 ms on 138.4.31.89 (executor driver) (2/2)
[2025-07-14T12:34:14.403+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2025-07-14T12:34:14.404+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: ShuffleMapStage 6 (collect at StringIndexer.scala:204) finished in 2,957 s
[2025-07-14T12:34:14.404+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:14.404+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:14.404+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:14.404+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:14.407+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-14T12:34:14.417+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO CodeGenerator: Code generated in 3.453465 ms
[2025-07-14T12:34:14.421+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Registering RDD 30 (collect at StringIndexer.scala:204) as input to shuffle 4
[2025-07-14T12:34:14.422+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Got map stage job 7 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-14T12:34:14.422+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Final stage: ShuffleMapStage 11 (collect at StringIndexer.scala:204)
[2025-07-14T12:34:14.422+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
[2025-07-14T12:34:14.422+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:14.422+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[30] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-14T12:34:14.430+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 50.7 KiB, free 429.5 MiB)
[2025-07-14T12:34:14.433+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 429.4 MiB)
[2025-07-14T12:34:14.433+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 138.4.31.89:45589 (size: 24.0 KiB, free: 434.2 MiB)
[2025-07-14T12:34:14.433+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:14.433+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[30] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:14.433+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
[2025-07-14T12:34:14.434+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 33) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14833 bytes)
[2025-07-14T12:34:14.435+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO Executor: Running task 0.0 in stage 11.0 (TID 33)
[2025-07-14T12:34:14.442+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO ShuffleBlockFetcherIterator: Getting 2 (1126.9 KiB) non-empty blocks including 2 (1126.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:14.442+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:14.450+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 138.4.31.89:45589 in memory (size: 39.0 KiB, free: 434.2 MiB)
[2025-07-14T12:34:14.451+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO CodeGenerator: Code generated in 8.119301 ms
[2025-07-14T12:34:14.452+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 138.4.31.89:45589 in memory (size: 9.0 KiB, free: 434.2 MiB)
[2025-07-14T12:34:14.455+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 138.4.31.89:45589 in memory (size: 8.3 KiB, free: 434.3 MiB)
[2025-07-14T12:34:14.459+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO CodeGenerator: Code generated in 1.892499 ms
[2025-07-14T12:34:14.463+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO CodeGenerator: Code generated in 1.872088 ms
[2025-07-14T12:34:14.466+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO CodeGenerator: Code generated in 2.044468 ms
[2025-07-14T12:34:14.472+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO CodeGenerator: Code generated in 2.196273 ms
[2025-07-14T12:34:14.692+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO CodeGenerator: Code generated in 4.211201 ms
[2025-07-14T12:34:14.822+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO Executor: Finished task 0.0 in stage 11.0 (TID 33). 6500 bytes result sent to driver
[2025-07-14T12:34:14.822+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 33) in 388 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:14.822+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2025-07-14T12:34:14.823+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: ShuffleMapStage 11 (collect at StringIndexer.scala:204) finished in 0,400 s
[2025-07-14T12:34:14.823+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:14.823+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:14.823+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:14.823+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:14.835+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
[2025-07-14T12:34:14.836+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Got job 8 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-14T12:34:14.836+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Final stage: ResultStage 14 (collect at StringIndexer.scala:204)
[2025-07-14T12:34:14.836+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
[2025-07-14T12:34:14.836+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:14.836+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[33] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-14T12:34:14.837+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 49.9 KiB, free 429.7 MiB)
[2025-07-14T12:34:14.838+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 429.7 MiB)
[2025-07-14T12:34:14.838+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 138.4.31.89:45589 (size: 23.6 KiB, free: 434.2 MiB)
[2025-07-14T12:34:14.838+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:14.838+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[33] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:14.838+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
[2025-07-14T12:34:14.839+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 34) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-14T12:34:14.839+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO Executor: Running task 0.0 in stage 14.0 (TID 34)
[2025-07-14T12:34:14.842+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:14.842+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:14.849+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO CodeGenerator: Code generated in 3.229647 ms
[2025-07-14T12:34:14.865+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO Executor: Finished task 0.0 in stage 14.0 (TID 34). 8145 bytes result sent to driver
[2025-07-14T12:34:14.866+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 34) in 26 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:14.866+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2025-07-14T12:34:14.866+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: ResultStage 14 (collect at StringIndexer.scala:204) finished in 0,030 s
[2025-07-14T12:34:14.866+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:14.866+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
[2025-07-14T12:34:14.867+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Job 8 finished: collect at StringIndexer.scala:204, took 0,031631 s
[2025-07-14T12:34:14.871+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO CodeGenerator: Code generated in 2.886369 ms
[2025-07-14T12:34:14.912+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO FileSystemOverwrite: Path /home/monica.fernandez/practica_creativa/models/string_indexer_model_Carrier.bin already exists. It will be overwritten.
[2025-07-14T12:34:14.923+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-14T12:34:14.924+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:14.924+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:14.940+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-14T12:34:14.940+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Got job 9 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-14T12:34:14.940+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Final stage: ResultStage 15 (runJob at SparkHadoopWriter.scala:83)
[2025-07-14T12:34:14.940+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:14.940+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:14.940+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[35] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-14T12:34:14.944+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 101.3 KiB, free 429.6 MiB)
[2025-07-14T12:34:14.945+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 36.6 KiB, free 429.5 MiB)
[2025-07-14T12:34:14.945+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 138.4.31.89:45589 (size: 36.6 KiB, free: 434.2 MiB)
[2025-07-14T12:34:14.945+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:14.946+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[35] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:14.946+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
[2025-07-14T12:34:14.946+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 35) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15158 bytes)
[2025-07-14T12:34:14.947+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO Executor: Running task 0.0 in stage 15.0 (TID 35)
[2025-07-14T12:34:14.950+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-14T12:34:14.950+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:14.950+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:14.968+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO FileOutputCommitter: Saved output of task 'attempt_202507141234144246957543428915002_0035_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Carrier.bin/metadata/_temporary/0/task_202507141234144246957543428915002_0035_m_000000
[2025-07-14T12:34:14.968+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO SparkHadoopMapRedUtil: attempt_202507141234144246957543428915002_0035_m_000000_0: Committed. Elapsed time: 0 ms.
[2025-07-14T12:34:14.969+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO Executor: Finished task 0.0 in stage 15.0 (TID 35). 1170 bytes result sent to driver
[2025-07-14T12:34:14.969+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 35) in 23 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:14.969+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2025-07-14T12:34:14.970+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: ResultStage 15 (runJob at SparkHadoopWriter.scala:83) finished in 0,030 s
[2025-07-14T12:34:14.970+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:14.970+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
[2025-07-14T12:34:14.970+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO DAGScheduler: Job 9 finished: runJob at SparkHadoopWriter.scala:83, took 0,030375 s
[2025-07-14T12:34:14.970+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO SparkHadoopWriter: Start to commit write Job job_202507141234144246957543428915002_0035.
[2025-07-14T12:34:14.985+0200] {subprocess.py:93} INFO - 25/07/14 12:34:14 INFO SparkHadoopWriter: Write Job job_202507141234144246957543428915002_0035 committed. Elapsed time: 15 ms.
[2025-07-14T12:34:15.046+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO CodeGenerator: Code generated in 4.914971 ms
[2025-07-14T12:34:15.049+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Registering RDD 38 (parquet at StringIndexer.scala:499) as input to shuffle 5
[2025-07-14T12:34:15.049+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Got map stage job 10 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-14T12:34:15.049+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Final stage: ShuffleMapStage 16 (parquet at StringIndexer.scala:499)
[2025-07-14T12:34:15.049+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:15.049+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:15.049+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[38] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-14T12:34:15.050+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.1 KiB, free 429.5 MiB)
[2025-07-14T12:34:15.051+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 429.5 MiB)
[2025-07-14T12:34:15.051+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 138.4.31.89:45589 (size: 4.4 KiB, free: 434.2 MiB)
[2025-07-14T12:34:15.051+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:15.051+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[38] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:15.051+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
[2025-07-14T12:34:15.052+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 36) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15256 bytes)
[2025-07-14T12:34:15.052+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Running task 0.0 in stage 16.0 (TID 36)
[2025-07-14T12:34:15.056+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Finished task 0.0 in stage 16.0 (TID 36). 1585 bytes result sent to driver
[2025-07-14T12:34:15.056+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 36) in 5 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:15.056+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool
[2025-07-14T12:34:15.056+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: ShuffleMapStage 16 (parquet at StringIndexer.scala:499) finished in 0,007 s
[2025-07-14T12:34:15.056+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:15.056+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:15.056+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:15.056+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:15.084+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:15.093+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:15.094+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:15.094+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:15.094+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:15.094+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:15.094+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:15.106+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO SparkContext: Starting job: parquet at StringIndexer.scala:499
[2025-07-14T12:34:15.107+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Got job 11 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-14T12:34:15.107+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Final stage: ResultStage 18 (parquet at StringIndexer.scala:499)
[2025-07-14T12:34:15.107+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
[2025-07-14T12:34:15.107+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:15.107+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[40] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-14T12:34:15.118+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 239.5 KiB, free 429.3 MiB)
[2025-07-14T12:34:15.119+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 83.6 KiB, free 429.2 MiB)
[2025-07-14T12:34:15.119+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 138.4.31.89:45589 (size: 83.6 KiB, free: 434.1 MiB)
[2025-07-14T12:34:15.120+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:15.120+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[40] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:15.120+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
[2025-07-14T12:34:15.120+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 37) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-14T12:34:15.121+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Running task 0.0 in stage 18.0 (TID 37)
[2025-07-14T12:34:15.129+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:15.129+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:15.130+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:15.130+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:15.130+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:15.130+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:15.130+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:15.130+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:15.131+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO CodecConfig: Compression: SNAPPY
[2025-07-14T12:34:15.133+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO CodecConfig: Compression: SNAPPY
[2025-07-14T12:34:15.146+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-14T12:34:15.160+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-14T12:34:15.160+0200] {subprocess.py:93} INFO - {
[2025-07-14T12:34:15.160+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-14T12:34:15.160+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-14T12:34:15.160+0200] {subprocess.py:93} INFO -     "name" : "labelsArray",
[2025-07-14T12:34:15.160+0200] {subprocess.py:93} INFO -     "type" : {
[2025-07-14T12:34:15.160+0200] {subprocess.py:93} INFO -       "type" : "array",
[2025-07-14T12:34:15.160+0200] {subprocess.py:93} INFO -       "elementType" : {
[2025-07-14T12:34:15.160+0200] {subprocess.py:93} INFO -         "type" : "array",
[2025-07-14T12:34:15.160+0200] {subprocess.py:93} INFO -         "elementType" : "string",
[2025-07-14T12:34:15.160+0200] {subprocess.py:93} INFO -         "containsNull" : true
[2025-07-14T12:34:15.160+0200] {subprocess.py:93} INFO -       },
[2025-07-14T12:34:15.160+0200] {subprocess.py:93} INFO -       "containsNull" : true
[2025-07-14T12:34:15.160+0200] {subprocess.py:93} INFO -     },
[2025-07-14T12:34:15.160+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-14T12:34:15.160+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-14T12:34:15.161+0200] {subprocess.py:93} INFO -   } ]
[2025-07-14T12:34:15.161+0200] {subprocess.py:93} INFO - }
[2025-07-14T12:34:15.161+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-14T12:34:15.161+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-14T12:34:15.161+0200] {subprocess.py:93} INFO -   optional group labelsArray (LIST) {
[2025-07-14T12:34:15.161+0200] {subprocess.py:93} INFO -     repeated group list {
[2025-07-14T12:34:15.161+0200] {subprocess.py:93} INFO -       optional group element (LIST) {
[2025-07-14T12:34:15.161+0200] {subprocess.py:93} INFO -         repeated group list {
[2025-07-14T12:34:15.161+0200] {subprocess.py:93} INFO -           optional binary element (STRING);
[2025-07-14T12:34:15.161+0200] {subprocess.py:93} INFO -         }
[2025-07-14T12:34:15.161+0200] {subprocess.py:93} INFO -       }
[2025-07-14T12:34:15.161+0200] {subprocess.py:93} INFO -     }
[2025-07-14T12:34:15.161+0200] {subprocess.py:93} INFO -   }
[2025-07-14T12:34:15.161+0200] {subprocess.py:93} INFO - }
[2025-07-14T12:34:15.161+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:15.161+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:15.198+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO CodecPool: Got brand-new compressor [.snappy]
[2025-07-14T12:34:15.503+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO FileOutputCommitter: Saved output of task 'attempt_202507141234154842629848295391706_0018_m_000000_37' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Carrier.bin/data/_temporary/0/task_202507141234154842629848295391706_0018_m_000000
[2025-07-14T12:34:15.503+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO SparkHadoopMapRedUtil: attempt_202507141234154842629848295391706_0018_m_000000_37: Committed. Elapsed time: 1 ms.
[2025-07-14T12:34:15.505+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Finished task 0.0 in stage 18.0 (TID 37). 4740 bytes result sent to driver
[2025-07-14T12:34:15.505+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 37) in 385 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:15.505+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool
[2025-07-14T12:34:15.506+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: ResultStage 18 (parquet at StringIndexer.scala:499) finished in 0,399 s
[2025-07-14T12:34:15.506+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:15.506+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
[2025-07-14T12:34:15.506+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Job 11 finished: parquet at StringIndexer.scala:499, took 0,399809 s
[2025-07-14T12:34:15.507+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO FileFormatWriter: Start to commit write Job d4d9204c-da00-475f-aaa6-2490bea6d29f.
[2025-07-14T12:34:15.523+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO FileFormatWriter: Write Job d4d9204c-da00-475f-aaa6-2490bea6d29f committed. Elapsed time: 15 ms.
[2025-07-14T12:34:15.524+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO FileFormatWriter: Finished processing stats for write job d4d9204c-da00-475f-aaa6-2490bea6d29f.
[2025-07-14T12:34:15.549+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:15.549+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-14T12:34:15.549+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-14T12:34:15.549+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-14T12:34:15.549+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:15.555+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:15.555+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68
[2025-07-14T12:34:15.555+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:15.562+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO FileSourceStrategy: Pushed Filters:
[2025-07-14T12:34:15.562+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-14T12:34:15.570+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 138.4.31.89:45589 in memory (size: 83.6 KiB, free: 434.2 MiB)
[2025-07-14T12:34:15.571+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 138.4.31.89:45589 in memory (size: 4.4 KiB, free: 434.2 MiB)
[2025-07-14T12:34:15.572+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 138.4.31.89:45589 in memory (size: 24.0 KiB, free: 434.2 MiB)
[2025-07-14T12:34:15.574+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 138.4.31.89:45589 in memory (size: 36.6 KiB, free: 434.3 MiB)
[2025-07-14T12:34:15.575+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 138.4.31.89:45589 in memory (size: 23.6 KiB, free: 434.3 MiB)
[2025-07-14T12:34:15.577+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO CodeGenerator: Code generated in 2.952457 ms
[2025-07-14T12:34:15.578+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 214.5 KiB, free 429.6 MiB)
[2025-07-14T12:34:15.583+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 39.0 KiB, free 429.6 MiB)
[2025-07-14T12:34:15.583+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 138.4.31.89:45589 (size: 39.0 KiB, free: 434.2 MiB)
[2025-07-14T12:34:15.584+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO SparkContext: Created broadcast 15 from collect at StringIndexer.scala:204
[2025-07-14T12:34:15.584+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-14T12:34:15.587+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Registering RDD 44 (collect at StringIndexer.scala:204) as input to shuffle 6
[2025-07-14T12:34:15.587+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Got map stage job 12 (collect at StringIndexer.scala:204) with 2 output partitions
[2025-07-14T12:34:15.587+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Final stage: ShuffleMapStage 19 (collect at StringIndexer.scala:204)
[2025-07-14T12:34:15.587+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:15.587+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:15.587+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[44] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-14T12:34:15.588+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 16.9 KiB, free 429.6 MiB)
[2025-07-14T12:34:15.588+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 429.5 MiB)
[2025-07-14T12:34:15.588+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 138.4.31.89:45589 (size: 8.2 KiB, free: 434.2 MiB)
[2025-07-14T12:34:15.588+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:15.589+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[44] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-14T12:34:15.589+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSchedulerImpl: Adding task set 19.0 with 2 tasks resource profile 0
[2025-07-14T12:34:15.589+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 38) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:15.590+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 39) (138.4.31.89, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:15.590+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Registering RDD 48 (collect at StringIndexer.scala:204) as input to shuffle 7
[2025-07-14T12:34:15.590+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Got map stage job 13 (collect at StringIndexer.scala:204) with 13 output partitions
[2025-07-14T12:34:15.590+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Final stage: ShuffleMapStage 20 (collect at StringIndexer.scala:204)
[2025-07-14T12:34:15.590+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:15.590+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:15.590+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[48] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-14T12:34:15.590+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Running task 0.0 in stage 19.0 (TID 38)
[2025-07-14T12:34:15.590+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Running task 1.0 in stage 19.0 (TID 39)
[2025-07-14T12:34:15.591+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 18.2 KiB, free 429.5 MiB)
[2025-07-14T12:34:15.591+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 429.5 MiB)
[2025-07-14T12:34:15.592+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 138.4.31.89:45589 (size: 9.0 KiB, free: 434.2 MiB)
[2025-07-14T12:34:15.592+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:15.592+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[48] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-14T12:34:15.592+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSchedulerImpl: Adding task set 20.0 with 13 tasks resource profile 0
[2025-07-14T12:34:15.593+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 40) (138.4.31.89, executor driver, partition 0, ANY, 16719 bytes)
[2025-07-14T12:34:15.593+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 41) (138.4.31.89, executor driver, partition 1, ANY, 16719 bytes)
[2025-07-14T12:34:15.593+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Running task 1.0 in stage 20.0 (TID 41)
[2025-07-14T12:34:15.593+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Running task 0.0 in stage 20.0 (TID 40)
[2025-07-14T12:34:15.594+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO CodeGenerator: Code generated in 2.598502 ms
[2025-07-14T12:34:15.597+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-14T12:34:15.597+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-14T12:34:15.623+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Finished task 1.0 in stage 20.0 (TID 41). 1988 bytes result sent to driver
[2025-07-14T12:34:15.624+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 42) (138.4.31.89, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-14T12:34:15.624+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Running task 2.0 in stage 20.0 (TID 42)
[2025-07-14T12:34:15.624+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 41) in 31 ms on 138.4.31.89 (executor driver) (1/13)
[2025-07-14T12:34:15.626+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Finished task 0.0 in stage 20.0 (TID 40). 1988 bytes result sent to driver
[2025-07-14T12:34:15.627+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 43) (138.4.31.89, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-14T12:34:15.627+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Running task 3.0 in stage 20.0 (TID 43)
[2025-07-14T12:34:15.627+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 40) in 35 ms on 138.4.31.89 (executor driver) (2/13)
[2025-07-14T12:34:15.645+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Finished task 3.0 in stage 20.0 (TID 43). 1945 bytes result sent to driver
[2025-07-14T12:34:15.645+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Finished task 2.0 in stage 20.0 (TID 42). 1945 bytes result sent to driver
[2025-07-14T12:34:15.646+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Starting task 4.0 in stage 20.0 (TID 44) (138.4.31.89, executor driver, partition 4, ANY, 16839 bytes)
[2025-07-14T12:34:15.646+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Running task 4.0 in stage 20.0 (TID 44)
[2025-07-14T12:34:15.646+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Starting task 5.0 in stage 20.0 (TID 45) (138.4.31.89, executor driver, partition 5, ANY, 16719 bytes)
[2025-07-14T12:34:15.646+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 43) in 20 ms on 138.4.31.89 (executor driver) (3/13)
[2025-07-14T12:34:15.646+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Running task 5.0 in stage 20.0 (TID 45)
[2025-07-14T12:34:15.646+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 42) in 23 ms on 138.4.31.89 (executor driver) (4/13)
[2025-07-14T12:34:15.660+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Finished task 5.0 in stage 20.0 (TID 45). 1945 bytes result sent to driver
[2025-07-14T12:34:15.660+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Starting task 6.0 in stage 20.0 (TID 46) (138.4.31.89, executor driver, partition 6, ANY, 16839 bytes)
[2025-07-14T12:34:15.661+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Finished task 5.0 in stage 20.0 (TID 45) in 14 ms on 138.4.31.89 (executor driver) (5/13)
[2025-07-14T12:34:15.661+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Running task 6.0 in stage 20.0 (TID 46)
[2025-07-14T12:34:15.665+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Finished task 4.0 in stage 20.0 (TID 44). 1945 bytes result sent to driver
[2025-07-14T12:34:15.666+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Starting task 7.0 in stage 20.0 (TID 47) (138.4.31.89, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-14T12:34:15.666+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Finished task 4.0 in stage 20.0 (TID 44) in 21 ms on 138.4.31.89 (executor driver) (6/13)
[2025-07-14T12:34:15.666+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Running task 7.0 in stage 20.0 (TID 47)
[2025-07-14T12:34:15.679+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Finished task 7.0 in stage 20.0 (TID 47). 1945 bytes result sent to driver
[2025-07-14T12:34:15.680+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Starting task 8.0 in stage 20.0 (TID 48) (138.4.31.89, executor driver, partition 8, ANY, 16839 bytes)
[2025-07-14T12:34:15.680+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Running task 8.0 in stage 20.0 (TID 48)
[2025-07-14T12:34:15.680+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Finished task 7.0 in stage 20.0 (TID 47) in 15 ms on 138.4.31.89 (executor driver) (7/13)
[2025-07-14T12:34:15.681+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Finished task 6.0 in stage 20.0 (TID 46). 1945 bytes result sent to driver
[2025-07-14T12:34:15.682+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Starting task 9.0 in stage 20.0 (TID 49) (138.4.31.89, executor driver, partition 9, ANY, 16715 bytes)
[2025-07-14T12:34:15.682+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Running task 9.0 in stage 20.0 (TID 49)
[2025-07-14T12:34:15.682+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Finished task 6.0 in stage 20.0 (TID 46) in 22 ms on 138.4.31.89 (executor driver) (8/13)
[2025-07-14T12:34:15.697+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Finished task 9.0 in stage 20.0 (TID 49). 1945 bytes result sent to driver
[2025-07-14T12:34:15.697+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Starting task 10.0 in stage 20.0 (TID 50) (138.4.31.89, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-14T12:34:15.697+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Finished task 9.0 in stage 20.0 (TID 49) in 15 ms on 138.4.31.89 (executor driver) (9/13)
[2025-07-14T12:34:15.697+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Running task 10.0 in stage 20.0 (TID 50)
[2025-07-14T12:34:15.699+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Finished task 8.0 in stage 20.0 (TID 48). 1945 bytes result sent to driver
[2025-07-14T12:34:15.700+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Starting task 11.0 in stage 20.0 (TID 51) (138.4.31.89, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-14T12:34:15.700+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Finished task 8.0 in stage 20.0 (TID 48) in 21 ms on 138.4.31.89 (executor driver) (10/13)
[2025-07-14T12:34:15.700+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Running task 11.0 in stage 20.0 (TID 51)
[2025-07-14T12:34:15.716+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Finished task 10.0 in stage 20.0 (TID 50). 1945 bytes result sent to driver
[2025-07-14T12:34:15.716+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Starting task 12.0 in stage 20.0 (TID 52) (138.4.31.89, executor driver, partition 12, ANY, 16719 bytes)
[2025-07-14T12:34:15.717+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Finished task 10.0 in stage 20.0 (TID 50) in 19 ms on 138.4.31.89 (executor driver) (11/13)
[2025-07-14T12:34:15.717+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Running task 12.0 in stage 20.0 (TID 52)
[2025-07-14T12:34:15.725+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Finished task 11.0 in stage 20.0 (TID 51). 1988 bytes result sent to driver
[2025-07-14T12:34:15.725+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Finished task 11.0 in stage 20.0 (TID 51) in 26 ms on 138.4.31.89 (executor driver) (12/13)
[2025-07-14T12:34:15.732+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Finished task 12.0 in stage 20.0 (TID 52). 1945 bytes result sent to driver
[2025-07-14T12:34:15.732+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Finished task 12.0 in stage 20.0 (TID 52) in 16 ms on 138.4.31.89 (executor driver) (13/13)
[2025-07-14T12:34:15.732+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool
[2025-07-14T12:34:15.732+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: ShuffleMapStage 20 (collect at StringIndexer.scala:204) finished in 0,142 s
[2025-07-14T12:34:15.732+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:15.732+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: running: Set(ShuffleMapStage 19)
[2025-07-14T12:34:15.732+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:15.733+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:15.736+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-14T12:34:15.744+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-14T12:34:15.744+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Got job 14 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-14T12:34:15.744+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Final stage: ResultStage 22 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-14T12:34:15.744+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
[2025-07-14T12:34:15.744+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:15.745+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[50] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-14T12:34:15.746+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 8.2 KiB, free 429.5 MiB)
[2025-07-14T12:34:15.750+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 429.5 MiB)
[2025-07-14T12:34:15.750+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 138.4.31.89:45589 (size: 4.2 KiB, free: 434.2 MiB)
[2025-07-14T12:34:15.750+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:15.751+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[50] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:15.751+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
[2025-07-14T12:34:15.752+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 53) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-14T12:34:15.752+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Running task 0.0 in stage 22.0 (TID 53)
[2025-07-14T12:34:15.755+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO ShuffleBlockFetcherIterator: Getting 13 (195.7 KiB) non-empty blocks including 13 (195.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:15.755+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:15.761+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO Executor: Finished task 0.0 in stage 22.0 (TID 53). 40432 bytes result sent to driver
[2025-07-14T12:34:15.762+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 53) in 11 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:15.762+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool
[2025-07-14T12:34:15.762+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: ResultStage 22 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,017 s
[2025-07-14T12:34:15.762+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:15.762+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
[2025-07-14T12:34:15.763+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO DAGScheduler: Job 14 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,018817 s
[2025-07-14T12:34:15.773+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 138.4.31.89:45589 in memory (size: 39.0 KiB, free: 434.3 MiB)
[2025-07-14T12:34:15.775+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 138.4.31.89:45589 in memory (size: 89.4 KiB, free: 434.3 MiB)
[2025-07-14T12:34:15.781+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 4.3 MiB, free 429.8 MiB)
[2025-07-14T12:34:15.783+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 89.5 KiB, free 429.8 MiB)
[2025-07-14T12:34:15.783+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 138.4.31.89:45589 (size: 89.5 KiB, free: 434.3 MiB)
[2025-07-14T12:34:15.784+0200] {subprocess.py:93} INFO - 25/07/14 12:34:15 INFO SparkContext: Created broadcast 19 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-14T12:34:16.049+0200] {subprocess.py:93} INFO - 25/07/14 12:34:16 INFO Executor: Finished task 1.0 in stage 19.0 (TID 39). 2031 bytes result sent to driver
[2025-07-14T12:34:16.050+0200] {subprocess.py:93} INFO - 25/07/14 12:34:16 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 39) in 461 ms on 138.4.31.89 (executor driver) (1/2)
[2025-07-14T12:34:16.430+0200] {subprocess.py:93} INFO - 25/07/14 12:34:16 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 138.4.31.89:45589 in memory (size: 4.2 KiB, free: 434.3 MiB)
[2025-07-14T12:34:18.564+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO Executor: Finished task 0.0 in stage 19.0 (TID 38). 2074 bytes result sent to driver
[2025-07-14T12:34:18.565+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 38) in 2976 ms on 138.4.31.89 (executor driver) (2/2)
[2025-07-14T12:34:18.565+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool
[2025-07-14T12:34:18.565+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: ShuffleMapStage 19 (collect at StringIndexer.scala:204) finished in 2,978 s
[2025-07-14T12:34:18.565+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:18.565+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:18.565+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:18.565+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:18.568+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO ShufflePartitionsUtil: For shuffle(6), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-14T12:34:18.578+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO CodeGenerator: Code generated in 3.391649 ms
[2025-07-14T12:34:18.582+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 138.4.31.89:45589 in memory (size: 9.0 KiB, free: 434.3 MiB)
[2025-07-14T12:34:18.583+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Registering RDD 54 (collect at StringIndexer.scala:204) as input to shuffle 8
[2025-07-14T12:34:18.583+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Got map stage job 15 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-14T12:34:18.583+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Final stage: ShuffleMapStage 24 (collect at StringIndexer.scala:204)
[2025-07-14T12:34:18.583+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
[2025-07-14T12:34:18.583+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:18.583+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[54] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-14T12:34:18.584+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 50.6 KiB, free 429.7 MiB)
[2025-07-14T12:34:18.585+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 24.1 KiB, free 429.7 MiB)
[2025-07-14T12:34:18.585+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 138.4.31.89:45589 (size: 24.1 KiB, free: 434.2 MiB)
[2025-07-14T12:34:18.585+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:18.586+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[54] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:18.586+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
[2025-07-14T12:34:18.587+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 54) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14833 bytes)
[2025-07-14T12:34:18.587+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO Executor: Running task 0.0 in stage 24.0 (TID 54)
[2025-07-14T12:34:18.590+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO ShuffleBlockFetcherIterator: Getting 2 (887.5 KiB) non-empty blocks including 2 (887.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:18.590+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:18.595+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO CodeGenerator: Code generated in 3.973102 ms
[2025-07-14T12:34:18.762+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO Executor: Finished task 0.0 in stage 24.0 (TID 54). 6500 bytes result sent to driver
[2025-07-14T12:34:18.763+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 54) in 177 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:18.763+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool
[2025-07-14T12:34:18.763+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: ShuffleMapStage 24 (collect at StringIndexer.scala:204) finished in 0,180 s
[2025-07-14T12:34:18.763+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:18.764+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:18.764+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:18.764+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:18.772+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
[2025-07-14T12:34:18.773+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Got job 16 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-14T12:34:18.773+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Final stage: ResultStage 27 (collect at StringIndexer.scala:204)
[2025-07-14T12:34:18.773+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
[2025-07-14T12:34:18.773+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:18.773+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[57] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-14T12:34:18.774+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 49.7 KiB, free 429.7 MiB)
[2025-07-14T12:34:18.775+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 429.6 MiB)
[2025-07-14T12:34:18.775+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 138.4.31.89:45589 (size: 23.6 KiB, free: 434.2 MiB)
[2025-07-14T12:34:18.775+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:18.775+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[57] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:18.776+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
[2025-07-14T12:34:18.776+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 55) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-14T12:34:18.777+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO Executor: Running task 0.0 in stage 27.0 (TID 55)
[2025-07-14T12:34:18.779+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO ShuffleBlockFetcherIterator: Getting 1 (3.2 KiB) non-empty blocks including 1 (3.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:18.779+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:18.788+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO Executor: Finished task 0.0 in stage 27.0 (TID 55). 10936 bytes result sent to driver
[2025-07-14T12:34:18.789+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 55) in 13 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:18.789+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool
[2025-07-14T12:34:18.789+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: ResultStage 27 (collect at StringIndexer.scala:204) finished in 0,016 s
[2025-07-14T12:34:18.790+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:18.790+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
[2025-07-14T12:34:18.790+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Job 16 finished: collect at StringIndexer.scala:204, took 0,017173 s
[2025-07-14T12:34:18.812+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO FileSystemOverwrite: Path /home/monica.fernandez/practica_creativa/models/string_indexer_model_Origin.bin already exists. It will be overwritten.
[2025-07-14T12:34:18.825+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-14T12:34:18.825+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:18.825+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:18.847+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-14T12:34:18.848+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Got job 17 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-14T12:34:18.848+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Final stage: ResultStage 28 (runJob at SparkHadoopWriter.scala:83)
[2025-07-14T12:34:18.848+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:18.848+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:18.848+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[59] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-14T12:34:18.852+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 101.3 KiB, free 429.5 MiB)
[2025-07-14T12:34:18.853+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 429.5 MiB)
[2025-07-14T12:34:18.853+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 138.4.31.89:45589 (size: 36.5 KiB, free: 434.2 MiB)
[2025-07-14T12:34:18.854+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:18.854+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[59] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:18.854+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
[2025-07-14T12:34:18.854+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 56) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15156 bytes)
[2025-07-14T12:34:18.855+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO Executor: Running task 0.0 in stage 28.0 (TID 56)
[2025-07-14T12:34:18.858+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-14T12:34:18.858+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:18.858+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:18.879+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO FileOutputCommitter: Saved output of task 'attempt_202507141234183070327626782056585_0059_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Origin.bin/metadata/_temporary/0/task_202507141234183070327626782056585_0059_m_000000
[2025-07-14T12:34:18.879+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO SparkHadoopMapRedUtil: attempt_202507141234183070327626782056585_0059_m_000000_0: Committed. Elapsed time: 1 ms.
[2025-07-14T12:34:18.879+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO Executor: Finished task 0.0 in stage 28.0 (TID 56). 1170 bytes result sent to driver
[2025-07-14T12:34:18.880+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 56) in 26 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:18.880+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool
[2025-07-14T12:34:18.880+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: ResultStage 28 (runJob at SparkHadoopWriter.scala:83) finished in 0,032 s
[2025-07-14T12:34:18.880+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:18.880+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
[2025-07-14T12:34:18.880+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Job 17 finished: runJob at SparkHadoopWriter.scala:83, took 0,032869 s
[2025-07-14T12:34:18.881+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO SparkHadoopWriter: Start to commit write Job job_202507141234183070327626782056585_0059.
[2025-07-14T12:34:18.896+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO SparkHadoopWriter: Write Job job_202507141234183070327626782056585_0059 committed. Elapsed time: 15 ms.
[2025-07-14T12:34:18.911+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Registering RDD 62 (parquet at StringIndexer.scala:499) as input to shuffle 9
[2025-07-14T12:34:18.912+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Got map stage job 18 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-14T12:34:18.912+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Final stage: ShuffleMapStage 29 (parquet at StringIndexer.scala:499)
[2025-07-14T12:34:18.912+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:18.912+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:18.912+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[62] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-14T12:34:18.912+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 8.1 KiB, free 429.5 MiB)
[2025-07-14T12:34:18.913+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 429.5 MiB)
[2025-07-14T12:34:18.913+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 138.4.31.89:45589 (size: 4.4 KiB, free: 434.2 MiB)
[2025-07-14T12:34:18.913+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:18.913+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[62] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:18.913+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
[2025-07-14T12:34:18.914+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 57) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 20076 bytes)
[2025-07-14T12:34:18.914+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO Executor: Running task 0.0 in stage 29.0 (TID 57)
[2025-07-14T12:34:18.916+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO Executor: Finished task 0.0 in stage 29.0 (TID 57). 1542 bytes result sent to driver
[2025-07-14T12:34:18.916+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 57) in 2 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:18.916+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool
[2025-07-14T12:34:18.916+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: ShuffleMapStage 29 (parquet at StringIndexer.scala:499) finished in 0,004 s
[2025-07-14T12:34:18.916+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:18.917+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:18.917+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:18.917+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:18.919+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:18.920+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:18.920+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:18.920+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:18.920+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:18.920+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:18.920+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:18.930+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO SparkContext: Starting job: parquet at StringIndexer.scala:499
[2025-07-14T12:34:18.930+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Got job 19 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-14T12:34:18.930+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Final stage: ResultStage 31 (parquet at StringIndexer.scala:499)
[2025-07-14T12:34:18.930+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)
[2025-07-14T12:34:18.930+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:18.930+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[64] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-14T12:34:18.939+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 239.5 KiB, free 429.3 MiB)
[2025-07-14T12:34:18.940+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 83.7 KiB, free 429.2 MiB)
[2025-07-14T12:34:18.940+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 138.4.31.89:45589 (size: 83.7 KiB, free: 434.1 MiB)
[2025-07-14T12:34:18.940+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:18.941+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[64] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:18.941+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
[2025-07-14T12:34:18.941+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 58) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-14T12:34:18.942+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO Executor: Running task 0.0 in stage 31.0 (TID 58)
[2025-07-14T12:34:18.948+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:18.948+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:18.948+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:18.948+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:18.949+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:18.949+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:18.949+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:18.949+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:18.949+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO CodecConfig: Compression: SNAPPY
[2025-07-14T12:34:18.949+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO CodecConfig: Compression: SNAPPY
[2025-07-14T12:34:18.949+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO - {
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -     "name" : "labelsArray",
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -     "type" : {
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -       "type" : "array",
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -       "elementType" : {
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -         "type" : "array",
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -         "elementType" : "string",
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -         "containsNull" : true
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -       },
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -       "containsNull" : true
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -     },
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -   } ]
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO - }
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -   optional group labelsArray (LIST) {
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -     repeated group list {
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -       optional group element (LIST) {
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -         repeated group list {
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -           optional binary element (STRING);
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -         }
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -       }
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -     }
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO -   }
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO - }
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:18.950+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:18.972+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO FileOutputCommitter: Saved output of task 'attempt_202507141234185735575339692610625_0031_m_000000_58' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Origin.bin/data/_temporary/0/task_202507141234185735575339692610625_0031_m_000000
[2025-07-14T12:34:18.973+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO SparkHadoopMapRedUtil: attempt_202507141234185735575339692610625_0031_m_000000_58: Committed. Elapsed time: 0 ms.
[2025-07-14T12:34:18.973+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO Executor: Finished task 0.0 in stage 31.0 (TID 58). 4740 bytes result sent to driver
[2025-07-14T12:34:18.974+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 58) in 33 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:18.974+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool
[2025-07-14T12:34:18.974+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: ResultStage 31 (parquet at StringIndexer.scala:499) finished in 0,044 s
[2025-07-14T12:34:18.974+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:18.974+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
[2025-07-14T12:34:18.974+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO DAGScheduler: Job 19 finished: parquet at StringIndexer.scala:499, took 0,044610 s
[2025-07-14T12:34:18.974+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO FileFormatWriter: Start to commit write Job fe03b494-fa59-44f7-a3ed-3579cddbdfa7.
[2025-07-14T12:34:18.990+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO FileFormatWriter: Write Job fe03b494-fa59-44f7-a3ed-3579cddbdfa7 committed. Elapsed time: 15 ms.
[2025-07-14T12:34:18.990+0200] {subprocess.py:93} INFO - 25/07/14 12:34:18 INFO FileFormatWriter: Finished processing stats for write job fe03b494-fa59-44f7-a3ed-3579cddbdfa7.
[2025-07-14T12:34:19.014+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:19.014+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-14T12:34:19.014+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-14T12:34:19.014+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-14T12:34:19.014+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:19.020+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:19.020+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68
[2025-07-14T12:34:19.020+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:19.031+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO FileSourceStrategy: Pushed Filters:
[2025-07-14T12:34:19.031+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-14T12:34:19.044+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 214.5 KiB, free 429.0 MiB)
[2025-07-14T12:34:19.048+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 39.0 KiB, free 428.9 MiB)
[2025-07-14T12:34:19.049+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 138.4.31.89:45589 (size: 39.0 KiB, free: 434.1 MiB)
[2025-07-14T12:34:19.049+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO SparkContext: Created broadcast 25 from collect at StringIndexer.scala:204
[2025-07-14T12:34:19.049+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-14T12:34:19.051+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: Registering RDD 68 (collect at StringIndexer.scala:204) as input to shuffle 10
[2025-07-14T12:34:19.051+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: Got map stage job 20 (collect at StringIndexer.scala:204) with 2 output partitions
[2025-07-14T12:34:19.051+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: Final stage: ShuffleMapStage 32 (collect at StringIndexer.scala:204)
[2025-07-14T12:34:19.052+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:19.052+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:19.052+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[68] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-14T12:34:19.052+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 16.9 KiB, free 428.9 MiB)
[2025-07-14T12:34:19.053+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 428.9 MiB)
[2025-07-14T12:34:19.053+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 138.4.31.89:45589 (size: 8.2 KiB, free: 434.1 MiB)
[2025-07-14T12:34:19.053+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:19.053+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[68] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-14T12:34:19.053+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSchedulerImpl: Adding task set 32.0 with 2 tasks resource profile 0
[2025-07-14T12:34:19.054+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 59) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:19.054+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: Registering RDD 72 (collect at StringIndexer.scala:204) as input to shuffle 11
[2025-07-14T12:34:19.054+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: Got map stage job 21 (collect at StringIndexer.scala:204) with 13 output partitions
[2025-07-14T12:34:19.054+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: Final stage: ShuffleMapStage 33 (collect at StringIndexer.scala:204)
[2025-07-14T12:34:19.054+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:19.054+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 60) (138.4.31.89, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:19.054+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:19.055+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[72] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-14T12:34:19.055+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Running task 0.0 in stage 32.0 (TID 59)
[2025-07-14T12:34:19.055+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Running task 1.0 in stage 32.0 (TID 60)
[2025-07-14T12:34:19.056+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 18.2 KiB, free 428.9 MiB)
[2025-07-14T12:34:19.056+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 428.9 MiB)
[2025-07-14T12:34:19.056+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 138.4.31.89:45589 (size: 9.1 KiB, free: 434.0 MiB)
[2025-07-14T12:34:19.057+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:19.057+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[72] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-14T12:34:19.057+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSchedulerImpl: Adding task set 33.0 with 13 tasks resource profile 0
[2025-07-14T12:34:19.058+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 61) (138.4.31.89, executor driver, partition 0, ANY, 16839 bytes)
[2025-07-14T12:34:19.058+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-14T12:34:19.058+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-14T12:34:19.058+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 62) (138.4.31.89, executor driver, partition 1, ANY, 16719 bytes)
[2025-07-14T12:34:19.059+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Running task 0.0 in stage 33.0 (TID 61)
[2025-07-14T12:34:19.059+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Running task 1.0 in stage 33.0 (TID 62)
[2025-07-14T12:34:19.081+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Finished task 0.0 in stage 33.0 (TID 61). 1945 bytes result sent to driver
[2025-07-14T12:34:19.081+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Finished task 1.0 in stage 33.0 (TID 62). 1945 bytes result sent to driver
[2025-07-14T12:34:19.081+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 63) (138.4.31.89, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-14T12:34:19.082+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Running task 2.0 in stage 33.0 (TID 63)
[2025-07-14T12:34:19.082+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 61) in 23 ms on 138.4.31.89 (executor driver) (1/13)
[2025-07-14T12:34:19.082+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Starting task 3.0 in stage 33.0 (TID 64) (138.4.31.89, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-14T12:34:19.082+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Running task 3.0 in stage 33.0 (TID 64)
[2025-07-14T12:34:19.082+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 62) in 24 ms on 138.4.31.89 (executor driver) (2/13)
[2025-07-14T12:34:19.092+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 138.4.31.89:45589 in memory (size: 23.6 KiB, free: 434.1 MiB)
[2025-07-14T12:34:19.093+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 138.4.31.89:45589 in memory (size: 36.5 KiB, free: 434.1 MiB)
[2025-07-14T12:34:19.094+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 138.4.31.89:45589 in memory (size: 4.4 KiB, free: 434.1 MiB)
[2025-07-14T12:34:19.096+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 138.4.31.89:45589 in memory (size: 24.1 KiB, free: 434.1 MiB)
[2025-07-14T12:34:19.097+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 138.4.31.89:45589 in memory (size: 83.7 KiB, free: 434.2 MiB)
[2025-07-14T12:34:19.111+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Finished task 2.0 in stage 33.0 (TID 63). 1988 bytes result sent to driver
[2025-07-14T12:34:19.111+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Finished task 3.0 in stage 33.0 (TID 64). 1988 bytes result sent to driver
[2025-07-14T12:34:19.111+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Starting task 4.0 in stage 33.0 (TID 65) (138.4.31.89, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-14T12:34:19.112+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Running task 4.0 in stage 33.0 (TID 65)
[2025-07-14T12:34:19.112+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Starting task 5.0 in stage 33.0 (TID 66) (138.4.31.89, executor driver, partition 5, ANY, 16719 bytes)
[2025-07-14T12:34:19.112+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 63) in 31 ms on 138.4.31.89 (executor driver) (3/13)
[2025-07-14T12:34:19.112+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Running task 5.0 in stage 33.0 (TID 66)
[2025-07-14T12:34:19.112+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Finished task 3.0 in stage 33.0 (TID 64) in 30 ms on 138.4.31.89 (executor driver) (4/13)
[2025-07-14T12:34:19.126+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Finished task 5.0 in stage 33.0 (TID 66). 1945 bytes result sent to driver
[2025-07-14T12:34:19.126+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Starting task 6.0 in stage 33.0 (TID 67) (138.4.31.89, executor driver, partition 6, ANY, 16839 bytes)
[2025-07-14T12:34:19.126+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Finished task 5.0 in stage 33.0 (TID 66) in 14 ms on 138.4.31.89 (executor driver) (5/13)
[2025-07-14T12:34:19.126+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Running task 6.0 in stage 33.0 (TID 67)
[2025-07-14T12:34:19.129+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Finished task 4.0 in stage 33.0 (TID 65). 1945 bytes result sent to driver
[2025-07-14T12:34:19.129+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Starting task 7.0 in stage 33.0 (TID 68) (138.4.31.89, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-14T12:34:19.129+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Running task 7.0 in stage 33.0 (TID 68)
[2025-07-14T12:34:19.129+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Finished task 4.0 in stage 33.0 (TID 65) in 18 ms on 138.4.31.89 (executor driver) (6/13)
[2025-07-14T12:34:19.142+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Finished task 7.0 in stage 33.0 (TID 68). 1945 bytes result sent to driver
[2025-07-14T12:34:19.143+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Starting task 8.0 in stage 33.0 (TID 69) (138.4.31.89, executor driver, partition 8, ANY, 16839 bytes)
[2025-07-14T12:34:19.143+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Running task 8.0 in stage 33.0 (TID 69)
[2025-07-14T12:34:19.143+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Finished task 7.0 in stage 33.0 (TID 68) in 14 ms on 138.4.31.89 (executor driver) (7/13)
[2025-07-14T12:34:19.146+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Finished task 6.0 in stage 33.0 (TID 67). 1945 bytes result sent to driver
[2025-07-14T12:34:19.147+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Starting task 9.0 in stage 33.0 (TID 70) (138.4.31.89, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-14T12:34:19.147+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Running task 9.0 in stage 33.0 (TID 70)
[2025-07-14T12:34:19.147+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Finished task 6.0 in stage 33.0 (TID 67) in 21 ms on 138.4.31.89 (executor driver) (8/13)
[2025-07-14T12:34:19.162+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Finished task 9.0 in stage 33.0 (TID 70). 1945 bytes result sent to driver
[2025-07-14T12:34:19.162+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Starting task 10.0 in stage 33.0 (TID 71) (138.4.31.89, executor driver, partition 10, ANY, 16715 bytes)
[2025-07-14T12:34:19.163+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Finished task 9.0 in stage 33.0 (TID 70) in 17 ms on 138.4.31.89 (executor driver) (9/13)
[2025-07-14T12:34:19.163+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Running task 10.0 in stage 33.0 (TID 71)
[2025-07-14T12:34:19.163+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Finished task 8.0 in stage 33.0 (TID 69). 1945 bytes result sent to driver
[2025-07-14T12:34:19.163+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Starting task 11.0 in stage 33.0 (TID 72) (138.4.31.89, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-14T12:34:19.163+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Running task 11.0 in stage 33.0 (TID 72)
[2025-07-14T12:34:19.163+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Finished task 8.0 in stage 33.0 (TID 69) in 21 ms on 138.4.31.89 (executor driver) (10/13)
[2025-07-14T12:34:19.178+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Finished task 10.0 in stage 33.0 (TID 71). 1945 bytes result sent to driver
[2025-07-14T12:34:19.179+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Starting task 12.0 in stage 33.0 (TID 73) (138.4.31.89, executor driver, partition 12, ANY, 16719 bytes)
[2025-07-14T12:34:19.179+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Finished task 11.0 in stage 33.0 (TID 72). 1902 bytes result sent to driver
[2025-07-14T12:34:19.179+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Running task 12.0 in stage 33.0 (TID 73)
[2025-07-14T12:34:19.179+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Finished task 10.0 in stage 33.0 (TID 71) in 17 ms on 138.4.31.89 (executor driver) (11/13)
[2025-07-14T12:34:19.179+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Finished task 11.0 in stage 33.0 (TID 72) in 16 ms on 138.4.31.89 (executor driver) (12/13)
[2025-07-14T12:34:19.195+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Finished task 12.0 in stage 33.0 (TID 73). 1945 bytes result sent to driver
[2025-07-14T12:34:19.197+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Finished task 12.0 in stage 33.0 (TID 73) in 19 ms on 138.4.31.89 (executor driver) (13/13)
[2025-07-14T12:34:19.197+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool
[2025-07-14T12:34:19.197+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: ShuffleMapStage 33 (collect at StringIndexer.scala:204) finished in 0,142 s
[2025-07-14T12:34:19.197+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:19.197+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: running: Set(ShuffleMapStage 32)
[2025-07-14T12:34:19.197+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:19.197+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:19.201+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO ShufflePartitionsUtil: For shuffle(11), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-14T12:34:19.209+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-14T12:34:19.209+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: Got job 22 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-14T12:34:19.210+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: Final stage: ResultStage 35 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-14T12:34:19.210+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
[2025-07-14T12:34:19.210+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:19.210+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[74] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-14T12:34:19.211+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 8.2 KiB, free 429.5 MiB)
[2025-07-14T12:34:19.212+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 429.5 MiB)
[2025-07-14T12:34:19.212+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 138.4.31.89:45589 (size: 4.2 KiB, free: 434.2 MiB)
[2025-07-14T12:34:19.212+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:19.212+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[74] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:19.212+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0
[2025-07-14T12:34:19.213+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 74) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-14T12:34:19.213+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Running task 0.0 in stage 35.0 (TID 74)
[2025-07-14T12:34:19.215+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO ShuffleBlockFetcherIterator: Getting 13 (195.7 KiB) non-empty blocks including 13 (195.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:19.215+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:19.224+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Finished task 0.0 in stage 35.0 (TID 74). 40655 bytes result sent to driver
[2025-07-14T12:34:19.224+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 74) in 11 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:19.224+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool
[2025-07-14T12:34:19.224+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: ResultStage 35 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,014 s
[2025-07-14T12:34:19.225+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:19.225+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
[2025-07-14T12:34:19.225+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO DAGScheduler: Job 22 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,015813 s
[2025-07-14T12:34:19.229+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 4.3 MiB, free 425.2 MiB)
[2025-07-14T12:34:19.232+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 138.4.31.89:45589 in memory (size: 4.2 KiB, free: 434.2 MiB)
[2025-07-14T12:34:19.232+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 89.5 KiB, free 425.2 MiB)
[2025-07-14T12:34:19.232+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 138.4.31.89:45589 (size: 89.5 KiB, free: 434.1 MiB)
[2025-07-14T12:34:19.233+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO SparkContext: Created broadcast 29 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-14T12:34:19.461+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO Executor: Finished task 1.0 in stage 32.0 (TID 60). 2074 bytes result sent to driver
[2025-07-14T12:34:19.461+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 60) in 407 ms on 138.4.31.89 (executor driver) (1/2)
[2025-07-14T12:34:19.484+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 138.4.31.89:45589 in memory (size: 89.5 KiB, free: 434.2 MiB)
[2025-07-14T12:34:19.485+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 138.4.31.89:45589 in memory (size: 9.1 KiB, free: 434.2 MiB)
[2025-07-14T12:34:19.486+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 138.4.31.89:45589 in memory (size: 8.2 KiB, free: 434.2 MiB)
[2025-07-14T12:34:19.487+0200] {subprocess.py:93} INFO - 25/07/14 12:34:19 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 138.4.31.89:45589 in memory (size: 39.0 KiB, free: 434.3 MiB)
[2025-07-14T12:34:21.910+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO Executor: Finished task 0.0 in stage 32.0 (TID 59). 2074 bytes result sent to driver
[2025-07-14T12:34:21.911+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 59) in 2857 ms on 138.4.31.89 (executor driver) (2/2)
[2025-07-14T12:34:21.911+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool
[2025-07-14T12:34:21.911+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO DAGScheduler: ShuffleMapStage 32 (collect at StringIndexer.scala:204) finished in 2,859 s
[2025-07-14T12:34:21.911+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:21.911+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:21.911+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:21.911+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:21.916+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-14T12:34:21.933+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO CodeGenerator: Code generated in 5.32646 ms
[2025-07-14T12:34:21.936+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO DAGScheduler: Registering RDD 78 (collect at StringIndexer.scala:204) as input to shuffle 12
[2025-07-14T12:34:21.936+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO DAGScheduler: Got map stage job 23 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-14T12:34:21.936+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO DAGScheduler: Final stage: ShuffleMapStage 37 (collect at StringIndexer.scala:204)
[2025-07-14T12:34:21.936+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)
[2025-07-14T12:34:21.936+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:21.936+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[78] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-14T12:34:21.939+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 50.6 KiB, free 429.7 MiB)
[2025-07-14T12:34:21.940+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 24.1 KiB, free 429.7 MiB)
[2025-07-14T12:34:21.940+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 138.4.31.89:45589 (size: 24.1 KiB, free: 434.2 MiB)
[2025-07-14T12:34:21.940+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:21.941+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[78] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:21.941+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0
[2025-07-14T12:34:21.941+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 75) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14833 bytes)
[2025-07-14T12:34:21.942+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO Executor: Running task 0.0 in stage 37.0 (TID 75)
[2025-07-14T12:34:21.944+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO ShuffleBlockFetcherIterator: Getting 2 (887.5 KiB) non-empty blocks including 2 (887.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:21.944+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:21.948+0200] {subprocess.py:93} INFO - 25/07/14 12:34:21 INFO CodeGenerator: Code generated in 3.205337 ms
[2025-07-14T12:34:22.069+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Finished task 0.0 in stage 37.0 (TID 75). 6500 bytes result sent to driver
[2025-07-14T12:34:22.069+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 75) in 128 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:22.069+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool
[2025-07-14T12:34:22.069+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: ShuffleMapStage 37 (collect at StringIndexer.scala:204) finished in 0,132 s
[2025-07-14T12:34:22.070+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:22.070+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:22.070+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:22.070+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:22.078+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
[2025-07-14T12:34:22.079+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Got job 24 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-14T12:34:22.079+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Final stage: ResultStage 40 (collect at StringIndexer.scala:204)
[2025-07-14T12:34:22.079+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)
[2025-07-14T12:34:22.079+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:22.079+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[81] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-14T12:34:22.081+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 49.7 KiB, free 429.7 MiB)
[2025-07-14T12:34:22.082+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 429.6 MiB)
[2025-07-14T12:34:22.082+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 138.4.31.89:45589 (size: 23.6 KiB, free: 434.2 MiB)
[2025-07-14T12:34:22.082+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:22.082+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[81] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:22.082+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
[2025-07-14T12:34:22.083+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 76) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-14T12:34:22.083+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Running task 0.0 in stage 40.0 (TID 76)
[2025-07-14T12:34:22.086+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO ShuffleBlockFetcherIterator: Getting 1 (3.2 KiB) non-empty blocks including 1 (3.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:22.086+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:22.094+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Finished task 0.0 in stage 40.0 (TID 76). 10963 bytes result sent to driver
[2025-07-14T12:34:22.094+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 76) in 11 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:22.095+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool
[2025-07-14T12:34:22.095+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: ResultStage 40 (collect at StringIndexer.scala:204) finished in 0,015 s
[2025-07-14T12:34:22.095+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:22.095+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
[2025-07-14T12:34:22.095+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Job 24 finished: collect at StringIndexer.scala:204, took 0,016941 s
[2025-07-14T12:34:22.119+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileSystemOverwrite: Path /home/monica.fernandez/practica_creativa/models/string_indexer_model_Dest.bin already exists. It will be overwritten.
[2025-07-14T12:34:22.131+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-14T12:34:22.131+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:22.131+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:22.147+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-14T12:34:22.147+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Got job 25 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-14T12:34:22.147+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Final stage: ResultStage 41 (runJob at SparkHadoopWriter.scala:83)
[2025-07-14T12:34:22.147+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:22.147+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:22.147+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[83] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-14T12:34:22.153+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 101.3 KiB, free 429.5 MiB)
[2025-07-14T12:34:22.153+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 429.5 MiB)
[2025-07-14T12:34:22.154+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 138.4.31.89:45589 (size: 36.5 KiB, free: 434.2 MiB)
[2025-07-14T12:34:22.154+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:22.154+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[83] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:22.154+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
[2025-07-14T12:34:22.155+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 77) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15152 bytes)
[2025-07-14T12:34:22.155+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Running task 0.0 in stage 41.0 (TID 77)
[2025-07-14T12:34:22.158+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-14T12:34:22.158+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:22.158+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:22.175+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileOutputCommitter: Saved output of task 'attempt_202507141234226346307483270299616_0083_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Dest.bin/metadata/_temporary/0/task_202507141234226346307483270299616_0083_m_000000
[2025-07-14T12:34:22.175+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO SparkHadoopMapRedUtil: attempt_202507141234226346307483270299616_0083_m_000000_0: Committed. Elapsed time: 1 ms.
[2025-07-14T12:34:22.176+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Finished task 0.0 in stage 41.0 (TID 77). 1170 bytes result sent to driver
[2025-07-14T12:34:22.176+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 77) in 22 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:22.176+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool
[2025-07-14T12:34:22.177+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: ResultStage 41 (runJob at SparkHadoopWriter.scala:83) finished in 0,028 s
[2025-07-14T12:34:22.177+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:22.177+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished
[2025-07-14T12:34:22.177+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Job 25 finished: runJob at SparkHadoopWriter.scala:83, took 0,030173 s
[2025-07-14T12:34:22.177+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO SparkHadoopWriter: Start to commit write Job job_202507141234226346307483270299616_0083.
[2025-07-14T12:34:22.190+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO SparkHadoopWriter: Write Job job_202507141234226346307483270299616_0083 committed. Elapsed time: 13 ms.
[2025-07-14T12:34:22.205+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Registering RDD 86 (parquet at StringIndexer.scala:499) as input to shuffle 13
[2025-07-14T12:34:22.205+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Got map stage job 26 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-14T12:34:22.205+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Final stage: ShuffleMapStage 42 (parquet at StringIndexer.scala:499)
[2025-07-14T12:34:22.205+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:22.205+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:22.205+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[86] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-14T12:34:22.205+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 8.1 KiB, free 429.5 MiB)
[2025-07-14T12:34:22.206+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 429.5 MiB)
[2025-07-14T12:34:22.206+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 138.4.31.89:45589 (size: 4.4 KiB, free: 434.2 MiB)
[2025-07-14T12:34:22.206+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:22.206+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[86] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:22.206+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
[2025-07-14T12:34:22.207+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 78) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 20076 bytes)
[2025-07-14T12:34:22.207+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Running task 0.0 in stage 42.0 (TID 78)
[2025-07-14T12:34:22.209+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Finished task 0.0 in stage 42.0 (TID 78). 1542 bytes result sent to driver
[2025-07-14T12:34:22.209+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 78) in 2 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:22.209+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool
[2025-07-14T12:34:22.209+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: ShuffleMapStage 42 (parquet at StringIndexer.scala:499) finished in 0,004 s
[2025-07-14T12:34:22.210+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:22.210+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:22.210+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:22.210+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:22.212+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:22.213+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:22.213+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:22.213+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:22.213+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:22.213+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:22.213+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:22.223+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO SparkContext: Starting job: parquet at StringIndexer.scala:499
[2025-07-14T12:34:22.223+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Got job 27 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-14T12:34:22.223+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Final stage: ResultStage 44 (parquet at StringIndexer.scala:499)
[2025-07-14T12:34:22.223+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
[2025-07-14T12:34:22.223+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:22.224+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[88] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-14T12:34:22.233+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 239.5 KiB, free 429.3 MiB)
[2025-07-14T12:34:22.234+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 83.6 KiB, free 429.2 MiB)
[2025-07-14T12:34:22.234+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 138.4.31.89:45589 (size: 83.6 KiB, free: 434.1 MiB)
[2025-07-14T12:34:22.234+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:22.234+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[88] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:22.234+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
[2025-07-14T12:34:22.235+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 79) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-14T12:34:22.235+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Running task 0.0 in stage 44.0 (TID 79)
[2025-07-14T12:34:22.241+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:22.241+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:22.242+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:22.242+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:22.242+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:22.242+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:22.242+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:22.242+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:22.242+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO CodecConfig: Compression: SNAPPY
[2025-07-14T12:34:22.242+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO CodecConfig: Compression: SNAPPY
[2025-07-14T12:34:22.243+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO - {
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -     "name" : "labelsArray",
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -     "type" : {
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -       "type" : "array",
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -       "elementType" : {
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -         "type" : "array",
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -         "elementType" : "string",
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -         "containsNull" : true
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -       },
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -       "containsNull" : true
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -     },
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -   } ]
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO - }
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -   optional group labelsArray (LIST) {
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -     repeated group list {
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -       optional group element (LIST) {
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -         repeated group list {
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -           optional binary element (STRING);
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -         }
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -       }
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -     }
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO -   }
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO - }
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:22.244+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:22.265+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileOutputCommitter: Saved output of task 'attempt_202507141234223406610330573944021_0044_m_000000_79' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Dest.bin/data/_temporary/0/task_202507141234223406610330573944021_0044_m_000000
[2025-07-14T12:34:22.266+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO SparkHadoopMapRedUtil: attempt_202507141234223406610330573944021_0044_m_000000_79: Committed. Elapsed time: 0 ms.
[2025-07-14T12:34:22.266+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Finished task 0.0 in stage 44.0 (TID 79). 4740 bytes result sent to driver
[2025-07-14T12:34:22.267+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 79) in 32 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:22.267+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool
[2025-07-14T12:34:22.268+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: ResultStage 44 (parquet at StringIndexer.scala:499) finished in 0,043 s
[2025-07-14T12:34:22.268+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:22.268+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
[2025-07-14T12:34:22.268+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Job 27 finished: parquet at StringIndexer.scala:499, took 0,044769 s
[2025-07-14T12:34:22.268+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileFormatWriter: Start to commit write Job ce6e27f9-fad9-48e5-9f44-a389139dc21d.
[2025-07-14T12:34:22.284+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileFormatWriter: Write Job ce6e27f9-fad9-48e5-9f44-a389139dc21d committed. Elapsed time: 15 ms.
[2025-07-14T12:34:22.284+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileFormatWriter: Finished processing stats for write job ce6e27f9-fad9-48e5-9f44-a389139dc21d.
[2025-07-14T12:34:22.304+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:22.304+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-14T12:34:22.304+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-14T12:34:22.304+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-14T12:34:22.304+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:22.312+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:22.312+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68
[2025-07-14T12:34:22.312+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:22.322+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileSourceStrategy: Pushed Filters:
[2025-07-14T12:34:22.323+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-14T12:34:22.334+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO CodeGenerator: Code generated in 3.135927 ms
[2025-07-14T12:34:22.335+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 214.5 KiB, free 429.0 MiB)
[2025-07-14T12:34:22.340+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 39.0 KiB, free 428.9 MiB)
[2025-07-14T12:34:22.340+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 138.4.31.89:45589 (size: 39.0 KiB, free: 434.1 MiB)
[2025-07-14T12:34:22.340+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO SparkContext: Created broadcast 35 from collect at StringIndexer.scala:204
[2025-07-14T12:34:22.341+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-14T12:34:22.343+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Registering RDD 92 (collect at StringIndexer.scala:204) as input to shuffle 14
[2025-07-14T12:34:22.343+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Got map stage job 28 (collect at StringIndexer.scala:204) with 2 output partitions
[2025-07-14T12:34:22.343+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Final stage: ShuffleMapStage 45 (collect at StringIndexer.scala:204)
[2025-07-14T12:34:22.343+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:22.343+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:22.343+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[92] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-14T12:34:22.344+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 18.1 KiB, free 428.9 MiB)
[2025-07-14T12:34:22.344+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 428.9 MiB)
[2025-07-14T12:34:22.344+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 138.4.31.89:45589 (size: 8.7 KiB, free: 434.1 MiB)
[2025-07-14T12:34:22.345+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:22.345+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[92] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-14T12:34:22.345+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSchedulerImpl: Adding task set 45.0 with 2 tasks resource profile 0
[2025-07-14T12:34:22.345+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 80) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:22.345+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 81) (138.4.31.89, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:22.345+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Running task 0.0 in stage 45.0 (TID 80)
[2025-07-14T12:34:22.346+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Running task 1.0 in stage 45.0 (TID 81)
[2025-07-14T12:34:22.346+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Registering RDD 96 (collect at StringIndexer.scala:204) as input to shuffle 15
[2025-07-14T12:34:22.346+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Got map stage job 29 (collect at StringIndexer.scala:204) with 13 output partitions
[2025-07-14T12:34:22.346+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Final stage: ShuffleMapStage 46 (collect at StringIndexer.scala:204)
[2025-07-14T12:34:22.346+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:22.346+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:22.346+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[96] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-14T12:34:22.347+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 18.2 KiB, free 428.9 MiB)
[2025-07-14T12:34:22.347+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 428.9 MiB)
[2025-07-14T12:34:22.348+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 138.4.31.89:45589 (size: 9.0 KiB, free: 434.0 MiB)
[2025-07-14T12:34:22.348+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:22.348+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[96] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-14T12:34:22.348+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSchedulerImpl: Adding task set 46.0 with 13 tasks resource profile 0
[2025-07-14T12:34:22.349+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 82) (138.4.31.89, executor driver, partition 0, ANY, 16715 bytes)
[2025-07-14T12:34:22.349+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Starting task 1.0 in stage 46.0 (TID 83) (138.4.31.89, executor driver, partition 1, ANY, 16839 bytes)
[2025-07-14T12:34:22.349+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Running task 0.0 in stage 46.0 (TID 82)
[2025-07-14T12:34:22.349+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Running task 1.0 in stage 46.0 (TID 83)
[2025-07-14T12:34:22.350+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO CodeGenerator: Code generated in 3.19499 ms
[2025-07-14T12:34:22.352+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-14T12:34:22.352+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-14T12:34:22.367+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Finished task 0.0 in stage 46.0 (TID 82). 1945 bytes result sent to driver
[2025-07-14T12:34:22.367+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Starting task 2.0 in stage 46.0 (TID 84) (138.4.31.89, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-14T12:34:22.368+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 82) in 20 ms on 138.4.31.89 (executor driver) (1/13)
[2025-07-14T12:34:22.368+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Running task 2.0 in stage 46.0 (TID 84)
[2025-07-14T12:34:22.369+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Finished task 1.0 in stage 46.0 (TID 83). 1945 bytes result sent to driver
[2025-07-14T12:34:22.369+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Starting task 3.0 in stage 46.0 (TID 85) (138.4.31.89, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-14T12:34:22.370+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Finished task 1.0 in stage 46.0 (TID 83) in 21 ms on 138.4.31.89 (executor driver) (2/13)
[2025-07-14T12:34:22.370+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Running task 3.0 in stage 46.0 (TID 85)
[2025-07-14T12:34:22.389+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 138.4.31.89:45589 in memory (size: 4.4 KiB, free: 434.0 MiB)
[2025-07-14T12:34:22.390+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 138.4.31.89:45589 in memory (size: 36.5 KiB, free: 434.1 MiB)
[2025-07-14T12:34:22.391+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 138.4.31.89:45589 in memory (size: 24.1 KiB, free: 434.1 MiB)
[2025-07-14T12:34:22.392+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 138.4.31.89:45589 in memory (size: 83.6 KiB, free: 434.2 MiB)
[2025-07-14T12:34:22.393+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 138.4.31.89:45589 in memory (size: 23.6 KiB, free: 434.2 MiB)
[2025-07-14T12:34:22.395+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Finished task 3.0 in stage 46.0 (TID 85). 1945 bytes result sent to driver
[2025-07-14T12:34:22.396+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Starting task 4.0 in stage 46.0 (TID 86) (138.4.31.89, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-14T12:34:22.396+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Running task 4.0 in stage 46.0 (TID 86)
[2025-07-14T12:34:22.396+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Finished task 3.0 in stage 46.0 (TID 85) in 27 ms on 138.4.31.89 (executor driver) (3/13)
[2025-07-14T12:34:22.396+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Finished task 2.0 in stage 46.0 (TID 84). 1988 bytes result sent to driver
[2025-07-14T12:34:22.397+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Starting task 5.0 in stage 46.0 (TID 87) (138.4.31.89, executor driver, partition 5, ANY, 16719 bytes)
[2025-07-14T12:34:22.397+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Finished task 2.0 in stage 46.0 (TID 84) in 30 ms on 138.4.31.89 (executor driver) (4/13)
[2025-07-14T12:34:22.397+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Running task 5.0 in stage 46.0 (TID 87)
[2025-07-14T12:34:22.409+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Finished task 5.0 in stage 46.0 (TID 87). 1945 bytes result sent to driver
[2025-07-14T12:34:22.410+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Starting task 6.0 in stage 46.0 (TID 88) (138.4.31.89, executor driver, partition 6, ANY, 16839 bytes)
[2025-07-14T12:34:22.410+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Running task 6.0 in stage 46.0 (TID 88)
[2025-07-14T12:34:22.410+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Finished task 5.0 in stage 46.0 (TID 87) in 14 ms on 138.4.31.89 (executor driver) (5/13)
[2025-07-14T12:34:22.413+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Finished task 4.0 in stage 46.0 (TID 86). 1945 bytes result sent to driver
[2025-07-14T12:34:22.413+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Starting task 7.0 in stage 46.0 (TID 89) (138.4.31.89, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-14T12:34:22.414+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Finished task 4.0 in stage 46.0 (TID 86) in 19 ms on 138.4.31.89 (executor driver) (6/13)
[2025-07-14T12:34:22.414+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Running task 7.0 in stage 46.0 (TID 89)
[2025-07-14T12:34:22.424+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Finished task 7.0 in stage 46.0 (TID 89). 1902 bytes result sent to driver
[2025-07-14T12:34:22.424+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Starting task 8.0 in stage 46.0 (TID 90) (138.4.31.89, executor driver, partition 8, ANY, 16719 bytes)
[2025-07-14T12:34:22.424+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Running task 8.0 in stage 46.0 (TID 90)
[2025-07-14T12:34:22.424+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Finished task 7.0 in stage 46.0 (TID 89) in 11 ms on 138.4.31.89 (executor driver) (7/13)
[2025-07-14T12:34:22.430+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Finished task 6.0 in stage 46.0 (TID 88). 1945 bytes result sent to driver
[2025-07-14T12:34:22.431+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Starting task 9.0 in stage 46.0 (TID 91) (138.4.31.89, executor driver, partition 9, ANY, 16839 bytes)
[2025-07-14T12:34:22.431+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Finished task 6.0 in stage 46.0 (TID 88) in 21 ms on 138.4.31.89 (executor driver) (8/13)
[2025-07-14T12:34:22.431+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Running task 9.0 in stage 46.0 (TID 91)
[2025-07-14T12:34:22.437+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Finished task 8.0 in stage 46.0 (TID 90). 1945 bytes result sent to driver
[2025-07-14T12:34:22.437+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Starting task 10.0 in stage 46.0 (TID 92) (138.4.31.89, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-14T12:34:22.438+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Running task 10.0 in stage 46.0 (TID 92)
[2025-07-14T12:34:22.438+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Finished task 8.0 in stage 46.0 (TID 90) in 14 ms on 138.4.31.89 (executor driver) (9/13)
[2025-07-14T12:34:22.449+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Finished task 9.0 in stage 46.0 (TID 91). 1945 bytes result sent to driver
[2025-07-14T12:34:22.450+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Starting task 11.0 in stage 46.0 (TID 93) (138.4.31.89, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-14T12:34:22.450+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Finished task 9.0 in stage 46.0 (TID 91) in 20 ms on 138.4.31.89 (executor driver) (10/13)
[2025-07-14T12:34:22.450+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Running task 11.0 in stage 46.0 (TID 93)
[2025-07-14T12:34:22.454+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Finished task 10.0 in stage 46.0 (TID 92). 1945 bytes result sent to driver
[2025-07-14T12:34:22.454+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Starting task 12.0 in stage 46.0 (TID 94) (138.4.31.89, executor driver, partition 12, ANY, 16719 bytes)
[2025-07-14T12:34:22.454+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Running task 12.0 in stage 46.0 (TID 94)
[2025-07-14T12:34:22.454+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Finished task 10.0 in stage 46.0 (TID 92) in 17 ms on 138.4.31.89 (executor driver) (11/13)
[2025-07-14T12:34:22.469+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Finished task 11.0 in stage 46.0 (TID 93). 1988 bytes result sent to driver
[2025-07-14T12:34:22.470+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Finished task 11.0 in stage 46.0 (TID 93) in 19 ms on 138.4.31.89 (executor driver) (12/13)
[2025-07-14T12:34:22.475+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Finished task 12.0 in stage 46.0 (TID 94). 1988 bytes result sent to driver
[2025-07-14T12:34:22.475+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Finished task 12.0 in stage 46.0 (TID 94) in 21 ms on 138.4.31.89 (executor driver) (13/13)
[2025-07-14T12:34:22.475+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool
[2025-07-14T12:34:22.475+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: ShuffleMapStage 46 (collect at StringIndexer.scala:204) finished in 0,129 s
[2025-07-14T12:34:22.476+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:22.476+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: running: Set(ShuffleMapStage 45)
[2025-07-14T12:34:22.476+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:22.476+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:22.478+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-14T12:34:22.485+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-14T12:34:22.485+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Got job 30 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-14T12:34:22.485+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Final stage: ResultStage 48 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-14T12:34:22.485+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
[2025-07-14T12:34:22.485+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:22.486+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[98] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-14T12:34:22.486+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 8.2 KiB, free 429.5 MiB)
[2025-07-14T12:34:22.490+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 429.5 MiB)
[2025-07-14T12:34:22.490+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 138.4.31.89:45589 (size: 4.2 KiB, free: 434.2 MiB)
[2025-07-14T12:34:22.490+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:22.490+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[98] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:22.490+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
[2025-07-14T12:34:22.491+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 95) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-14T12:34:22.491+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Running task 0.0 in stage 48.0 (TID 95)
[2025-07-14T12:34:22.494+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO ShuffleBlockFetcherIterator: Getting 13 (195.7 KiB) non-empty blocks including 13 (195.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:22.495+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-14T12:34:22.514+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 138.4.31.89:45589 in memory (size: 39.0 KiB, free: 434.2 MiB)
[2025-07-14T12:34:22.514+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Finished task 0.0 in stage 48.0 (TID 95). 40603 bytes result sent to driver
[2025-07-14T12:34:22.515+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 95) in 24 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:22.515+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool
[2025-07-14T12:34:22.515+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: ResultStage 48 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,029 s
[2025-07-14T12:34:22.515+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:22.515+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
[2025-07-14T12:34:22.515+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO DAGScheduler: Job 30 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,030466 s
[2025-07-14T12:34:22.516+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 138.4.31.89:45589 in memory (size: 8.2 KiB, free: 434.3 MiB)
[2025-07-14T12:34:22.517+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 138.4.31.89:45589 in memory (size: 9.0 KiB, free: 434.3 MiB)
[2025-07-14T12:34:22.518+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 138.4.31.89:45589 in memory (size: 89.5 KiB, free: 434.3 MiB)
[2025-07-14T12:34:22.525+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 4.3 MiB, free 429.9 MiB)
[2025-07-14T12:34:22.526+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 89.4 KiB, free 429.8 MiB)
[2025-07-14T12:34:22.526+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 138.4.31.89:45589 (size: 89.4 KiB, free: 434.3 MiB)
[2025-07-14T12:34:22.528+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO SparkContext: Created broadcast 39 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-14T12:34:22.769+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO Executor: Finished task 1.0 in stage 45.0 (TID 81). 2031 bytes result sent to driver
[2025-07-14T12:34:22.770+0200] {subprocess.py:93} INFO - 25/07/14 12:34:22 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 81) in 425 ms on 138.4.31.89 (executor driver) (1/2)
[2025-07-14T12:34:23.010+0200] {subprocess.py:93} INFO - 25/07/14 12:34:23 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 138.4.31.89:45589 in memory (size: 4.2 KiB, free: 434.3 MiB)
[2025-07-14T12:34:25.231+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Finished task 0.0 in stage 45.0 (TID 80). 2074 bytes result sent to driver
[2025-07-14T12:34:25.231+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 80) in 2886 ms on 138.4.31.89 (executor driver) (2/2)
[2025-07-14T12:34:25.231+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool
[2025-07-14T12:34:25.232+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: ShuffleMapStage 45 (collect at StringIndexer.scala:204) finished in 2,888 s
[2025-07-14T12:34:25.232+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:25.232+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:25.232+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:25.232+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:25.234+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-14T12:34:25.248+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO CodeGenerator: Code generated in 6.622139 ms
[2025-07-14T12:34:25.250+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Registering RDD 102 (collect at StringIndexer.scala:204) as input to shuffle 16
[2025-07-14T12:34:25.250+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Got map stage job 31 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-14T12:34:25.250+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Final stage: ShuffleMapStage 50 (collect at StringIndexer.scala:204)
[2025-07-14T12:34:25.250+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 49)
[2025-07-14T12:34:25.250+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:25.250+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[102] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-14T12:34:25.253+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 51.4 KiB, free 429.7 MiB)
[2025-07-14T12:34:25.254+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 429.7 MiB)
[2025-07-14T12:34:25.254+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 138.4.31.89:45589 (size: 24.3 KiB, free: 434.2 MiB)
[2025-07-14T12:34:25.254+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:25.255+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[102] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:25.255+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks resource profile 0
[2025-07-14T12:34:25.255+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 96) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14833 bytes)
[2025-07-14T12:34:25.256+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Running task 0.0 in stage 50.0 (TID 96)
[2025-07-14T12:34:25.258+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO ShuffleBlockFetcherIterator: Getting 2 (1220.4 KiB) non-empty blocks including 2 (1220.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:25.258+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:25.262+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO CodeGenerator: Code generated in 2.993208 ms
[2025-07-14T12:34:25.392+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Finished task 0.0 in stage 50.0 (TID 96). 6500 bytes result sent to driver
[2025-07-14T12:34:25.393+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 96) in 138 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:25.393+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool
[2025-07-14T12:34:25.393+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: ShuffleMapStage 50 (collect at StringIndexer.scala:204) finished in 0,143 s
[2025-07-14T12:34:25.393+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:25.393+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:25.393+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:25.393+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:25.401+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
[2025-07-14T12:34:25.401+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Got job 32 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-14T12:34:25.401+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Final stage: ResultStage 53 (collect at StringIndexer.scala:204)
[2025-07-14T12:34:25.401+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
[2025-07-14T12:34:25.401+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:25.401+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[105] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-14T12:34:25.402+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 50.5 KiB, free 429.7 MiB)
[2025-07-14T12:34:25.403+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 429.6 MiB)
[2025-07-14T12:34:25.403+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 138.4.31.89:45589 (size: 24.0 KiB, free: 434.2 MiB)
[2025-07-14T12:34:25.403+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:25.403+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[105] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:25.403+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0
[2025-07-14T12:34:25.404+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 97) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-14T12:34:25.404+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Running task 0.0 in stage 53.0 (TID 97)
[2025-07-14T12:34:25.406+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO ShuffleBlockFetcherIterator: Getting 1 (46.5 KiB) non-empty blocks including 1 (46.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:25.406+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:25.417+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Finished task 0.0 in stage 53.0 (TID 97). 53379 bytes result sent to driver
[2025-07-14T12:34:25.418+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 97) in 13 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:25.418+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool
[2025-07-14T12:34:25.418+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: ResultStage 53 (collect at StringIndexer.scala:204) finished in 0,017 s
[2025-07-14T12:34:25.418+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:25.418+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
[2025-07-14T12:34:25.418+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Job 32 finished: collect at StringIndexer.scala:204, took 0,017267 s
[2025-07-14T12:34:25.443+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileSystemOverwrite: Path /home/monica.fernandez/practica_creativa/models/string_indexer_model_Route.bin already exists. It will be overwritten.
[2025-07-14T12:34:25.455+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-14T12:34:25.455+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:25.455+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:25.470+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-14T12:34:25.470+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Got job 33 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-14T12:34:25.470+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Final stage: ResultStage 54 (runJob at SparkHadoopWriter.scala:83)
[2025-07-14T12:34:25.470+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:25.470+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:25.470+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[107] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-14T12:34:25.474+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 101.3 KiB, free 429.5 MiB)
[2025-07-14T12:34:25.475+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 429.5 MiB)
[2025-07-14T12:34:25.475+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 138.4.31.89:45589 (size: 36.5 KiB, free: 434.2 MiB)
[2025-07-14T12:34:25.475+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:25.475+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[107] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:25.475+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks resource profile 0
[2025-07-14T12:34:25.476+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 98) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15154 bytes)
[2025-07-14T12:34:25.476+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Running task 0.0 in stage 54.0 (TID 98)
[2025-07-14T12:34:25.479+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-14T12:34:25.479+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:25.479+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:25.494+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileOutputCommitter: Saved output of task 'attempt_202507141234257942079257474003416_0107_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Route.bin/metadata/_temporary/0/task_202507141234257942079257474003416_0107_m_000000
[2025-07-14T12:34:25.494+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkHadoopMapRedUtil: attempt_202507141234257942079257474003416_0107_m_000000_0: Committed. Elapsed time: 0 ms.
[2025-07-14T12:34:25.495+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Finished task 0.0 in stage 54.0 (TID 98). 1170 bytes result sent to driver
[2025-07-14T12:34:25.495+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 98) in 19 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:25.495+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool
[2025-07-14T12:34:25.495+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: ResultStage 54 (runJob at SparkHadoopWriter.scala:83) finished in 0,025 s
[2025-07-14T12:34:25.495+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:25.495+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished
[2025-07-14T12:34:25.495+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Job 33 finished: runJob at SparkHadoopWriter.scala:83, took 0,025812 s
[2025-07-14T12:34:25.496+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkHadoopWriter: Start to commit write Job job_202507141234257942079257474003416_0107.
[2025-07-14T12:34:25.508+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkHadoopWriter: Write Job job_202507141234257942079257474003416_0107 committed. Elapsed time: 12 ms.
[2025-07-14T12:34:25.521+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Registering RDD 110 (parquet at StringIndexer.scala:499) as input to shuffle 17
[2025-07-14T12:34:25.521+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Got map stage job 34 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-14T12:34:25.521+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Final stage: ShuffleMapStage 55 (parquet at StringIndexer.scala:499)
[2025-07-14T12:34:25.521+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:25.521+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:25.521+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Submitting ShuffleMapStage 55 (MapPartitionsRDD[110] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-14T12:34:25.522+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 8.1 KiB, free 429.5 MiB)
[2025-07-14T12:34:25.522+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 429.5 MiB)
[2025-07-14T12:34:25.523+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 138.4.31.89:45589 (size: 4.4 KiB, free: 434.2 MiB)
[2025-07-14T12:34:25.523+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:25.523+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 55 (MapPartitionsRDD[110] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:25.523+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0
[2025-07-14T12:34:25.523+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 99) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 82517 bytes)
[2025-07-14T12:34:25.524+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Running task 0.0 in stage 55.0 (TID 99)
[2025-07-14T12:34:25.526+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Finished task 0.0 in stage 55.0 (TID 99). 1542 bytes result sent to driver
[2025-07-14T12:34:25.526+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 99) in 3 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:25.526+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool
[2025-07-14T12:34:25.526+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: ShuffleMapStage 55 (parquet at StringIndexer.scala:499) finished in 0,005 s
[2025-07-14T12:34:25.526+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:25.526+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:25.526+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:25.526+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:25.529+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:25.529+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:25.529+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:25.529+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:25.529+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:25.529+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:25.529+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:25.538+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkContext: Starting job: parquet at StringIndexer.scala:499
[2025-07-14T12:34:25.539+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Got job 35 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-14T12:34:25.539+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Final stage: ResultStage 57 (parquet at StringIndexer.scala:499)
[2025-07-14T12:34:25.539+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
[2025-07-14T12:34:25.539+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:25.539+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[112] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-14T12:34:25.547+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 239.5 KiB, free 429.3 MiB)
[2025-07-14T12:34:25.548+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 83.7 KiB, free 429.2 MiB)
[2025-07-14T12:34:25.548+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 138.4.31.89:45589 (size: 83.7 KiB, free: 434.1 MiB)
[2025-07-14T12:34:25.548+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:25.549+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[112] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:25.549+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0
[2025-07-14T12:34:25.549+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 100) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-14T12:34:25.549+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Running task 0.0 in stage 57.0 (TID 100)
[2025-07-14T12:34:25.555+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO ShuffleBlockFetcherIterator: Getting 1 (42.2 KiB) non-empty blocks including 1 (42.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:25.555+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:25.555+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:25.555+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:25.556+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:25.556+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:25.556+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:25.556+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:25.556+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO CodecConfig: Compression: SNAPPY
[2025-07-14T12:34:25.556+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO CodecConfig: Compression: SNAPPY
[2025-07-14T12:34:25.556+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO - {
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -     "name" : "labelsArray",
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -     "type" : {
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -       "type" : "array",
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -       "elementType" : {
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -         "type" : "array",
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -         "elementType" : "string",
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -         "containsNull" : true
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -       },
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -       "containsNull" : true
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -     },
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -   } ]
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO - }
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -   optional group labelsArray (LIST) {
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -     repeated group list {
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -       optional group element (LIST) {
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -         repeated group list {
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -           optional binary element (STRING);
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -         }
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -       }
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -     }
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO -   }
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO - }
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:25.557+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:25.578+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileOutputCommitter: Saved output of task 'attempt_202507141234258065816238911455909_0057_m_000000_100' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Route.bin/data/_temporary/0/task_202507141234258065816238911455909_0057_m_000000
[2025-07-14T12:34:25.578+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkHadoopMapRedUtil: attempt_202507141234258065816238911455909_0057_m_000000_100: Committed. Elapsed time: 0 ms.
[2025-07-14T12:34:25.578+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Finished task 0.0 in stage 57.0 (TID 100). 4740 bytes result sent to driver
[2025-07-14T12:34:25.579+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 100) in 30 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:25.579+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool
[2025-07-14T12:34:25.579+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: ResultStage 57 (parquet at StringIndexer.scala:499) finished in 0,040 s
[2025-07-14T12:34:25.579+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:25.579+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
[2025-07-14T12:34:25.579+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Job 35 finished: parquet at StringIndexer.scala:499, took 0,040897 s
[2025-07-14T12:34:25.580+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileFormatWriter: Start to commit write Job 5a169646-719a-44f8-a441-96f85dd3f43e.
[2025-07-14T12:34:25.593+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileFormatWriter: Write Job 5a169646-719a-44f8-a441-96f85dd3f43e committed. Elapsed time: 12 ms.
[2025-07-14T12:34:25.593+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileFormatWriter: Finished processing stats for write job 5a169646-719a-44f8-a441-96f85dd3f43e.
[2025-07-14T12:34:25.618+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileSystemOverwrite: Path /home/monica.fernandez/practica_creativa/models/numeric_vector_assembler.bin already exists. It will be overwritten.
[2025-07-14T12:34:25.625+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-14T12:34:25.625+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:25.625+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:25.640+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-14T12:34:25.640+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Got job 36 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-14T12:34:25.640+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Final stage: ResultStage 58 (runJob at SparkHadoopWriter.scala:83)
[2025-07-14T12:34:25.640+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:25.640+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:25.640+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[114] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-14T12:34:25.644+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 101.3 KiB, free 429.1 MiB)
[2025-07-14T12:34:25.645+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 429.0 MiB)
[2025-07-14T12:34:25.645+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 138.4.31.89:45589 (size: 36.5 KiB, free: 434.1 MiB)
[2025-07-14T12:34:25.645+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:25.646+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[114] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:25.646+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0
[2025-07-14T12:34:25.646+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 101) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15234 bytes)
[2025-07-14T12:34:25.646+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Running task 0.0 in stage 58.0 (TID 101)
[2025-07-14T12:34:25.649+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-14T12:34:25.649+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:25.649+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:25.664+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileOutputCommitter: Saved output of task 'attempt_202507141234254959061009376031310_0114_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/numeric_vector_assembler.bin/metadata/_temporary/0/task_202507141234254959061009376031310_0114_m_000000
[2025-07-14T12:34:25.664+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkHadoopMapRedUtil: attempt_202507141234254959061009376031310_0114_m_000000_0: Committed. Elapsed time: 0 ms.
[2025-07-14T12:34:25.664+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Finished task 0.0 in stage 58.0 (TID 101). 1170 bytes result sent to driver
[2025-07-14T12:34:25.665+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 101) in 19 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:25.665+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool
[2025-07-14T12:34:25.665+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: ResultStage 58 (runJob at SparkHadoopWriter.scala:83) finished in 0,025 s
[2025-07-14T12:34:25.665+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:25.665+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 58: Stage finished
[2025-07-14T12:34:25.665+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Job 36 finished: runJob at SparkHadoopWriter.scala:83, took 0,025380 s
[2025-07-14T12:34:25.665+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkHadoopWriter: Start to commit write Job job_202507141234254959061009376031310_0114.
[2025-07-14T12:34:25.678+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkHadoopWriter: Write Job job_202507141234254959061009376031310_0114 committed. Elapsed time: 12 ms.
[2025-07-14T12:34:25.715+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:25.715+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-14T12:34:25.715+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-14T12:34:25.715+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-14T12:34:25.715+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:25.723+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:25.723+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-14T12:34:25.723+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:25.736+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileSourceStrategy: Pushed Filters:
[2025-07-14T12:34:25.736+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-14T12:34:25.755+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO CodeGenerator: Code generated in 4.326934 ms
[2025-07-14T12:34:25.756+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 214.5 KiB, free 428.8 MiB)
[2025-07-14T12:34:25.760+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 39.0 KiB, free 428.8 MiB)
[2025-07-14T12:34:25.761+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 138.4.31.89:45589 (size: 39.0 KiB, free: 434.0 MiB)
[2025-07-14T12:34:25.761+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkContext: Created broadcast 46 from showString at NativeMethodAccessorImpl.java:0
[2025-07-14T12:34:25.761+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-14T12:34:25.763+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Registering RDD 118 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 18
[2025-07-14T12:34:25.763+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Got map stage job 37 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-07-14T12:34:25.763+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Final stage: ShuffleMapStage 59 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-14T12:34:25.763+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:25.763+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:25.763+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Submitting ShuffleMapStage 59 (MapPartitionsRDD[118] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-14T12:34:25.764+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 22.8 KiB, free 428.8 MiB)
[2025-07-14T12:34:25.765+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 428.8 MiB)
[2025-07-14T12:34:25.765+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 138.4.31.89:45589 (size: 9.9 KiB, free: 434.0 MiB)
[2025-07-14T12:34:25.765+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:25.765+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 59 (MapPartitionsRDD[118] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-14T12:34:25.765+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Adding task set 59.0 with 2 tasks resource profile 0
[2025-07-14T12:34:25.766+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Registering RDD 122 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 19
[2025-07-14T12:34:25.766+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Got map stage job 38 (showString at NativeMethodAccessorImpl.java:0) with 13 output partitions
[2025-07-14T12:34:25.766+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Final stage: ShuffleMapStage 60 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-14T12:34:25.766+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:25.766+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:25.766+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 102) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:25.766+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[122] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-14T12:34:25.766+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Starting task 1.0 in stage 59.0 (TID 103) (138.4.31.89, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:25.766+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Running task 0.0 in stage 59.0 (TID 102)
[2025-07-14T12:34:25.766+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Running task 1.0 in stage 59.0 (TID 103)
[2025-07-14T12:34:25.767+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 18.7 KiB, free 428.7 MiB)
[2025-07-14T12:34:25.768+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 428.7 MiB)
[2025-07-14T12:34:25.768+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 138.4.31.89:45589 (size: 9.2 KiB, free: 434.0 MiB)
[2025-07-14T12:34:25.768+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:25.768+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[122] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-14T12:34:25.768+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Adding task set 60.0 with 13 tasks resource profile 0
[2025-07-14T12:34:25.769+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 104) (138.4.31.89, executor driver, partition 0, ANY, 16719 bytes)
[2025-07-14T12:34:25.769+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 105) (138.4.31.89, executor driver, partition 1, ANY, 16839 bytes)
[2025-07-14T12:34:25.770+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Running task 1.0 in stage 60.0 (TID 105)
[2025-07-14T12:34:25.770+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Running task 0.0 in stage 60.0 (TID 104)
[2025-07-14T12:34:25.772+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO CodeGenerator: Code generated in 4.053419 ms
[2025-07-14T12:34:25.776+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO CodeGenerator: Code generated in 3.065189 ms
[2025-07-14T12:34:25.776+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-14T12:34:25.776+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-14T12:34:25.782+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Finished task 0.0 in stage 60.0 (TID 104). 1945 bytes result sent to driver
[2025-07-14T12:34:25.783+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Starting task 2.0 in stage 60.0 (TID 106) (138.4.31.89, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-14T12:34:25.783+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO CodeGenerator: Code generated in 4.856385 ms
[2025-07-14T12:34:25.783+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Running task 2.0 in stage 60.0 (TID 106)
[2025-07-14T12:34:25.783+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 104) in 14 ms on 138.4.31.89 (executor driver) (1/13)
[2025-07-14T12:34:25.789+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Finished task 1.0 in stage 60.0 (TID 105). 1945 bytes result sent to driver
[2025-07-14T12:34:25.790+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Starting task 3.0 in stage 60.0 (TID 107) (138.4.31.89, executor driver, partition 3, ANY, 16715 bytes)
[2025-07-14T12:34:25.790+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Running task 3.0 in stage 60.0 (TID 107)
[2025-07-14T12:34:25.790+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 105) in 21 ms on 138.4.31.89 (executor driver) (2/13)
[2025-07-14T12:34:25.796+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Finished task 2.0 in stage 60.0 (TID 106). 1945 bytes result sent to driver
[2025-07-14T12:34:25.797+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Starting task 4.0 in stage 60.0 (TID 108) (138.4.31.89, executor driver, partition 4, ANY, 16839 bytes)
[2025-07-14T12:34:25.797+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Running task 4.0 in stage 60.0 (TID 108)
[2025-07-14T12:34:25.797+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Finished task 2.0 in stage 60.0 (TID 106) in 14 ms on 138.4.31.89 (executor driver) (3/13)
[2025-07-14T12:34:25.802+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 138.4.31.89:45589 in memory (size: 36.5 KiB, free: 434.0 MiB)
[2025-07-14T12:34:25.803+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 138.4.31.89:45589 in memory (size: 24.3 KiB, free: 434.1 MiB)
[2025-07-14T12:34:25.803+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 138.4.31.89:45589 in memory (size: 4.4 KiB, free: 434.1 MiB)
[2025-07-14T12:34:25.804+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 138.4.31.89:45589 in memory (size: 24.0 KiB, free: 434.1 MiB)
[2025-07-14T12:34:25.804+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 138.4.31.89:45589 in memory (size: 36.5 KiB, free: 434.1 MiB)
[2025-07-14T12:34:25.805+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 138.4.31.89:45589 in memory (size: 83.7 KiB, free: 434.2 MiB)
[2025-07-14T12:34:25.818+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Finished task 3.0 in stage 60.0 (TID 107). 1988 bytes result sent to driver
[2025-07-14T12:34:25.818+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Starting task 5.0 in stage 60.0 (TID 109) (138.4.31.89, executor driver, partition 5, ANY, 16719 bytes)
[2025-07-14T12:34:25.818+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Finished task 3.0 in stage 60.0 (TID 107) in 29 ms on 138.4.31.89 (executor driver) (4/13)
[2025-07-14T12:34:25.818+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Running task 5.0 in stage 60.0 (TID 109)
[2025-07-14T12:34:25.829+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Finished task 4.0 in stage 60.0 (TID 108). 1988 bytes result sent to driver
[2025-07-14T12:34:25.829+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Starting task 6.0 in stage 60.0 (TID 110) (138.4.31.89, executor driver, partition 6, ANY, 16719 bytes)
[2025-07-14T12:34:25.829+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Running task 6.0 in stage 60.0 (TID 110)
[2025-07-14T12:34:25.829+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Finished task 4.0 in stage 60.0 (TID 108) in 33 ms on 138.4.31.89 (executor driver) (5/13)
[2025-07-14T12:34:25.838+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Finished task 5.0 in stage 60.0 (TID 109). 1945 bytes result sent to driver
[2025-07-14T12:34:25.838+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Starting task 7.0 in stage 60.0 (TID 111) (138.4.31.89, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-14T12:34:25.838+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Running task 7.0 in stage 60.0 (TID 111)
[2025-07-14T12:34:25.839+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Finished task 5.0 in stage 60.0 (TID 109) in 20 ms on 138.4.31.89 (executor driver) (6/13)
[2025-07-14T12:34:25.845+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Finished task 6.0 in stage 60.0 (TID 110). 1945 bytes result sent to driver
[2025-07-14T12:34:25.846+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Starting task 8.0 in stage 60.0 (TID 112) (138.4.31.89, executor driver, partition 8, ANY, 16839 bytes)
[2025-07-14T12:34:25.846+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Running task 8.0 in stage 60.0 (TID 112)
[2025-07-14T12:34:25.846+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Finished task 6.0 in stage 60.0 (TID 110) in 17 ms on 138.4.31.89 (executor driver) (7/13)
[2025-07-14T12:34:25.854+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Finished task 7.0 in stage 60.0 (TID 111). 1945 bytes result sent to driver
[2025-07-14T12:34:25.855+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Starting task 9.0 in stage 60.0 (TID 113) (138.4.31.89, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-14T12:34:25.855+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Finished task 7.0 in stage 60.0 (TID 111) in 17 ms on 138.4.31.89 (executor driver) (8/13)
[2025-07-14T12:34:25.855+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Running task 9.0 in stage 60.0 (TID 113)
[2025-07-14T12:34:25.864+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Finished task 8.0 in stage 60.0 (TID 112). 1945 bytes result sent to driver
[2025-07-14T12:34:25.864+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Starting task 10.0 in stage 60.0 (TID 114) (138.4.31.89, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-14T12:34:25.864+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Running task 10.0 in stage 60.0 (TID 114)
[2025-07-14T12:34:25.864+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Finished task 8.0 in stage 60.0 (TID 112) in 18 ms on 138.4.31.89 (executor driver) (9/13)
[2025-07-14T12:34:25.870+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Finished task 9.0 in stage 60.0 (TID 113). 1945 bytes result sent to driver
[2025-07-14T12:34:25.870+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Starting task 11.0 in stage 60.0 (TID 115) (138.4.31.89, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-14T12:34:25.870+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Finished task 9.0 in stage 60.0 (TID 113) in 15 ms on 138.4.31.89 (executor driver) (10/13)
[2025-07-14T12:34:25.870+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Running task 11.0 in stage 60.0 (TID 115)
[2025-07-14T12:34:25.881+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Finished task 10.0 in stage 60.0 (TID 114). 1902 bytes result sent to driver
[2025-07-14T12:34:25.881+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Starting task 12.0 in stage 60.0 (TID 116) (138.4.31.89, executor driver, partition 12, ANY, 16719 bytes)
[2025-07-14T12:34:25.882+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Finished task 10.0 in stage 60.0 (TID 114) in 17 ms on 138.4.31.89 (executor driver) (11/13)
[2025-07-14T12:34:25.882+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Running task 12.0 in stage 60.0 (TID 116)
[2025-07-14T12:34:25.886+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Finished task 11.0 in stage 60.0 (TID 115). 1902 bytes result sent to driver
[2025-07-14T12:34:25.886+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Finished task 11.0 in stage 60.0 (TID 115) in 16 ms on 138.4.31.89 (executor driver) (12/13)
[2025-07-14T12:34:25.899+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Finished task 12.0 in stage 60.0 (TID 116). 1988 bytes result sent to driver
[2025-07-14T12:34:25.900+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Finished task 12.0 in stage 60.0 (TID 116) in 19 ms on 138.4.31.89 (executor driver) (13/13)
[2025-07-14T12:34:25.900+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool
[2025-07-14T12:34:25.900+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: ShuffleMapStage 60 (showString at NativeMethodAccessorImpl.java:0) finished in 0,133 s
[2025-07-14T12:34:25.900+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:25.900+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: running: Set(ShuffleMapStage 59)
[2025-07-14T12:34:25.900+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:25.900+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:25.911+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO ShufflePartitionsUtil: For shuffle(19), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-14T12:34:25.918+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-14T12:34:25.918+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Got job 39 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-14T12:34:25.918+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Final stage: ResultStage 62 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-14T12:34:25.918+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)
[2025-07-14T12:34:25.919+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:25.919+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[124] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-14T12:34:25.920+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 8.2 KiB, free 429.5 MiB)
[2025-07-14T12:34:25.926+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 429.5 MiB)
[2025-07-14T12:34:25.926+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 138.4.31.89:45589 (size: 4.2 KiB, free: 434.2 MiB)
[2025-07-14T12:34:25.926+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:25.926+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[124] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:25.926+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0
[2025-07-14T12:34:25.927+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 117) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-14T12:34:25.927+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Running task 0.0 in stage 62.0 (TID 117)
[2025-07-14T12:34:25.930+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO ShuffleBlockFetcherIterator: Getting 13 (217.3 KiB) non-empty blocks including 13 (217.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:25.930+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-14T12:34:25.950+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 138.4.31.89:45589 in memory (size: 9.2 KiB, free: 434.2 MiB)
[2025-07-14T12:34:25.950+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO Executor: Finished task 0.0 in stage 62.0 (TID 117). 51449 bytes result sent to driver
[2025-07-14T12:34:25.951+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 138.4.31.89:45589 in memory (size: 89.4 KiB, free: 434.3 MiB)
[2025-07-14T12:34:25.951+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 117) in 24 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:25.951+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool
[2025-07-14T12:34:25.951+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 138.4.31.89:45589 in memory (size: 39.0 KiB, free: 434.3 MiB)
[2025-07-14T12:34:25.951+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: ResultStage 62 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,032 s
[2025-07-14T12:34:25.951+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:25.951+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 62: Stage finished
[2025-07-14T12:34:25.952+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO DAGScheduler: Job 39 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,033547 s
[2025-07-14T12:34:25.952+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 138.4.31.89:45589 in memory (size: 8.7 KiB, free: 434.3 MiB)
[2025-07-14T12:34:25.961+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 4.3 MiB, free 429.9 MiB)
[2025-07-14T12:34:25.962+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 109.6 KiB, free 429.8 MiB)
[2025-07-14T12:34:25.962+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 138.4.31.89:45589 (size: 109.6 KiB, free: 434.2 MiB)
[2025-07-14T12:34:25.962+0200] {subprocess.py:93} INFO - 25/07/14 12:34:25 INFO SparkContext: Created broadcast 50 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-14T12:34:26.133+0200] {subprocess.py:93} INFO - 25/07/14 12:34:26 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 138.4.31.89:45589 in memory (size: 4.2 KiB, free: 434.2 MiB)
[2025-07-14T12:34:26.498+0200] {subprocess.py:93} INFO - 25/07/14 12:34:26 INFO Executor: Finished task 1.0 in stage 59.0 (TID 103). 2074 bytes result sent to driver
[2025-07-14T12:34:26.498+0200] {subprocess.py:93} INFO - 25/07/14 12:34:26 INFO TaskSetManager: Finished task 1.0 in stage 59.0 (TID 103) in 732 ms on 138.4.31.89 (executor driver) (1/2)
[2025-07-14T12:34:29.965+0200] {subprocess.py:93} INFO - 25/07/14 12:34:29 INFO Executor: Finished task 0.0 in stage 59.0 (TID 102). 2031 bytes result sent to driver
[2025-07-14T12:34:29.966+0200] {subprocess.py:93} INFO - 25/07/14 12:34:29 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 102) in 4200 ms on 138.4.31.89 (executor driver) (2/2)
[2025-07-14T12:34:29.966+0200] {subprocess.py:93} INFO - 25/07/14 12:34:29 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool
[2025-07-14T12:34:29.966+0200] {subprocess.py:93} INFO - 25/07/14 12:34:29 INFO DAGScheduler: ShuffleMapStage 59 (showString at NativeMethodAccessorImpl.java:0) finished in 4,203 s
[2025-07-14T12:34:29.966+0200] {subprocess.py:93} INFO - 25/07/14 12:34:29 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:29.966+0200] {subprocess.py:93} INFO - 25/07/14 12:34:29 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:29.966+0200] {subprocess.py:93} INFO - 25/07/14 12:34:29 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:29.966+0200] {subprocess.py:93} INFO - 25/07/14 12:34:29 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:29.983+0200] {subprocess.py:93} INFO - 25/07/14 12:34:29 INFO ShufflePartitionsUtil: For shuffle(18), advisory target size: 67108864, actual target size 4228400, minimum partition size: 1048576
[2025-07-14T12:34:30.037+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO CodeGenerator: Code generated in 17.755496 ms
[2025-07-14T12:34:30.054+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2025-07-14T12:34:30.054+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Got job 40 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-07-14T12:34:30.054+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Final stage: ResultStage 64 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-14T12:34:30.054+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)
[2025-07-14T12:34:30.054+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:30.054+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[127] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-14T12:34:30.057+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 207.0 KiB, free 429.6 MiB)
[2025-07-14T12:34:30.058+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 99.7 KiB, free 429.5 MiB)
[2025-07-14T12:34:30.058+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 138.4.31.89:45589 (size: 99.7 KiB, free: 434.1 MiB)
[2025-07-14T12:34:30.058+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:30.058+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[127] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:30.058+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0
[2025-07-14T12:34:30.059+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 118) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14847 bytes)
[2025-07-14T12:34:30.059+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Running task 0.0 in stage 64.0 (TID 118)
[2025-07-14T12:34:30.071+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO ShuffleBlockFetcherIterator: Getting 1 (7.1 MiB) non-empty blocks including 1 (7.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:30.071+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:30.081+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO CodeGenerator: Code generated in 10.058776 ms
[2025-07-14T12:34:30.084+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO CodeGenerator: Code generated in 1.755076 ms
[2025-07-14T12:34:30.094+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO CodeGenerator: Code generated in 3.035031 ms
[2025-07-14T12:34:30.099+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Finished task 0.0 in stage 64.0 (TID 118). 4916 bytes result sent to driver
[2025-07-14T12:34:30.099+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 118) in 40 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:30.100+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool
[2025-07-14T12:34:30.100+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: ResultStage 64 (showString at NativeMethodAccessorImpl.java:0) finished in 0,046 s
[2025-07-14T12:34:30.100+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:30.100+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished
[2025-07-14T12:34:30.100+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Job 40 finished: showString at NativeMethodAccessorImpl.java:0, took 0,046365 s
[2025-07-14T12:34:30.106+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO CodeGenerator: Code generated in 3.695104 ms
[2025-07-14T12:34:30.107+0200] {subprocess.py:93} INFO - +--------+-------------------+-------------------+----------+---------+---------+--------+----------+---------+--------+--------------+--------------------+
[2025-07-14T12:34:30.107+0200] {subprocess.py:93} INFO - |ArrDelay|         CRSArrTime|         CRSDepTime|DayOfMonth|DayOfWeek|DayOfYear|DepDelay|FlightDate|FlightNum|Distance|ArrDelayBucket|        Features_vec|
[2025-07-14T12:34:30.107+0200] {subprocess.py:93} INFO - +--------+-------------------+-------------------+----------+---------+---------+--------+----------+---------+--------+--------------+--------------------+
[2025-07-14T12:34:30.107+0200] {subprocess.py:93} INFO - |   -19.0|2015-01-01 19:25:00|2015-01-01 16:50:00|         1|        4|        1|     3.0|2015-01-01|       99|  1739.0|           0.0|[3.0,1739.0,1.0,4...|
[2025-07-14T12:34:30.107+0200] {subprocess.py:93} INFO - |    -3.0|2015-01-01 19:40:00|2015-01-01 17:25:00|         1|        4|        1|    -4.0|2015-01-01|     1576|   338.0|           1.0|[-4.0,338.0,1.0,4...|
[2025-07-14T12:34:30.108+0200] {subprocess.py:93} INFO - |   -30.0|2015-01-01 21:20:00|2015-01-01 18:30:00|         1|        4|        1|    -7.0|2015-01-01|      675|  1739.0|           0.0|[-7.0,1739.0,1.0,...|
[2025-07-14T12:34:30.108+0200] {subprocess.py:93} INFO - |    20.0|2015-01-01 06:00:00|2015-01-01 04:07:00|         1|        4|        1|    -3.0|2015-01-01|     1030|  1129.0|           2.0|[-3.0,1129.0,1.0,...|
[2025-07-14T12:34:30.108+0200] {subprocess.py:93} INFO - |    -7.0|2015-01-01 07:13:00|2015-01-01 05:19:00|         1|        4|        1|     4.0|2015-01-01|      730|  1129.0|           1.0|[4.0,1129.0,1.0,4...|
[2025-07-14T12:34:30.108+0200] {subprocess.py:93} INFO - |   -10.0|2015-01-01 14:20:00|2015-01-01 12:05:00|         1|        4|        1|   -12.0|2015-01-01|      634|   857.0|           1.0|[-12.0,857.0,1.0,...|
[2025-07-14T12:34:30.108+0200] {subprocess.py:93} INFO - |    -4.0|2015-01-01 18:45:00|2015-01-01 16:29:00|         1|        4|        1|    -4.0|2015-01-01|      934|   857.0|           1.0|[-4.0,857.0,1.0,4...|
[2025-07-14T12:34:30.108+0200] {subprocess.py:93} INFO - |   -10.0|2015-01-01 21:33:00|2015-01-01 20:35:00|         1|        4|        1|    -5.0|2015-01-01|     1209|   153.0|           1.0|[-5.0,153.0,1.0,4...|
[2025-07-14T12:34:30.108+0200] {subprocess.py:93} INFO - |    -4.0|2015-01-01 15:35:00|2015-01-01 14:41:00|         1|        4|        1|    -2.0|2015-01-01|     1341|   153.0|           1.0|[-2.0,153.0,1.0,4...|
[2025-07-14T12:34:30.108+0200] {subprocess.py:93} INFO - |   -14.0|2015-01-01 12:19:00|2015-01-01 11:25:00|         1|        4|        1|    -4.0|2015-01-01|     5107|   153.0|           1.0|[-4.0,153.0,1.0,4...|
[2025-07-14T12:34:30.108+0200] {subprocess.py:93} INFO - |   -10.0|2015-01-01 18:31:00|2015-01-01 17:36:00|         1|        4|        1|    -5.0|2015-01-01|     5248|   153.0|           1.0|[-5.0,153.0,1.0,4...|
[2025-07-14T12:34:30.108+0200] {subprocess.py:93} INFO - |    86.0|2015-01-01 19:42:00|2015-01-01 19:08:00|         1|        4|        1|    91.0|2015-01-01|     4601|   456.0|           3.0|[91.0,456.0,1.0,4...|
[2025-07-14T12:34:30.108+0200] {subprocess.py:93} INFO - |   152.0|2015-01-01 15:36:00|2015-01-01 15:01:00|         1|        4|        1|   151.0|2015-01-01|     5997|   456.0|           3.0|[151.0,456.0,1.0,...|
[2025-07-14T12:34:30.108+0200] {subprocess.py:93} INFO - |    20.0|2015-01-01 10:08:00|2015-01-01 09:31:00|         1|        4|        1|     5.0|2015-01-01|     6184|   456.0|           2.0|[5.0,456.0,1.0,4....|
[2025-07-14T12:34:30.108+0200] {subprocess.py:93} INFO - |    -9.0|2015-01-01 10:30:00|2015-01-01 08:15:00|         1|        4|        1|    -7.0|2015-01-01|     4134|   643.0|           1.0|[-7.0,643.0,1.0,4...|
[2025-07-14T12:34:30.108+0200] {subprocess.py:93} INFO - |    18.0|2015-01-01 17:02:00|2015-01-01 14:55:00|         1|        4|        1|    -5.0|2015-01-01|     4178|   643.0|           2.0|[-5.0,643.0,1.0,4...|
[2025-07-14T12:34:30.108+0200] {subprocess.py:93} INFO - |     8.0|2015-01-01 13:10:00|2015-01-01 11:00:00|         1|        4|        1|    -5.0|2015-01-01|     4497|   643.0|           2.0|[-5.0,643.0,1.0,4...|
[2025-07-14T12:34:30.108+0200] {subprocess.py:93} INFO - |    10.0|2015-01-01 19:12:00|2015-01-01 17:06:00|         1|        4|        1|    -6.0|2015-01-01|     4550|   643.0|           2.0|[-6.0,643.0,1.0,4...|
[2025-07-14T12:34:30.108+0200] {subprocess.py:93} INFO - |     1.0|2015-01-01 09:05:00|2015-01-01 06:50:00|         1|        4|        1|    -2.0|2015-01-01|     4555|   643.0|           2.0|[-2.0,643.0,1.0,4...|
[2025-07-14T12:34:30.108+0200] {subprocess.py:93} INFO - |     4.0|2015-01-01 21:50:00|2015-01-01 19:10:00|         1|        4|        1|     2.0|2015-01-01|     1277|   861.0|           2.0|[2.0,861.0,1.0,4....|
[2025-07-14T12:34:30.108+0200] {subprocess.py:93} INFO - +--------+-------------------+-------------------+----------+---------+---------+--------+----------+---------+--------+--------------+--------------------+
[2025-07-14T12:34:30.108+0200] {subprocess.py:93} INFO - only showing top 20 rows
[2025-07-14T12:34:30.108+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:30.153+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Instrumentation: [f4d6894d] Stage class: RandomForestClassifier
[2025-07-14T12:34:30.154+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Instrumentation: [f4d6894d] Stage uid: RandomForestClassifier_e8cbd20e9585
[2025-07-14T12:34:30.167+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:30.167+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-14T12:34:30.167+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-14T12:34:30.167+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-14T12:34:30.167+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:30.170+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:30.170+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-14T12:34:30.170+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:30.179+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO FileSourceStrategy: Pushed Filters:
[2025-07-14T12:34:30.179+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-14T12:34:30.187+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 214.5 KiB, free 429.3 MiB)
[2025-07-14T12:34:30.191+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 39.0 KiB, free 429.2 MiB)
[2025-07-14T12:34:30.191+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 138.4.31.89:45589 (size: 39.0 KiB, free: 434.1 MiB)
[2025-07-14T12:34:30.191+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO SparkContext: Created broadcast 52 from rdd at Instrumentation.scala:62
[2025-07-14T12:34:30.192+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-14T12:34:30.194+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Registering RDD 131 (rdd at Instrumentation.scala:62) as input to shuffle 20
[2025-07-14T12:34:30.194+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Got map stage job 41 (rdd at Instrumentation.scala:62) with 2 output partitions
[2025-07-14T12:34:30.194+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Final stage: ShuffleMapStage 65 (rdd at Instrumentation.scala:62)
[2025-07-14T12:34:30.194+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:30.194+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:30.194+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[131] at rdd at Instrumentation.scala:62), which has no missing parents
[2025-07-14T12:34:30.195+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 22.8 KiB, free 429.2 MiB)
[2025-07-14T12:34:30.195+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 429.2 MiB)
[2025-07-14T12:34:30.195+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 138.4.31.89:45589 (size: 9.9 KiB, free: 434.1 MiB)
[2025-07-14T12:34:30.195+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:30.195+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[131] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-14T12:34:30.196+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSchedulerImpl: Adding task set 65.0 with 2 tasks resource profile 0
[2025-07-14T12:34:30.196+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Registering RDD 135 (rdd at Instrumentation.scala:62) as input to shuffle 21
[2025-07-14T12:34:30.196+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Got map stage job 42 (rdd at Instrumentation.scala:62) with 13 output partitions
[2025-07-14T12:34:30.196+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 119) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:30.196+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Final stage: ShuffleMapStage 66 (rdd at Instrumentation.scala:62)
[2025-07-14T12:34:30.196+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:30.196+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:30.196+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Submitting ShuffleMapStage 66 (MapPartitionsRDD[135] at rdd at Instrumentation.scala:62), which has no missing parents
[2025-07-14T12:34:30.196+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Starting task 1.0 in stage 65.0 (TID 120) (138.4.31.89, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:30.196+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Running task 0.0 in stage 65.0 (TID 119)
[2025-07-14T12:34:30.196+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Running task 1.0 in stage 65.0 (TID 120)
[2025-07-14T12:34:30.197+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 18.7 KiB, free 429.2 MiB)
[2025-07-14T12:34:30.197+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 429.2 MiB)
[2025-07-14T12:34:30.198+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 138.4.31.89:45589 (size: 9.2 KiB, free: 434.1 MiB)
[2025-07-14T12:34:30.198+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:30.198+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[135] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-14T12:34:30.198+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSchedulerImpl: Adding task set 66.0 with 13 tasks resource profile 0
[2025-07-14T12:34:30.198+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 121) (138.4.31.89, executor driver, partition 0, ANY, 16719 bytes)
[2025-07-14T12:34:30.198+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-14T12:34:30.199+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Starting task 1.0 in stage 66.0 (TID 122) (138.4.31.89, executor driver, partition 1, ANY, 16719 bytes)
[2025-07-14T12:34:30.199+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-14T12:34:30.199+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Running task 0.0 in stage 66.0 (TID 121)
[2025-07-14T12:34:30.199+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Running task 1.0 in stage 66.0 (TID 122)
[2025-07-14T12:34:30.213+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Finished task 1.0 in stage 66.0 (TID 122). 1902 bytes result sent to driver
[2025-07-14T12:34:30.213+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Starting task 2.0 in stage 66.0 (TID 123) (138.4.31.89, executor driver, partition 2, ANY, 16839 bytes)
[2025-07-14T12:34:30.214+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Finished task 1.0 in stage 66.0 (TID 122) in 15 ms on 138.4.31.89 (executor driver) (1/13)
[2025-07-14T12:34:30.214+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Running task 2.0 in stage 66.0 (TID 123)
[2025-07-14T12:34:30.226+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Finished task 0.0 in stage 66.0 (TID 121). 1945 bytes result sent to driver
[2025-07-14T12:34:30.226+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Starting task 3.0 in stage 66.0 (TID 124) (138.4.31.89, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-14T12:34:30.226+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 121) in 28 ms on 138.4.31.89 (executor driver) (2/13)
[2025-07-14T12:34:30.226+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Running task 3.0 in stage 66.0 (TID 124)
[2025-07-14T12:34:30.232+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Finished task 2.0 in stage 66.0 (TID 123). 1945 bytes result sent to driver
[2025-07-14T12:34:30.232+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Starting task 4.0 in stage 66.0 (TID 125) (138.4.31.89, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-14T12:34:30.232+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Finished task 2.0 in stage 66.0 (TID 123) in 19 ms on 138.4.31.89 (executor driver) (3/13)
[2025-07-14T12:34:30.232+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Running task 4.0 in stage 66.0 (TID 125)
[2025-07-14T12:34:30.244+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Finished task 4.0 in stage 66.0 (TID 125). 1902 bytes result sent to driver
[2025-07-14T12:34:30.244+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Starting task 5.0 in stage 66.0 (TID 126) (138.4.31.89, executor driver, partition 5, ANY, 16719 bytes)
[2025-07-14T12:34:30.244+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Finished task 4.0 in stage 66.0 (TID 125) in 12 ms on 138.4.31.89 (executor driver) (4/13)
[2025-07-14T12:34:30.245+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Running task 5.0 in stage 66.0 (TID 126)
[2025-07-14T12:34:30.247+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Finished task 3.0 in stage 66.0 (TID 124). 1945 bytes result sent to driver
[2025-07-14T12:34:30.248+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Starting task 6.0 in stage 66.0 (TID 127) (138.4.31.89, executor driver, partition 6, ANY, 16719 bytes)
[2025-07-14T12:34:30.248+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Finished task 3.0 in stage 66.0 (TID 124) in 22 ms on 138.4.31.89 (executor driver) (5/13)
[2025-07-14T12:34:30.248+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Running task 6.0 in stage 66.0 (TID 127)
[2025-07-14T12:34:30.261+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 138.4.31.89:45589 in memory (size: 99.7 KiB, free: 434.2 MiB)
[2025-07-14T12:34:30.274+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Finished task 5.0 in stage 66.0 (TID 126). 1988 bytes result sent to driver
[2025-07-14T12:34:30.274+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Starting task 7.0 in stage 66.0 (TID 128) (138.4.31.89, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-14T12:34:30.274+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Finished task 5.0 in stage 66.0 (TID 126) in 30 ms on 138.4.31.89 (executor driver) (6/13)
[2025-07-14T12:34:30.274+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Running task 7.0 in stage 66.0 (TID 128)
[2025-07-14T12:34:30.275+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Finished task 6.0 in stage 66.0 (TID 127). 1945 bytes result sent to driver
[2025-07-14T12:34:30.276+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Starting task 8.0 in stage 66.0 (TID 129) (138.4.31.89, executor driver, partition 8, ANY, 16839 bytes)
[2025-07-14T12:34:30.276+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Running task 8.0 in stage 66.0 (TID 129)
[2025-07-14T12:34:30.276+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Finished task 6.0 in stage 66.0 (TID 127) in 28 ms on 138.4.31.89 (executor driver) (7/13)
[2025-07-14T12:34:30.291+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Finished task 7.0 in stage 66.0 (TID 128). 1945 bytes result sent to driver
[2025-07-14T12:34:30.291+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Starting task 9.0 in stage 66.0 (TID 130) (138.4.31.89, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-14T12:34:30.292+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Running task 9.0 in stage 66.0 (TID 130)
[2025-07-14T12:34:30.292+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Finished task 7.0 in stage 66.0 (TID 128) in 18 ms on 138.4.31.89 (executor driver) (8/13)
[2025-07-14T12:34:30.295+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Finished task 8.0 in stage 66.0 (TID 129). 1902 bytes result sent to driver
[2025-07-14T12:34:30.295+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Starting task 10.0 in stage 66.0 (TID 131) (138.4.31.89, executor driver, partition 10, ANY, 16715 bytes)
[2025-07-14T12:34:30.295+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Running task 10.0 in stage 66.0 (TID 131)
[2025-07-14T12:34:30.295+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Finished task 8.0 in stage 66.0 (TID 129) in 20 ms on 138.4.31.89 (executor driver) (9/13)
[2025-07-14T12:34:30.306+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Finished task 9.0 in stage 66.0 (TID 130). 1945 bytes result sent to driver
[2025-07-14T12:34:30.306+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Starting task 11.0 in stage 66.0 (TID 132) (138.4.31.89, executor driver, partition 11, ANY, 16839 bytes)
[2025-07-14T12:34:30.306+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Running task 11.0 in stage 66.0 (TID 132)
[2025-07-14T12:34:30.306+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Finished task 9.0 in stage 66.0 (TID 130) in 15 ms on 138.4.31.89 (executor driver) (10/13)
[2025-07-14T12:34:30.309+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Finished task 10.0 in stage 66.0 (TID 131). 1945 bytes result sent to driver
[2025-07-14T12:34:30.309+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Starting task 12.0 in stage 66.0 (TID 133) (138.4.31.89, executor driver, partition 12, ANY, 16719 bytes)
[2025-07-14T12:34:30.309+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Running task 12.0 in stage 66.0 (TID 133)
[2025-07-14T12:34:30.309+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Finished task 10.0 in stage 66.0 (TID 131) in 14 ms on 138.4.31.89 (executor driver) (11/13)
[2025-07-14T12:34:30.329+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Finished task 12.0 in stage 66.0 (TID 133). 1945 bytes result sent to driver
[2025-07-14T12:34:30.329+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Finished task 12.0 in stage 66.0 (TID 133) in 20 ms on 138.4.31.89 (executor driver) (12/13)
[2025-07-14T12:34:30.330+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Finished task 11.0 in stage 66.0 (TID 132). 1988 bytes result sent to driver
[2025-07-14T12:34:30.330+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Finished task 11.0 in stage 66.0 (TID 132) in 24 ms on 138.4.31.89 (executor driver) (13/13)
[2025-07-14T12:34:30.330+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool
[2025-07-14T12:34:30.330+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: ShuffleMapStage 66 (rdd at Instrumentation.scala:62) finished in 0,134 s
[2025-07-14T12:34:30.330+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:30.331+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: running: Set(ShuffleMapStage 65)
[2025-07-14T12:34:30.331+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:30.331+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:30.340+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-14T12:34:30.345+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-14T12:34:30.345+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Got job 43 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-14T12:34:30.345+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Final stage: ResultStage 68 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-14T12:34:30.345+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67)
[2025-07-14T12:34:30.346+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:30.346+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[137] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-14T12:34:30.346+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 8.2 KiB, free 429.4 MiB)
[2025-07-14T12:34:30.347+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 429.4 MiB)
[2025-07-14T12:34:30.347+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 138.4.31.89:45589 (size: 4.2 KiB, free: 434.2 MiB)
[2025-07-14T12:34:30.347+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:30.348+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[137] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:30.348+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks resource profile 0
[2025-07-14T12:34:30.348+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 134) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-14T12:34:30.349+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Running task 0.0 in stage 68.0 (TID 134)
[2025-07-14T12:34:30.351+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO ShuffleBlockFetcherIterator: Getting 13 (217.3 KiB) non-empty blocks including 13 (217.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:30.351+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:30.356+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Finished task 0.0 in stage 68.0 (TID 134). 51067 bytes result sent to driver
[2025-07-14T12:34:30.356+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 134) in 8 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:30.357+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool
[2025-07-14T12:34:30.357+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: ResultStage 68 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,011 s
[2025-07-14T12:34:30.357+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:30.357+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 68: Stage finished
[2025-07-14T12:34:30.357+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO DAGScheduler: Job 43 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,012310 s
[2025-07-14T12:34:30.360+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 4.3 MiB, free 425.2 MiB)
[2025-07-14T12:34:30.362+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 109.5 KiB, free 425.1 MiB)
[2025-07-14T12:34:30.362+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 138.4.31.89:45589 (size: 109.5 KiB, free: 434.1 MiB)
[2025-07-14T12:34:30.362+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO SparkContext: Created broadcast 56 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-14T12:34:30.428+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 138.4.31.89:45589 in memory (size: 4.2 KiB, free: 434.1 MiB)
[2025-07-14T12:34:30.759+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO Executor: Finished task 1.0 in stage 65.0 (TID 120). 2031 bytes result sent to driver
[2025-07-14T12:34:30.759+0200] {subprocess.py:93} INFO - 25/07/14 12:34:30 INFO TaskSetManager: Finished task 1.0 in stage 65.0 (TID 120) in 563 ms on 138.4.31.89 (executor driver) (1/2)
[2025-07-14T12:34:37.054+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Finished task 0.0 in stage 65.0 (TID 119). 2031 bytes result sent to driver
[2025-07-14T12:34:37.055+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 119) in 6859 ms on 138.4.31.89 (executor driver) (2/2)
[2025-07-14T12:34:37.055+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool
[2025-07-14T12:34:37.055+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: ShuffleMapStage 65 (rdd at Instrumentation.scala:62) finished in 6,861 s
[2025-07-14T12:34:37.055+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:37.055+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:37.055+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:37.055+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:37.061+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 4228400, minimum partition size: 1048576
[2025-07-14T12:34:37.076+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO CodeGenerator: Code generated in 7.958928 ms
[2025-07-14T12:34:37.082+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Instrumentation: [f4d6894d] training: numPartitions=4 storageLevel=StorageLevel(1 replicas)
[2025-07-14T12:34:37.116+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:37.116+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-14T12:34:37.116+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-14T12:34:37.116+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-14T12:34:37.116+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:37.124+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:37.124+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-14T12:34:37.124+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:37.135+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO FileSourceStrategy: Pushed Filters:
[2025-07-14T12:34:37.135+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-14T12:34:37.146+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO CodeGenerator: Code generated in 3.888583 ms
[2025-07-14T12:34:37.147+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 214.5 KiB, free 424.9 MiB)
[2025-07-14T12:34:37.154+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 39.0 KiB, free 424.9 MiB)
[2025-07-14T12:34:37.154+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 138.4.31.89:45589 (size: 39.0 KiB, free: 434.0 MiB)
[2025-07-14T12:34:37.154+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO SparkContext: Created broadcast 57 from rdd at RandomForestClassifier.scala:155
[2025-07-14T12:34:37.155+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-14T12:34:37.157+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: Registering RDD 146 (rdd at RandomForestClassifier.scala:155) as input to shuffle 22
[2025-07-14T12:34:37.158+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: Got map stage job 44 (rdd at RandomForestClassifier.scala:155) with 2 output partitions
[2025-07-14T12:34:37.158+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: Final stage: ShuffleMapStage 69 (rdd at RandomForestClassifier.scala:155)
[2025-07-14T12:34:37.158+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:37.158+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:37.158+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: Submitting ShuffleMapStage 69 (MapPartitionsRDD[146] at rdd at RandomForestClassifier.scala:155), which has no missing parents
[2025-07-14T12:34:37.158+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 20.7 KiB, free 424.8 MiB)
[2025-07-14T12:34:37.160+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 9.3 KiB, free 424.8 MiB)
[2025-07-14T12:34:37.161+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 138.4.31.89:45589 (size: 9.3 KiB, free: 434.0 MiB)
[2025-07-14T12:34:37.161+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:37.161+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 69 (MapPartitionsRDD[146] at rdd at RandomForestClassifier.scala:155) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-14T12:34:37.161+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSchedulerImpl: Adding task set 69.0 with 2 tasks resource profile 0
[2025-07-14T12:34:37.161+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 135) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:37.162+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 136) (138.4.31.89, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:37.162+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Running task 0.0 in stage 69.0 (TID 135)
[2025-07-14T12:34:37.162+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Running task 1.0 in stage 69.0 (TID 136)
[2025-07-14T12:34:37.162+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: Registering RDD 150 (rdd at RandomForestClassifier.scala:155) as input to shuffle 23
[2025-07-14T12:34:37.162+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: Got map stage job 45 (rdd at RandomForestClassifier.scala:155) with 13 output partitions
[2025-07-14T12:34:37.162+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: Final stage: ShuffleMapStage 70 (rdd at RandomForestClassifier.scala:155)
[2025-07-14T12:34:37.162+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:37.162+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:37.163+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: Submitting ShuffleMapStage 70 (MapPartitionsRDD[150] at rdd at RandomForestClassifier.scala:155), which has no missing parents
[2025-07-14T12:34:37.164+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 18.7 KiB, free 424.8 MiB)
[2025-07-14T12:34:37.166+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 424.8 MiB)
[2025-07-14T12:34:37.166+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 138.4.31.89:45589 (size: 9.2 KiB, free: 434.0 MiB)
[2025-07-14T12:34:37.167+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:37.167+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[150] at rdd at RandomForestClassifier.scala:155) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-14T12:34:37.167+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSchedulerImpl: Adding task set 70.0 with 13 tasks resource profile 0
[2025-07-14T12:34:37.168+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 137) (138.4.31.89, executor driver, partition 0, ANY, 16719 bytes)
[2025-07-14T12:34:37.168+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Starting task 1.0 in stage 70.0 (TID 138) (138.4.31.89, executor driver, partition 1, ANY, 16839 bytes)
[2025-07-14T12:34:37.168+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Running task 0.0 in stage 70.0 (TID 137)
[2025-07-14T12:34:37.168+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Running task 1.0 in stage 70.0 (TID 138)
[2025-07-14T12:34:37.168+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO CodeGenerator: Code generated in 5.103628 ms
[2025-07-14T12:34:37.172+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO CodeGenerator: Code generated in 2.875269 ms
[2025-07-14T12:34:37.173+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-14T12:34:37.173+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-14T12:34:37.176+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO CodeGenerator: Code generated in 2.586527 ms
[2025-07-14T12:34:37.187+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Finished task 0.0 in stage 70.0 (TID 137). 1988 bytes result sent to driver
[2025-07-14T12:34:37.187+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Starting task 2.0 in stage 70.0 (TID 139) (138.4.31.89, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-14T12:34:37.187+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 137) in 19 ms on 138.4.31.89 (executor driver) (1/13)
[2025-07-14T12:34:37.187+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Running task 2.0 in stage 70.0 (TID 139)
[2025-07-14T12:34:37.192+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Finished task 1.0 in stage 70.0 (TID 138). 1988 bytes result sent to driver
[2025-07-14T12:34:37.193+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Starting task 3.0 in stage 70.0 (TID 140) (138.4.31.89, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-14T12:34:37.193+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Running task 3.0 in stage 70.0 (TID 140)
[2025-07-14T12:34:37.193+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Finished task 1.0 in stage 70.0 (TID 138) in 25 ms on 138.4.31.89 (executor driver) (2/13)
[2025-07-14T12:34:37.206+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Finished task 2.0 in stage 70.0 (TID 139). 2031 bytes result sent to driver
[2025-07-14T12:34:37.206+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Starting task 4.0 in stage 70.0 (TID 141) (138.4.31.89, executor driver, partition 4, ANY, 16839 bytes)
[2025-07-14T12:34:37.206+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Finished task 2.0 in stage 70.0 (TID 139) in 19 ms on 138.4.31.89 (executor driver) (3/13)
[2025-07-14T12:34:37.206+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Running task 4.0 in stage 70.0 (TID 141)
[2025-07-14T12:34:37.213+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Finished task 3.0 in stage 70.0 (TID 140). 1988 bytes result sent to driver
[2025-07-14T12:34:37.214+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Starting task 5.0 in stage 70.0 (TID 142) (138.4.31.89, executor driver, partition 5, ANY, 16839 bytes)
[2025-07-14T12:34:37.214+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Running task 5.0 in stage 70.0 (TID 142)
[2025-07-14T12:34:37.214+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Finished task 3.0 in stage 70.0 (TID 140) in 22 ms on 138.4.31.89 (executor driver) (4/13)
[2025-07-14T12:34:37.226+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 138.4.31.89:45589 in memory (size: 9.2 KiB, free: 434.0 MiB)
[2025-07-14T12:34:37.227+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 138.4.31.89:45589 in memory (size: 9.9 KiB, free: 434.0 MiB)
[2025-07-14T12:34:37.227+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 138.4.31.89:45589 in memory (size: 109.6 KiB, free: 434.2 MiB)
[2025-07-14T12:34:37.228+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 138.4.31.89:45589 in memory (size: 39.0 KiB, free: 434.2 MiB)
[2025-07-14T12:34:37.228+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 138.4.31.89:45589 in memory (size: 9.9 KiB, free: 434.2 MiB)
[2025-07-14T12:34:37.230+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Finished task 4.0 in stage 70.0 (TID 141). 1945 bytes result sent to driver
[2025-07-14T12:34:37.230+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Starting task 6.0 in stage 70.0 (TID 143) (138.4.31.89, executor driver, partition 6, ANY, 16719 bytes)
[2025-07-14T12:34:37.231+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Finished task 4.0 in stage 70.0 (TID 141) in 25 ms on 138.4.31.89 (executor driver) (5/13)
[2025-07-14T12:34:37.231+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Running task 6.0 in stage 70.0 (TID 143)
[2025-07-14T12:34:37.238+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Finished task 5.0 in stage 70.0 (TID 142). 1945 bytes result sent to driver
[2025-07-14T12:34:37.239+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Starting task 7.0 in stage 70.0 (TID 144) (138.4.31.89, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-14T12:34:37.239+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Running task 7.0 in stage 70.0 (TID 144)
[2025-07-14T12:34:37.239+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Finished task 5.0 in stage 70.0 (TID 142) in 25 ms on 138.4.31.89 (executor driver) (6/13)
[2025-07-14T12:34:37.248+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Finished task 6.0 in stage 70.0 (TID 143). 1945 bytes result sent to driver
[2025-07-14T12:34:37.248+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Starting task 8.0 in stage 70.0 (TID 145) (138.4.31.89, executor driver, partition 8, ANY, 16719 bytes)
[2025-07-14T12:34:37.248+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Finished task 6.0 in stage 70.0 (TID 143) in 18 ms on 138.4.31.89 (executor driver) (7/13)
[2025-07-14T12:34:37.248+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Running task 8.0 in stage 70.0 (TID 145)
[2025-07-14T12:34:37.256+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Finished task 7.0 in stage 70.0 (TID 144). 1902 bytes result sent to driver
[2025-07-14T12:34:37.257+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Starting task 9.0 in stage 70.0 (TID 146) (138.4.31.89, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-14T12:34:37.257+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Finished task 7.0 in stage 70.0 (TID 144) in 19 ms on 138.4.31.89 (executor driver) (8/13)
[2025-07-14T12:34:37.257+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Running task 9.0 in stage 70.0 (TID 146)
[2025-07-14T12:34:37.274+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Finished task 8.0 in stage 70.0 (TID 145). 1988 bytes result sent to driver
[2025-07-14T12:34:37.274+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Starting task 10.0 in stage 70.0 (TID 147) (138.4.31.89, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-14T12:34:37.274+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Finished task 8.0 in stage 70.0 (TID 145) in 26 ms on 138.4.31.89 (executor driver) (9/13)
[2025-07-14T12:34:37.274+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Running task 10.0 in stage 70.0 (TID 147)
[2025-07-14T12:34:37.288+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Finished task 10.0 in stage 70.0 (TID 147). 1945 bytes result sent to driver
[2025-07-14T12:34:37.288+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Finished task 9.0 in stage 70.0 (TID 146). 1988 bytes result sent to driver
[2025-07-14T12:34:37.288+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Starting task 11.0 in stage 70.0 (TID 148) (138.4.31.89, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-14T12:34:37.289+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Running task 11.0 in stage 70.0 (TID 148)
[2025-07-14T12:34:37.289+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Starting task 12.0 in stage 70.0 (TID 149) (138.4.31.89, executor driver, partition 12, ANY, 16715 bytes)
[2025-07-14T12:34:37.289+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Finished task 9.0 in stage 70.0 (TID 146) in 33 ms on 138.4.31.89 (executor driver) (10/13)
[2025-07-14T12:34:37.289+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Finished task 10.0 in stage 70.0 (TID 147) in 15 ms on 138.4.31.89 (executor driver) (11/13)
[2025-07-14T12:34:37.289+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Running task 12.0 in stage 70.0 (TID 149)
[2025-07-14T12:34:37.302+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Finished task 11.0 in stage 70.0 (TID 148). 1945 bytes result sent to driver
[2025-07-14T12:34:37.302+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Finished task 11.0 in stage 70.0 (TID 148) in 14 ms on 138.4.31.89 (executor driver) (12/13)
[2025-07-14T12:34:37.310+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Finished task 12.0 in stage 70.0 (TID 149). 1945 bytes result sent to driver
[2025-07-14T12:34:37.310+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Finished task 12.0 in stage 70.0 (TID 149) in 21 ms on 138.4.31.89 (executor driver) (13/13)
[2025-07-14T12:34:37.311+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool
[2025-07-14T12:34:37.311+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: ShuffleMapStage 70 (rdd at RandomForestClassifier.scala:155) finished in 0,148 s
[2025-07-14T12:34:37.311+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:37.311+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: running: Set(ShuffleMapStage 69)
[2025-07-14T12:34:37.311+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:37.311+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:37.320+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO ShufflePartitionsUtil: For shuffle(23), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-14T12:34:37.327+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-14T12:34:37.327+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: Got job 46 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-14T12:34:37.327+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: Final stage: ResultStage 72 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-14T12:34:37.327+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 71)
[2025-07-14T12:34:37.327+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:37.327+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[152] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-14T12:34:37.328+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 8.2 KiB, free 429.5 MiB)
[2025-07-14T12:34:37.329+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 429.5 MiB)
[2025-07-14T12:34:37.329+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 138.4.31.89:45589 (size: 4.2 KiB, free: 434.2 MiB)
[2025-07-14T12:34:37.329+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:37.330+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[152] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:37.330+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks resource profile 0
[2025-07-14T12:34:37.331+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 150) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-14T12:34:37.331+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Running task 0.0 in stage 72.0 (TID 150)
[2025-07-14T12:34:37.333+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO ShuffleBlockFetcherIterator: Getting 13 (217.3 KiB) non-empty blocks including 13 (217.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:37.333+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:37.339+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Finished task 0.0 in stage 72.0 (TID 150). 51184 bytes result sent to driver
[2025-07-14T12:34:37.340+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 150) in 9 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:37.340+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool
[2025-07-14T12:34:37.340+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: ResultStage 72 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,012 s
[2025-07-14T12:34:37.340+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:37.340+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished
[2025-07-14T12:34:37.340+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO DAGScheduler: Job 46 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,013703 s
[2025-07-14T12:34:37.346+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 4.3 MiB, free 425.2 MiB)
[2025-07-14T12:34:37.349+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 109.4 KiB, free 425.1 MiB)
[2025-07-14T12:34:37.349+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 138.4.31.89:45589 (size: 109.4 KiB, free: 434.1 MiB)
[2025-07-14T12:34:37.349+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO SparkContext: Created broadcast 61 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-14T12:34:37.525+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 138.4.31.89:45589 in memory (size: 4.2 KiB, free: 434.1 MiB)
[2025-07-14T12:34:37.605+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO Executor: Finished task 1.0 in stage 69.0 (TID 136). 1988 bytes result sent to driver
[2025-07-14T12:34:37.605+0200] {subprocess.py:93} INFO - 25/07/14 12:34:37 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 136) in 444 ms on 138.4.31.89 (executor driver) (1/2)
[2025-07-14T12:34:39.992+0200] {subprocess.py:93} INFO - 25/07/14 12:34:39 INFO Executor: Finished task 0.0 in stage 69.0 (TID 135). 2031 bytes result sent to driver
[2025-07-14T12:34:39.993+0200] {subprocess.py:93} INFO - 25/07/14 12:34:39 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 135) in 2832 ms on 138.4.31.89 (executor driver) (2/2)
[2025-07-14T12:34:39.993+0200] {subprocess.py:93} INFO - 25/07/14 12:34:39 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool
[2025-07-14T12:34:39.993+0200] {subprocess.py:93} INFO - 25/07/14 12:34:39 INFO DAGScheduler: ShuffleMapStage 69 (rdd at RandomForestClassifier.scala:155) finished in 2,835 s
[2025-07-14T12:34:39.993+0200] {subprocess.py:93} INFO - 25/07/14 12:34:39 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:39.993+0200] {subprocess.py:93} INFO - 25/07/14 12:34:39 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:39.993+0200] {subprocess.py:93} INFO - 25/07/14 12:34:39 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:39.993+0200] {subprocess.py:93} INFO - 25/07/14 12:34:39 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:39.998+0200] {subprocess.py:93} INFO - 25/07/14 12:34:39 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1923052, minimum partition size: 1048576
[2025-07-14T12:34:40.021+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO CodeGenerator: Code generated in 12.797201 ms
[2025-07-14T12:34:40.031+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO Instrumentation: [f4d6894d] {"featuresCol":"Features_vec","labelCol":"ArrDelayBucket","predictionCol":"Prediction","maxMemoryInMB":1024,"maxBins":4657,"numTrees":10}
[2025-07-14T12:34:40.050+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:119
[2025-07-14T12:34:40.050+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO DAGScheduler: Got job 47 (take at DecisionTreeMetadata.scala:119) with 1 output partitions
[2025-07-14T12:34:40.050+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO DAGScheduler: Final stage: ResultStage 74 (take at DecisionTreeMetadata.scala:119)
[2025-07-14T12:34:40.050+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)
[2025-07-14T12:34:40.050+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:40.050+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[160] at map at DecisionTreeMetadata.scala:119), which has no missing parents
[2025-07-14T12:34:40.054+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 278.1 KiB, free 424.9 MiB)
[2025-07-14T12:34:40.055+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 126.8 KiB, free 424.7 MiB)
[2025-07-14T12:34:40.055+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 138.4.31.89:45589 (size: 126.8 KiB, free: 434.0 MiB)
[2025-07-14T12:34:40.056+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:40.056+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[160] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:40.056+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0
[2025-07-14T12:34:40.056+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 151) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14847 bytes)
[2025-07-14T12:34:40.057+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO Executor: Running task 0.0 in stage 74.0 (TID 151)
[2025-07-14T12:34:40.068+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO ShuffleBlockFetcherIterator: Getting 1 (3.2 MiB) non-empty blocks including 1 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:40.068+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:40.080+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO CodeGenerator: Code generated in 11.968917 ms
[2025-07-14T12:34:40.085+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO CodeGenerator: Code generated in 2.61989 ms
[2025-07-14T12:34:40.089+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO CodeGenerator: Code generated in 1.94418 ms
[2025-07-14T12:34:40.090+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO Executor: Finished task 0.0 in stage 74.0 (TID 151). 5038 bytes result sent to driver
[2025-07-14T12:34:40.091+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 151) in 35 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:40.091+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool
[2025-07-14T12:34:40.091+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO DAGScheduler: ResultStage 74 (take at DecisionTreeMetadata.scala:119) finished in 0,040 s
[2025-07-14T12:34:40.091+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:40.091+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished
[2025-07-14T12:34:40.091+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO DAGScheduler: Job 47 finished: take at DecisionTreeMetadata.scala:119, took 0,041741 s
[2025-07-14T12:34:40.096+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125
[2025-07-14T12:34:40.096+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO DAGScheduler: Got job 48 (aggregate at DecisionTreeMetadata.scala:125) with 4 output partitions
[2025-07-14T12:34:40.096+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO DAGScheduler: Final stage: ResultStage 76 (aggregate at DecisionTreeMetadata.scala:125)
[2025-07-14T12:34:40.096+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)
[2025-07-14T12:34:40.096+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:40.096+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[159] at retag at RandomForest.scala:274), which has no missing parents
[2025-07-14T12:34:40.099+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 278.2 KiB, free 424.5 MiB)
[2025-07-14T12:34:40.100+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 126.9 KiB, free 424.3 MiB)
[2025-07-14T12:34:40.100+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 138.4.31.89:45589 (size: 126.9 KiB, free: 433.8 MiB)
[2025-07-14T12:34:40.100+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:40.100+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 76 (MapPartitionsRDD[159] at retag at RandomForest.scala:274) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-14T12:34:40.101+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO TaskSchedulerImpl: Adding task set 76.0 with 4 tasks resource profile 0
[2025-07-14T12:34:40.101+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 152) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14847 bytes)
[2025-07-14T12:34:40.101+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO TaskSetManager: Starting task 1.0 in stage 76.0 (TID 153) (138.4.31.89, executor driver, partition 1, NODE_LOCAL, 14847 bytes)
[2025-07-14T12:34:40.101+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO TaskSetManager: Starting task 2.0 in stage 76.0 (TID 154) (138.4.31.89, executor driver, partition 2, NODE_LOCAL, 14847 bytes)
[2025-07-14T12:34:40.101+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO TaskSetManager: Starting task 3.0 in stage 76.0 (TID 155) (138.4.31.89, executor driver, partition 3, NODE_LOCAL, 14847 bytes)
[2025-07-14T12:34:40.102+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO Executor: Running task 0.0 in stage 76.0 (TID 152)
[2025-07-14T12:34:40.102+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO Executor: Running task 2.0 in stage 76.0 (TID 154)
[2025-07-14T12:34:40.102+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO Executor: Running task 3.0 in stage 76.0 (TID 155)
[2025-07-14T12:34:40.102+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO Executor: Running task 1.0 in stage 76.0 (TID 153)
[2025-07-14T12:34:40.108+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO ShuffleBlockFetcherIterator: Getting 1 (3.2 MiB) non-empty blocks including 1 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:40.108+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO ShuffleBlockFetcherIterator: Getting 1 (384.6 KiB) non-empty blocks including 1 (384.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:40.108+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:40.108+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:40.108+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO ShuffleBlockFetcherIterator: Getting 1 (366.2 KiB) non-empty blocks including 1 (366.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:40.108+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:40.109+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO ShuffleBlockFetcherIterator: Getting 1 (3.4 MiB) non-empty blocks including 1 (3.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:40.109+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:40.575+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 138.4.31.89:45589 in memory (size: 126.8 KiB, free: 434.0 MiB)
[2025-07-14T12:34:40.705+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO Executor: Finished task 2.0 in stage 76.0 (TID 154). 5927 bytes result sent to driver
[2025-07-14T12:34:40.706+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO TaskSetManager: Finished task 2.0 in stage 76.0 (TID 154) in 605 ms on 138.4.31.89 (executor driver) (1/4)
[2025-07-14T12:34:40.713+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO Executor: Finished task 3.0 in stage 76.0 (TID 155). 5927 bytes result sent to driver
[2025-07-14T12:34:40.714+0200] {subprocess.py:93} INFO - 25/07/14 12:34:40 INFO TaskSetManager: Finished task 3.0 in stage 76.0 (TID 155) in 613 ms on 138.4.31.89 (executor driver) (2/4)
[2025-07-14T12:34:41.006+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Executor: Finished task 0.0 in stage 76.0 (TID 152). 5927 bytes result sent to driver
[2025-07-14T12:34:41.006+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 152) in 905 ms on 138.4.31.89 (executor driver) (3/4)
[2025-07-14T12:34:41.014+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Executor: Finished task 1.0 in stage 76.0 (TID 153). 5927 bytes result sent to driver
[2025-07-14T12:34:41.014+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSetManager: Finished task 1.0 in stage 76.0 (TID 153) in 913 ms on 138.4.31.89 (executor driver) (4/4)
[2025-07-14T12:34:41.014+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool
[2025-07-14T12:34:41.014+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: ResultStage 76 (aggregate at DecisionTreeMetadata.scala:125) finished in 0,918 s
[2025-07-14T12:34:41.014+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:41.014+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 76: Stage finished
[2025-07-14T12:34:41.015+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: Job 48 finished: aggregate at DecisionTreeMetadata.scala:125, took 0,918842 s
[2025-07-14T12:34:41.050+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:1054
[2025-07-14T12:34:41.051+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: Registering RDD 162 (flatMap at RandomForest.scala:1039) as input to shuffle 24
[2025-07-14T12:34:41.051+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: Got job 49 (collectAsMap at RandomForest.scala:1054) with 4 output partitions
[2025-07-14T12:34:41.051+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: Final stage: ResultStage 79 (collectAsMap at RandomForest.scala:1054)
[2025-07-14T12:34:41.051+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78)
[2025-07-14T12:34:41.051+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 78)
[2025-07-14T12:34:41.051+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: Submitting ShuffleMapStage 78 (MapPartitionsRDD[162] at flatMap at RandomForest.scala:1039), which has no missing parents
[2025-07-14T12:34:41.054+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 281.5 KiB, free 424.5 MiB)
[2025-07-14T12:34:41.058+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 138.4.31.89:45589 in memory (size: 126.9 KiB, free: 434.1 MiB)
[2025-07-14T12:34:41.058+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 128.0 KiB, free 424.7 MiB)
[2025-07-14T12:34:41.058+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 138.4.31.89:45589 (size: 128.0 KiB, free: 434.0 MiB)
[2025-07-14T12:34:41.058+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:41.058+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[162] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-14T12:34:41.058+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSchedulerImpl: Adding task set 78.0 with 4 tasks resource profile 0
[2025-07-14T12:34:41.059+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 156) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14836 bytes)
[2025-07-14T12:34:41.059+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 157) (138.4.31.89, executor driver, partition 1, NODE_LOCAL, 14836 bytes)
[2025-07-14T12:34:41.059+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSetManager: Starting task 2.0 in stage 78.0 (TID 158) (138.4.31.89, executor driver, partition 2, NODE_LOCAL, 14836 bytes)
[2025-07-14T12:34:41.059+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSetManager: Starting task 3.0 in stage 78.0 (TID 159) (138.4.31.89, executor driver, partition 3, NODE_LOCAL, 14836 bytes)
[2025-07-14T12:34:41.059+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Executor: Running task 0.0 in stage 78.0 (TID 156)
[2025-07-14T12:34:41.059+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Executor: Running task 3.0 in stage 78.0 (TID 159)
[2025-07-14T12:34:41.060+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Executor: Running task 1.0 in stage 78.0 (TID 157)
[2025-07-14T12:34:41.060+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Executor: Running task 2.0 in stage 78.0 (TID 158)
[2025-07-14T12:34:41.077+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Getting 1 (384.6 KiB) non-empty blocks including 1 (384.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:41.077+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Getting 1 (3.4 MiB) non-empty blocks including 1 (3.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:41.077+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Getting 1 (3.2 MiB) non-empty blocks including 1 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:41.077+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Getting 1 (366.2 KiB) non-empty blocks including 1 (366.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:41.077+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:41.077+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:41.077+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:41.077+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:41.504+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Executor: Finished task 3.0 in stage 78.0 (TID 159). 6108 bytes result sent to driver
[2025-07-14T12:34:41.504+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Executor: Finished task 2.0 in stage 78.0 (TID 158). 6108 bytes result sent to driver
[2025-07-14T12:34:41.505+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSetManager: Finished task 3.0 in stage 78.0 (TID 159) in 445 ms on 138.4.31.89 (executor driver) (1/4)
[2025-07-14T12:34:41.505+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSetManager: Finished task 2.0 in stage 78.0 (TID 158) in 446 ms on 138.4.31.89 (executor driver) (2/4)
[2025-07-14T12:34:41.747+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Executor: Finished task 0.0 in stage 78.0 (TID 156). 6108 bytes result sent to driver
[2025-07-14T12:34:41.748+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 156) in 689 ms on 138.4.31.89 (executor driver) (3/4)
[2025-07-14T12:34:41.765+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Executor: Finished task 1.0 in stage 78.0 (TID 157). 6108 bytes result sent to driver
[2025-07-14T12:34:41.765+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 157) in 706 ms on 138.4.31.89 (executor driver) (4/4)
[2025-07-14T12:34:41.765+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool
[2025-07-14T12:34:41.765+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: ShuffleMapStage 78 (flatMap at RandomForest.scala:1039) finished in 0,714 s
[2025-07-14T12:34:41.765+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:41.765+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:41.766+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: waiting: Set(ResultStage 79)
[2025-07-14T12:34:41.766+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:41.766+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[164] at map at RandomForest.scala:1054), which has no missing parents
[2025-07-14T12:34:41.767+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 9.9 KiB, free 424.7 MiB)
[2025-07-14T12:34:41.767+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 424.7 MiB)
[2025-07-14T12:34:41.767+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 138.4.31.89:45589 (size: 4.6 KiB, free: 434.0 MiB)
[2025-07-14T12:34:41.768+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:41.768+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 79 (MapPartitionsRDD[164] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-14T12:34:41.768+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSchedulerImpl: Adding task set 79.0 with 4 tasks resource profile 0
[2025-07-14T12:34:41.769+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 160) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:41.769+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 161) (138.4.31.89, executor driver, partition 1, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:41.769+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSetManager: Starting task 2.0 in stage 79.0 (TID 162) (138.4.31.89, executor driver, partition 2, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:41.769+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSetManager: Starting task 3.0 in stage 79.0 (TID 163) (138.4.31.89, executor driver, partition 3, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:41.769+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Executor: Running task 0.0 in stage 79.0 (TID 160)
[2025-07-14T12:34:41.769+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Executor: Running task 1.0 in stage 79.0 (TID 161)
[2025-07-14T12:34:41.769+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Executor: Running task 2.0 in stage 79.0 (TID 162)
[2025-07-14T12:34:41.769+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Executor: Running task 3.0 in stage 79.0 (TID 163)
[2025-07-14T12:34:41.771+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Getting 4 (4.5 KiB) non-empty blocks including 4 (4.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:41.771+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Getting 4 (22.4 KiB) non-empty blocks including 4 (22.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:41.771+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Getting 4 (5.0 KiB) non-empty blocks including 4 (5.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:41.771+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Getting 4 (50.2 KiB) non-empty blocks including 4 (50.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:41.771+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:41.771+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:41.771+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:41.771+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:41.785+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Executor: Finished task 2.0 in stage 79.0 (TID 162). 2565 bytes result sent to driver
[2025-07-14T12:34:41.785+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Executor: Finished task 3.0 in stage 79.0 (TID 163). 2133 bytes result sent to driver
[2025-07-14T12:34:41.785+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSetManager: Finished task 2.0 in stage 79.0 (TID 162) in 16 ms on 138.4.31.89 (executor driver) (1/4)
[2025-07-14T12:34:41.785+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSetManager: Finished task 3.0 in stage 79.0 (TID 163) in 16 ms on 138.4.31.89 (executor driver) (2/4)
[2025-07-14T12:34:41.792+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Executor: Finished task 0.0 in stage 79.0 (TID 160). 14394 bytes result sent to driver
[2025-07-14T12:34:41.792+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Executor: Finished task 1.0 in stage 79.0 (TID 161). 25393 bytes result sent to driver
[2025-07-14T12:34:41.792+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 138.4.31.89:45589 in memory (size: 128.0 KiB, free: 434.1 MiB)
[2025-07-14T12:34:41.793+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 160) in 25 ms on 138.4.31.89 (executor driver) (3/4)
[2025-07-14T12:34:41.793+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 161) in 24 ms on 138.4.31.89 (executor driver) (4/4)
[2025-07-14T12:34:41.793+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool
[2025-07-14T12:34:41.793+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: ResultStage 79 (collectAsMap at RandomForest.scala:1054) finished in 0,027 s
[2025-07-14T12:34:41.793+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:41.793+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 79: Stage finished
[2025-07-14T12:34:41.793+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: Job 49 finished: collectAsMap at RandomForest.scala:1054, took 0,743431 s
[2025-07-14T12:34:41.797+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 51.8 KiB, free 425.1 MiB)
[2025-07-14T12:34:41.800+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 425.1 MiB)
[2025-07-14T12:34:41.800+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 138.4.31.89:45589 (size: 9.0 KiB, free: 434.1 MiB)
[2025-07-14T12:34:41.800+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 138.4.31.89:45589 in memory (size: 4.6 KiB, free: 434.1 MiB)
[2025-07-14T12:34:41.800+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO SparkContext: Created broadcast 66 from broadcast at RandomForest.scala:293
[2025-07-14T12:34:41.810+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Instrumentation: [f4d6894d] {"numFeatures":9}
[2025-07-14T12:34:41.810+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Instrumentation: [f4d6894d] {"numClasses":4}
[2025-07-14T12:34:41.810+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Instrumentation: [f4d6894d] {"numExamples":457013}
[2025-07-14T12:34:41.810+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Instrumentation: [f4d6894d] {"sumOfWeights":457013.0}
[2025-07-14T12:34:41.813+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 1160.0 B, free 425.1 MiB)
[2025-07-14T12:34:41.816+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 412.0 B, free 425.1 MiB)
[2025-07-14T12:34:41.816+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 138.4.31.89:45589 (size: 412.0 B, free: 434.1 MiB)
[2025-07-14T12:34:41.816+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO SparkContext: Created broadcast 67 from broadcast at RandomForest.scala:622
[2025-07-14T12:34:41.833+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
[2025-07-14T12:34:41.834+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: Registering RDD 167 (mapPartitions at RandomForest.scala:644) as input to shuffle 25
[2025-07-14T12:34:41.834+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: Got job 50 (collectAsMap at RandomForest.scala:663) with 4 output partitions
[2025-07-14T12:34:41.834+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: Final stage: ResultStage 82 (collectAsMap at RandomForest.scala:663)
[2025-07-14T12:34:41.834+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 81)
[2025-07-14T12:34:41.834+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 81)
[2025-07-14T12:34:41.835+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[167] at mapPartitions at RandomForest.scala:644), which has no missing parents
[2025-07-14T12:34:41.839+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 298.0 KiB, free 424.8 MiB)
[2025-07-14T12:34:41.840+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 136.6 KiB, free 424.6 MiB)
[2025-07-14T12:34:41.840+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 138.4.31.89:45589 (size: 136.6 KiB, free: 433.9 MiB)
[2025-07-14T12:34:41.840+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:41.840+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[167] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-14T12:34:41.840+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSchedulerImpl: Adding task set 81.0 with 4 tasks resource profile 0
[2025-07-14T12:34:41.841+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 164) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14836 bytes)
[2025-07-14T12:34:41.841+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 165) (138.4.31.89, executor driver, partition 1, NODE_LOCAL, 14836 bytes)
[2025-07-14T12:34:41.841+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSetManager: Starting task 2.0 in stage 81.0 (TID 166) (138.4.31.89, executor driver, partition 2, NODE_LOCAL, 14836 bytes)
[2025-07-14T12:34:41.841+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO TaskSetManager: Starting task 3.0 in stage 81.0 (TID 167) (138.4.31.89, executor driver, partition 3, NODE_LOCAL, 14836 bytes)
[2025-07-14T12:34:41.842+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Executor: Running task 0.0 in stage 81.0 (TID 164)
[2025-07-14T12:34:41.842+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Executor: Running task 3.0 in stage 81.0 (TID 167)
[2025-07-14T12:34:41.842+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Executor: Running task 2.0 in stage 81.0 (TID 166)
[2025-07-14T12:34:41.842+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO Executor: Running task 1.0 in stage 81.0 (TID 165)
[2025-07-14T12:34:41.869+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Getting 1 (366.2 KiB) non-empty blocks including 1 (366.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:41.870+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Getting 1 (384.6 KiB) non-empty blocks including 1 (384.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:41.870+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Getting 1 (3.2 MiB) non-empty blocks including 1 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:41.870+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Getting 1 (3.4 MiB) non-empty blocks including 1 (3.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:41.870+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:41.870+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:41.870+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:41.870+0200] {subprocess.py:93} INFO - 25/07/14 12:34:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:42.299+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO MemoryStore: Block rdd_166_3 stored as values in memory (estimated size 3.9 MiB, free 420.7 MiB)
[2025-07-14T12:34:42.300+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO BlockManagerInfo: Added rdd_166_3 in memory on 138.4.31.89:45589 (size: 3.9 MiB, free: 430.0 MiB)
[2025-07-14T12:34:42.328+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO MemoryStore: Block rdd_166_2 stored as values in memory (estimated size 3.8 MiB, free 417.0 MiB)
[2025-07-14T12:34:42.328+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO BlockManagerInfo: Added rdd_166_2 in memory on 138.4.31.89:45589 (size: 3.8 MiB, free: 426.3 MiB)
[2025-07-14T12:34:42.381+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO Executor: Finished task 3.0 in stage 81.0 (TID 167). 6108 bytes result sent to driver
[2025-07-14T12:34:42.382+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO TaskSetManager: Finished task 3.0 in stage 81.0 (TID 167) in 541 ms on 138.4.31.89 (executor driver) (1/4)
[2025-07-14T12:34:42.386+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO Executor: Finished task 2.0 in stage 81.0 (TID 166). 6108 bytes result sent to driver
[2025-07-14T12:34:42.386+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO TaskSetManager: Finished task 2.0 in stage 81.0 (TID 166) in 545 ms on 138.4.31.89 (executor driver) (2/4)
[2025-07-14T12:34:42.681+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO MemoryStore: Block rdd_166_0 stored as values in memory (estimated size 34.6 MiB, free 382.4 MiB)
[2025-07-14T12:34:42.682+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO BlockManagerInfo: Added rdd_166_0 in memory on 138.4.31.89:45589 (size: 34.6 MiB, free: 391.7 MiB)
[2025-07-14T12:34:42.696+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO MemoryStore: Block rdd_166_1 stored as values in memory (estimated size 36.2 MiB, free 346.2 MiB)
[2025-07-14T12:34:42.696+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO BlockManagerInfo: Added rdd_166_1 in memory on 138.4.31.89:45589 (size: 36.2 MiB, free: 355.5 MiB)
[2025-07-14T12:34:42.743+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO Executor: Finished task 0.0 in stage 81.0 (TID 164). 6108 bytes result sent to driver
[2025-07-14T12:34:42.743+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 164) in 902 ms on 138.4.31.89 (executor driver) (3/4)
[2025-07-14T12:34:42.753+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO Executor: Finished task 1.0 in stage 81.0 (TID 165). 6108 bytes result sent to driver
[2025-07-14T12:34:42.753+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 165) in 912 ms on 138.4.31.89 (executor driver) (4/4)
[2025-07-14T12:34:42.753+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool
[2025-07-14T12:34:42.754+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO DAGScheduler: ShuffleMapStage 81 (mapPartitions at RandomForest.scala:644) finished in 0,919 s
[2025-07-14T12:34:42.754+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:42.754+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:42.754+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO DAGScheduler: waiting: Set(ResultStage 82)
[2025-07-14T12:34:42.754+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:42.754+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[169] at map at RandomForest.scala:663), which has no missing parents
[2025-07-14T12:34:42.755+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 7.2 KiB, free 346.2 MiB)
[2025-07-14T12:34:42.755+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 346.2 MiB)
[2025-07-14T12:34:42.755+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 138.4.31.89:45589 (size: 3.8 KiB, free: 355.5 MiB)
[2025-07-14T12:34:42.756+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:42.756+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 82 (MapPartitionsRDD[169] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-14T12:34:42.756+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO TaskSchedulerImpl: Adding task set 82.0 with 4 tasks resource profile 0
[2025-07-14T12:34:42.756+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 168) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:42.757+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO TaskSetManager: Starting task 1.0 in stage 82.0 (TID 169) (138.4.31.89, executor driver, partition 1, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:42.757+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO TaskSetManager: Starting task 2.0 in stage 82.0 (TID 170) (138.4.31.89, executor driver, partition 2, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:42.757+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO TaskSetManager: Starting task 3.0 in stage 82.0 (TID 171) (138.4.31.89, executor driver, partition 3, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:42.757+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO Executor: Running task 0.0 in stage 82.0 (TID 168)
[2025-07-14T12:34:42.757+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO Executor: Running task 3.0 in stage 82.0 (TID 171)
[2025-07-14T12:34:42.757+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO Executor: Running task 2.0 in stage 82.0 (TID 170)
[2025-07-14T12:34:42.757+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO Executor: Running task 1.0 in stage 82.0 (TID 169)
[2025-07-14T12:34:42.759+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO ShuffleBlockFetcherIterator: Getting 4 (323.9 KiB) non-empty blocks including 4 (323.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:42.759+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO ShuffleBlockFetcherIterator: Getting 4 (232.1 KiB) non-empty blocks including 4 (232.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:42.759+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO ShuffleBlockFetcherIterator: Getting 4 (267.7 KiB) non-empty blocks including 4 (267.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:42.759+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO ShuffleBlockFetcherIterator: Getting 4 (179.0 KiB) non-empty blocks including 4 (179.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:42.759+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:42.759+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:42.759+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:42.759+0200] {subprocess.py:93} INFO - 25/07/14 12:34:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:43.017+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Finished task 2.0 in stage 82.0 (TID 170). 2814 bytes result sent to driver
[2025-07-14T12:34:43.017+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Finished task 2.0 in stage 82.0 (TID 170) in 260 ms on 138.4.31.89 (executor driver) (1/4)
[2025-07-14T12:34:43.020+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Finished task 3.0 in stage 82.0 (TID 171). 6377 bytes result sent to driver
[2025-07-14T12:34:43.020+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Finished task 1.0 in stage 82.0 (TID 169). 6583 bytes result sent to driver
[2025-07-14T12:34:43.020+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Finished task 3.0 in stage 82.0 (TID 171) in 263 ms on 138.4.31.89 (executor driver) (2/4)
[2025-07-14T12:34:43.020+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Finished task 1.0 in stage 82.0 (TID 169) in 263 ms on 138.4.31.89 (executor driver) (3/4)
[2025-07-14T12:34:43.044+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 138.4.31.89:45589 in memory (size: 9.3 KiB, free: 355.5 MiB)
[2025-07-14T12:34:43.045+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 138.4.31.89:45589 in memory (size: 9.2 KiB, free: 355.5 MiB)
[2025-07-14T12:34:43.045+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 138.4.31.89:45589 in memory (size: 136.6 KiB, free: 355.7 MiB)
[2025-07-14T12:34:43.069+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Finished task 0.0 in stage 82.0 (TID 168). 6619 bytes result sent to driver
[2025-07-14T12:34:43.070+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 168) in 314 ms on 138.4.31.89 (executor driver) (4/4)
[2025-07-14T12:34:43.070+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool
[2025-07-14T12:34:43.070+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: ResultStage 82 (collectAsMap at RandomForest.scala:663) finished in 0,316 s
[2025-07-14T12:34:43.070+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:43.070+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 82: Stage finished
[2025-07-14T12:34:43.071+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Job 50 finished: collectAsMap at RandomForest.scala:663, took 1,237086 s
[2025-07-14T12:34:43.071+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TorrentBroadcast: Destroying Broadcast(67) (from destroy at RandomForest.scala:674)
[2025-07-14T12:34:43.072+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 138.4.31.89:45589 in memory (size: 412.0 B, free: 355.7 MiB)
[2025-07-14T12:34:43.073+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 2.2 KiB, free 346.7 MiB)
[2025-07-14T12:34:43.074+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 537.0 B, free 346.7 MiB)
[2025-07-14T12:34:43.074+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 138.4.31.89:45589 (size: 537.0 B, free: 355.7 MiB)
[2025-07-14T12:34:43.074+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO SparkContext: Created broadcast 70 from broadcast at RandomForest.scala:622
[2025-07-14T12:34:43.082+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
[2025-07-14T12:34:43.082+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Registering RDD 170 (mapPartitions at RandomForest.scala:644) as input to shuffle 26
[2025-07-14T12:34:43.083+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Got job 51 (collectAsMap at RandomForest.scala:663) with 4 output partitions
[2025-07-14T12:34:43.083+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Final stage: ResultStage 85 (collectAsMap at RandomForest.scala:663)
[2025-07-14T12:34:43.083+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 84)
[2025-07-14T12:34:43.083+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 84)
[2025-07-14T12:34:43.083+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Submitting ShuffleMapStage 84 (MapPartitionsRDD[170] at mapPartitions at RandomForest.scala:644), which has no missing parents
[2025-07-14T12:34:43.086+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 311.7 KiB, free 346.4 MiB)
[2025-07-14T12:34:43.087+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 141.9 KiB, free 346.3 MiB)
[2025-07-14T12:34:43.087+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 138.4.31.89:45589 (size: 141.9 KiB, free: 355.5 MiB)
[2025-07-14T12:34:43.087+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:43.087+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 84 (MapPartitionsRDD[170] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-14T12:34:43.087+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSchedulerImpl: Adding task set 84.0 with 4 tasks resource profile 0
[2025-07-14T12:34:43.088+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 172) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 14836 bytes)
[2025-07-14T12:34:43.088+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Starting task 1.0 in stage 84.0 (TID 173) (138.4.31.89, executor driver, partition 1, PROCESS_LOCAL, 14836 bytes)
[2025-07-14T12:34:43.088+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Starting task 2.0 in stage 84.0 (TID 174) (138.4.31.89, executor driver, partition 2, PROCESS_LOCAL, 14836 bytes)
[2025-07-14T12:34:43.088+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Starting task 3.0 in stage 84.0 (TID 175) (138.4.31.89, executor driver, partition 3, PROCESS_LOCAL, 14836 bytes)
[2025-07-14T12:34:43.089+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Running task 3.0 in stage 84.0 (TID 175)
[2025-07-14T12:34:43.089+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Running task 1.0 in stage 84.0 (TID 173)
[2025-07-14T12:34:43.089+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Running task 2.0 in stage 84.0 (TID 174)
[2025-07-14T12:34:43.089+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Running task 0.0 in stage 84.0 (TID 172)
[2025-07-14T12:34:43.097+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManager: Found block rdd_166_3 locally
[2025-07-14T12:34:43.097+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManager: Found block rdd_166_2 locally
[2025-07-14T12:34:43.098+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManager: Found block rdd_166_0 locally
[2025-07-14T12:34:43.098+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManager: Found block rdd_166_1 locally
[2025-07-14T12:34:43.178+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Finished task 2.0 in stage 84.0 (TID 174). 5420 bytes result sent to driver
[2025-07-14T12:34:43.178+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Finished task 3.0 in stage 84.0 (TID 175). 5420 bytes result sent to driver
[2025-07-14T12:34:43.179+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Finished task 2.0 in stage 84.0 (TID 174) in 91 ms on 138.4.31.89 (executor driver) (1/4)
[2025-07-14T12:34:43.179+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Finished task 3.0 in stage 84.0 (TID 175) in 91 ms on 138.4.31.89 (executor driver) (2/4)
[2025-07-14T12:34:43.246+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Finished task 0.0 in stage 84.0 (TID 172). 5420 bytes result sent to driver
[2025-07-14T12:34:43.246+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 172) in 158 ms on 138.4.31.89 (executor driver) (3/4)
[2025-07-14T12:34:43.249+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Finished task 1.0 in stage 84.0 (TID 173). 5420 bytes result sent to driver
[2025-07-14T12:34:43.249+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Finished task 1.0 in stage 84.0 (TID 173) in 161 ms on 138.4.31.89 (executor driver) (4/4)
[2025-07-14T12:34:43.249+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool
[2025-07-14T12:34:43.249+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: ShuffleMapStage 84 (mapPartitions at RandomForest.scala:644) finished in 0,166 s
[2025-07-14T12:34:43.249+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:43.249+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:43.249+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: waiting: Set(ResultStage 85)
[2025-07-14T12:34:43.249+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:43.249+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[172] at map at RandomForest.scala:663), which has no missing parents
[2025-07-14T12:34:43.250+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 9.4 KiB, free 346.3 MiB)
[2025-07-14T12:34:43.250+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 346.2 MiB)
[2025-07-14T12:34:43.250+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 138.4.31.89:45589 (size: 4.9 KiB, free: 355.5 MiB)
[2025-07-14T12:34:43.251+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:43.251+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 85 (MapPartitionsRDD[172] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-14T12:34:43.251+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSchedulerImpl: Adding task set 85.0 with 4 tasks resource profile 0
[2025-07-14T12:34:43.251+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 176) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:43.251+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Starting task 1.0 in stage 85.0 (TID 177) (138.4.31.89, executor driver, partition 1, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:43.252+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Starting task 2.0 in stage 85.0 (TID 178) (138.4.31.89, executor driver, partition 2, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:43.252+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Starting task 3.0 in stage 85.0 (TID 179) (138.4.31.89, executor driver, partition 3, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:43.252+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Running task 1.0 in stage 85.0 (TID 177)
[2025-07-14T12:34:43.252+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Running task 0.0 in stage 85.0 (TID 176)
[2025-07-14T12:34:43.252+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Running task 2.0 in stage 85.0 (TID 178)
[2025-07-14T12:34:43.252+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Running task 3.0 in stage 85.0 (TID 179)
[2025-07-14T12:34:43.253+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO ShuffleBlockFetcherIterator: Getting 4 (433.2 KiB) non-empty blocks including 4 (433.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:43.253+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:43.253+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO ShuffleBlockFetcherIterator: Getting 4 (373.7 KiB) non-empty blocks including 4 (373.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:43.253+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO ShuffleBlockFetcherIterator: Getting 4 (375.9 KiB) non-empty blocks including 4 (375.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:43.253+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO ShuffleBlockFetcherIterator: Getting 4 (170.9 KiB) non-empty blocks including 4 (170.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:43.253+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:43.253+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:43.253+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:43.307+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Finished task 2.0 in stage 85.0 (TID 178). 10668 bytes result sent to driver
[2025-07-14T12:34:43.308+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Finished task 2.0 in stage 85.0 (TID 178) in 57 ms on 138.4.31.89 (executor driver) (1/4)
[2025-07-14T12:34:43.334+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 138.4.31.89:45589 in memory (size: 3.8 KiB, free: 355.5 MiB)
[2025-07-14T12:34:43.334+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 138.4.31.89:45589 in memory (size: 141.9 KiB, free: 355.7 MiB)
[2025-07-14T12:34:43.393+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Finished task 1.0 in stage 85.0 (TID 177). 43293 bytes result sent to driver
[2025-07-14T12:34:43.394+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Finished task 1.0 in stage 85.0 (TID 177) in 143 ms on 138.4.31.89 (executor driver) (2/4)
[2025-07-14T12:34:43.412+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Finished task 3.0 in stage 85.0 (TID 179). 113364 bytes result sent to driver
[2025-07-14T12:34:43.414+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Finished task 3.0 in stage 85.0 (TID 179) in 162 ms on 138.4.31.89 (executor driver) (3/4)
[2025-07-14T12:34:43.435+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Finished task 0.0 in stage 85.0 (TID 176). 89282 bytes result sent to driver
[2025-07-14T12:34:43.436+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 176) in 185 ms on 138.4.31.89 (executor driver) (4/4)
[2025-07-14T12:34:43.436+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool
[2025-07-14T12:34:43.437+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: ResultStage 85 (collectAsMap at RandomForest.scala:663) finished in 0,186 s
[2025-07-14T12:34:43.437+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:43.437+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 85: Stage finished
[2025-07-14T12:34:43.437+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Job 51 finished: collectAsMap at RandomForest.scala:663, took 0,354592 s
[2025-07-14T12:34:43.437+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TorrentBroadcast: Destroying Broadcast(70) (from destroy at RandomForest.scala:674)
[2025-07-14T12:34:43.438+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 138.4.31.89:45589 in memory (size: 537.0 B, free: 355.7 MiB)
[2025-07-14T12:34:43.439+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 4.8 KiB, free 346.7 MiB)
[2025-07-14T12:34:43.439+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 755.0 B, free 346.7 MiB)
[2025-07-14T12:34:43.439+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 138.4.31.89:45589 (size: 755.0 B, free: 355.7 MiB)
[2025-07-14T12:34:43.440+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO SparkContext: Created broadcast 73 from broadcast at RandomForest.scala:622
[2025-07-14T12:34:43.450+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
[2025-07-14T12:34:43.450+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Registering RDD 173 (mapPartitions at RandomForest.scala:644) as input to shuffle 27
[2025-07-14T12:34:43.450+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Got job 52 (collectAsMap at RandomForest.scala:663) with 4 output partitions
[2025-07-14T12:34:43.450+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Final stage: ResultStage 88 (collectAsMap at RandomForest.scala:663)
[2025-07-14T12:34:43.450+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 87)
[2025-07-14T12:34:43.450+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 87)
[2025-07-14T12:34:43.451+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Submitting ShuffleMapStage 87 (MapPartitionsRDD[173] at mapPartitions at RandomForest.scala:644), which has no missing parents
[2025-07-14T12:34:43.455+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 553.0 KiB, free 346.2 MiB)
[2025-07-14T12:34:43.456+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 246.2 KiB, free 345.9 MiB)
[2025-07-14T12:34:43.456+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 138.4.31.89:45589 (size: 246.2 KiB, free: 355.4 MiB)
[2025-07-14T12:34:43.456+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:43.457+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 87 (MapPartitionsRDD[173] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-14T12:34:43.457+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSchedulerImpl: Adding task set 87.0 with 4 tasks resource profile 0
[2025-07-14T12:34:43.457+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 180) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 14836 bytes)
[2025-07-14T12:34:43.457+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Starting task 1.0 in stage 87.0 (TID 181) (138.4.31.89, executor driver, partition 1, PROCESS_LOCAL, 14836 bytes)
[2025-07-14T12:34:43.458+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Starting task 2.0 in stage 87.0 (TID 182) (138.4.31.89, executor driver, partition 2, PROCESS_LOCAL, 14836 bytes)
[2025-07-14T12:34:43.458+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Starting task 3.0 in stage 87.0 (TID 183) (138.4.31.89, executor driver, partition 3, PROCESS_LOCAL, 14836 bytes)
[2025-07-14T12:34:43.458+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Running task 3.0 in stage 87.0 (TID 183)
[2025-07-14T12:34:43.458+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Running task 1.0 in stage 87.0 (TID 181)
[2025-07-14T12:34:43.458+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Running task 0.0 in stage 87.0 (TID 180)
[2025-07-14T12:34:43.458+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Running task 2.0 in stage 87.0 (TID 182)
[2025-07-14T12:34:43.481+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManager: Found block rdd_166_3 locally
[2025-07-14T12:34:43.482+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManager: Found block rdd_166_2 locally
[2025-07-14T12:34:43.482+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManager: Found block rdd_166_0 locally
[2025-07-14T12:34:43.482+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManager: Found block rdd_166_1 locally
[2025-07-14T12:34:43.542+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Finished task 2.0 in stage 87.0 (TID 182). 5420 bytes result sent to driver
[2025-07-14T12:34:43.542+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Finished task 3.0 in stage 87.0 (TID 183). 5420 bytes result sent to driver
[2025-07-14T12:34:43.542+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Finished task 2.0 in stage 87.0 (TID 182) in 85 ms on 138.4.31.89 (executor driver) (1/4)
[2025-07-14T12:34:43.542+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Finished task 3.0 in stage 87.0 (TID 183) in 84 ms on 138.4.31.89 (executor driver) (2/4)
[2025-07-14T12:34:43.640+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Finished task 0.0 in stage 87.0 (TID 180). 5420 bytes result sent to driver
[2025-07-14T12:34:43.640+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 180) in 183 ms on 138.4.31.89 (executor driver) (3/4)
[2025-07-14T12:34:43.645+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Finished task 1.0 in stage 87.0 (TID 181). 5420 bytes result sent to driver
[2025-07-14T12:34:43.646+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Finished task 1.0 in stage 87.0 (TID 181) in 188 ms on 138.4.31.89 (executor driver) (4/4)
[2025-07-14T12:34:43.646+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool
[2025-07-14T12:34:43.646+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: ShuffleMapStage 87 (mapPartitions at RandomForest.scala:644) finished in 0,195 s
[2025-07-14T12:34:43.646+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:43.646+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:43.646+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: waiting: Set(ResultStage 88)
[2025-07-14T12:34:43.646+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:43.646+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[175] at map at RandomForest.scala:663), which has no missing parents
[2025-07-14T12:34:43.647+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 11.5 KiB, free 345.9 MiB)
[2025-07-14T12:34:43.647+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 345.9 MiB)
[2025-07-14T12:34:43.647+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 138.4.31.89:45589 (size: 5.7 KiB, free: 355.4 MiB)
[2025-07-14T12:34:43.648+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:43.648+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 88 (MapPartitionsRDD[175] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-14T12:34:43.648+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSchedulerImpl: Adding task set 88.0 with 4 tasks resource profile 0
[2025-07-14T12:34:43.648+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 184) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:43.649+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Starting task 1.0 in stage 88.0 (TID 185) (138.4.31.89, executor driver, partition 1, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:43.649+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Starting task 2.0 in stage 88.0 (TID 186) (138.4.31.89, executor driver, partition 2, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:43.649+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Starting task 3.0 in stage 88.0 (TID 187) (138.4.31.89, executor driver, partition 3, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:43.649+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Running task 0.0 in stage 88.0 (TID 184)
[2025-07-14T12:34:43.649+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Running task 2.0 in stage 88.0 (TID 186)
[2025-07-14T12:34:43.649+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Running task 1.0 in stage 88.0 (TID 185)
[2025-07-14T12:34:43.649+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Running task 3.0 in stage 88.0 (TID 187)
[2025-07-14T12:34:43.650+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO ShuffleBlockFetcherIterator: Getting 4 (431.1 KiB) non-empty blocks including 4 (431.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:43.650+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO ShuffleBlockFetcherIterator: Getting 4 (459.4 KiB) non-empty blocks including 4 (459.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:43.650+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO ShuffleBlockFetcherIterator: Getting 4 (342.8 KiB) non-empty blocks including 4 (342.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:43.650+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO ShuffleBlockFetcherIterator: Getting 4 (577.0 KiB) non-empty blocks including 4 (577.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:43.650+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:43.650+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:43.650+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:43.651+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:43.669+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 138.4.31.89:45589 in memory (size: 246.2 KiB, free: 355.7 MiB)
[2025-07-14T12:34:43.742+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Finished task 0.0 in stage 88.0 (TID 184). 4947 bytes result sent to driver
[2025-07-14T12:34:43.742+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 184) in 94 ms on 138.4.31.89 (executor driver) (1/4)
[2025-07-14T12:34:43.778+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Finished task 2.0 in stage 88.0 (TID 186). 27990 bytes result sent to driver
[2025-07-14T12:34:43.779+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Finished task 2.0 in stage 88.0 (TID 186) in 129 ms on 138.4.31.89 (executor driver) (2/4)
[2025-07-14T12:34:43.812+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Finished task 3.0 in stage 88.0 (TID 187). 11295 bytes result sent to driver
[2025-07-14T12:34:43.813+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Finished task 3.0 in stage 88.0 (TID 187) in 164 ms on 138.4.31.89 (executor driver) (3/4)
[2025-07-14T12:34:43.854+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Finished task 1.0 in stage 88.0 (TID 185). 172571 bytes result sent to driver
[2025-07-14T12:34:43.856+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Finished task 1.0 in stage 88.0 (TID 185) in 208 ms on 138.4.31.89 (executor driver) (4/4)
[2025-07-14T12:34:43.856+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool
[2025-07-14T12:34:43.856+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: ResultStage 88 (collectAsMap at RandomForest.scala:663) finished in 0,210 s
[2025-07-14T12:34:43.856+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:43.856+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 88: Stage finished
[2025-07-14T12:34:43.856+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Job 52 finished: collectAsMap at RandomForest.scala:663, took 0,406599 s
[2025-07-14T12:34:43.857+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TorrentBroadcast: Destroying Broadcast(73) (from destroy at RandomForest.scala:674)
[2025-07-14T12:34:43.857+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 138.4.31.89:45589 in memory (size: 755.0 B, free: 355.7 MiB)
[2025-07-14T12:34:43.858+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 9.7 KiB, free 346.7 MiB)
[2025-07-14T12:34:43.858+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 1216.0 B, free 346.7 MiB)
[2025-07-14T12:34:43.858+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 138.4.31.89:45589 (size: 1216.0 B, free: 355.7 MiB)
[2025-07-14T12:34:43.859+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO SparkContext: Created broadcast 76 from broadcast at RandomForest.scala:622
[2025-07-14T12:34:43.870+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
[2025-07-14T12:34:43.870+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Registering RDD 176 (mapPartitions at RandomForest.scala:644) as input to shuffle 28
[2025-07-14T12:34:43.870+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Got job 53 (collectAsMap at RandomForest.scala:663) with 4 output partitions
[2025-07-14T12:34:43.870+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Final stage: ResultStage 91 (collectAsMap at RandomForest.scala:663)
[2025-07-14T12:34:43.870+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)
[2025-07-14T12:34:43.870+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 90)
[2025-07-14T12:34:43.871+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Submitting ShuffleMapStage 90 (MapPartitionsRDD[176] at mapPartitions at RandomForest.scala:644), which has no missing parents
[2025-07-14T12:34:43.878+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 138.4.31.89:45589 in memory (size: 5.7 KiB, free: 355.7 MiB)
[2025-07-14T12:34:43.878+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 757.7 KiB, free 346.0 MiB)
[2025-07-14T12:34:43.880+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 329.9 KiB, free 345.6 MiB)
[2025-07-14T12:34:43.880+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 138.4.31.89:45589 (size: 329.9 KiB, free: 355.4 MiB)
[2025-07-14T12:34:43.880+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:43.881+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 90 (MapPartitionsRDD[176] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-14T12:34:43.881+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSchedulerImpl: Adding task set 90.0 with 4 tasks resource profile 0
[2025-07-14T12:34:43.881+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 188) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 14836 bytes)
[2025-07-14T12:34:43.881+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Starting task 1.0 in stage 90.0 (TID 189) (138.4.31.89, executor driver, partition 1, PROCESS_LOCAL, 14836 bytes)
[2025-07-14T12:34:43.881+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Starting task 2.0 in stage 90.0 (TID 190) (138.4.31.89, executor driver, partition 2, PROCESS_LOCAL, 14836 bytes)
[2025-07-14T12:34:43.881+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO TaskSetManager: Starting task 3.0 in stage 90.0 (TID 191) (138.4.31.89, executor driver, partition 3, PROCESS_LOCAL, 14836 bytes)
[2025-07-14T12:34:43.882+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Running task 2.0 in stage 90.0 (TID 190)
[2025-07-14T12:34:43.882+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Running task 1.0 in stage 90.0 (TID 189)
[2025-07-14T12:34:43.882+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Running task 0.0 in stage 90.0 (TID 188)
[2025-07-14T12:34:43.882+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO Executor: Running task 3.0 in stage 90.0 (TID 191)
[2025-07-14T12:34:43.898+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManager: Found block rdd_166_3 locally
[2025-07-14T12:34:43.898+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManager: Found block rdd_166_0 locally
[2025-07-14T12:34:43.898+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManager: Found block rdd_166_2 locally
[2025-07-14T12:34:43.898+0200] {subprocess.py:93} INFO - 25/07/14 12:34:43 INFO BlockManager: Found block rdd_166_1 locally
[2025-07-14T12:34:44.113+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO Executor: Finished task 2.0 in stage 90.0 (TID 190). 5420 bytes result sent to driver
[2025-07-14T12:34:44.118+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSetManager: Finished task 2.0 in stage 90.0 (TID 190) in 237 ms on 138.4.31.89 (executor driver) (1/4)
[2025-07-14T12:34:44.118+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO Executor: Finished task 3.0 in stage 90.0 (TID 191). 5506 bytes result sent to driver
[2025-07-14T12:34:44.118+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSetManager: Finished task 3.0 in stage 90.0 (TID 191) in 237 ms on 138.4.31.89 (executor driver) (2/4)
[2025-07-14T12:34:44.258+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO Executor: Finished task 0.0 in stage 90.0 (TID 188). 5463 bytes result sent to driver
[2025-07-14T12:34:44.259+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 188) in 378 ms on 138.4.31.89 (executor driver) (3/4)
[2025-07-14T12:34:44.265+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO Executor: Finished task 1.0 in stage 90.0 (TID 189). 5463 bytes result sent to driver
[2025-07-14T12:34:44.266+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSetManager: Finished task 1.0 in stage 90.0 (TID 189) in 384 ms on 138.4.31.89 (executor driver) (4/4)
[2025-07-14T12:34:44.266+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool
[2025-07-14T12:34:44.266+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO DAGScheduler: ShuffleMapStage 90 (mapPartitions at RandomForest.scala:644) finished in 0,395 s
[2025-07-14T12:34:44.266+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:44.266+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:44.266+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO DAGScheduler: waiting: Set(ResultStage 91)
[2025-07-14T12:34:44.266+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:44.266+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[178] at map at RandomForest.scala:663), which has no missing parents
[2025-07-14T12:34:44.267+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 15.6 KiB, free 345.6 MiB)
[2025-07-14T12:34:44.267+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 345.6 MiB)
[2025-07-14T12:34:44.267+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 138.4.31.89:45589 (size: 7.3 KiB, free: 355.4 MiB)
[2025-07-14T12:34:44.268+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:44.268+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 91 (MapPartitionsRDD[178] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-14T12:34:44.268+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSchedulerImpl: Adding task set 91.0 with 4 tasks resource profile 0
[2025-07-14T12:34:44.268+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 192) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:44.268+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 193) (138.4.31.89, executor driver, partition 1, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:44.268+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSetManager: Starting task 2.0 in stage 91.0 (TID 194) (138.4.31.89, executor driver, partition 2, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:44.268+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSetManager: Starting task 3.0 in stage 91.0 (TID 195) (138.4.31.89, executor driver, partition 3, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:44.268+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO Executor: Running task 0.0 in stage 91.0 (TID 192)
[2025-07-14T12:34:44.269+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO Executor: Running task 3.0 in stage 91.0 (TID 195)
[2025-07-14T12:34:44.269+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO Executor: Running task 1.0 in stage 91.0 (TID 193)
[2025-07-14T12:34:44.269+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO Executor: Running task 2.0 in stage 91.0 (TID 194)
[2025-07-14T12:34:44.270+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO ShuffleBlockFetcherIterator: Getting 4 (666.0 KiB) non-empty blocks including 4 (666.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:44.270+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO ShuffleBlockFetcherIterator: Getting 4 (578.3 KiB) non-empty blocks including 4 (578.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:44.270+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO ShuffleBlockFetcherIterator: Getting 4 (619.3 KiB) non-empty blocks including 4 (619.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:44.270+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO ShuffleBlockFetcherIterator: Getting 4 (784.8 KiB) non-empty blocks including 4 (784.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:44.270+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:44.270+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:44.270+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:44.270+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:44.504+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO Executor: Finished task 3.0 in stage 91.0 (TID 195). 117293 bytes result sent to driver
[2025-07-14T12:34:44.507+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSetManager: Finished task 3.0 in stage 91.0 (TID 195) in 239 ms on 138.4.31.89 (executor driver) (1/4)
[2025-07-14T12:34:44.544+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO Executor: Finished task 0.0 in stage 91.0 (TID 192). 78959 bytes result sent to driver
[2025-07-14T12:34:44.545+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 192) in 277 ms on 138.4.31.89 (executor driver) (2/4)
[2025-07-14T12:34:44.577+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO Executor: Finished task 1.0 in stage 91.0 (TID 193). 97103 bytes result sent to driver
[2025-07-14T12:34:44.578+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 193) in 310 ms on 138.4.31.89 (executor driver) (3/4)
[2025-07-14T12:34:44.689+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO Executor: Finished task 2.0 in stage 91.0 (TID 194). 79296 bytes result sent to driver
[2025-07-14T12:34:44.690+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSetManager: Finished task 2.0 in stage 91.0 (TID 194) in 422 ms on 138.4.31.89 (executor driver) (4/4)
[2025-07-14T12:34:44.690+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool
[2025-07-14T12:34:44.691+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO DAGScheduler: ResultStage 91 (collectAsMap at RandomForest.scala:663) finished in 0,424 s
[2025-07-14T12:34:44.691+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:44.691+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 91: Stage finished
[2025-07-14T12:34:44.691+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO DAGScheduler: Job 53 finished: collectAsMap at RandomForest.scala:663, took 0,821182 s
[2025-07-14T12:34:44.691+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TorrentBroadcast: Destroying Broadcast(76) (from destroy at RandomForest.scala:674)
[2025-07-14T12:34:44.692+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 138.4.31.89:45589 in memory (size: 1216.0 B, free: 355.4 MiB)
[2025-07-14T12:34:44.693+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 18.9 KiB, free 345.6 MiB)
[2025-07-14T12:34:44.694+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 2.1 KiB, free 345.6 MiB)
[2025-07-14T12:34:44.694+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 138.4.31.89:45589 (size: 2.1 KiB, free: 355.3 MiB)
[2025-07-14T12:34:44.694+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO SparkContext: Created broadcast 79 from broadcast at RandomForest.scala:622
[2025-07-14T12:34:44.707+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
[2025-07-14T12:34:44.708+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO DAGScheduler: Registering RDD 179 (mapPartitions at RandomForest.scala:644) as input to shuffle 29
[2025-07-14T12:34:44.708+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO DAGScheduler: Got job 54 (collectAsMap at RandomForest.scala:663) with 4 output partitions
[2025-07-14T12:34:44.708+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO DAGScheduler: Final stage: ResultStage 94 (collectAsMap at RandomForest.scala:663)
[2025-07-14T12:34:44.708+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 93)
[2025-07-14T12:34:44.708+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 93)
[2025-07-14T12:34:44.708+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO DAGScheduler: Submitting ShuffleMapStage 93 (MapPartitionsRDD[179] at mapPartitions at RandomForest.scala:644), which has no missing parents
[2025-07-14T12:34:44.716+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 WARN DAGScheduler: Broadcasting large task binary with size 1118.1 KiB
[2025-07-14T12:34:44.716+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 1118.1 KiB, free 344.5 MiB)
[2025-07-14T12:34:44.718+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 479.7 KiB, free 344.0 MiB)
[2025-07-14T12:34:44.718+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 138.4.31.89:45589 (size: 479.7 KiB, free: 354.9 MiB)
[2025-07-14T12:34:44.719+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:44.719+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 93 (MapPartitionsRDD[179] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-14T12:34:44.719+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSchedulerImpl: Adding task set 93.0 with 4 tasks resource profile 0
[2025-07-14T12:34:44.719+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 196) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 14836 bytes)
[2025-07-14T12:34:44.720+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSetManager: Starting task 1.0 in stage 93.0 (TID 197) (138.4.31.89, executor driver, partition 1, PROCESS_LOCAL, 14836 bytes)
[2025-07-14T12:34:44.720+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSetManager: Starting task 2.0 in stage 93.0 (TID 198) (138.4.31.89, executor driver, partition 2, PROCESS_LOCAL, 14836 bytes)
[2025-07-14T12:34:44.720+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSetManager: Starting task 3.0 in stage 93.0 (TID 199) (138.4.31.89, executor driver, partition 3, PROCESS_LOCAL, 14836 bytes)
[2025-07-14T12:34:44.720+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO Executor: Running task 0.0 in stage 93.0 (TID 196)
[2025-07-14T12:34:44.720+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO Executor: Running task 2.0 in stage 93.0 (TID 198)
[2025-07-14T12:34:44.720+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO Executor: Running task 1.0 in stage 93.0 (TID 197)
[2025-07-14T12:34:44.720+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO Executor: Running task 3.0 in stage 93.0 (TID 199)
[2025-07-14T12:34:44.730+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO BlockManager: Found block rdd_166_2 locally
[2025-07-14T12:34:44.730+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO BlockManager: Found block rdd_166_1 locally
[2025-07-14T12:34:44.730+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO BlockManager: Found block rdd_166_0 locally
[2025-07-14T12:34:44.730+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO BlockManager: Found block rdd_166_3 locally
[2025-07-14T12:34:44.817+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO Executor: Finished task 2.0 in stage 93.0 (TID 198). 5420 bytes result sent to driver
[2025-07-14T12:34:44.818+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSetManager: Finished task 2.0 in stage 93.0 (TID 198) in 98 ms on 138.4.31.89 (executor driver) (1/4)
[2025-07-14T12:34:44.819+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO Executor: Finished task 3.0 in stage 93.0 (TID 199). 5420 bytes result sent to driver
[2025-07-14T12:34:44.819+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO TaskSetManager: Finished task 3.0 in stage 93.0 (TID 199) in 99 ms on 138.4.31.89 (executor driver) (2/4)
[2025-07-14T12:34:44.899+0200] {subprocess.py:93} INFO - 25/07/14 12:34:44 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 138.4.31.89:45589 in memory (size: 7.3 KiB, free: 354.9 MiB)
[2025-07-14T12:34:45.060+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Finished task 0.0 in stage 93.0 (TID 196). 5463 bytes result sent to driver
[2025-07-14T12:34:45.061+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 196) in 342 ms on 138.4.31.89 (executor driver) (3/4)
[2025-07-14T12:34:45.068+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Finished task 1.0 in stage 93.0 (TID 197). 5463 bytes result sent to driver
[2025-07-14T12:34:45.068+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Finished task 1.0 in stage 93.0 (TID 197) in 349 ms on 138.4.31.89 (executor driver) (4/4)
[2025-07-14T12:34:45.068+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool
[2025-07-14T12:34:45.068+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: ShuffleMapStage 93 (mapPartitions at RandomForest.scala:644) finished in 0,360 s
[2025-07-14T12:34:45.068+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:45.068+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:45.068+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: waiting: Set(ResultStage 94)
[2025-07-14T12:34:45.068+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:45.068+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[181] at map at RandomForest.scala:663), which has no missing parents
[2025-07-14T12:34:45.069+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 24.0 KiB, free 344.0 MiB)
[2025-07-14T12:34:45.070+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 344.0 MiB)
[2025-07-14T12:34:45.070+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 138.4.31.89:45589 (size: 10.3 KiB, free: 354.9 MiB)
[2025-07-14T12:34:45.070+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:45.070+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 94 (MapPartitionsRDD[181] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-14T12:34:45.070+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSchedulerImpl: Adding task set 94.0 with 4 tasks resource profile 0
[2025-07-14T12:34:45.071+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 200) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:45.071+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Starting task 1.0 in stage 94.0 (TID 201) (138.4.31.89, executor driver, partition 1, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:45.071+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Starting task 2.0 in stage 94.0 (TID 202) (138.4.31.89, executor driver, partition 2, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:45.071+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Starting task 3.0 in stage 94.0 (TID 203) (138.4.31.89, executor driver, partition 3, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:45.071+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Running task 3.0 in stage 94.0 (TID 203)
[2025-07-14T12:34:45.071+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Running task 2.0 in stage 94.0 (TID 202)
[2025-07-14T12:34:45.071+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Running task 1.0 in stage 94.0 (TID 201)
[2025-07-14T12:34:45.071+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Running task 0.0 in stage 94.0 (TID 200)
[2025-07-14T12:34:45.073+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO ShuffleBlockFetcherIterator: Getting 4 (749.4 KiB) non-empty blocks including 4 (749.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:45.073+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO ShuffleBlockFetcherIterator: Getting 4 (861.8 KiB) non-empty blocks including 4 (861.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:45.073+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO ShuffleBlockFetcherIterator: Getting 4 (757.6 KiB) non-empty blocks including 4 (757.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:45.073+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO ShuffleBlockFetcherIterator: Getting 4 (897.4 KiB) non-empty blocks including 4 (897.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:45.073+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:45.073+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:45.073+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:45.073+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:45.526+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Finished task 1.0 in stage 94.0 (TID 201). 163209 bytes result sent to driver
[2025-07-14T12:34:45.528+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Finished task 1.0 in stage 94.0 (TID 201) in 457 ms on 138.4.31.89 (executor driver) (1/4)
[2025-07-14T12:34:45.538+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Finished task 3.0 in stage 94.0 (TID 203). 132045 bytes result sent to driver
[2025-07-14T12:34:45.541+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Finished task 3.0 in stage 94.0 (TID 203) in 470 ms on 138.4.31.89 (executor driver) (2/4)
[2025-07-14T12:34:45.543+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Finished task 0.0 in stage 94.0 (TID 200). 101975 bytes result sent to driver
[2025-07-14T12:34:45.544+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 200) in 474 ms on 138.4.31.89 (executor driver) (3/4)
[2025-07-14T12:34:45.757+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Finished task 2.0 in stage 94.0 (TID 202). 327296 bytes result sent to driver
[2025-07-14T12:34:45.760+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Finished task 2.0 in stage 94.0 (TID 202) in 689 ms on 138.4.31.89 (executor driver) (4/4)
[2025-07-14T12:34:45.760+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool
[2025-07-14T12:34:45.760+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: ResultStage 94 (collectAsMap at RandomForest.scala:663) finished in 0,691 s
[2025-07-14T12:34:45.760+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:45.760+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 94: Stage finished
[2025-07-14T12:34:45.761+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: Job 54 finished: collectAsMap at RandomForest.scala:663, took 1,053444 s
[2025-07-14T12:34:45.761+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TorrentBroadcast: Destroying Broadcast(79) (from destroy at RandomForest.scala:674)
[2025-07-14T12:34:45.762+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 138.4.31.89:45589 in memory (size: 2.1 KiB, free: 354.9 MiB)
[2025-07-14T12:34:45.762+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO RandomForest: Internal timing for DecisionTree:
[2025-07-14T12:34:45.762+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO RandomForest:   init: 9.18798E-4
[2025-07-14T12:34:45.762+0200] {subprocess.py:93} INFO -   total: 3.952767406
[2025-07-14T12:34:45.762+0200] {subprocess.py:93} INFO -   findBestSplits: 3.947387603
[2025-07-14T12:34:45.762+0200] {subprocess.py:93} INFO -   chooseSplits: 3.94430099
[2025-07-14T12:34:45.768+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO MapPartitionsRDD: Removing RDD 166 from persistence list
[2025-07-14T12:34:45.770+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO BlockManager: Removing RDD 166
[2025-07-14T12:34:45.770+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TorrentBroadcast: Destroying Broadcast(66) (from destroy at RandomForest.scala:305)
[2025-07-14T12:34:45.770+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 138.4.31.89:45589 in memory (size: 9.0 KiB, free: 433.3 MiB)
[2025-07-14T12:34:45.774+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Instrumentation: [f4d6894d] {"numClasses":4}
[2025-07-14T12:34:45.774+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Instrumentation: [f4d6894d] {"numFeatures":9}
[2025-07-14T12:34:45.861+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:45.862+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-14T12:34:45.862+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-14T12:34:45.862+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-14T12:34:45.862+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:45.868+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:45.868+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-14T12:34:45.869+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:45.877+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO FileSourceStrategy: Pushed Filters:
[2025-07-14T12:34:45.877+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-14T12:34:45.882+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 214.5 KiB, free 422.3 MiB)
[2025-07-14T12:34:45.886+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 39.0 KiB, free 422.3 MiB)
[2025-07-14T12:34:45.887+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 138.4.31.89:45589 (size: 39.0 KiB, free: 433.3 MiB)
[2025-07-14T12:34:45.887+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO SparkContext: Created broadcast 82 from rdd at ClassificationSummary.scala:58
[2025-07-14T12:34:45.887+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-14T12:34:45.889+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: Registering RDD 185 (rdd at ClassificationSummary.scala:58) as input to shuffle 30
[2025-07-14T12:34:45.889+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: Got map stage job 55 (rdd at ClassificationSummary.scala:58) with 2 output partitions
[2025-07-14T12:34:45.889+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: Final stage: ShuffleMapStage 95 (rdd at ClassificationSummary.scala:58)
[2025-07-14T12:34:45.889+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:45.889+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:45.889+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: Submitting ShuffleMapStage 95 (MapPartitionsRDD[185] at rdd at ClassificationSummary.scala:58), which has no missing parents
[2025-07-14T12:34:45.889+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 20.7 KiB, free 422.3 MiB)
[2025-07-14T12:34:45.890+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 9.3 KiB, free 422.2 MiB)
[2025-07-14T12:34:45.890+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 138.4.31.89:45589 (size: 9.3 KiB, free: 433.3 MiB)
[2025-07-14T12:34:45.890+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:45.890+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 95 (MapPartitionsRDD[185] at rdd at ClassificationSummary.scala:58) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-14T12:34:45.890+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSchedulerImpl: Adding task set 95.0 with 2 tasks resource profile 0
[2025-07-14T12:34:45.891+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 204) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:45.891+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: Registering RDD 189 (rdd at ClassificationSummary.scala:58) as input to shuffle 31
[2025-07-14T12:34:45.891+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: Got map stage job 56 (rdd at ClassificationSummary.scala:58) with 13 output partitions
[2025-07-14T12:34:45.891+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: Final stage: ShuffleMapStage 96 (rdd at ClassificationSummary.scala:58)
[2025-07-14T12:34:45.891+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:45.891+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:45.891+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: Submitting ShuffleMapStage 96 (MapPartitionsRDD[189] at rdd at ClassificationSummary.scala:58), which has no missing parents
[2025-07-14T12:34:45.891+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Starting task 1.0 in stage 95.0 (TID 205) (138.4.31.89, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:45.891+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Running task 0.0 in stage 95.0 (TID 204)
[2025-07-14T12:34:45.891+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Running task 1.0 in stage 95.0 (TID 205)
[2025-07-14T12:34:45.891+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 18.7 KiB, free 422.2 MiB)
[2025-07-14T12:34:45.892+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 422.2 MiB)
[2025-07-14T12:34:45.892+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 138.4.31.89:45589 (size: 9.2 KiB, free: 433.2 MiB)
[2025-07-14T12:34:45.892+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:45.892+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 96 (MapPartitionsRDD[189] at rdd at ClassificationSummary.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-14T12:34:45.892+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSchedulerImpl: Adding task set 96.0 with 13 tasks resource profile 0
[2025-07-14T12:34:45.893+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 206) (138.4.31.89, executor driver, partition 0, ANY, 16839 bytes)
[2025-07-14T12:34:45.893+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Starting task 1.0 in stage 96.0 (TID 207) (138.4.31.89, executor driver, partition 1, ANY, 16839 bytes)
[2025-07-14T12:34:45.893+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Running task 0.0 in stage 96.0 (TID 206)
[2025-07-14T12:34:45.893+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-14T12:34:45.893+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-14T12:34:45.893+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Running task 1.0 in stage 96.0 (TID 207)
[2025-07-14T12:34:45.913+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Finished task 1.0 in stage 96.0 (TID 207). 1945 bytes result sent to driver
[2025-07-14T12:34:45.913+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Finished task 0.0 in stage 96.0 (TID 206). 1945 bytes result sent to driver
[2025-07-14T12:34:45.913+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Starting task 2.0 in stage 96.0 (TID 208) (138.4.31.89, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-14T12:34:45.913+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Finished task 1.0 in stage 96.0 (TID 207) in 20 ms on 138.4.31.89 (executor driver) (1/13)
[2025-07-14T12:34:45.913+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Running task 2.0 in stage 96.0 (TID 208)
[2025-07-14T12:34:45.914+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 206) in 22 ms on 138.4.31.89 (executor driver) (2/13)
[2025-07-14T12:34:45.914+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Starting task 3.0 in stage 96.0 (TID 209) (138.4.31.89, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-14T12:34:45.914+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Running task 3.0 in stage 96.0 (TID 209)
[2025-07-14T12:34:45.927+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 138.4.31.89:45589 in memory (size: 10.3 KiB, free: 433.3 MiB)
[2025-07-14T12:34:45.929+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Finished task 2.0 in stage 96.0 (TID 208). 1945 bytes result sent to driver
[2025-07-14T12:34:45.929+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Starting task 4.0 in stage 96.0 (TID 210) (138.4.31.89, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-14T12:34:45.929+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Running task 4.0 in stage 96.0 (TID 210)
[2025-07-14T12:34:45.929+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Finished task 2.0 in stage 96.0 (TID 208) in 16 ms on 138.4.31.89 (executor driver) (3/13)
[2025-07-14T12:34:45.935+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Finished task 3.0 in stage 96.0 (TID 209). 1945 bytes result sent to driver
[2025-07-14T12:34:45.935+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Starting task 5.0 in stage 96.0 (TID 211) (138.4.31.89, executor driver, partition 5, ANY, 16719 bytes)
[2025-07-14T12:34:45.936+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Finished task 3.0 in stage 96.0 (TID 209) in 22 ms on 138.4.31.89 (executor driver) (4/13)
[2025-07-14T12:34:45.936+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Running task 5.0 in stage 96.0 (TID 211)
[2025-07-14T12:34:45.942+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Finished task 4.0 in stage 96.0 (TID 210). 1945 bytes result sent to driver
[2025-07-14T12:34:45.943+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Starting task 6.0 in stage 96.0 (TID 212) (138.4.31.89, executor driver, partition 6, ANY, 16719 bytes)
[2025-07-14T12:34:45.943+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Finished task 4.0 in stage 96.0 (TID 210) in 14 ms on 138.4.31.89 (executor driver) (5/13)
[2025-07-14T12:34:45.943+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Running task 6.0 in stage 96.0 (TID 212)
[2025-07-14T12:34:45.949+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Finished task 5.0 in stage 96.0 (TID 211). 1902 bytes result sent to driver
[2025-07-14T12:34:45.949+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Starting task 7.0 in stage 96.0 (TID 213) (138.4.31.89, executor driver, partition 7, ANY, 16715 bytes)
[2025-07-14T12:34:45.949+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Running task 7.0 in stage 96.0 (TID 213)
[2025-07-14T12:34:45.949+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Finished task 5.0 in stage 96.0 (TID 211) in 14 ms on 138.4.31.89 (executor driver) (6/13)
[2025-07-14T12:34:45.957+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Finished task 6.0 in stage 96.0 (TID 212). 1902 bytes result sent to driver
[2025-07-14T12:34:45.957+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Starting task 8.0 in stage 96.0 (TID 214) (138.4.31.89, executor driver, partition 8, ANY, 16719 bytes)
[2025-07-14T12:34:45.957+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Finished task 6.0 in stage 96.0 (TID 212) in 15 ms on 138.4.31.89 (executor driver) (7/13)
[2025-07-14T12:34:45.957+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Running task 8.0 in stage 96.0 (TID 214)
[2025-07-14T12:34:45.961+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Finished task 7.0 in stage 96.0 (TID 213). 1902 bytes result sent to driver
[2025-07-14T12:34:45.962+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Starting task 9.0 in stage 96.0 (TID 215) (138.4.31.89, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-14T12:34:45.962+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Finished task 7.0 in stage 96.0 (TID 213) in 13 ms on 138.4.31.89 (executor driver) (8/13)
[2025-07-14T12:34:45.962+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Running task 9.0 in stage 96.0 (TID 215)
[2025-07-14T12:34:45.969+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Finished task 8.0 in stage 96.0 (TID 214). 1902 bytes result sent to driver
[2025-07-14T12:34:45.969+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Starting task 10.0 in stage 96.0 (TID 216) (138.4.31.89, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-14T12:34:45.970+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Finished task 8.0 in stage 96.0 (TID 214) in 13 ms on 138.4.31.89 (executor driver) (9/13)
[2025-07-14T12:34:45.970+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Running task 10.0 in stage 96.0 (TID 216)
[2025-07-14T12:34:45.977+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Finished task 9.0 in stage 96.0 (TID 215). 1945 bytes result sent to driver
[2025-07-14T12:34:45.977+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Starting task 11.0 in stage 96.0 (TID 217) (138.4.31.89, executor driver, partition 11, ANY, 16839 bytes)
[2025-07-14T12:34:45.977+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Finished task 9.0 in stage 96.0 (TID 215) in 16 ms on 138.4.31.89 (executor driver) (10/13)
[2025-07-14T12:34:45.977+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Running task 11.0 in stage 96.0 (TID 217)
[2025-07-14T12:34:45.985+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Finished task 10.0 in stage 96.0 (TID 216). 1902 bytes result sent to driver
[2025-07-14T12:34:45.986+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Starting task 12.0 in stage 96.0 (TID 218) (138.4.31.89, executor driver, partition 12, ANY, 16719 bytes)
[2025-07-14T12:34:45.986+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Running task 12.0 in stage 96.0 (TID 218)
[2025-07-14T12:34:45.986+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Finished task 10.0 in stage 96.0 (TID 216) in 17 ms on 138.4.31.89 (executor driver) (11/13)
[2025-07-14T12:34:45.994+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Finished task 11.0 in stage 96.0 (TID 217). 1902 bytes result sent to driver
[2025-07-14T12:34:45.995+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Finished task 11.0 in stage 96.0 (TID 217) in 17 ms on 138.4.31.89 (executor driver) (12/13)
[2025-07-14T12:34:45.997+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO Executor: Finished task 12.0 in stage 96.0 (TID 218). 1945 bytes result sent to driver
[2025-07-14T12:34:45.997+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSetManager: Finished task 12.0 in stage 96.0 (TID 218) in 12 ms on 138.4.31.89 (executor driver) (13/13)
[2025-07-14T12:34:45.997+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool
[2025-07-14T12:34:45.997+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: ShuffleMapStage 96 (rdd at ClassificationSummary.scala:58) finished in 0,106 s
[2025-07-14T12:34:45.997+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:45.997+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: running: Set(ShuffleMapStage 95)
[2025-07-14T12:34:45.997+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:45.997+0200] {subprocess.py:93} INFO - 25/07/14 12:34:45 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:46.002+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO ShufflePartitionsUtil: For shuffle(31), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-14T12:34:46.011+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-14T12:34:46.012+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO DAGScheduler: Got job 57 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-14T12:34:46.012+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO DAGScheduler: Final stage: ResultStage 98 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-14T12:34:46.012+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 97)
[2025-07-14T12:34:46.012+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:46.012+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[191] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-14T12:34:46.013+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 8.2 KiB, free 422.2 MiB)
[2025-07-14T12:34:46.013+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 422.2 MiB)
[2025-07-14T12:34:46.014+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 138.4.31.89:45589 (size: 4.2 KiB, free: 433.3 MiB)
[2025-07-14T12:34:46.014+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:46.014+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[191] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:46.014+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks resource profile 0
[2025-07-14T12:34:46.015+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 219) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-14T12:34:46.015+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO Executor: Running task 0.0 in stage 98.0 (TID 219)
[2025-07-14T12:34:46.017+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO ShuffleBlockFetcherIterator: Getting 13 (217.3 KiB) non-empty blocks including 13 (217.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:46.017+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:46.022+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO Executor: Finished task 0.0 in stage 98.0 (TID 219). 51267 bytes result sent to driver
[2025-07-14T12:34:46.023+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 219) in 9 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:46.023+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool
[2025-07-14T12:34:46.023+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO DAGScheduler: ResultStage 98 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,011 s
[2025-07-14T12:34:46.023+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:46.023+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 98: Stage finished
[2025-07-14T12:34:46.023+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO DAGScheduler: Job 57 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,011695 s
[2025-07-14T12:34:46.026+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 4.3 MiB, free 418.0 MiB)
[2025-07-14T12:34:46.028+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 109.3 KiB, free 417.9 MiB)
[2025-07-14T12:34:46.028+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 138.4.31.89:45589 (size: 109.3 KiB, free: 433.1 MiB)
[2025-07-14T12:34:46.028+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO SparkContext: Created broadcast 86 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-14T12:34:46.276+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 138.4.31.89:45589 in memory (size: 4.2 KiB, free: 433.2 MiB)
[2025-07-14T12:34:46.295+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO Executor: Finished task 1.0 in stage 95.0 (TID 205). 2031 bytes result sent to driver
[2025-07-14T12:34:46.296+0200] {subprocess.py:93} INFO - 25/07/14 12:34:46 INFO TaskSetManager: Finished task 1.0 in stage 95.0 (TID 205) in 405 ms on 138.4.31.89 (executor driver) (1/2)
[2025-07-14T12:34:48.796+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO Executor: Finished task 0.0 in stage 95.0 (TID 204). 2031 bytes result sent to driver
[2025-07-14T12:34:48.796+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 204) in 2905 ms on 138.4.31.89 (executor driver) (2/2)
[2025-07-14T12:34:48.796+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool
[2025-07-14T12:34:48.796+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: ShuffleMapStage 95 (rdd at ClassificationSummary.scala:58) finished in 2,907 s
[2025-07-14T12:34:48.796+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:48.796+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:48.796+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:48.796+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:48.801+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO ShufflePartitionsUtil: For shuffle(30), advisory target size: 67108864, actual target size 1923052, minimum partition size: 1048576
[2025-07-14T12:34:48.814+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO CodeGenerator: Code generated in 7.024852 ms
[2025-07-14T12:34:48.829+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO Instrumentation: [f4d6894d] training finished
[2025-07-14T12:34:48.842+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO FileSystemOverwrite: Path /home/monica.fernandez/practica_creativa/models/spark_random_forest_classifier.flight_delays.5.0.bin already exists. It will be overwritten.
[2025-07-14T12:34:48.863+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-14T12:34:48.863+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:48.863+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:48.878+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-14T12:34:48.879+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: Got job 58 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-14T12:34:48.879+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: Final stage: ResultStage 99 (runJob at SparkHadoopWriter.scala:83)
[2025-07-14T12:34:48.879+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:48.879+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:48.879+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[199] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-14T12:34:48.883+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 101.4 KiB, free 417.8 MiB)
[2025-07-14T12:34:48.884+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 417.8 MiB)
[2025-07-14T12:34:48.884+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 138.4.31.89:45589 (size: 36.5 KiB, free: 433.1 MiB)
[2025-07-14T12:34:48.884+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:48.884+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[199] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:48.884+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks resource profile 0
[2025-07-14T12:34:48.884+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 220) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15042 bytes)
[2025-07-14T12:34:48.885+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO Executor: Running task 0.0 in stage 99.0 (TID 220)
[2025-07-14T12:34:48.887+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-14T12:34:48.887+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:48.887+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:48.903+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO FileOutputCommitter: Saved output of task 'attempt_202507141234487291416384337812873_0199_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/spark_random_forest_classifier.flight_delays.5.0.bin/metadata/_temporary/0/task_202507141234487291416384337812873_0199_m_000000
[2025-07-14T12:34:48.903+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO SparkHadoopMapRedUtil: attempt_202507141234487291416384337812873_0199_m_000000_0: Committed. Elapsed time: 0 ms.
[2025-07-14T12:34:48.903+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO Executor: Finished task 0.0 in stage 99.0 (TID 220). 1170 bytes result sent to driver
[2025-07-14T12:34:48.903+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 220) in 19 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:48.903+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool
[2025-07-14T12:34:48.903+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: ResultStage 99 (runJob at SparkHadoopWriter.scala:83) finished in 0,024 s
[2025-07-14T12:34:48.904+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:48.904+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 99: Stage finished
[2025-07-14T12:34:48.904+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: Job 58 finished: runJob at SparkHadoopWriter.scala:83, took 0,025101 s
[2025-07-14T12:34:48.904+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO SparkHadoopWriter: Start to commit write Job job_202507141234487291416384337812873_0199.
[2025-07-14T12:34:48.917+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO SparkHadoopWriter: Write Job job_202507141234487291416384337812873_0199 committed. Elapsed time: 12 ms.
[2025-07-14T12:34:48.923+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-14T12:34:48.923+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:48.923+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:48.939+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-14T12:34:48.939+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: Got job 59 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-14T12:34:48.939+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: Final stage: ResultStage 100 (runJob at SparkHadoopWriter.scala:83)
[2025-07-14T12:34:48.939+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:48.939+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:48.939+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[201] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-14T12:34:48.944+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 101.5 KiB, free 417.7 MiB)
[2025-07-14T12:34:48.944+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 36.6 KiB, free 417.6 MiB)
[2025-07-14T12:34:48.944+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 138.4.31.89:45589 (size: 36.6 KiB, free: 433.1 MiB)
[2025-07-14T12:34:48.944+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:48.945+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[201] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:48.945+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks resource profile 0
[2025-07-14T12:34:48.945+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 221) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15658 bytes)
[2025-07-14T12:34:48.945+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO Executor: Running task 0.0 in stage 100.0 (TID 221)
[2025-07-14T12:34:48.948+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-14T12:34:48.948+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:48.948+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:48.962+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO FileOutputCommitter: Saved output of task 'attempt_202507141234484675392434004902334_0201_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/spark_random_forest_classifier.flight_delays.5.0.bin/stages/0_RandomForestClassifier_e8cbd20e9585/metadata/_temporary/0/task_202507141234484675392434004902334_0201_m_000000
[2025-07-14T12:34:48.962+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO SparkHadoopMapRedUtil: attempt_202507141234484675392434004902334_0201_m_000000_0: Committed. Elapsed time: 0 ms.
[2025-07-14T12:34:48.962+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO Executor: Finished task 0.0 in stage 100.0 (TID 221). 1170 bytes result sent to driver
[2025-07-14T12:34:48.963+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 221) in 18 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:48.963+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool
[2025-07-14T12:34:48.963+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: ResultStage 100 (runJob at SparkHadoopWriter.scala:83) finished in 0,024 s
[2025-07-14T12:34:48.963+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:48.963+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 100: Stage finished
[2025-07-14T12:34:48.963+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO DAGScheduler: Job 59 finished: runJob at SparkHadoopWriter.scala:83, took 0,024140 s
[2025-07-14T12:34:48.963+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO SparkHadoopWriter: Start to commit write Job job_202507141234484675392434004902334_0201.
[2025-07-14T12:34:48.977+0200] {subprocess.py:93} INFO - 25/07/14 12:34:48 INFO SparkHadoopWriter: Write Job job_202507141234484675392434004902334_0201 committed. Elapsed time: 13 ms.
[2025-07-14T12:34:49.001+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO CodeGenerator: Code generated in 2.242315 ms
[2025-07-14T12:34:49.002+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Registering RDD 204 (parquet at treeModels.scala:483) as input to shuffle 32
[2025-07-14T12:34:49.002+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Got map stage job 60 (parquet at treeModels.scala:483) with 4 output partitions
[2025-07-14T12:34:49.002+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Final stage: ShuffleMapStage 101 (parquet at treeModels.scala:483)
[2025-07-14T12:34:49.002+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:49.002+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:49.003+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Submitting ShuffleMapStage 101 (MapPartitionsRDD[204] at parquet at treeModels.scala:483), which has no missing parents
[2025-07-14T12:34:49.003+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 8.3 KiB, free 417.6 MiB)
[2025-07-14T12:34:49.006+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 417.6 MiB)
[2025-07-14T12:34:49.006+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 138.4.31.89:45589 (size: 4.5 KiB, free: 433.1 MiB)
[2025-07-14T12:34:49.006+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 138.4.31.89:45589 in memory (size: 36.5 KiB, free: 433.1 MiB)
[2025-07-14T12:34:49.006+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:49.006+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 101 (MapPartitionsRDD[204] at parquet at treeModels.scala:483) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-14T12:34:49.006+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSchedulerImpl: Adding task set 101.0 with 4 tasks resource profile 0
[2025-07-14T12:34:49.006+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 138.4.31.89:45589 in memory (size: 36.6 KiB, free: 433.1 MiB)
[2025-07-14T12:34:49.006+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 222) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 16404 bytes)
[2025-07-14T12:34:49.006+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 1.0 in stage 101.0 (TID 223) (138.4.31.89, executor driver, partition 1, PROCESS_LOCAL, 17128 bytes)
[2025-07-14T12:34:49.007+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 2.0 in stage 101.0 (TID 224) (138.4.31.89, executor driver, partition 2, PROCESS_LOCAL, 16404 bytes)
[2025-07-14T12:34:49.007+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 3.0 in stage 101.0 (TID 225) (138.4.31.89, executor driver, partition 3, PROCESS_LOCAL, 17128 bytes)
[2025-07-14T12:34:49.007+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 2.0 in stage 101.0 (TID 224)
[2025-07-14T12:34:49.007+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 1.0 in stage 101.0 (TID 223)
[2025-07-14T12:34:49.007+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 3.0 in stage 101.0 (TID 225)
[2025-07-14T12:34:49.007+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 0.0 in stage 101.0 (TID 222)
[2025-07-14T12:34:49.009+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 3.0 in stage 101.0 (TID 225). 1542 bytes result sent to driver
[2025-07-14T12:34:49.009+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 0.0 in stage 101.0 (TID 222). 1542 bytes result sent to driver
[2025-07-14T12:34:49.009+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 2.0 in stage 101.0 (TID 224). 1542 bytes result sent to driver
[2025-07-14T12:34:49.009+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 1.0 in stage 101.0 (TID 223). 1585 bytes result sent to driver
[2025-07-14T12:34:49.009+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 3.0 in stage 101.0 (TID 225) in 2 ms on 138.4.31.89 (executor driver) (1/4)
[2025-07-14T12:34:49.009+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 2.0 in stage 101.0 (TID 224) in 3 ms on 138.4.31.89 (executor driver) (2/4)
[2025-07-14T12:34:49.009+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 222) in 3 ms on 138.4.31.89 (executor driver) (3/4)
[2025-07-14T12:34:49.009+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 1.0 in stage 101.0 (TID 223) in 3 ms on 138.4.31.89 (executor driver) (4/4)
[2025-07-14T12:34:49.009+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool
[2025-07-14T12:34:49.009+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: ShuffleMapStage 101 (parquet at treeModels.scala:483) finished in 0,006 s
[2025-07-14T12:34:49.009+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:49.009+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:49.009+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:49.009+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:49.012+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:49.012+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:49.012+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:49.012+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:49.012+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:49.012+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:49.012+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:49.021+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO SparkContext: Starting job: parquet at treeModels.scala:483
[2025-07-14T12:34:49.022+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Got job 61 (parquet at treeModels.scala:483) with 1 output partitions
[2025-07-14T12:34:49.022+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Final stage: ResultStage 103 (parquet at treeModels.scala:483)
[2025-07-14T12:34:49.022+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 102)
[2025-07-14T12:34:49.022+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:49.022+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[206] at parquet at treeModels.scala:483), which has no missing parents
[2025-07-14T12:34:49.033+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 239.9 KiB, free 417.6 MiB)
[2025-07-14T12:34:49.034+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 84.0 KiB, free 417.6 MiB)
[2025-07-14T12:34:49.034+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 138.4.31.89:45589 (size: 84.0 KiB, free: 433.1 MiB)
[2025-07-14T12:34:49.035+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:49.035+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[206] at parquet at treeModels.scala:483) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:49.035+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks resource profile 0
[2025-07-14T12:34:49.035+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 226) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-14T12:34:49.036+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 0.0 in stage 103.0 (TID 226)
[2025-07-14T12:34:49.040+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:49.040+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:49.041+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:49.041+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:49.041+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:49.041+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:49.041+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:49.041+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:49.041+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO CodecConfig: Compression: SNAPPY
[2025-07-14T12:34:49.041+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO CodecConfig: Compression: SNAPPY
[2025-07-14T12:34:49.042+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-14T12:34:49.042+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-14T12:34:49.042+0200] {subprocess.py:93} INFO - {
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO -     "name" : "treeID",
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO -     "type" : "integer",
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO -     "nullable" : false,
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO -   }, {
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO -     "name" : "metadata",
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO -     "type" : "string",
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO -   }, {
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO -     "name" : "weights",
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO -     "type" : "double",
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO -     "nullable" : false,
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO -   } ]
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO - }
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO -   required int32 treeID;
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO -   optional binary metadata (STRING);
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO -   required double weights;
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO - }
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:49.043+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:49.077+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileOutputCommitter: Saved output of task 'attempt_202507141234495356227429854337853_0103_m_000000_226' to file:/home/monica.fernandez/practica_creativa/models/spark_random_forest_classifier.flight_delays.5.0.bin/stages/0_RandomForestClassifier_e8cbd20e9585/treesMetadata/_temporary/0/task_202507141234495356227429854337853_0103_m_000000
[2025-07-14T12:34:49.077+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO SparkHadoopMapRedUtil: attempt_202507141234495356227429854337853_0103_m_000000_226: Committed. Elapsed time: 0 ms.
[2025-07-14T12:34:49.080+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 0.0 in stage 103.0 (TID 226). 4826 bytes result sent to driver
[2025-07-14T12:34:49.080+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 138.4.31.89:45589 in memory (size: 4.5 KiB, free: 433.1 MiB)
[2025-07-14T12:34:49.080+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 226) in 45 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:49.080+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool
[2025-07-14T12:34:49.080+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: ResultStage 103 (parquet at treeModels.scala:483) finished in 0,058 s
[2025-07-14T12:34:49.080+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:49.080+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 103: Stage finished
[2025-07-14T12:34:49.080+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Job 61 finished: parquet at treeModels.scala:483, took 0,058948 s
[2025-07-14T12:34:49.080+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileFormatWriter: Start to commit write Job e18f40d5-67cb-4eaf-9a39-7ac08d56b946.
[2025-07-14T12:34:49.094+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileFormatWriter: Write Job e18f40d5-67cb-4eaf-9a39-7ac08d56b946 committed. Elapsed time: 13 ms.
[2025-07-14T12:34:49.094+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileFormatWriter: Finished processing stats for write job e18f40d5-67cb-4eaf-9a39-7ac08d56b946.
[2025-07-14T12:34:49.134+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO CodeGenerator: Code generated in 8.506707 ms
[2025-07-14T12:34:49.136+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Registering RDD 211 (parquet at treeModels.scala:491) as input to shuffle 33
[2025-07-14T12:34:49.136+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Got map stage job 62 (parquet at treeModels.scala:491) with 4 output partitions
[2025-07-14T12:34:49.136+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Final stage: ShuffleMapStage 104 (parquet at treeModels.scala:491)
[2025-07-14T12:34:49.136+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:49.136+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:49.136+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Submitting ShuffleMapStage 104 (MapPartitionsRDD[211] at parquet at treeModels.scala:491), which has no missing parents
[2025-07-14T12:34:49.137+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 41.5 KiB, free 417.5 MiB)
[2025-07-14T12:34:49.138+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 12.3 KiB, free 417.5 MiB)
[2025-07-14T12:34:49.138+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 138.4.31.89:45589 (size: 12.3 KiB, free: 433.1 MiB)
[2025-07-14T12:34:49.138+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:49.138+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 104 (MapPartitionsRDD[211] at parquet at treeModels.scala:491) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-14T12:34:49.138+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSchedulerImpl: Adding task set 104.0 with 4 tasks resource profile 0
[2025-07-14T12:34:49.140+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 227) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 140337 bytes)
[2025-07-14T12:34:49.142+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 1.0 in stage 104.0 (TID 228) (138.4.31.89, executor driver, partition 1, PROCESS_LOCAL, 386293 bytes)
[2025-07-14T12:34:49.142+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 2.0 in stage 104.0 (TID 229) (138.4.31.89, executor driver, partition 2, PROCESS_LOCAL, 128364 bytes)
[2025-07-14T12:34:49.144+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 3.0 in stage 104.0 (TID 230) (138.4.31.89, executor driver, partition 3, PROCESS_LOCAL, 208919 bytes)
[2025-07-14T12:34:49.144+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 0.0 in stage 104.0 (TID 227)
[2025-07-14T12:34:49.144+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 1.0 in stage 104.0 (TID 228)
[2025-07-14T12:34:49.144+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 2.0 in stage 104.0 (TID 229)
[2025-07-14T12:34:49.144+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 3.0 in stage 104.0 (TID 230)
[2025-07-14T12:34:49.156+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO CodeGenerator: Code generated in 7.418424 ms
[2025-07-14T12:34:49.162+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 2.0 in stage 104.0 (TID 229). 1700 bytes result sent to driver
[2025-07-14T12:34:49.163+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 2.0 in stage 104.0 (TID 229) in 20 ms on 138.4.31.89 (executor driver) (1/4)
[2025-07-14T12:34:49.163+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 0.0 in stage 104.0 (TID 227). 1700 bytes result sent to driver
[2025-07-14T12:34:49.164+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 227) in 25 ms on 138.4.31.89 (executor driver) (2/4)
[2025-07-14T12:34:49.166+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 3.0 in stage 104.0 (TID 230). 1700 bytes result sent to driver
[2025-07-14T12:34:49.166+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 3.0 in stage 104.0 (TID 230) in 24 ms on 138.4.31.89 (executor driver) (3/4)
[2025-07-14T12:34:49.167+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 1.0 in stage 104.0 (TID 228). 1700 bytes result sent to driver
[2025-07-14T12:34:49.168+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 1.0 in stage 104.0 (TID 228) in 28 ms on 138.4.31.89 (executor driver) (4/4)
[2025-07-14T12:34:49.168+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool
[2025-07-14T12:34:49.168+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: ShuffleMapStage 104 (parquet at treeModels.scala:491) finished in 0,032 s
[2025-07-14T12:34:49.168+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:49.168+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:49.168+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:49.168+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:49.171+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:49.171+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:49.171+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:49.171+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:49.171+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:49.171+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:49.172+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:49.181+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO SparkContext: Starting job: parquet at treeModels.scala:491
[2025-07-14T12:34:49.181+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Got job 63 (parquet at treeModels.scala:491) with 1 output partitions
[2025-07-14T12:34:49.181+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Final stage: ResultStage 106 (parquet at treeModels.scala:491)
[2025-07-14T12:34:49.181+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 105)
[2025-07-14T12:34:49.181+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:49.181+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[213] at parquet at treeModels.scala:491), which has no missing parents
[2025-07-14T12:34:49.189+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 241.5 KiB, free 417.3 MiB)
[2025-07-14T12:34:49.189+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 84.9 KiB, free 417.2 MiB)
[2025-07-14T12:34:49.190+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 138.4.31.89:45589 (size: 84.9 KiB, free: 433.0 MiB)
[2025-07-14T12:34:49.190+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:49.190+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[213] at parquet at treeModels.scala:491) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:49.190+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks resource profile 0
[2025-07-14T12:34:49.190+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 231) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-14T12:34:49.191+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 0.0 in stage 106.0 (TID 231)
[2025-07-14T12:34:49.195+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO ShuffleBlockFetcherIterator: Getting 4 (176.9 KiB) non-empty blocks including 4 (176.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:49.195+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:49.196+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:49.196+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:49.196+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:49.196+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:34:49.196+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:34:49.196+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:34:49.196+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO CodecConfig: Compression: SNAPPY
[2025-07-14T12:34:49.196+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO CodecConfig: Compression: SNAPPY
[2025-07-14T12:34:49.196+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO - {
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO -     "name" : "treeID",
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO -     "type" : "integer",
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO -     "nullable" : false,
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO -   }, {
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO -     "name" : "nodeData",
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO -     "type" : {
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO -       "type" : "struct",
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO -       "fields" : [ {
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO -         "name" : "id",
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO -         "type" : "integer",
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO -       }, {
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO -         "name" : "prediction",
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO -         "type" : "double",
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO -       }, {
[2025-07-14T12:34:49.198+0200] {subprocess.py:93} INFO -         "name" : "impurity",
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -         "type" : "double",
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -       }, {
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -         "name" : "impurityStats",
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -         "type" : {
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -           "type" : "array",
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -           "elementType" : "double",
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -           "containsNull" : false
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -         },
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -         "nullable" : true,
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -       }, {
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -         "name" : "rawCount",
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -         "type" : "long",
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -       }, {
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -         "name" : "gain",
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -         "type" : "double",
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -       }, {
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -         "name" : "leftChild",
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -         "type" : "integer",
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -       }, {
[2025-07-14T12:34:49.199+0200] {subprocess.py:93} INFO -         "name" : "rightChild",
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -         "type" : "integer",
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -       }, {
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -         "name" : "split",
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -         "type" : {
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -           "type" : "struct",
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -           "fields" : [ {
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -             "name" : "featureIndex",
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -             "type" : "integer",
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -             "nullable" : false,
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -             "metadata" : { }
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -           }, {
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -             "name" : "leftCategoriesOrThreshold",
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -             "type" : {
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -               "type" : "array",
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -               "elementType" : "double",
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -               "containsNull" : false
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -             },
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -             "nullable" : true,
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -             "metadata" : { }
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -           }, {
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -             "name" : "numCategories",
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -             "type" : "integer",
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -             "nullable" : false,
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -             "metadata" : { }
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -           } ]
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -         },
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -         "nullable" : true,
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -       } ]
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -     },
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -   } ]
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO - }
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -   required int32 treeID;
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -   optional group nodeData {
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -     required int32 id;
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -     required double prediction;
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -     required double impurity;
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -     optional group impurityStats (LIST) {
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -       repeated group list {
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -         required double element;
[2025-07-14T12:34:49.200+0200] {subprocess.py:93} INFO -       }
[2025-07-14T12:34:49.201+0200] {subprocess.py:93} INFO -     }
[2025-07-14T12:34:49.201+0200] {subprocess.py:93} INFO -     required int64 rawCount;
[2025-07-14T12:34:49.201+0200] {subprocess.py:93} INFO -     required double gain;
[2025-07-14T12:34:49.201+0200] {subprocess.py:93} INFO -     required int32 leftChild;
[2025-07-14T12:34:49.201+0200] {subprocess.py:93} INFO -     required int32 rightChild;
[2025-07-14T12:34:49.201+0200] {subprocess.py:93} INFO -     optional group split {
[2025-07-14T12:34:49.201+0200] {subprocess.py:93} INFO -       required int32 featureIndex;
[2025-07-14T12:34:49.201+0200] {subprocess.py:93} INFO -       optional group leftCategoriesOrThreshold (LIST) {
[2025-07-14T12:34:49.201+0200] {subprocess.py:93} INFO -         repeated group list {
[2025-07-14T12:34:49.201+0200] {subprocess.py:93} INFO -           required double element;
[2025-07-14T12:34:49.201+0200] {subprocess.py:93} INFO -         }
[2025-07-14T12:34:49.201+0200] {subprocess.py:93} INFO -       }
[2025-07-14T12:34:49.201+0200] {subprocess.py:93} INFO -       required int32 numCategories;
[2025-07-14T12:34:49.201+0200] {subprocess.py:93} INFO -     }
[2025-07-14T12:34:49.201+0200] {subprocess.py:93} INFO -   }
[2025-07-14T12:34:49.201+0200] {subprocess.py:93} INFO - }
[2025-07-14T12:34:49.201+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:49.201+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:49.246+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileOutputCommitter: Saved output of task 'attempt_202507141234496302562240180484631_0106_m_000000_231' to file:/home/monica.fernandez/practica_creativa/models/spark_random_forest_classifier.flight_delays.5.0.bin/stages/0_RandomForestClassifier_e8cbd20e9585/data/_temporary/0/task_202507141234496302562240180484631_0106_m_000000
[2025-07-14T12:34:49.247+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO SparkHadoopMapRedUtil: attempt_202507141234496302562240180484631_0106_m_000000_231: Committed. Elapsed time: 1 ms.
[2025-07-14T12:34:49.249+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 0.0 in stage 106.0 (TID 231). 4826 bytes result sent to driver
[2025-07-14T12:34:49.250+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 138.4.31.89:45589 in memory (size: 12.3 KiB, free: 433.0 MiB)
[2025-07-14T12:34:49.250+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 231) in 60 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:49.250+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool
[2025-07-14T12:34:49.250+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 138.4.31.89:45589 in memory (size: 84.0 KiB, free: 433.1 MiB)
[2025-07-14T12:34:49.250+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: ResultStage 106 (parquet at treeModels.scala:491) finished in 0,069 s
[2025-07-14T12:34:49.250+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:49.250+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 106: Stage finished
[2025-07-14T12:34:49.250+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Job 63 finished: parquet at treeModels.scala:491, took 0,069551 s
[2025-07-14T12:34:49.250+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileFormatWriter: Start to commit write Job 07512bab-f253-4788-9d50-0bdd453ac7d4.
[2025-07-14T12:34:49.264+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileFormatWriter: Write Job 07512bab-f253-4788-9d50-0bdd453ac7d4 committed. Elapsed time: 13 ms.
[2025-07-14T12:34:49.264+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileFormatWriter: Finished processing stats for write job 07512bab-f253-4788-9d50-0bdd453ac7d4.
[2025-07-14T12:34:49.264+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Instrumentation: [a9e30f30] training finished
[2025-07-14T12:34:49.264+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Instrumentation: [99619aab] training finished
[2025-07-14T12:34:49.304+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:49.304+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-14T12:34:49.304+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-14T12:34:49.304+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-14T12:34:49.304+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:49.311+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:49.312+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-14T12:34:49.312+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:49.323+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileSourceStrategy: Pushed Filters:
[2025-07-14T12:34:49.323+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-14T12:34:49.328+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 214.5 KiB, free 417.4 MiB)
[2025-07-14T12:34:49.332+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 39.0 KiB, free 417.3 MiB)
[2025-07-14T12:34:49.332+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 138.4.31.89:45589 (size: 39.0 KiB, free: 433.0 MiB)
[2025-07-14T12:34:49.333+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO SparkContext: Created broadcast 93 from rdd at MulticlassClassificationEvaluator.scala:191
[2025-07-14T12:34:49.333+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-14T12:34:49.335+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Registering RDD 217 (rdd at MulticlassClassificationEvaluator.scala:191) as input to shuffle 34
[2025-07-14T12:34:49.335+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Got map stage job 64 (rdd at MulticlassClassificationEvaluator.scala:191) with 2 output partitions
[2025-07-14T12:34:49.335+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Final stage: ShuffleMapStage 107 (rdd at MulticlassClassificationEvaluator.scala:191)
[2025-07-14T12:34:49.335+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:49.335+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:49.335+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Submitting ShuffleMapStage 107 (MapPartitionsRDD[217] at rdd at MulticlassClassificationEvaluator.scala:191), which has no missing parents
[2025-07-14T12:34:49.335+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 20.7 KiB, free 417.3 MiB)
[2025-07-14T12:34:49.336+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 9.3 KiB, free 417.3 MiB)
[2025-07-14T12:34:49.336+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 138.4.31.89:45589 (size: 9.3 KiB, free: 433.0 MiB)
[2025-07-14T12:34:49.336+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:49.336+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 107 (MapPartitionsRDD[217] at rdd at MulticlassClassificationEvaluator.scala:191) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-14T12:34:49.336+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSchedulerImpl: Adding task set 107.0 with 2 tasks resource profile 0
[2025-07-14T12:34:49.337+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 232) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:49.337+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Registering RDD 221 (rdd at MulticlassClassificationEvaluator.scala:191) as input to shuffle 35
[2025-07-14T12:34:49.337+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 1.0 in stage 107.0 (TID 233) (138.4.31.89, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:49.337+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Got map stage job 65 (rdd at MulticlassClassificationEvaluator.scala:191) with 13 output partitions
[2025-07-14T12:34:49.337+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Final stage: ShuffleMapStage 108 (rdd at MulticlassClassificationEvaluator.scala:191)
[2025-07-14T12:34:49.337+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:49.337+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:49.337+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Submitting ShuffleMapStage 108 (MapPartitionsRDD[221] at rdd at MulticlassClassificationEvaluator.scala:191), which has no missing parents
[2025-07-14T12:34:49.337+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 0.0 in stage 107.0 (TID 232)
[2025-07-14T12:34:49.337+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 1.0 in stage 107.0 (TID 233)
[2025-07-14T12:34:49.337+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 18.7 KiB, free 417.3 MiB)
[2025-07-14T12:34:49.338+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 417.3 MiB)
[2025-07-14T12:34:49.338+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 138.4.31.89:45589 (size: 9.2 KiB, free: 433.0 MiB)
[2025-07-14T12:34:49.338+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:49.338+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 108 (MapPartitionsRDD[221] at rdd at MulticlassClassificationEvaluator.scala:191) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-14T12:34:49.338+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSchedulerImpl: Adding task set 108.0 with 13 tasks resource profile 0
[2025-07-14T12:34:49.339+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 234) (138.4.31.89, executor driver, partition 0, ANY, 16719 bytes)
[2025-07-14T12:34:49.339+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-14T12:34:49.339+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-14T12:34:49.339+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 1.0 in stage 108.0 (TID 235) (138.4.31.89, executor driver, partition 1, ANY, 16839 bytes)
[2025-07-14T12:34:49.339+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 0.0 in stage 108.0 (TID 234)
[2025-07-14T12:34:49.339+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 1.0 in stage 108.0 (TID 235)
[2025-07-14T12:34:49.347+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 138.4.31.89:45589 in memory (size: 84.9 KiB, free: 433.1 MiB)
[2025-07-14T12:34:49.354+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 0.0 in stage 108.0 (TID 234). 1945 bytes result sent to driver
[2025-07-14T12:34:49.354+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 2.0 in stage 108.0 (TID 236) (138.4.31.89, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-14T12:34:49.355+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 2.0 in stage 108.0 (TID 236)
[2025-07-14T12:34:49.355+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 234) in 17 ms on 138.4.31.89 (executor driver) (1/13)
[2025-07-14T12:34:49.361+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 1.0 in stage 108.0 (TID 235). 1945 bytes result sent to driver
[2025-07-14T12:34:49.361+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 3.0 in stage 108.0 (TID 237) (138.4.31.89, executor driver, partition 3, ANY, 16839 bytes)
[2025-07-14T12:34:49.361+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 3.0 in stage 108.0 (TID 237)
[2025-07-14T12:34:49.361+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 1.0 in stage 108.0 (TID 235) in 22 ms on 138.4.31.89 (executor driver) (2/13)
[2025-07-14T12:34:49.370+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 2.0 in stage 108.0 (TID 236). 1945 bytes result sent to driver
[2025-07-14T12:34:49.370+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 4.0 in stage 108.0 (TID 238) (138.4.31.89, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-14T12:34:49.370+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 4.0 in stage 108.0 (TID 238)
[2025-07-14T12:34:49.370+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 2.0 in stage 108.0 (TID 236) in 16 ms on 138.4.31.89 (executor driver) (3/13)
[2025-07-14T12:34:49.378+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 3.0 in stage 108.0 (TID 237). 1902 bytes result sent to driver
[2025-07-14T12:34:49.379+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 5.0 in stage 108.0 (TID 239) (138.4.31.89, executor driver, partition 5, ANY, 16719 bytes)
[2025-07-14T12:34:49.379+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 5.0 in stage 108.0 (TID 239)
[2025-07-14T12:34:49.379+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 3.0 in stage 108.0 (TID 237) in 18 ms on 138.4.31.89 (executor driver) (4/13)
[2025-07-14T12:34:49.380+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 4.0 in stage 108.0 (TID 238). 1945 bytes result sent to driver
[2025-07-14T12:34:49.381+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 6.0 in stage 108.0 (TID 240) (138.4.31.89, executor driver, partition 6, ANY, 16719 bytes)
[2025-07-14T12:34:49.381+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 4.0 in stage 108.0 (TID 238) in 11 ms on 138.4.31.89 (executor driver) (5/13)
[2025-07-14T12:34:49.381+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 6.0 in stage 108.0 (TID 240)
[2025-07-14T12:34:49.393+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 6.0 in stage 108.0 (TID 240). 1902 bytes result sent to driver
[2025-07-14T12:34:49.394+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 7.0 in stage 108.0 (TID 241) (138.4.31.89, executor driver, partition 7, ANY, 16715 bytes)
[2025-07-14T12:34:49.394+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 7.0 in stage 108.0 (TID 241)
[2025-07-14T12:34:49.394+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 6.0 in stage 108.0 (TID 240) in 13 ms on 138.4.31.89 (executor driver) (6/13)
[2025-07-14T12:34:49.394+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 5.0 in stage 108.0 (TID 239). 1902 bytes result sent to driver
[2025-07-14T12:34:49.394+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 8.0 in stage 108.0 (TID 242) (138.4.31.89, executor driver, partition 8, ANY, 16719 bytes)
[2025-07-14T12:34:49.394+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 8.0 in stage 108.0 (TID 242)
[2025-07-14T12:34:49.394+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 5.0 in stage 108.0 (TID 239) in 16 ms on 138.4.31.89 (executor driver) (7/13)
[2025-07-14T12:34:49.407+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 7.0 in stage 108.0 (TID 241). 1902 bytes result sent to driver
[2025-07-14T12:34:49.408+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 9.0 in stage 108.0 (TID 243) (138.4.31.89, executor driver, partition 9, ANY, 16839 bytes)
[2025-07-14T12:34:49.408+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 9.0 in stage 108.0 (TID 243)
[2025-07-14T12:34:49.408+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 7.0 in stage 108.0 (TID 241) in 15 ms on 138.4.31.89 (executor driver) (8/13)
[2025-07-14T12:34:49.408+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 8.0 in stage 108.0 (TID 242). 1902 bytes result sent to driver
[2025-07-14T12:34:49.408+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 10.0 in stage 108.0 (TID 244) (138.4.31.89, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-14T12:34:49.409+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 8.0 in stage 108.0 (TID 242) in 14 ms on 138.4.31.89 (executor driver) (9/13)
[2025-07-14T12:34:49.409+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 10.0 in stage 108.0 (TID 244)
[2025-07-14T12:34:49.429+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 10.0 in stage 108.0 (TID 244). 1945 bytes result sent to driver
[2025-07-14T12:34:49.430+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 11.0 in stage 108.0 (TID 245) (138.4.31.89, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-14T12:34:49.430+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 11.0 in stage 108.0 (TID 245)
[2025-07-14T12:34:49.430+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 10.0 in stage 108.0 (TID 244) in 22 ms on 138.4.31.89 (executor driver) (10/13)
[2025-07-14T12:34:49.433+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 9.0 in stage 108.0 (TID 243). 1945 bytes result sent to driver
[2025-07-14T12:34:49.433+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 12.0 in stage 108.0 (TID 246) (138.4.31.89, executor driver, partition 12, ANY, 16719 bytes)
[2025-07-14T12:34:49.433+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 12.0 in stage 108.0 (TID 246)
[2025-07-14T12:34:49.433+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 9.0 in stage 108.0 (TID 243) in 26 ms on 138.4.31.89 (executor driver) (11/13)
[2025-07-14T12:34:49.441+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 11.0 in stage 108.0 (TID 245). 1945 bytes result sent to driver
[2025-07-14T12:34:49.442+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 11.0 in stage 108.0 (TID 245) in 12 ms on 138.4.31.89 (executor driver) (12/13)
[2025-07-14T12:34:49.449+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 12.0 in stage 108.0 (TID 246). 1902 bytes result sent to driver
[2025-07-14T12:34:49.449+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 12.0 in stage 108.0 (TID 246) in 16 ms on 138.4.31.89 (executor driver) (13/13)
[2025-07-14T12:34:49.449+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool
[2025-07-14T12:34:49.449+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: ShuffleMapStage 108 (rdd at MulticlassClassificationEvaluator.scala:191) finished in 0,112 s
[2025-07-14T12:34:49.449+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:49.449+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: running: Set(ShuffleMapStage 107)
[2025-07-14T12:34:49.449+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:49.449+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:49.456+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO ShufflePartitionsUtil: For shuffle(35), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-14T12:34:49.460+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-14T12:34:49.460+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Got job 66 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-14T12:34:49.460+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Final stage: ResultStage 110 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-14T12:34:49.460+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 109)
[2025-07-14T12:34:49.460+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:49.460+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Submitting ResultStage 110 (MapPartitionsRDD[223] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-14T12:34:49.461+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 8.2 KiB, free 417.6 MiB)
[2025-07-14T12:34:49.461+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 417.6 MiB)
[2025-07-14T12:34:49.461+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 138.4.31.89:45589 (size: 4.2 KiB, free: 433.1 MiB)
[2025-07-14T12:34:49.462+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:49.462+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 110 (MapPartitionsRDD[223] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:49.462+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSchedulerImpl: Adding task set 110.0 with 1 tasks resource profile 0
[2025-07-14T12:34:49.462+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 247) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-14T12:34:49.463+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Running task 0.0 in stage 110.0 (TID 247)
[2025-07-14T12:34:49.464+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO ShuffleBlockFetcherIterator: Getting 13 (217.3 KiB) non-empty blocks including 13 (217.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:49.464+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:49.470+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 0.0 in stage 110.0 (TID 247). 51384 bytes result sent to driver
[2025-07-14T12:34:49.470+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 247) in 8 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:49.470+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool
[2025-07-14T12:34:49.471+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: ResultStage 110 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,011 s
[2025-07-14T12:34:49.471+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:49.471+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 110: Stage finished
[2025-07-14T12:34:49.471+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO DAGScheduler: Job 66 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,010992 s
[2025-07-14T12:34:49.474+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 4.3 MiB, free 413.3 MiB)
[2025-07-14T12:34:49.475+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 109.4 KiB, free 413.2 MiB)
[2025-07-14T12:34:49.475+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 138.4.31.89:45589 (size: 109.4 KiB, free: 433.0 MiB)
[2025-07-14T12:34:49.476+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO SparkContext: Created broadcast 97 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-14T12:34:49.572+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 138.4.31.89:45589 in memory (size: 4.2 KiB, free: 433.0 MiB)
[2025-07-14T12:34:49.720+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO Executor: Finished task 1.0 in stage 107.0 (TID 233). 1988 bytes result sent to driver
[2025-07-14T12:34:49.720+0200] {subprocess.py:93} INFO - 25/07/14 12:34:49 INFO TaskSetManager: Finished task 1.0 in stage 107.0 (TID 233) in 383 ms on 138.4.31.89 (executor driver) (1/2)
[2025-07-14T12:34:52.213+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO Executor: Finished task 0.0 in stage 107.0 (TID 232). 1988 bytes result sent to driver
[2025-07-14T12:34:52.214+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 232) in 2878 ms on 138.4.31.89 (executor driver) (2/2)
[2025-07-14T12:34:52.214+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool
[2025-07-14T12:34:52.214+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO DAGScheduler: ShuffleMapStage 107 (rdd at MulticlassClassificationEvaluator.scala:191) finished in 2,879 s
[2025-07-14T12:34:52.214+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:52.214+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:52.214+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:52.214+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:52.219+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO ShufflePartitionsUtil: For shuffle(34), advisory target size: 67108864, actual target size 1923052, minimum partition size: 1048576
[2025-07-14T12:34:52.235+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO CodeGenerator: Code generated in 8.119115 ms
[2025-07-14T12:34:52.251+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO SparkContext: Starting job: collectAsMap at MulticlassMetrics.scala:61
[2025-07-14T12:34:52.251+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO DAGScheduler: Registering RDD 230 (map at MulticlassMetrics.scala:52) as input to shuffle 36
[2025-07-14T12:34:52.251+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO DAGScheduler: Got job 67 (collectAsMap at MulticlassMetrics.scala:61) with 4 output partitions
[2025-07-14T12:34:52.251+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO DAGScheduler: Final stage: ResultStage 113 (collectAsMap at MulticlassMetrics.scala:61)
[2025-07-14T12:34:52.251+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 112)
[2025-07-14T12:34:52.251+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 112)
[2025-07-14T12:34:52.251+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO DAGScheduler: Submitting ShuffleMapStage 112 (MapPartitionsRDD[230] at map at MulticlassMetrics.scala:52), which has no missing parents
[2025-07-14T12:34:52.258+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 WARN DAGScheduler: Broadcasting large task binary with size 1043.2 KiB
[2025-07-14T12:34:52.258+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 1043.3 KiB, free 412.2 MiB)
[2025-07-14T12:34:52.261+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 454.4 KiB, free 411.8 MiB)
[2025-07-14T12:34:52.261+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 138.4.31.89:45589 (size: 454.4 KiB, free: 432.5 MiB)
[2025-07-14T12:34:52.261+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:52.261+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 112 (MapPartitionsRDD[230] at map at MulticlassMetrics.scala:52) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-14T12:34:52.261+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO TaskSchedulerImpl: Adding task set 112.0 with 4 tasks resource profile 0
[2025-07-14T12:34:52.262+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 248) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14836 bytes)
[2025-07-14T12:34:52.262+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO TaskSetManager: Starting task 1.0 in stage 112.0 (TID 249) (138.4.31.89, executor driver, partition 1, NODE_LOCAL, 14836 bytes)
[2025-07-14T12:34:52.262+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO TaskSetManager: Starting task 2.0 in stage 112.0 (TID 250) (138.4.31.89, executor driver, partition 2, NODE_LOCAL, 14836 bytes)
[2025-07-14T12:34:52.262+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO TaskSetManager: Starting task 3.0 in stage 112.0 (TID 251) (138.4.31.89, executor driver, partition 3, NODE_LOCAL, 14836 bytes)
[2025-07-14T12:34:52.262+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO Executor: Running task 0.0 in stage 112.0 (TID 248)
[2025-07-14T12:34:52.262+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO Executor: Running task 1.0 in stage 112.0 (TID 249)
[2025-07-14T12:34:52.262+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO Executor: Running task 3.0 in stage 112.0 (TID 251)
[2025-07-14T12:34:52.263+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO Executor: Running task 2.0 in stage 112.0 (TID 250)
[2025-07-14T12:34:52.277+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO ShuffleBlockFetcherIterator: Getting 1 (3.2 MiB) non-empty blocks including 1 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:52.277+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO ShuffleBlockFetcherIterator: Getting 1 (3.4 MiB) non-empty blocks including 1 (3.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:52.277+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO ShuffleBlockFetcherIterator: Getting 1 (384.6 KiB) non-empty blocks including 1 (384.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:52.277+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO ShuffleBlockFetcherIterator: Getting 1 (366.2 KiB) non-empty blocks including 1 (366.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:52.277+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:52.277+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:52.277+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:52.277+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:52.285+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO CodeGenerator: Code generated in 7.67245 ms
[2025-07-14T12:34:52.289+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO CodeGenerator: Code generated in 2.482393 ms
[2025-07-14T12:34:52.759+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO Executor: Finished task 2.0 in stage 112.0 (TID 250). 6108 bytes result sent to driver
[2025-07-14T12:34:52.759+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO TaskSetManager: Finished task 2.0 in stage 112.0 (TID 250) in 497 ms on 138.4.31.89 (executor driver) (1/4)
[2025-07-14T12:34:52.768+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO Executor: Finished task 3.0 in stage 112.0 (TID 251). 6108 bytes result sent to driver
[2025-07-14T12:34:52.768+0200] {subprocess.py:93} INFO - 25/07/14 12:34:52 INFO TaskSetManager: Finished task 3.0 in stage 112.0 (TID 251) in 506 ms on 138.4.31.89 (executor driver) (2/4)
[2025-07-14T12:34:53.271+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Finished task 0.0 in stage 112.0 (TID 248). 6108 bytes result sent to driver
[2025-07-14T12:34:53.272+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 248) in 1009 ms on 138.4.31.89 (executor driver) (3/4)
[2025-07-14T12:34:53.300+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Finished task 1.0 in stage 112.0 (TID 249). 6108 bytes result sent to driver
[2025-07-14T12:34:53.301+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Finished task 1.0 in stage 112.0 (TID 249) in 1039 ms on 138.4.31.89 (executor driver) (4/4)
[2025-07-14T12:34:53.301+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool
[2025-07-14T12:34:53.301+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: ShuffleMapStage 112 (map at MulticlassMetrics.scala:52) finished in 1,049 s
[2025-07-14T12:34:53.301+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:53.301+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:53.301+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: waiting: Set(ResultStage 113)
[2025-07-14T12:34:53.301+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:53.301+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Submitting ResultStage 113 (ShuffledRDD[231] at reduceByKey at MulticlassMetrics.scala:61), which has no missing parents
[2025-07-14T12:34:53.302+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 4.7 KiB, free 411.8 MiB)
[2025-07-14T12:34:53.303+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 2.8 KiB, free 411.8 MiB)
[2025-07-14T12:34:53.303+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 138.4.31.89:45589 (size: 2.8 KiB, free: 432.5 MiB)
[2025-07-14T12:34:53.303+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:53.303+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 113 (ShuffledRDD[231] at reduceByKey at MulticlassMetrics.scala:61) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-14T12:34:53.303+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSchedulerImpl: Adding task set 113.0 with 4 tasks resource profile 0
[2025-07-14T12:34:53.304+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 252) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:53.304+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Starting task 1.0 in stage 113.0 (TID 253) (138.4.31.89, executor driver, partition 1, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:53.304+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Starting task 2.0 in stage 113.0 (TID 254) (138.4.31.89, executor driver, partition 2, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:53.304+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Starting task 3.0 in stage 113.0 (TID 255) (138.4.31.89, executor driver, partition 3, NODE_LOCAL, 14646 bytes)
[2025-07-14T12:34:53.304+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Running task 2.0 in stage 113.0 (TID 254)
[2025-07-14T12:34:53.305+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Running task 3.0 in stage 113.0 (TID 255)
[2025-07-14T12:34:53.305+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Running task 0.0 in stage 113.0 (TID 252)
[2025-07-14T12:34:53.305+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Running task 1.0 in stage 113.0 (TID 253)
[2025-07-14T12:34:53.306+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO ShuffleBlockFetcherIterator: Getting 4 (1370.0 B) non-empty blocks including 4 (1370.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:53.306+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO ShuffleBlockFetcherIterator: Getting 4 (1054.0 B) non-empty blocks including 4 (1054.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:53.306+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO ShuffleBlockFetcherIterator: Getting 4 (1472.0 B) non-empty blocks including 4 (1472.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:53.306+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO ShuffleBlockFetcherIterator: Getting 4 (1104.0 B) non-empty blocks including 4 (1104.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:53.306+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:53.306+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:53.306+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:53.306+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:53.309+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Finished task 0.0 in stage 113.0 (TID 252). 1980 bytes result sent to driver
[2025-07-14T12:34:53.309+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Finished task 1.0 in stage 113.0 (TID 253). 2023 bytes result sent to driver
[2025-07-14T12:34:53.309+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Finished task 2.0 in stage 113.0 (TID 254). 2199 bytes result sent to driver
[2025-07-14T12:34:53.309+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Finished task 3.0 in stage 113.0 (TID 255). 2156 bytes result sent to driver
[2025-07-14T12:34:53.309+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 252) in 5 ms on 138.4.31.89 (executor driver) (1/4)
[2025-07-14T12:34:53.310+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Finished task 2.0 in stage 113.0 (TID 254) in 5 ms on 138.4.31.89 (executor driver) (2/4)
[2025-07-14T12:34:53.310+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Finished task 3.0 in stage 113.0 (TID 255) in 6 ms on 138.4.31.89 (executor driver) (3/4)
[2025-07-14T12:34:53.310+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Finished task 1.0 in stage 113.0 (TID 253) in 6 ms on 138.4.31.89 (executor driver) (4/4)
[2025-07-14T12:34:53.310+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool
[2025-07-14T12:34:53.310+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: ResultStage 113 (collectAsMap at MulticlassMetrics.scala:61) finished in 0,008 s
[2025-07-14T12:34:53.310+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:53.310+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 113: Stage finished
[2025-07-14T12:34:53.310+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Job 67 finished: collectAsMap at MulticlassMetrics.scala:61, took 1,059442 s
[2025-07-14T12:34:53.311+0200] {subprocess.py:93} INFO - Accuracy: 0.5919
[2025-07-14T12:34:53.391+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:53.391+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-14T12:34:53.391+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-14T12:34:53.391+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-14T12:34:53.391+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:53.395+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:53.396+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-14T12:34:53.396+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:53.406+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO FileSourceStrategy: Pushed Filters:
[2025-07-14T12:34:53.406+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-14T12:34:53.419+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO CodeGenerator: Code generated in 3.049277 ms
[2025-07-14T12:34:53.420+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 214.5 KiB, free 411.6 MiB)
[2025-07-14T12:34:53.424+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 39.0 KiB, free 411.5 MiB)
[2025-07-14T12:34:53.424+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 138.4.31.89:45589 (size: 39.0 KiB, free: 432.5 MiB)
[2025-07-14T12:34:53.424+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO SparkContext: Created broadcast 100 from showString at NativeMethodAccessorImpl.java:0
[2025-07-14T12:34:53.425+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-14T12:34:53.426+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Registering RDD 235 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 37
[2025-07-14T12:34:53.426+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Got map stage job 68 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-07-14T12:34:53.426+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Final stage: ShuffleMapStage 114 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-14T12:34:53.426+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:53.426+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:53.426+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Submitting ShuffleMapStage 114 (MapPartitionsRDD[235] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-14T12:34:53.427+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 20.2 KiB, free 411.5 MiB)
[2025-07-14T12:34:53.430+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 138.4.31.89:45589 in memory (size: 2.8 KiB, free: 432.5 MiB)
[2025-07-14T12:34:53.430+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 411.5 MiB)
[2025-07-14T12:34:53.430+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 138.4.31.89:45589 (size: 9.2 KiB, free: 432.5 MiB)
[2025-07-14T12:34:53.430+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:53.430+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 114 (MapPartitionsRDD[235] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-14T12:34:53.430+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSchedulerImpl: Adding task set 114.0 with 2 tasks resource profile 0
[2025-07-14T12:34:53.431+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Registering RDD 239 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 38
[2025-07-14T12:34:53.431+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Got map stage job 69 (showString at NativeMethodAccessorImpl.java:0) with 13 output partitions
[2025-07-14T12:34:53.431+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Final stage: ShuffleMapStage 115 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-14T12:34:53.431+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:53.431+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:53.431+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Submitting ShuffleMapStage 115 (MapPartitionsRDD[239] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-14T12:34:53.431+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 256) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:53.431+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Starting task 1.0 in stage 114.0 (TID 257) (138.4.31.89, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:53.431+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Running task 0.0 in stage 114.0 (TID 256)
[2025-07-14T12:34:53.432+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Running task 1.0 in stage 114.0 (TID 257)
[2025-07-14T12:34:53.432+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 18.7 KiB, free 411.5 MiB)
[2025-07-14T12:34:53.432+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 411.5 MiB)
[2025-07-14T12:34:53.432+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 138.4.31.89:45589 (size: 9.2 KiB, free: 432.5 MiB)
[2025-07-14T12:34:53.432+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:53.432+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 115 (MapPartitionsRDD[239] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-14T12:34:53.433+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSchedulerImpl: Adding task set 115.0 with 13 tasks resource profile 0
[2025-07-14T12:34:53.433+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 258) (138.4.31.89, executor driver, partition 0, ANY, 16719 bytes)
[2025-07-14T12:34:53.433+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Starting task 1.0 in stage 115.0 (TID 259) (138.4.31.89, executor driver, partition 1, ANY, 16719 bytes)
[2025-07-14T12:34:53.433+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Running task 1.0 in stage 115.0 (TID 259)
[2025-07-14T12:34:53.433+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Running task 0.0 in stage 115.0 (TID 258)
[2025-07-14T12:34:53.436+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO CodeGenerator: Code generated in 2.944159 ms
[2025-07-14T12:34:53.440+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO CodeGenerator: Code generated in 3.14506 ms
[2025-07-14T12:34:53.440+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-14T12:34:53.441+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-14T12:34:53.444+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO CodeGenerator: Code generated in 2.494817 ms
[2025-07-14T12:34:53.458+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 138.4.31.89:45589 in memory (size: 9.3 KiB, free: 432.5 MiB)
[2025-07-14T12:34:53.458+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 138.4.31.89:45589 in memory (size: 109.4 KiB, free: 432.6 MiB)
[2025-07-14T12:34:53.459+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 138.4.31.89:45589 in memory (size: 109.5 KiB, free: 432.7 MiB)
[2025-07-14T12:34:53.459+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 138.4.31.89:45589 in memory (size: 39.0 KiB, free: 432.8 MiB)
[2025-07-14T12:34:53.459+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 138.4.31.89:45589 in memory (size: 454.4 KiB, free: 433.2 MiB)
[2025-07-14T12:34:53.460+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 138.4.31.89:45589 in memory (size: 4.9 KiB, free: 433.2 MiB)
[2025-07-14T12:34:53.460+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 138.4.31.89:45589 in memory (size: 9.2 KiB, free: 433.2 MiB)
[2025-07-14T12:34:53.461+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 138.4.31.89:45589 in memory (size: 9.2 KiB, free: 433.2 MiB)
[2025-07-14T12:34:53.462+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 138.4.31.89:45589 in memory (size: 9.3 KiB, free: 433.2 MiB)
[2025-07-14T12:34:53.463+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 138.4.31.89:45589 in memory (size: 39.0 KiB, free: 433.3 MiB)
[2025-07-14T12:34:53.463+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 138.4.31.89:45589 in memory (size: 39.0 KiB, free: 433.3 MiB)
[2025-07-14T12:34:53.463+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 138.4.31.89:45589 in memory (size: 329.9 KiB, free: 433.6 MiB)
[2025-07-14T12:34:53.465+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Finished task 0.0 in stage 115.0 (TID 258). 1945 bytes result sent to driver
[2025-07-14T12:34:53.465+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManager: Removing RDD 166
[2025-07-14T12:34:53.465+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Starting task 2.0 in stage 115.0 (TID 260) (138.4.31.89, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-14T12:34:53.465+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 258) in 32 ms on 138.4.31.89 (executor driver) (1/13)
[2025-07-14T12:34:53.465+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Running task 2.0 in stage 115.0 (TID 260)
[2025-07-14T12:34:53.466+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 138.4.31.89:45589 in memory (size: 479.7 KiB, free: 434.1 MiB)
[2025-07-14T12:34:53.467+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 138.4.31.89:45589 in memory (size: 109.4 KiB, free: 434.2 MiB)
[2025-07-14T12:34:53.468+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Finished task 1.0 in stage 115.0 (TID 259). 1945 bytes result sent to driver
[2025-07-14T12:34:53.468+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Starting task 3.0 in stage 115.0 (TID 261) (138.4.31.89, executor driver, partition 3, ANY, 16839 bytes)
[2025-07-14T12:34:53.469+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Running task 3.0 in stage 115.0 (TID 261)
[2025-07-14T12:34:53.469+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Finished task 1.0 in stage 115.0 (TID 259) in 35 ms on 138.4.31.89 (executor driver) (2/13)
[2025-07-14T12:34:53.484+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Finished task 2.0 in stage 115.0 (TID 260). 1945 bytes result sent to driver
[2025-07-14T12:34:53.484+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Starting task 4.0 in stage 115.0 (TID 262) (138.4.31.89, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-14T12:34:53.485+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Finished task 2.0 in stage 115.0 (TID 260) in 19 ms on 138.4.31.89 (executor driver) (3/13)
[2025-07-14T12:34:53.485+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Running task 4.0 in stage 115.0 (TID 262)
[2025-07-14T12:34:53.493+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Finished task 3.0 in stage 115.0 (TID 261). 1945 bytes result sent to driver
[2025-07-14T12:34:53.493+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Starting task 5.0 in stage 115.0 (TID 263) (138.4.31.89, executor driver, partition 5, ANY, 16719 bytes)
[2025-07-14T12:34:53.493+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Running task 5.0 in stage 115.0 (TID 263)
[2025-07-14T12:34:53.493+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Finished task 3.0 in stage 115.0 (TID 261) in 25 ms on 138.4.31.89 (executor driver) (4/13)
[2025-07-14T12:34:53.497+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Finished task 4.0 in stage 115.0 (TID 262). 1945 bytes result sent to driver
[2025-07-14T12:34:53.497+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Starting task 6.0 in stage 115.0 (TID 264) (138.4.31.89, executor driver, partition 6, ANY, 16719 bytes)
[2025-07-14T12:34:53.497+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Finished task 4.0 in stage 115.0 (TID 262) in 13 ms on 138.4.31.89 (executor driver) (5/13)
[2025-07-14T12:34:53.497+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Running task 6.0 in stage 115.0 (TID 264)
[2025-07-14T12:34:53.514+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Finished task 5.0 in stage 115.0 (TID 263). 1945 bytes result sent to driver
[2025-07-14T12:34:53.514+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Starting task 7.0 in stage 115.0 (TID 265) (138.4.31.89, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-14T12:34:53.515+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Running task 7.0 in stage 115.0 (TID 265)
[2025-07-14T12:34:53.515+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Finished task 5.0 in stage 115.0 (TID 263) in 22 ms on 138.4.31.89 (executor driver) (6/13)
[2025-07-14T12:34:53.517+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Finished task 6.0 in stage 115.0 (TID 264). 1945 bytes result sent to driver
[2025-07-14T12:34:53.518+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Starting task 8.0 in stage 115.0 (TID 266) (138.4.31.89, executor driver, partition 8, ANY, 16839 bytes)
[2025-07-14T12:34:53.518+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Running task 8.0 in stage 115.0 (TID 266)
[2025-07-14T12:34:53.518+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Finished task 6.0 in stage 115.0 (TID 264) in 21 ms on 138.4.31.89 (executor driver) (7/13)
[2025-07-14T12:34:53.529+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Finished task 7.0 in stage 115.0 (TID 265). 1988 bytes result sent to driver
[2025-07-14T12:34:53.529+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Starting task 9.0 in stage 115.0 (TID 267) (138.4.31.89, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-14T12:34:53.529+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Running task 9.0 in stage 115.0 (TID 267)
[2025-07-14T12:34:53.529+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Finished task 7.0 in stage 115.0 (TID 265) in 15 ms on 138.4.31.89 (executor driver) (8/13)
[2025-07-14T12:34:53.540+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Finished task 8.0 in stage 115.0 (TID 266). 1988 bytes result sent to driver
[2025-07-14T12:34:53.541+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Starting task 10.0 in stage 115.0 (TID 268) (138.4.31.89, executor driver, partition 10, ANY, 16839 bytes)
[2025-07-14T12:34:53.541+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Running task 10.0 in stage 115.0 (TID 268)
[2025-07-14T12:34:53.541+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Finished task 8.0 in stage 115.0 (TID 266) in 24 ms on 138.4.31.89 (executor driver) (9/13)
[2025-07-14T12:34:53.542+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Finished task 9.0 in stage 115.0 (TID 267). 1988 bytes result sent to driver
[2025-07-14T12:34:53.542+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Starting task 11.0 in stage 115.0 (TID 269) (138.4.31.89, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-14T12:34:53.542+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Finished task 9.0 in stage 115.0 (TID 267) in 13 ms on 138.4.31.89 (executor driver) (10/13)
[2025-07-14T12:34:53.542+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Running task 11.0 in stage 115.0 (TID 269)
[2025-07-14T12:34:53.553+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Finished task 11.0 in stage 115.0 (TID 269). 1902 bytes result sent to driver
[2025-07-14T12:34:53.553+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Starting task 12.0 in stage 115.0 (TID 270) (138.4.31.89, executor driver, partition 12, ANY, 16715 bytes)
[2025-07-14T12:34:53.553+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Finished task 11.0 in stage 115.0 (TID 269) in 11 ms on 138.4.31.89 (executor driver) (11/13)
[2025-07-14T12:34:53.554+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Running task 12.0 in stage 115.0 (TID 270)
[2025-07-14T12:34:53.560+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Finished task 10.0 in stage 115.0 (TID 268). 1945 bytes result sent to driver
[2025-07-14T12:34:53.560+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Finished task 10.0 in stage 115.0 (TID 268) in 19 ms on 138.4.31.89 (executor driver) (12/13)
[2025-07-14T12:34:53.568+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Finished task 12.0 in stage 115.0 (TID 270). 1945 bytes result sent to driver
[2025-07-14T12:34:53.568+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Finished task 12.0 in stage 115.0 (TID 270) in 15 ms on 138.4.31.89 (executor driver) (13/13)
[2025-07-14T12:34:53.568+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool
[2025-07-14T12:34:53.568+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: ShuffleMapStage 115 (showString at NativeMethodAccessorImpl.java:0) finished in 0,137 s
[2025-07-14T12:34:53.568+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:53.568+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: running: Set(ShuffleMapStage 114)
[2025-07-14T12:34:53.568+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:53.568+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:53.574+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO ShufflePartitionsUtil: For shuffle(38), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-14T12:34:53.580+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-14T12:34:53.580+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Got job 70 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-14T12:34:53.580+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Final stage: ResultStage 117 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-14T12:34:53.580+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 116)
[2025-07-14T12:34:53.580+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:53.581+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[241] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-14T12:34:53.581+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 8.2 KiB, free 429.5 MiB)
[2025-07-14T12:34:53.582+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 429.5 MiB)
[2025-07-14T12:34:53.582+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 138.4.31.89:45589 (size: 4.2 KiB, free: 434.2 MiB)
[2025-07-14T12:34:53.582+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:53.583+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[241] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:53.583+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSchedulerImpl: Adding task set 117.0 with 1 tasks resource profile 0
[2025-07-14T12:34:53.583+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 271) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-14T12:34:53.584+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Running task 0.0 in stage 117.0 (TID 271)
[2025-07-14T12:34:53.585+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO ShuffleBlockFetcherIterator: Getting 13 (217.3 KiB) non-empty blocks including 13 (217.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:53.585+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:53.591+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Finished task 0.0 in stage 117.0 (TID 271). 51129 bytes result sent to driver
[2025-07-14T12:34:53.591+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 271) in 8 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:53.591+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool
[2025-07-14T12:34:53.592+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: ResultStage 117 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,011 s
[2025-07-14T12:34:53.592+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:53.592+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 117: Stage finished
[2025-07-14T12:34:53.592+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO DAGScheduler: Job 70 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,011957 s
[2025-07-14T12:34:53.596+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 4.3 MiB, free 425.2 MiB)
[2025-07-14T12:34:53.598+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 109.4 KiB, free 425.1 MiB)
[2025-07-14T12:34:53.598+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 138.4.31.89:45589 (size: 109.4 KiB, free: 434.1 MiB)
[2025-07-14T12:34:53.598+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO SparkContext: Created broadcast 104 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-14T12:34:53.790+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 138.4.31.89:45589 in memory (size: 4.2 KiB, free: 434.1 MiB)
[2025-07-14T12:34:53.835+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO Executor: Finished task 1.0 in stage 114.0 (TID 257). 2031 bytes result sent to driver
[2025-07-14T12:34:53.836+0200] {subprocess.py:93} INFO - 25/07/14 12:34:53 INFO TaskSetManager: Finished task 1.0 in stage 114.0 (TID 257) in 404 ms on 138.4.31.89 (executor driver) (1/2)
[2025-07-14T12:34:56.306+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO Executor: Finished task 0.0 in stage 114.0 (TID 256). 2031 bytes result sent to driver
[2025-07-14T12:34:56.306+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 256) in 2875 ms on 138.4.31.89 (executor driver) (2/2)
[2025-07-14T12:34:56.306+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool
[2025-07-14T12:34:56.307+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO DAGScheduler: ShuffleMapStage 114 (showString at NativeMethodAccessorImpl.java:0) finished in 2,879 s
[2025-07-14T12:34:56.307+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:56.307+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:56.307+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:56.307+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:56.312+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO ShufflePartitionsUtil: For shuffle(37), advisory target size: 67108864, actual target size 1399865, minimum partition size: 1048576
[2025-07-14T12:34:56.353+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO CodeGenerator: Code generated in 23.656402 ms
[2025-07-14T12:34:56.365+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO DAGScheduler: Registering RDD 244 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 39
[2025-07-14T12:34:56.365+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO DAGScheduler: Got map stage job 71 (showString at NativeMethodAccessorImpl.java:0) with 4 output partitions
[2025-07-14T12:34:56.365+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO DAGScheduler: Final stage: ShuffleMapStage 119 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-14T12:34:56.365+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 118)
[2025-07-14T12:34:56.365+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:56.365+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO DAGScheduler: Submitting ShuffleMapStage 119 (MapPartitionsRDD[244] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-14T12:34:56.374+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 WARN DAGScheduler: Broadcasting large task binary with size 1020.3 KiB
[2025-07-14T12:34:56.375+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 1020.4 KiB, free 424.1 MiB)
[2025-07-14T12:34:56.377+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 452.6 KiB, free 423.7 MiB)
[2025-07-14T12:34:56.377+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 138.4.31.89:45589 (size: 452.6 KiB, free: 433.7 MiB)
[2025-07-14T12:34:56.378+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:56.378+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 119 (MapPartitionsRDD[244] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-14T12:34:56.378+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO TaskSchedulerImpl: Adding task set 119.0 with 4 tasks resource profile 0
[2025-07-14T12:34:56.378+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 272) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14836 bytes)
[2025-07-14T12:34:56.378+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO TaskSetManager: Starting task 1.0 in stage 119.0 (TID 273) (138.4.31.89, executor driver, partition 1, NODE_LOCAL, 14836 bytes)
[2025-07-14T12:34:56.379+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO TaskSetManager: Starting task 2.0 in stage 119.0 (TID 274) (138.4.31.89, executor driver, partition 2, NODE_LOCAL, 14836 bytes)
[2025-07-14T12:34:56.379+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO TaskSetManager: Starting task 3.0 in stage 119.0 (TID 275) (138.4.31.89, executor driver, partition 3, NODE_LOCAL, 14836 bytes)
[2025-07-14T12:34:56.379+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO Executor: Running task 0.0 in stage 119.0 (TID 272)
[2025-07-14T12:34:56.379+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO Executor: Running task 3.0 in stage 119.0 (TID 275)
[2025-07-14T12:34:56.379+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO Executor: Running task 1.0 in stage 119.0 (TID 273)
[2025-07-14T12:34:56.379+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO Executor: Running task 2.0 in stage 119.0 (TID 274)
[2025-07-14T12:34:56.389+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO ShuffleBlockFetcherIterator: Getting 1 (268.8 KiB) non-empty blocks including 1 (268.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:56.389+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO ShuffleBlockFetcherIterator: Getting 1 (2.5 MiB) non-empty blocks including 1 (2.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:56.389+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO ShuffleBlockFetcherIterator: Getting 1 (283.3 KiB) non-empty blocks including 1 (283.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:56.389+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:56.389+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:56.389+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:56.390+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO ShuffleBlockFetcherIterator: Getting 1 (2.3 MiB) non-empty blocks including 1 (2.3 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:56.390+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:56.400+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO CodeGenerator: Code generated in 10.868004 ms
[2025-07-14T12:34:56.404+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO CodeGenerator: Code generated in 2.862492 ms
[2025-07-14T12:34:56.407+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO CodeGenerator: Code generated in 1.330717 ms
[2025-07-14T12:34:56.410+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO CodeGenerator: Code generated in 1.51137 ms
[2025-07-14T12:34:56.412+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO CodeGenerator: Code generated in 1.481482 ms
[2025-07-14T12:34:56.515+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO Executor: Finished task 2.0 in stage 119.0 (TID 274). 6904 bytes result sent to driver
[2025-07-14T12:34:56.515+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO TaskSetManager: Finished task 2.0 in stage 119.0 (TID 274) in 137 ms on 138.4.31.89 (executor driver) (1/4)
[2025-07-14T12:34:56.518+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO Executor: Finished task 3.0 in stage 119.0 (TID 275). 6904 bytes result sent to driver
[2025-07-14T12:34:56.519+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO TaskSetManager: Finished task 3.0 in stage 119.0 (TID 275) in 141 ms on 138.4.31.89 (executor driver) (2/4)
[2025-07-14T12:34:56.952+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO Executor: Finished task 0.0 in stage 119.0 (TID 272). 6904 bytes result sent to driver
[2025-07-14T12:34:56.952+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 272) in 574 ms on 138.4.31.89 (executor driver) (3/4)
[2025-07-14T12:34:56.980+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO Executor: Finished task 1.0 in stage 119.0 (TID 273). 6904 bytes result sent to driver
[2025-07-14T12:34:56.980+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO TaskSetManager: Finished task 1.0 in stage 119.0 (TID 273) in 602 ms on 138.4.31.89 (executor driver) (4/4)
[2025-07-14T12:34:56.980+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool
[2025-07-14T12:34:56.980+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO DAGScheduler: ShuffleMapStage 119 (showString at NativeMethodAccessorImpl.java:0) finished in 0,614 s
[2025-07-14T12:34:56.980+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:56.980+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO DAGScheduler: running: Set()
[2025-07-14T12:34:56.980+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:56.981+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:56.982+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO ShufflePartitionsUtil: For shuffle(39), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-14T12:34:56.986+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-07-14T12:34:56.994+0200] {subprocess.py:93} INFO - 25/07/14 12:34:56 INFO CodeGenerator: Code generated in 5.661201 ms
[2025-07-14T12:34:57.017+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2025-07-14T12:34:57.018+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Got job 72 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-07-14T12:34:57.018+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Final stage: ResultStage 122 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-14T12:34:57.018+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 121)
[2025-07-14T12:34:57.018+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:57.018+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Submitting ResultStage 122 (MapPartitionsRDD[247] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-14T12:34:57.026+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 WARN DAGScheduler: Broadcasting large task binary with size 1004.9 KiB
[2025-07-14T12:34:57.026+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 1004.9 KiB, free 422.7 MiB)
[2025-07-14T12:34:57.028+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 446.4 KiB, free 422.3 MiB)
[2025-07-14T12:34:57.028+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 138.4.31.89:45589 (size: 446.4 KiB, free: 433.2 MiB)
[2025-07-14T12:34:57.029+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:57.029+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 122 (MapPartitionsRDD[247] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:57.029+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSchedulerImpl: Adding task set 122.0 with 1 tasks resource profile 0
[2025-07-14T12:34:57.029+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 276) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-14T12:34:57.030+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Running task 0.0 in stage 122.0 (TID 276)
[2025-07-14T12:34:57.039+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO ShuffleBlockFetcherIterator: Getting 4 (1008.0 B) non-empty blocks including 4 (1008.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:57.039+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:57.043+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO CodeGenerator: Code generated in 3.770527 ms
[2025-07-14T12:34:57.048+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 138.4.31.89:45589 in memory (size: 452.6 KiB, free: 433.7 MiB)
[2025-07-14T12:34:57.048+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Finished task 0.0 in stage 122.0 (TID 276). 8261 bytes result sent to driver
[2025-07-14T12:34:57.048+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 276) in 19 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:57.049+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool
[2025-07-14T12:34:57.049+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: ResultStage 122 (showString at NativeMethodAccessorImpl.java:0) finished in 0,029 s
[2025-07-14T12:34:57.049+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:57.049+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 122: Stage finished
[2025-07-14T12:34:57.049+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Job 72 finished: showString at NativeMethodAccessorImpl.java:0, took 0,031485 s
[2025-07-14T12:34:57.052+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO CodeGenerator: Code generated in 2.039831 ms
[2025-07-14T12:34:57.053+0200] {subprocess.py:93} INFO - +----------+------+
[2025-07-14T12:34:57.053+0200] {subprocess.py:93} INFO - |Prediction| count|
[2025-07-14T12:34:57.053+0200] {subprocess.py:93} INFO - +----------+------+
[2025-07-14T12:34:57.053+0200] {subprocess.py:93} INFO - |       0.0|  6192|
[2025-07-14T12:34:57.053+0200] {subprocess.py:93} INFO - |       1.0|315771|
[2025-07-14T12:34:57.053+0200] {subprocess.py:93} INFO - |       3.0| 51427|
[2025-07-14T12:34:57.053+0200] {subprocess.py:93} INFO - |       2.0| 83623|
[2025-07-14T12:34:57.053+0200] {subprocess.py:93} INFO - +----------+------+
[2025-07-14T12:34:57.053+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:57.076+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:57.076+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-14T12:34:57.076+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-14T12:34:57.076+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-14T12:34:57.076+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:57.084+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO V2ScanRelationPushDown:
[2025-07-14T12:34:57.084+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-14T12:34:57.084+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:34:57.095+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO FileSourceStrategy: Pushed Filters:
[2025-07-14T12:34:57.095+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-14T12:34:57.106+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 214.5 KiB, free 423.5 MiB)
[2025-07-14T12:34:57.110+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 39.0 KiB, free 423.5 MiB)
[2025-07-14T12:34:57.110+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 138.4.31.89:45589 (size: 39.0 KiB, free: 433.6 MiB)
[2025-07-14T12:34:57.110+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO SparkContext: Created broadcast 107 from showString at NativeMethodAccessorImpl.java:0
[2025-07-14T12:34:57.111+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-14T12:34:57.112+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Registering RDD 251 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 40
[2025-07-14T12:34:57.112+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Got map stage job 73 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-07-14T12:34:57.112+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Final stage: ShuffleMapStage 123 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-14T12:34:57.112+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:57.112+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:57.112+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Submitting ShuffleMapStage 123 (MapPartitionsRDD[251] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-14T12:34:57.113+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 22.8 KiB, free 423.4 MiB)
[2025-07-14T12:34:57.113+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 423.4 MiB)
[2025-07-14T12:34:57.113+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 138.4.31.89:45589 (size: 9.9 KiB, free: 433.6 MiB)
[2025-07-14T12:34:57.113+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:57.114+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 123 (MapPartitionsRDD[251] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-14T12:34:57.114+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSchedulerImpl: Adding task set 123.0 with 2 tasks resource profile 0
[2025-07-14T12:34:57.114+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Registering RDD 255 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 41
[2025-07-14T12:34:57.114+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Got map stage job 74 (showString at NativeMethodAccessorImpl.java:0) with 13 output partitions
[2025-07-14T12:34:57.114+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Final stage: ShuffleMapStage 124 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-14T12:34:57.114+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:34:57.114+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:57.114+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Submitting ShuffleMapStage 124 (MapPartitionsRDD[255] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-14T12:34:57.114+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 277) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:57.114+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Starting task 1.0 in stage 123.0 (TID 278) (138.4.31.89, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-14T12:34:57.114+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Running task 0.0 in stage 123.0 (TID 277)
[2025-07-14T12:34:57.114+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Running task 1.0 in stage 123.0 (TID 278)
[2025-07-14T12:34:57.115+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 18.7 KiB, free 423.4 MiB)
[2025-07-14T12:34:57.115+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 423.4 MiB)
[2025-07-14T12:34:57.115+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 138.4.31.89:45589 (size: 9.2 KiB, free: 433.6 MiB)
[2025-07-14T12:34:57.115+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:57.115+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Submitting 13 missing tasks from ShuffleMapStage 124 (MapPartitionsRDD[255] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
[2025-07-14T12:34:57.115+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSchedulerImpl: Adding task set 124.0 with 13 tasks resource profile 0
[2025-07-14T12:34:57.116+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 279) (138.4.31.89, executor driver, partition 0, ANY, 16719 bytes)
[2025-07-14T12:34:57.116+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Starting task 1.0 in stage 124.0 (TID 280) (138.4.31.89, executor driver, partition 1, ANY, 16719 bytes)
[2025-07-14T12:34:57.116+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Running task 1.0 in stage 124.0 (TID 280)
[2025-07-14T12:34:57.116+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Running task 0.0 in stage 124.0 (TID 279)
[2025-07-14T12:34:57.116+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-14T12:34:57.116+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-14T12:34:57.123+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 138.4.31.89:45589 in memory (size: 446.4 KiB, free: 434.0 MiB)
[2025-07-14T12:34:57.131+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Finished task 1.0 in stage 124.0 (TID 280). 1988 bytes result sent to driver
[2025-07-14T12:34:57.132+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Starting task 2.0 in stage 124.0 (TID 281) (138.4.31.89, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-14T12:34:57.132+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Running task 2.0 in stage 124.0 (TID 281)
[2025-07-14T12:34:57.132+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Finished task 1.0 in stage 124.0 (TID 280) in 16 ms on 138.4.31.89 (executor driver) (1/13)
[2025-07-14T12:34:57.134+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Finished task 0.0 in stage 124.0 (TID 279). 1945 bytes result sent to driver
[2025-07-14T12:34:57.134+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Starting task 3.0 in stage 124.0 (TID 282) (138.4.31.89, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-14T12:34:57.134+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 279) in 19 ms on 138.4.31.89 (executor driver) (2/13)
[2025-07-14T12:34:57.134+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Running task 3.0 in stage 124.0 (TID 282)
[2025-07-14T12:34:57.144+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Finished task 2.0 in stage 124.0 (TID 281). 1945 bytes result sent to driver
[2025-07-14T12:34:57.144+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Finished task 3.0 in stage 124.0 (TID 282). 1902 bytes result sent to driver
[2025-07-14T12:34:57.144+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Starting task 4.0 in stage 124.0 (TID 283) (138.4.31.89, executor driver, partition 4, ANY, 16839 bytes)
[2025-07-14T12:34:57.144+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Running task 4.0 in stage 124.0 (TID 283)
[2025-07-14T12:34:57.144+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Finished task 2.0 in stage 124.0 (TID 281) in 12 ms on 138.4.31.89 (executor driver) (3/13)
[2025-07-14T12:34:57.144+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Starting task 5.0 in stage 124.0 (TID 284) (138.4.31.89, executor driver, partition 5, ANY, 16719 bytes)
[2025-07-14T12:34:57.145+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Running task 5.0 in stage 124.0 (TID 284)
[2025-07-14T12:34:57.145+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Finished task 3.0 in stage 124.0 (TID 282) in 11 ms on 138.4.31.89 (executor driver) (4/13)
[2025-07-14T12:34:57.159+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Finished task 5.0 in stage 124.0 (TID 284). 1902 bytes result sent to driver
[2025-07-14T12:34:57.159+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Starting task 6.0 in stage 124.0 (TID 285) (138.4.31.89, executor driver, partition 6, ANY, 16719 bytes)
[2025-07-14T12:34:57.160+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Running task 6.0 in stage 124.0 (TID 285)
[2025-07-14T12:34:57.160+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Finished task 5.0 in stage 124.0 (TID 284) in 16 ms on 138.4.31.89 (executor driver) (5/13)
[2025-07-14T12:34:57.162+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Finished task 4.0 in stage 124.0 (TID 283). 1902 bytes result sent to driver
[2025-07-14T12:34:57.162+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Starting task 7.0 in stage 124.0 (TID 286) (138.4.31.89, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-14T12:34:57.162+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Finished task 4.0 in stage 124.0 (TID 283) in 18 ms on 138.4.31.89 (executor driver) (6/13)
[2025-07-14T12:34:57.162+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Running task 7.0 in stage 124.0 (TID 286)
[2025-07-14T12:34:57.174+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Finished task 6.0 in stage 124.0 (TID 285). 1945 bytes result sent to driver
[2025-07-14T12:34:57.174+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Starting task 8.0 in stage 124.0 (TID 287) (138.4.31.89, executor driver, partition 8, ANY, 16839 bytes)
[2025-07-14T12:34:57.174+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Running task 8.0 in stage 124.0 (TID 287)
[2025-07-14T12:34:57.174+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Finished task 6.0 in stage 124.0 (TID 285) in 15 ms on 138.4.31.89 (executor driver) (7/13)
[2025-07-14T12:34:57.177+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Finished task 7.0 in stage 124.0 (TID 286). 1902 bytes result sent to driver
[2025-07-14T12:34:57.177+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Starting task 9.0 in stage 124.0 (TID 288) (138.4.31.89, executor driver, partition 9, ANY, 16715 bytes)
[2025-07-14T12:34:57.177+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Finished task 7.0 in stage 124.0 (TID 286) in 15 ms on 138.4.31.89 (executor driver) (8/13)
[2025-07-14T12:34:57.177+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Running task 9.0 in stage 124.0 (TID 288)
[2025-07-14T12:34:57.196+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Finished task 9.0 in stage 124.0 (TID 288). 1945 bytes result sent to driver
[2025-07-14T12:34:57.197+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Starting task 10.0 in stage 124.0 (TID 289) (138.4.31.89, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-14T12:34:57.197+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Running task 10.0 in stage 124.0 (TID 289)
[2025-07-14T12:34:57.197+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Finished task 9.0 in stage 124.0 (TID 288) in 20 ms on 138.4.31.89 (executor driver) (9/13)
[2025-07-14T12:34:57.198+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Finished task 8.0 in stage 124.0 (TID 287). 1945 bytes result sent to driver
[2025-07-14T12:34:57.199+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Starting task 11.0 in stage 124.0 (TID 290) (138.4.31.89, executor driver, partition 11, ANY, 16839 bytes)
[2025-07-14T12:34:57.199+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Running task 11.0 in stage 124.0 (TID 290)
[2025-07-14T12:34:57.199+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Finished task 8.0 in stage 124.0 (TID 287) in 25 ms on 138.4.31.89 (executor driver) (10/13)
[2025-07-14T12:34:57.209+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Finished task 10.0 in stage 124.0 (TID 289). 1945 bytes result sent to driver
[2025-07-14T12:34:57.210+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Starting task 12.0 in stage 124.0 (TID 291) (138.4.31.89, executor driver, partition 12, ANY, 16719 bytes)
[2025-07-14T12:34:57.210+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Running task 12.0 in stage 124.0 (TID 291)
[2025-07-14T12:34:57.210+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Finished task 10.0 in stage 124.0 (TID 289) in 13 ms on 138.4.31.89 (executor driver) (11/13)
[2025-07-14T12:34:57.213+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Finished task 11.0 in stage 124.0 (TID 290). 1902 bytes result sent to driver
[2025-07-14T12:34:57.214+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Finished task 11.0 in stage 124.0 (TID 290) in 14 ms on 138.4.31.89 (executor driver) (12/13)
[2025-07-14T12:34:57.226+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Finished task 12.0 in stage 124.0 (TID 291). 1902 bytes result sent to driver
[2025-07-14T12:34:57.226+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Finished task 12.0 in stage 124.0 (TID 291) in 17 ms on 138.4.31.89 (executor driver) (13/13)
[2025-07-14T12:34:57.226+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool
[2025-07-14T12:34:57.226+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: ShuffleMapStage 124 (showString at NativeMethodAccessorImpl.java:0) finished in 0,112 s
[2025-07-14T12:34:57.226+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:34:57.226+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: running: Set(ShuffleMapStage 123)
[2025-07-14T12:34:57.226+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:34:57.226+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: failed: Set()
[2025-07-14T12:34:57.233+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO ShufflePartitionsUtil: For shuffle(41), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-14T12:34:57.239+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-14T12:34:57.239+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Got job 75 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-14T12:34:57.240+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Final stage: ResultStage 126 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-14T12:34:57.240+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 125)
[2025-07-14T12:34:57.240+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:34:57.240+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[257] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-14T12:34:57.240+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 8.2 KiB, free 424.8 MiB)
[2025-07-14T12:34:57.241+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 424.8 MiB)
[2025-07-14T12:34:57.241+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 138.4.31.89:45589 (size: 4.2 KiB, free: 434.0 MiB)
[2025-07-14T12:34:57.241+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:34:57.241+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 126 (MapPartitionsRDD[257] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:34:57.241+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSchedulerImpl: Adding task set 126.0 with 1 tasks resource profile 0
[2025-07-14T12:34:57.242+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 292) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-14T12:34:57.242+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Running task 0.0 in stage 126.0 (TID 292)
[2025-07-14T12:34:57.244+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO ShuffleBlockFetcherIterator: Getting 13 (217.3 KiB) non-empty blocks including 13 (217.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:34:57.244+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:34:57.249+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Finished task 0.0 in stage 126.0 (TID 292). 51377 bytes result sent to driver
[2025-07-14T12:34:57.249+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 292) in 7 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:34:57.249+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool
[2025-07-14T12:34:57.250+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: ResultStage 126 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,009 s
[2025-07-14T12:34:57.250+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:34:57.250+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 126: Stage finished
[2025-07-14T12:34:57.250+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO DAGScheduler: Job 75 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,010494 s
[2025-07-14T12:34:57.252+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 4.3 MiB, free 420.6 MiB)
[2025-07-14T12:34:57.253+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 109.4 KiB, free 420.5 MiB)
[2025-07-14T12:34:57.254+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 138.4.31.89:45589 (size: 109.4 KiB, free: 433.9 MiB)
[2025-07-14T12:34:57.254+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO SparkContext: Created broadcast 111 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-14T12:34:57.263+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 138.4.31.89:45589 in memory (size: 4.2 KiB, free: 433.9 MiB)
[2025-07-14T12:34:57.612+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO Executor: Finished task 1.0 in stage 123.0 (TID 278). 1988 bytes result sent to driver
[2025-07-14T12:34:57.613+0200] {subprocess.py:93} INFO - 25/07/14 12:34:57 INFO TaskSetManager: Finished task 1.0 in stage 123.0 (TID 278) in 499 ms on 138.4.31.89 (executor driver) (1/2)
[2025-07-14T12:35:00.774+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO Executor: Finished task 0.0 in stage 123.0 (TID 277). 1988 bytes result sent to driver
[2025-07-14T12:35:00.774+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 277) in 3660 ms on 138.4.31.89 (executor driver) (2/2)
[2025-07-14T12:35:00.775+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool
[2025-07-14T12:35:00.775+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO DAGScheduler: ShuffleMapStage 123 (showString at NativeMethodAccessorImpl.java:0) finished in 3,663 s
[2025-07-14T12:35:00.775+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:35:00.775+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO DAGScheduler: running: Set()
[2025-07-14T12:35:00.775+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:35:00.775+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO DAGScheduler: failed: Set()
[2025-07-14T12:35:00.781+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO ShufflePartitionsUtil: For shuffle(40), advisory target size: 67108864, actual target size 4228400, minimum partition size: 1048576
[2025-07-14T12:35:00.787+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO CodeGenerator: Code generated in 2.039123 ms
[2025-07-14T12:35:00.805+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO CodeGenerator: Code generated in 11.399566 ms
[2025-07-14T12:35:00.836+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2025-07-14T12:35:00.836+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO DAGScheduler: Got job 76 (showString at NativeMethodAccessorImpl.java:0) with 4 output partitions
[2025-07-14T12:35:00.837+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO DAGScheduler: Final stage: ResultStage 128 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-14T12:35:00.837+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 127)
[2025-07-14T12:35:00.837+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:35:00.837+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO DAGScheduler: Submitting ResultStage 128 (MapPartitionsRDD[261] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-14T12:35:00.842+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 WARN DAGScheduler: Broadcasting large task binary with size 1009.3 KiB
[2025-07-14T12:35:00.842+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 1009.4 KiB, free 419.5 MiB)
[2025-07-14T12:35:00.847+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 439.7 KiB, free 419.1 MiB)
[2025-07-14T12:35:00.847+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 138.4.31.89:45589 (size: 439.7 KiB, free: 433.5 MiB)
[2025-07-14T12:35:00.847+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:35:00.847+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 128 (MapPartitionsRDD[261] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-14T12:35:00.847+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO TaskSchedulerImpl: Adding task set 128.0 with 4 tasks resource profile 0
[2025-07-14T12:35:00.848+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 293) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14847 bytes)
[2025-07-14T12:35:00.848+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO TaskSetManager: Starting task 1.0 in stage 128.0 (TID 294) (138.4.31.89, executor driver, partition 1, NODE_LOCAL, 14847 bytes)
[2025-07-14T12:35:00.848+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO TaskSetManager: Starting task 2.0 in stage 128.0 (TID 295) (138.4.31.89, executor driver, partition 2, NODE_LOCAL, 14847 bytes)
[2025-07-14T12:35:00.848+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO TaskSetManager: Starting task 3.0 in stage 128.0 (TID 296) (138.4.31.89, executor driver, partition 3, NODE_LOCAL, 14847 bytes)
[2025-07-14T12:35:00.848+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO Executor: Running task 0.0 in stage 128.0 (TID 293)
[2025-07-14T12:35:00.848+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO Executor: Running task 3.0 in stage 128.0 (TID 296)
[2025-07-14T12:35:00.848+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO Executor: Running task 1.0 in stage 128.0 (TID 294)
[2025-07-14T12:35:00.848+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO Executor: Running task 2.0 in stage 128.0 (TID 295)
[2025-07-14T12:35:00.860+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO CodeGenerator: Code generated in 1.824076 ms
[2025-07-14T12:35:00.861+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO ShuffleBlockFetcherIterator: Getting 1 (840.2 KiB) non-empty blocks including 1 (840.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:35:00.861+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO ShuffleBlockFetcherIterator: Getting 1 (802.7 KiB) non-empty blocks including 1 (802.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:35:00.861+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO ShuffleBlockFetcherIterator: Getting 1 (7.1 MiB) non-empty blocks including 1 (7.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:35:00.861+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO ShuffleBlockFetcherIterator: Getting 1 (7.4 MiB) non-empty blocks including 1 (7.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:35:00.861+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:35:00.862+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:35:00.862+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:35:00.862+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:35:00.873+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO CodeGenerator: Code generated in 10.977011 ms
[2025-07-14T12:35:00.955+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO Executor: Finished task 2.0 in stage 128.0 (TID 295). 7241 bytes result sent to driver
[2025-07-14T12:35:00.956+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO TaskSetManager: Finished task 2.0 in stage 128.0 (TID 295) in 108 ms on 138.4.31.89 (executor driver) (1/4)
[2025-07-14T12:35:00.962+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO Executor: Finished task 3.0 in stage 128.0 (TID 296). 7241 bytes result sent to driver
[2025-07-14T12:35:00.963+0200] {subprocess.py:93} INFO - 25/07/14 12:35:00 INFO TaskSetManager: Finished task 3.0 in stage 128.0 (TID 296) in 115 ms on 138.4.31.89 (executor driver) (2/4)
[2025-07-14T12:35:01.375+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Finished task 0.0 in stage 128.0 (TID 293). 7241 bytes result sent to driver
[2025-07-14T12:35:01.375+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 293) in 527 ms on 138.4.31.89 (executor driver) (3/4)
[2025-07-14T12:35:01.385+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Finished task 1.0 in stage 128.0 (TID 294). 7241 bytes result sent to driver
[2025-07-14T12:35:01.386+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Finished task 1.0 in stage 128.0 (TID 294) in 538 ms on 138.4.31.89 (executor driver) (4/4)
[2025-07-14T12:35:01.386+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool
[2025-07-14T12:35:01.386+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: ResultStage 128 (showString at NativeMethodAccessorImpl.java:0) finished in 0,549 s
[2025-07-14T12:35:01.386+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:35:01.386+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 128: Stage finished
[2025-07-14T12:35:01.386+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Job 76 finished: showString at NativeMethodAccessorImpl.java:0, took 0,550066 s
[2025-07-14T12:35:01.392+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO CodeGenerator: Code generated in 4.127304 ms
[2025-07-14T12:35:01.396+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO CodeGenerator: Code generated in 2.325903 ms
[2025-07-14T12:35:01.397+0200] {subprocess.py:93} INFO - +--------+-------------------+-------------------+----------+---------+---------+--------+----------+---------+-----------------+--------------+--------------------+--------------------+--------------------+----------+
[2025-07-14T12:35:01.397+0200] {subprocess.py:93} INFO - |ArrDelay|         CRSArrTime|         CRSDepTime|DayOfMonth|DayOfWeek|DayOfYear|DepDelay|FlightDate|FlightNum|         Distance|ArrDelayBucket|        Features_vec|       rawPrediction|         probability|Prediction|
[2025-07-14T12:35:01.397+0200] {subprocess.py:93} INFO - +--------+-------------------+-------------------+----------+---------+---------+--------+----------+---------+-----------------+--------------+--------------------+--------------------+--------------------+----------+
[2025-07-14T12:35:01.397+0200] {subprocess.py:93} INFO - |   -22.0|2015-01-01 10:11:00|2015-01-01 07:00:00|         1|        4|        1|    -2.0|2015-01-01|     2282|            946.0|           0.0|[-2.0,946.0,1.0,4...|[2.80066385023886...|[0.28006638502388...|       1.0|
[2025-07-14T12:35:01.397+0200] {subprocess.py:93} INFO - |    -7.0|2015-01-01 12:42:00|2015-01-01 11:25:00|         1|        4|        1|    -6.0|2015-01-01|      626|            369.0|           1.0|[-6.0,369.0,1.0,4...|[1.53803424467514...|[0.15380342446751...|       1.0|
[2025-07-14T12:35:01.397+0200] {subprocess.py:93} INFO - |    -7.0|2015-01-01 17:09:00|2015-01-01 14:11:00|         1|        4|        1|    10.0|2015-01-01|     1236|588.7860861334595|           1.0|[10.0,588.7860861...|[1.29589735250055...|[0.12958973525005...|       2.0|
[2025-07-14T12:35:01.398+0200] {subprocess.py:93} INFO - |     8.0|2015-01-01 16:38:00|2015-01-01 15:45:00|         1|        4|        1|    -3.0|2015-01-01|     6603|            160.0|           2.0|[-3.0,160.0,1.0,4...|[0.96674469553972...|[0.09667446955397...|       1.0|
[2025-07-14T12:35:01.398+0200] {subprocess.py:93} INFO - |   -28.0|2015-01-01 19:10:00|2015-01-01 17:05:00|         1|        4|        1|    -8.0|2015-01-01|     3101|            693.0|           0.0|[-8.0,693.0,1.0,4...|[1.61008925327684...|[0.16100892532768...|       1.0|
[2025-07-14T12:35:01.398+0200] {subprocess.py:93} INFO - |    53.0|2015-01-01 21:18:00|2015-01-01 18:15:00|         1|        4|        1|    53.0|2015-01-01|     5159|            946.0|           3.0|[53.0,946.0,1.0,4...|[0.24994993756609...|[0.02499499375660...|       3.0|
[2025-07-14T12:35:01.398+0200] {subprocess.py:93} INFO - +--------+-------------------+-------------------+----------+---------+---------+--------+----------+---------+-----------------+--------------+--------------------+--------------------+--------------------+----------+
[2025-07-14T12:35:01.398+0200] {subprocess.py:93} INFO - only showing top 6 rows
[2025-07-14T12:35:01.398+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:35:01.432+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-14T12:35:01.432+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:35:01.432+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:35:01.443+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-14T12:35:01.443+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Got job 77 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-14T12:35:01.443+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Final stage: ResultStage 129 (runJob at SparkHadoopWriter.scala:83)
[2025-07-14T12:35:01.443+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:35:01.443+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:35:01.443+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Submitting ResultStage 129 (MapPartitionsRDD[263] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-14T12:35:01.448+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 101.3 KiB, free 419.0 MiB)
[2025-07-14T12:35:01.449+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 418.9 MiB)
[2025-07-14T12:35:01.449+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 138.4.31.89:45589 (size: 36.5 KiB, free: 433.5 MiB)
[2025-07-14T12:35:01.449+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:35:01.450+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 129 (MapPartitionsRDD[263] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:35:01.450+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSchedulerImpl: Adding task set 129.0 with 1 tasks resource profile 0
[2025-07-14T12:35:01.450+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 297) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15042 bytes)
[2025-07-14T12:35:01.450+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Running task 0.0 in stage 129.0 (TID 297)
[2025-07-14T12:35:01.453+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-14T12:35:01.453+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:35:01.453+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:35:01.459+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: Saved output of task 'attempt_202507141235013966111358256367033_0263_m_000000_0' to file:/tmp/mlflow/24ede259-b14f-4511-a2bd-3d66a7f5e470/metadata/_temporary/0/task_202507141235013966111358256367033_0263_m_000000
[2025-07-14T12:35:01.459+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SparkHadoopMapRedUtil: attempt_202507141235013966111358256367033_0263_m_000000_0: Committed. Elapsed time: 0 ms.
[2025-07-14T12:35:01.460+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Finished task 0.0 in stage 129.0 (TID 297). 1170 bytes result sent to driver
[2025-07-14T12:35:01.460+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 297) in 10 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:35:01.460+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool
[2025-07-14T12:35:01.460+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: ResultStage 129 (runJob at SparkHadoopWriter.scala:83) finished in 0,016 s
[2025-07-14T12:35:01.460+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Job 77 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:35:01.460+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 129: Stage finished
[2025-07-14T12:35:01.461+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Job 77 finished: runJob at SparkHadoopWriter.scala:83, took 0,017556 s
[2025-07-14T12:35:01.461+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SparkHadoopWriter: Start to commit write Job job_202507141235013966111358256367033_0263.
[2025-07-14T12:35:01.464+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SparkHadoopWriter: Write Job job_202507141235013966111358256367033_0263 committed. Elapsed time: 3 ms.
[2025-07-14T12:35:01.467+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-14T12:35:01.467+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:35:01.467+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:35:01.478+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-14T12:35:01.478+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Got job 78 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-14T12:35:01.478+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Final stage: ResultStage 130 (runJob at SparkHadoopWriter.scala:83)
[2025-07-14T12:35:01.478+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:35:01.478+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:35:01.478+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Submitting ResultStage 130 (MapPartitionsRDD[265] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-14T12:35:01.482+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 101.4 KiB, free 418.8 MiB)
[2025-07-14T12:35:01.483+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 36.6 KiB, free 418.8 MiB)
[2025-07-14T12:35:01.483+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 138.4.31.89:45589 (size: 36.6 KiB, free: 433.4 MiB)
[2025-07-14T12:35:01.483+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:35:01.483+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 130 (MapPartitionsRDD[265] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:35:01.483+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSchedulerImpl: Adding task set 130.0 with 1 tasks resource profile 0
[2025-07-14T12:35:01.484+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 298) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 15658 bytes)
[2025-07-14T12:35:01.484+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Running task 0.0 in stage 130.0 (TID 298)
[2025-07-14T12:35:01.486+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-14T12:35:01.487+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:35:01.487+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:35:01.493+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: Saved output of task 'attempt_202507141235013599158335705207754_0265_m_000000_0' to file:/tmp/mlflow/24ede259-b14f-4511-a2bd-3d66a7f5e470/stages/0_RandomForestClassifier_e8cbd20e9585/metadata/_temporary/0/task_202507141235013599158335705207754_0265_m_000000
[2025-07-14T12:35:01.493+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SparkHadoopMapRedUtil: attempt_202507141235013599158335705207754_0265_m_000000_0: Committed. Elapsed time: 0 ms.
[2025-07-14T12:35:01.493+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Finished task 0.0 in stage 130.0 (TID 298). 1170 bytes result sent to driver
[2025-07-14T12:35:01.494+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 298) in 10 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:35:01.494+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool
[2025-07-14T12:35:01.494+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: ResultStage 130 (runJob at SparkHadoopWriter.scala:83) finished in 0,016 s
[2025-07-14T12:35:01.494+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:35:01.494+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 130: Stage finished
[2025-07-14T12:35:01.494+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Job 78 finished: runJob at SparkHadoopWriter.scala:83, took 0,016019 s
[2025-07-14T12:35:01.494+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SparkHadoopWriter: Start to commit write Job job_202507141235013599158335705207754_0265.
[2025-07-14T12:35:01.497+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SparkHadoopWriter: Write Job job_202507141235013599158335705207754_0265 committed. Elapsed time: 3 ms.
[2025-07-14T12:35:01.512+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Registering RDD 268 (parquet at treeModels.scala:483) as input to shuffle 42
[2025-07-14T12:35:01.512+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Got map stage job 79 (parquet at treeModels.scala:483) with 4 output partitions
[2025-07-14T12:35:01.512+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Final stage: ShuffleMapStage 131 (parquet at treeModels.scala:483)
[2025-07-14T12:35:01.512+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:35:01.512+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:35:01.512+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Submitting ShuffleMapStage 131 (MapPartitionsRDD[268] at parquet at treeModels.scala:483), which has no missing parents
[2025-07-14T12:35:01.513+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 8.3 KiB, free 418.8 MiB)
[2025-07-14T12:35:01.513+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 418.8 MiB)
[2025-07-14T12:35:01.513+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 138.4.31.89:45589 (size: 4.5 KiB, free: 433.4 MiB)
[2025-07-14T12:35:01.513+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:35:01.513+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 131 (MapPartitionsRDD[268] at parquet at treeModels.scala:483) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-14T12:35:01.513+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSchedulerImpl: Adding task set 131.0 with 4 tasks resource profile 0
[2025-07-14T12:35:01.514+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 299) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 16404 bytes)
[2025-07-14T12:35:01.514+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Starting task 1.0 in stage 131.0 (TID 300) (138.4.31.89, executor driver, partition 1, PROCESS_LOCAL, 17128 bytes)
[2025-07-14T12:35:01.514+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Starting task 2.0 in stage 131.0 (TID 301) (138.4.31.89, executor driver, partition 2, PROCESS_LOCAL, 16404 bytes)
[2025-07-14T12:35:01.514+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Starting task 3.0 in stage 131.0 (TID 302) (138.4.31.89, executor driver, partition 3, PROCESS_LOCAL, 17128 bytes)
[2025-07-14T12:35:01.514+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Running task 0.0 in stage 131.0 (TID 299)
[2025-07-14T12:35:01.514+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Running task 1.0 in stage 131.0 (TID 300)
[2025-07-14T12:35:01.514+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Running task 3.0 in stage 131.0 (TID 302)
[2025-07-14T12:35:01.514+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Running task 2.0 in stage 131.0 (TID 301)
[2025-07-14T12:35:01.518+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Finished task 1.0 in stage 131.0 (TID 300). 1628 bytes result sent to driver
[2025-07-14T12:35:01.518+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Finished task 2.0 in stage 131.0 (TID 301). 1628 bytes result sent to driver
[2025-07-14T12:35:01.518+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Finished task 0.0 in stage 131.0 (TID 299). 1628 bytes result sent to driver
[2025-07-14T12:35:01.519+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Finished task 3.0 in stage 131.0 (TID 302). 1628 bytes result sent to driver
[2025-07-14T12:35:01.519+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Finished task 1.0 in stage 131.0 (TID 300) in 5 ms on 138.4.31.89 (executor driver) (1/4)
[2025-07-14T12:35:01.519+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 138.4.31.89:45589 in memory (size: 36.5 KiB, free: 433.5 MiB)
[2025-07-14T12:35:01.519+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Finished task 3.0 in stage 131.0 (TID 302) in 5 ms on 138.4.31.89 (executor driver) (2/4)
[2025-07-14T12:35:01.519+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Finished task 2.0 in stage 131.0 (TID 301) in 5 ms on 138.4.31.89 (executor driver) (3/4)
[2025-07-14T12:35:01.519+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 299) in 5 ms on 138.4.31.89 (executor driver) (4/4)
[2025-07-14T12:35:01.519+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool
[2025-07-14T12:35:01.519+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: ShuffleMapStage 131 (parquet at treeModels.scala:483) finished in 0,007 s
[2025-07-14T12:35:01.519+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:35:01.519+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: running: Set()
[2025-07-14T12:35:01.519+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:35:01.519+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: failed: Set()
[2025-07-14T12:35:01.519+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 138.4.31.89:45589 in memory (size: 439.7 KiB, free: 433.9 MiB)
[2025-07-14T12:35:01.520+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 138.4.31.89:45589 in memory (size: 36.6 KiB, free: 433.9 MiB)
[2025-07-14T12:35:01.521+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:35:01.521+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:35:01.521+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:35:01.521+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:35:01.522+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:35:01.522+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:35:01.522+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:35:01.527+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SparkContext: Starting job: parquet at treeModels.scala:483
[2025-07-14T12:35:01.527+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Got job 80 (parquet at treeModels.scala:483) with 1 output partitions
[2025-07-14T12:35:01.527+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Final stage: ResultStage 133 (parquet at treeModels.scala:483)
[2025-07-14T12:35:01.527+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 132)
[2025-07-14T12:35:01.528+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:35:01.528+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Submitting ResultStage 133 (MapPartitionsRDD[270] at parquet at treeModels.scala:483), which has no missing parents
[2025-07-14T12:35:01.536+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 239.7 KiB, free 420.2 MiB)
[2025-07-14T12:35:01.537+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 83.9 KiB, free 420.1 MiB)
[2025-07-14T12:35:01.537+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 138.4.31.89:45589 (size: 83.9 KiB, free: 433.8 MiB)
[2025-07-14T12:35:01.537+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:35:01.537+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 133 (MapPartitionsRDD[270] at parquet at treeModels.scala:483) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:35:01.537+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSchedulerImpl: Adding task set 133.0 with 1 tasks resource profile 0
[2025-07-14T12:35:01.537+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 303) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-14T12:35:01.538+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Running task 0.0 in stage 133.0 (TID 303)
[2025-07-14T12:35:01.542+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:35:01.542+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:35:01.543+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:35:01.543+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:35:01.543+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:35:01.543+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:35:01.543+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:35:01.543+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:35:01.543+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO CodecConfig: Compression: SNAPPY
[2025-07-14T12:35:01.543+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO CodecConfig: Compression: SNAPPY
[2025-07-14T12:35:01.544+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-14T12:35:01.544+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-14T12:35:01.544+0200] {subprocess.py:93} INFO - {
[2025-07-14T12:35:01.544+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-14T12:35:01.544+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-14T12:35:01.544+0200] {subprocess.py:93} INFO -     "name" : "treeID",
[2025-07-14T12:35:01.544+0200] {subprocess.py:93} INFO -     "type" : "integer",
[2025-07-14T12:35:01.544+0200] {subprocess.py:93} INFO -     "nullable" : false,
[2025-07-14T12:35:01.544+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-14T12:35:01.544+0200] {subprocess.py:93} INFO -   }, {
[2025-07-14T12:35:01.544+0200] {subprocess.py:93} INFO -     "name" : "metadata",
[2025-07-14T12:35:01.544+0200] {subprocess.py:93} INFO -     "type" : "string",
[2025-07-14T12:35:01.545+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-14T12:35:01.545+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-14T12:35:01.545+0200] {subprocess.py:93} INFO -   }, {
[2025-07-14T12:35:01.545+0200] {subprocess.py:93} INFO -     "name" : "weights",
[2025-07-14T12:35:01.545+0200] {subprocess.py:93} INFO -     "type" : "double",
[2025-07-14T12:35:01.545+0200] {subprocess.py:93} INFO -     "nullable" : false,
[2025-07-14T12:35:01.545+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-14T12:35:01.545+0200] {subprocess.py:93} INFO -   } ]
[2025-07-14T12:35:01.545+0200] {subprocess.py:93} INFO - }
[2025-07-14T12:35:01.545+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-14T12:35:01.545+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-14T12:35:01.545+0200] {subprocess.py:93} INFO -   required int32 treeID;
[2025-07-14T12:35:01.545+0200] {subprocess.py:93} INFO -   optional binary metadata (STRING);
[2025-07-14T12:35:01.545+0200] {subprocess.py:93} INFO -   required double weights;
[2025-07-14T12:35:01.545+0200] {subprocess.py:93} INFO - }
[2025-07-14T12:35:01.545+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:35:01.545+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:35:01.552+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: Saved output of task 'attempt_202507141235011219076293188206283_0133_m_000000_303' to file:/tmp/mlflow/24ede259-b14f-4511-a2bd-3d66a7f5e470/stages/0_RandomForestClassifier_e8cbd20e9585/treesMetadata/_temporary/0/task_202507141235011219076293188206283_0133_m_000000
[2025-07-14T12:35:01.552+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SparkHadoopMapRedUtil: attempt_202507141235011219076293188206283_0133_m_000000_303: Committed. Elapsed time: 0 ms.
[2025-07-14T12:35:01.552+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Finished task 0.0 in stage 133.0 (TID 303). 4740 bytes result sent to driver
[2025-07-14T12:35:01.553+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 303) in 16 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:35:01.553+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool
[2025-07-14T12:35:01.553+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: ResultStage 133 (parquet at treeModels.scala:483) finished in 0,025 s
[2025-07-14T12:35:01.553+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:35:01.553+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 133: Stage finished
[2025-07-14T12:35:01.553+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Job 80 finished: parquet at treeModels.scala:483, took 0,026164 s
[2025-07-14T12:35:01.553+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileFormatWriter: Start to commit write Job 2682f7c7-a644-4acf-bee2-5a179a0a39e4.
[2025-07-14T12:35:01.557+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileFormatWriter: Write Job 2682f7c7-a644-4acf-bee2-5a179a0a39e4 committed. Elapsed time: 3 ms.
[2025-07-14T12:35:01.557+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileFormatWriter: Finished processing stats for write job 2682f7c7-a644-4acf-bee2-5a179a0a39e4.
[2025-07-14T12:35:01.577+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Registering RDD 275 (parquet at treeModels.scala:491) as input to shuffle 43
[2025-07-14T12:35:01.577+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Got map stage job 81 (parquet at treeModels.scala:491) with 4 output partitions
[2025-07-14T12:35:01.577+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Final stage: ShuffleMapStage 134 (parquet at treeModels.scala:491)
[2025-07-14T12:35:01.578+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Parents of final stage: List()
[2025-07-14T12:35:01.578+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:35:01.578+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Submitting ShuffleMapStage 134 (MapPartitionsRDD[275] at parquet at treeModels.scala:491), which has no missing parents
[2025-07-14T12:35:01.578+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 41.5 KiB, free 420.1 MiB)
[2025-07-14T12:35:01.579+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 12.3 KiB, free 420.1 MiB)
[2025-07-14T12:35:01.579+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 138.4.31.89:45589 (size: 12.3 KiB, free: 433.8 MiB)
[2025-07-14T12:35:01.579+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:35:01.579+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 134 (MapPartitionsRDD[275] at parquet at treeModels.scala:491) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-14T12:35:01.579+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSchedulerImpl: Adding task set 134.0 with 4 tasks resource profile 0
[2025-07-14T12:35:01.580+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 304) (138.4.31.89, executor driver, partition 0, PROCESS_LOCAL, 140337 bytes)
[2025-07-14T12:35:01.583+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Starting task 1.0 in stage 134.0 (TID 305) (138.4.31.89, executor driver, partition 1, PROCESS_LOCAL, 386293 bytes)
[2025-07-14T12:35:01.583+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Starting task 2.0 in stage 134.0 (TID 306) (138.4.31.89, executor driver, partition 2, PROCESS_LOCAL, 128364 bytes)
[2025-07-14T12:35:01.584+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Starting task 3.0 in stage 134.0 (TID 307) (138.4.31.89, executor driver, partition 3, PROCESS_LOCAL, 208919 bytes)
[2025-07-14T12:35:01.585+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Running task 0.0 in stage 134.0 (TID 304)
[2025-07-14T12:35:01.585+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Running task 2.0 in stage 134.0 (TID 306)
[2025-07-14T12:35:01.585+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Running task 1.0 in stage 134.0 (TID 305)
[2025-07-14T12:35:01.585+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Running task 3.0 in stage 134.0 (TID 307)
[2025-07-14T12:35:01.590+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Finished task 2.0 in stage 134.0 (TID 306). 1700 bytes result sent to driver
[2025-07-14T12:35:01.590+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Finished task 2.0 in stage 134.0 (TID 306) in 7 ms on 138.4.31.89 (executor driver) (1/4)
[2025-07-14T12:35:01.593+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Finished task 0.0 in stage 134.0 (TID 304). 1700 bytes result sent to driver
[2025-07-14T12:35:01.593+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 304) in 13 ms on 138.4.31.89 (executor driver) (2/4)
[2025-07-14T12:35:01.594+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Finished task 3.0 in stage 134.0 (TID 307). 1700 bytes result sent to driver
[2025-07-14T12:35:01.594+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Finished task 3.0 in stage 134.0 (TID 307) in 11 ms on 138.4.31.89 (executor driver) (3/4)
[2025-07-14T12:35:01.601+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Finished task 1.0 in stage 134.0 (TID 305). 1786 bytes result sent to driver
[2025-07-14T12:35:01.601+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 138.4.31.89:45589 in memory (size: 83.9 KiB, free: 433.9 MiB)
[2025-07-14T12:35:01.601+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Finished task 1.0 in stage 134.0 (TID 305) in 21 ms on 138.4.31.89 (executor driver) (4/4)
[2025-07-14T12:35:01.601+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool
[2025-07-14T12:35:01.601+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: ShuffleMapStage 134 (parquet at treeModels.scala:491) finished in 0,023 s
[2025-07-14T12:35:01.601+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: looking for newly runnable stages
[2025-07-14T12:35:01.601+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: running: Set()
[2025-07-14T12:35:01.601+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: waiting: Set()
[2025-07-14T12:35:01.601+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: failed: Set()
[2025-07-14T12:35:01.601+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 138.4.31.89:45589 in memory (size: 4.5 KiB, free: 433.9 MiB)
[2025-07-14T12:35:01.604+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:35:01.604+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:35:01.604+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:35:01.604+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:35:01.604+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:35:01.604+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:35:01.604+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:35:01.610+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SparkContext: Starting job: parquet at treeModels.scala:491
[2025-07-14T12:35:01.610+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Got job 82 (parquet at treeModels.scala:491) with 1 output partitions
[2025-07-14T12:35:01.610+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Final stage: ResultStage 136 (parquet at treeModels.scala:491)
[2025-07-14T12:35:01.610+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 135)
[2025-07-14T12:35:01.610+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Missing parents: List()
[2025-07-14T12:35:01.610+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Submitting ResultStage 136 (MapPartitionsRDD[277] at parquet at treeModels.scala:491), which has no missing parents
[2025-07-14T12:35:01.618+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 241.4 KiB, free 420.2 MiB)
[2025-07-14T12:35:01.619+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 84.8 KiB, free 420.1 MiB)
[2025-07-14T12:35:01.619+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 138.4.31.89:45589 (size: 84.8 KiB, free: 433.8 MiB)
[2025-07-14T12:35:01.619+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1585
[2025-07-14T12:35:01.619+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 136 (MapPartitionsRDD[277] at parquet at treeModels.scala:491) (first 15 tasks are for partitions Vector(0))
[2025-07-14T12:35:01.619+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSchedulerImpl: Adding task set 136.0 with 1 tasks resource profile 0
[2025-07-14T12:35:01.620+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 308) (138.4.31.89, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-14T12:35:01.620+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Running task 0.0 in stage 136.0 (TID 308)
[2025-07-14T12:35:01.626+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO ShuffleBlockFetcherIterator: Getting 4 (176.9 KiB) non-empty blocks including 4 (176.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-14T12:35:01.626+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-14T12:35:01.627+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:35:01.627+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:35:01.627+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:35:01.627+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-14T12:35:01.627+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-14T12:35:01.627+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-14T12:35:01.627+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO CodecConfig: Compression: SNAPPY
[2025-07-14T12:35:01.627+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO CodecConfig: Compression: SNAPPY
[2025-07-14T12:35:01.627+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-14T12:35:01.628+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-14T12:35:01.628+0200] {subprocess.py:93} INFO - {
[2025-07-14T12:35:01.628+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-14T12:35:01.628+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-14T12:35:01.628+0200] {subprocess.py:93} INFO -     "name" : "treeID",
[2025-07-14T12:35:01.628+0200] {subprocess.py:93} INFO -     "type" : "integer",
[2025-07-14T12:35:01.628+0200] {subprocess.py:93} INFO -     "nullable" : false,
[2025-07-14T12:35:01.628+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-14T12:35:01.628+0200] {subprocess.py:93} INFO -   }, {
[2025-07-14T12:35:01.628+0200] {subprocess.py:93} INFO -     "name" : "nodeData",
[2025-07-14T12:35:01.628+0200] {subprocess.py:93} INFO -     "type" : {
[2025-07-14T12:35:01.628+0200] {subprocess.py:93} INFO -       "type" : "struct",
[2025-07-14T12:35:01.628+0200] {subprocess.py:93} INFO -       "fields" : [ {
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "name" : "id",
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "type" : "integer",
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -       }, {
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "name" : "prediction",
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "type" : "double",
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -       }, {
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "name" : "impurity",
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "type" : "double",
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -       }, {
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "name" : "impurityStats",
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "type" : {
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -           "type" : "array",
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -           "elementType" : "double",
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -           "containsNull" : false
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         },
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "nullable" : true,
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -       }, {
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "name" : "rawCount",
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "type" : "long",
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -       }, {
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "name" : "gain",
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "type" : "double",
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -       }, {
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "name" : "leftChild",
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "type" : "integer",
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -       }, {
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "name" : "rightChild",
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "type" : "integer",
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -       }, {
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "name" : "split",
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -         "type" : {
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -           "type" : "struct",
[2025-07-14T12:35:01.629+0200] {subprocess.py:93} INFO -           "fields" : [ {
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -             "name" : "featureIndex",
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -             "type" : "integer",
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -             "nullable" : false,
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -             "metadata" : { }
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -           }, {
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -             "name" : "leftCategoriesOrThreshold",
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -             "type" : {
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -               "type" : "array",
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -               "elementType" : "double",
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -               "containsNull" : false
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -             },
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -             "nullable" : true,
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -             "metadata" : { }
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -           }, {
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -             "name" : "numCategories",
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -             "type" : "integer",
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -             "nullable" : false,
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -             "metadata" : { }
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -           } ]
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -         },
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -         "nullable" : true,
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -       } ]
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -     },
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -   } ]
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO - }
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -   required int32 treeID;
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -   optional group nodeData {
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -     required int32 id;
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -     required double prediction;
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -     required double impurity;
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -     optional group impurityStats (LIST) {
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -       repeated group list {
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -         required double element;
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -       }
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -     }
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -     required int64 rawCount;
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -     required double gain;
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -     required int32 leftChild;
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -     required int32 rightChild;
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -     optional group split {
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -       required int32 featureIndex;
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -       optional group leftCategoriesOrThreshold (LIST) {
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -         repeated group list {
[2025-07-14T12:35:01.630+0200] {subprocess.py:93} INFO -           required double element;
[2025-07-14T12:35:01.631+0200] {subprocess.py:93} INFO -         }
[2025-07-14T12:35:01.631+0200] {subprocess.py:93} INFO -       }
[2025-07-14T12:35:01.631+0200] {subprocess.py:93} INFO -       required int32 numCategories;
[2025-07-14T12:35:01.631+0200] {subprocess.py:93} INFO -     }
[2025-07-14T12:35:01.631+0200] {subprocess.py:93} INFO -   }
[2025-07-14T12:35:01.631+0200] {subprocess.py:93} INFO - }
[2025-07-14T12:35:01.631+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:35:01.631+0200] {subprocess.py:93} INFO - 
[2025-07-14T12:35:01.649+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileOutputCommitter: Saved output of task 'attempt_202507141235012086271530681430124_0136_m_000000_308' to file:/tmp/mlflow/24ede259-b14f-4511-a2bd-3d66a7f5e470/stages/0_RandomForestClassifier_e8cbd20e9585/data/_temporary/0/task_202507141235012086271530681430124_0136_m_000000
[2025-07-14T12:35:01.649+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO SparkHadoopMapRedUtil: attempt_202507141235012086271530681430124_0136_m_000000_308: Committed. Elapsed time: 0 ms.
[2025-07-14T12:35:01.650+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Executor: Finished task 0.0 in stage 136.0 (TID 308). 4740 bytes result sent to driver
[2025-07-14T12:35:01.650+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 308) in 30 ms on 138.4.31.89 (executor driver) (1/1)
[2025-07-14T12:35:01.650+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool
[2025-07-14T12:35:01.650+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: ResultStage 136 (parquet at treeModels.scala:491) finished in 0,039 s
[2025-07-14T12:35:01.650+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-14T12:35:01.650+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 136: Stage finished
[2025-07-14T12:35:01.650+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO DAGScheduler: Job 82 finished: parquet at treeModels.scala:491, took 0,040356 s
[2025-07-14T12:35:01.650+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileFormatWriter: Start to commit write Job 442308b7-597f-4ad4-b254-a2d5a5b2e1ab.
[2025-07-14T12:35:01.654+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileFormatWriter: Write Job 442308b7-597f-4ad4-b254-a2d5a5b2e1ab committed. Elapsed time: 3 ms.
[2025-07-14T12:35:01.654+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO FileFormatWriter: Finished processing stats for write job 442308b7-597f-4ad4-b254-a2d5a5b2e1ab.
[2025-07-14T12:35:01.654+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Instrumentation: [9c20ec8e] training finished
[2025-07-14T12:35:01.654+0200] {subprocess.py:93} INFO - 25/07/14 12:35:01 INFO Instrumentation: [1491e7be] training finished
[2025-07-14T12:35:14.822+0200] {subprocess.py:93} INFO - 2025/07/14 12:35:14 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpgb9ge6id/model, flavor: spark). Fall back to return ['pyspark==3.5.3']. Set logging level to DEBUG to see the full traceback.
[2025-07-14T12:35:14.829+0200] {subprocess.py:93} INFO - [31m2025/07/14 12:35:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
[2025-07-14T12:35:14.901+0200] {subprocess.py:93} INFO - MLflow: Model and metrics logged successfully.
[2025-07-14T12:35:14.910+0200] {subprocess.py:93} INFO - 25/07/14 12:35:14 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2025-07-14T12:35:14.920+0200] {subprocess.py:93} INFO - 25/07/14 12:35:14 INFO SparkUI: Stopped Spark web UI at http://138.4.31.89:4041
[2025-07-14T12:35:14.930+0200] {subprocess.py:93} INFO - 25/07/14 12:35:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-07-14T12:35:14.941+0200] {subprocess.py:93} INFO - 25/07/14 12:35:14 INFO MemoryStore: MemoryStore cleared
[2025-07-14T12:35:14.941+0200] {subprocess.py:93} INFO - 25/07/14 12:35:14 INFO BlockManager: BlockManager stopped
[2025-07-14T12:35:14.943+0200] {subprocess.py:93} INFO - 25/07/14 12:35:14 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-07-14T12:35:14.944+0200] {subprocess.py:93} INFO - 25/07/14 12:35:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-07-14T12:35:14.950+0200] {subprocess.py:93} INFO - 25/07/14 12:35:14 INFO SparkContext: Successfully stopped SparkContext
[2025-07-14T12:35:15.564+0200] {subprocess.py:93} INFO - 25/07/14 12:35:15 INFO ShutdownHookManager: Shutdown hook called
[2025-07-14T12:35:15.564+0200] {subprocess.py:93} INFO - 25/07/14 12:35:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-6130e07c-ad77-4b4f-85be-0e2b5379cef9
[2025-07-14T12:35:15.567+0200] {subprocess.py:93} INFO - 25/07/14 12:35:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b/pyspark-999bbedb-d685-4360-8eae-30064efbffec
[2025-07-14T12:35:15.570+0200] {subprocess.py:93} INFO - 25/07/14 12:35:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-a9ebc13a-000a-4fa3-8f4b-849a9b31077b
[2025-07-14T12:35:15.580+0200] {subprocess.py:93} INFO - 25/07/14 12:35:15 INFO CassandraConnector: Disconnected from Cassandra cluster.
[2025-07-14T12:35:15.580+0200] {subprocess.py:93} INFO - 25/07/14 12:35:15 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
[2025-07-14T12:35:15.670+0200] {subprocess.py:97} INFO - Command exited with return code 0
[2025-07-14T12:35:15.713+0200] {taskinstance.py:1318} INFO - Marking task as SUCCESS. dag_id=agile_data_science_batch_prediction_model_training, task_id=pyspark_train_classifier_model, execution_date=20250714T103351, start_date=20250714T103354, end_date=20250714T103515
[2025-07-14T12:35:15.751+0200] {local_task_job.py:208} INFO - Task exited with return code 0
[2025-07-14T12:35:15.773+0200] {taskinstance.py:2578} INFO - 0 downstream tasks scheduled from follow-on schedule check
