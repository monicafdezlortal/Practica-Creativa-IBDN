[2025-06-17T13:24:02.747+0200] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: agile_data_science_batch_prediction_model_training.pyspark_train_classifier_model manual__2025-06-17T11:15:25.088137+00:00 [queued]>
[2025-06-17T13:24:02.769+0200] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: agile_data_science_batch_prediction_model_training.pyspark_train_classifier_model manual__2025-06-17T11:15:25.088137+00:00 [queued]>
[2025-06-17T13:24:02.769+0200] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2025-06-17T13:24:02.769+0200] {taskinstance.py:1280} INFO - Starting attempt 2 of 4
[2025-06-17T13:24:02.770+0200] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2025-06-17T13:24:02.798+0200] {taskinstance.py:1300} INFO - Executing <Task(BashOperator): pyspark_train_classifier_model> on 2025-06-17 11:15:25.088137+00:00
[2025-06-17T13:24:02.801+0200] {standard_task_runner.py:55} INFO - Started process 94423 to run task
[2025-06-17T13:24:02.807+0200] {standard_task_runner.py:82} INFO - Running: ['airflow', 'tasks', 'run', 'agile_data_science_batch_prediction_model_training', 'pyspark_train_classifier_model', 'manual__2025-06-17T11:15:25.088137+00:00', '--job-id', '35', '--raw', '--subdir', 'DAGS_FOLDER/setup.py', '--cfg-path', '/tmp/tmpgmx402i0']
[2025-06-17T13:24:02.808+0200] {standard_task_runner.py:83} INFO - Job 35: Subtask pyspark_train_classifier_model
[2025-06-17T13:24:02.901+0200] {task_command.py:388} INFO - Running <TaskInstance: agile_data_science_batch_prediction_model_training.pyspark_train_classifier_model manual__2025-06-17T11:15:25.088137+00:00 [running]> on host l019.lab.dit.upm.es
[2025-06-17T13:24:02.998+0200] {taskinstance.py:1507} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=agile_data_science_batch_prediction_model_training
AIRFLOW_CTX_TASK_ID=pyspark_train_classifier_model
AIRFLOW_CTX_EXECUTION_DATE=2025-06-17T11:15:25.088137+00:00
AIRFLOW_CTX_TRY_NUMBER=2
AIRFLOW_CTX_DAG_RUN_ID=manual__2025-06-17T11:15:25.088137+00:00
[2025-06-17T13:24:02.999+0200] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-06-17T13:24:02.999+0200] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', '\nspark-submit --master local[4]   /home/monica.fernandez/practica_creativa/resources/train_spark_mllib_model.py   /home/monica.fernandez/practica_creativa']
[2025-06-17T13:24:03.017+0200] {subprocess.py:86} INFO - Output:
[2025-06-17T13:24:06.850+0200] {subprocess.py:93} INFO - 25/06/17 13:24:06 WARN Utils: Your hostname, l019 resolves to a loopback address: 127.0.1.1; using 138.4.31.19 instead (on interface enp1s0)
[2025-06-17T13:24:06.853+0200] {subprocess.py:93} INFO - 25/06/17 13:24:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
[2025-06-17T13:24:14.109+0200] {subprocess.py:93} INFO - 25/06/17 13:24:14 INFO SparkContext: Running Spark version 3.5.3
[2025-06-17T13:24:14.110+0200] {subprocess.py:93} INFO - 25/06/17 13:24:14 INFO SparkContext: OS info Linux, 6.1.0-32-amd64, amd64
[2025-06-17T13:24:14.111+0200] {subprocess.py:93} INFO - 25/06/17 13:24:14 INFO SparkContext: Java version 17.0.14
[2025-06-17T13:24:14.425+0200] {subprocess.py:93} INFO - 25/06/17 13:24:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-06-17T13:24:14.706+0200] {subprocess.py:93} INFO - 25/06/17 13:24:14 INFO ResourceUtils: ==============================================================
[2025-06-17T13:24:14.707+0200] {subprocess.py:93} INFO - 25/06/17 13:24:14 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-06-17T13:24:14.708+0200] {subprocess.py:93} INFO - 25/06/17 13:24:14 INFO ResourceUtils: ==============================================================
[2025-06-17T13:24:14.709+0200] {subprocess.py:93} INFO - 25/06/17 13:24:14 INFO SparkContext: Submitted application: train_spark_mllib_model.py
[2025-06-17T13:24:14.768+0200] {subprocess.py:93} INFO - 25/06/17 13:24:14 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-06-17T13:24:14.777+0200] {subprocess.py:93} INFO - 25/06/17 13:24:14 INFO ResourceProfile: Limiting resource is cpu
[2025-06-17T13:24:14.782+0200] {subprocess.py:93} INFO - 25/06/17 13:24:14 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-06-17T13:24:14.952+0200] {subprocess.py:93} INFO - 25/06/17 13:24:14 INFO SecurityManager: Changing view acls to: monica.fernandez
[2025-06-17T13:24:14.954+0200] {subprocess.py:93} INFO - 25/06/17 13:24:14 INFO SecurityManager: Changing modify acls to: monica.fernandez
[2025-06-17T13:24:14.955+0200] {subprocess.py:93} INFO - 25/06/17 13:24:14 INFO SecurityManager: Changing view acls groups to:
[2025-06-17T13:24:14.956+0200] {subprocess.py:93} INFO - 25/06/17 13:24:14 INFO SecurityManager: Changing modify acls groups to:
[2025-06-17T13:24:14.957+0200] {subprocess.py:93} INFO - 25/06/17 13:24:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: monica.fernandez; groups with view permissions: EMPTY; users with modify permissions: monica.fernandez; groups with modify permissions: EMPTY
[2025-06-17T13:24:15.545+0200] {subprocess.py:93} INFO - 25/06/17 13:24:15 INFO Utils: Successfully started service 'sparkDriver' on port 45837.
[2025-06-17T13:24:15.592+0200] {subprocess.py:93} INFO - 25/06/17 13:24:15 INFO SparkEnv: Registering MapOutputTracker
[2025-06-17T13:24:15.667+0200] {subprocess.py:93} INFO - 25/06/17 13:24:15 INFO SparkEnv: Registering BlockManagerMaster
[2025-06-17T13:24:15.708+0200] {subprocess.py:93} INFO - 25/06/17 13:24:15 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-06-17T13:24:15.709+0200] {subprocess.py:93} INFO - 25/06/17 13:24:15 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-06-17T13:24:15.713+0200] {subprocess.py:93} INFO - 25/06/17 13:24:15 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-06-17T13:24:15.761+0200] {subprocess.py:93} INFO - 25/06/17 13:24:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d13548b3-80d1-46fc-92c8-1cecd0d4b413
[2025-06-17T13:24:15.788+0200] {subprocess.py:93} INFO - 25/06/17 13:24:15 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-06-17T13:24:15.834+0200] {subprocess.py:93} INFO - 25/06/17 13:24:15 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-06-17T13:24:16.190+0200] {subprocess.py:93} INFO - 25/06/17 13:24:16 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-06-17T13:24:16.410+0200] {subprocess.py:93} INFO - 25/06/17 13:24:16 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[2025-06-17T13:24:16.431+0200] {subprocess.py:93} INFO - 25/06/17 13:24:16 INFO Utils: Successfully started service 'SparkUI' on port 4041.
[2025-06-17T13:24:16.803+0200] {subprocess.py:93} INFO - 25/06/17 13:24:16 INFO Executor: Starting executor ID driver on host 138.4.31.19
[2025-06-17T13:24:16.804+0200] {subprocess.py:93} INFO - 25/06/17 13:24:16 INFO Executor: OS info Linux, 6.1.0-32-amd64, amd64
[2025-06-17T13:24:16.805+0200] {subprocess.py:93} INFO - 25/06/17 13:24:16 INFO Executor: Java version 17.0.14
[2025-06-17T13:24:16.849+0200] {subprocess.py:93} INFO - 25/06/17 13:24:16 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-06-17T13:24:16.852+0200] {subprocess.py:93} INFO - 25/06/17 13:24:16 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5de43805 for default.
[2025-06-17T13:24:16.944+0200] {subprocess.py:93} INFO - 25/06/17 13:24:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45769.
[2025-06-17T13:24:16.944+0200] {subprocess.py:93} INFO - 25/06/17 13:24:16 INFO NettyBlockTransferService: Server created on 138.4.31.19:45769
[2025-06-17T13:24:16.946+0200] {subprocess.py:93} INFO - 25/06/17 13:24:16 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-06-17T13:24:16.952+0200] {subprocess.py:93} INFO - 25/06/17 13:24:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 138.4.31.19, 45769, None)
[2025-06-17T13:24:16.959+0200] {subprocess.py:93} INFO - 25/06/17 13:24:16 INFO BlockManagerMasterEndpoint: Registering block manager 138.4.31.19:45769 with 434.4 MiB RAM, BlockManagerId(driver, 138.4.31.19, 45769, None)
[2025-06-17T13:24:16.962+0200] {subprocess.py:93} INFO - 25/06/17 13:24:16 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 138.4.31.19, 45769, None)
[2025-06-17T13:24:16.962+0200] {subprocess.py:93} INFO - 25/06/17 13:24:16 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 138.4.31.19, 45769, None)
[2025-06-17T13:24:18.600+0200] {subprocess.py:93} INFO - 25/06/17 13:24:18 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-06-17T13:24:18.625+0200] {subprocess.py:93} INFO - 25/06/17 13:24:18 INFO SharedState: Warehouse path is 'file:/tmp/airflowtmp746nbpjo/spark-warehouse'.
[2025-06-17T13:24:24.693+0200] {subprocess.py:93} INFO - MLflow Run ID: 9a00fe6819304b758f9e133afc7993c7, Experiment ID: 747474864229885894
[2025-06-17T13:24:24.693+0200] {subprocess.py:93} INFO - MLflow Tracking URI: file:///home/monica.fernandez/practica_creativa/mlruns
[2025-06-17T13:24:25.453+0200] {subprocess.py:93} INFO - 25/06/17 13:24:25 INFO InMemoryFileIndex: It took 160 ms to list leaf files for 1 paths.
[2025-06-17T13:24:29.385+0200] {subprocess.py:93} INFO - 25/06/17 13:24:29 INFO FileSourceStrategy: Pushed Filters:
[2025-06-17T13:24:29.388+0200] {subprocess.py:93} INFO - 25/06/17 13:24:29 INFO FileSourceStrategy: Post-Scan Filters:
[2025-06-17T13:24:30.132+0200] {subprocess.py:93} INFO - 25/06/17 13:24:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 199.2 KiB, free 434.2 MiB)
[2025-06-17T13:24:30.434+0200] {subprocess.py:93} INFO - 25/06/17 13:24:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 434.2 MiB)
[2025-06-17T13:24:30.445+0200] {subprocess.py:93} INFO - 25/06/17 13:24:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 138.4.31.19:45769 (size: 34.3 KiB, free: 434.4 MiB)
[2025-06-17T13:24:30.448+0200] {subprocess.py:93} INFO - 25/06/17 13:24:30 INFO SparkContext: Created broadcast 0 from first at /home/monica.fernandez/practica_creativa/resources/train_spark_mllib_model.py:55
[2025-06-17T13:24:30.614+0200] {subprocess.py:93} INFO - 25/06/17 13:24:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-06-17T13:24:31.035+0200] {subprocess.py:93} INFO - 25/06/17 13:24:31 INFO SparkContext: Starting job: first at /home/monica.fernandez/practica_creativa/resources/train_spark_mllib_model.py:55
[2025-06-17T13:24:31.109+0200] {subprocess.py:93} INFO - 25/06/17 13:24:31 INFO DAGScheduler: Got job 0 (first at /home/monica.fernandez/practica_creativa/resources/train_spark_mllib_model.py:55) with 1 output partitions
[2025-06-17T13:24:31.110+0200] {subprocess.py:93} INFO - 25/06/17 13:24:31 INFO DAGScheduler: Final stage: ResultStage 0 (first at /home/monica.fernandez/practica_creativa/resources/train_spark_mllib_model.py:55)
[2025-06-17T13:24:31.111+0200] {subprocess.py:93} INFO - 25/06/17 13:24:31 INFO DAGScheduler: Parents of final stage: List()
[2025-06-17T13:24:31.112+0200] {subprocess.py:93} INFO - 25/06/17 13:24:31 INFO DAGScheduler: Missing parents: List()
[2025-06-17T13:24:31.116+0200] {subprocess.py:93} INFO - 25/06/17 13:24:31 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at first at /home/monica.fernandez/practica_creativa/resources/train_spark_mllib_model.py:55), which has no missing parents
[2025-06-17T13:24:31.438+0200] {subprocess.py:93} INFO - 25/06/17 13:24:31 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 434.2 MiB)
[2025-06-17T13:24:31.469+0200] {subprocess.py:93} INFO - 25/06/17 13:24:31 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.2 MiB)
[2025-06-17T13:24:31.472+0200] {subprocess.py:93} INFO - 25/06/17 13:24:31 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 138.4.31.19:45769 (size: 6.3 KiB, free: 434.4 MiB)
[2025-06-17T13:24:31.472+0200] {subprocess.py:93} INFO - 25/06/17 13:24:31 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
[2025-06-17T13:24:31.517+0200] {subprocess.py:93} INFO - 25/06/17 13:24:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at first at /home/monica.fernandez/practica_creativa/resources/train_spark_mllib_model.py:55) (first 15 tasks are for partitions Vector(0))
[2025-06-17T13:24:31.528+0200] {subprocess.py:93} INFO - 25/06/17 13:24:31 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-06-17T13:24:31.674+0200] {subprocess.py:93} INFO - 25/06/17 13:24:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (138.4.31.19, executor driver, partition 0, PROCESS_LOCAL, 9653 bytes)
[2025-06-17T13:24:31.714+0200] {subprocess.py:93} INFO - 25/06/17 13:24:31 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2025-06-17T13:24:32.101+0200] {subprocess.py:93} INFO - 25/06/17 13:24:32 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-06-17T13:24:32.997+0200] {subprocess.py:93} INFO - 25/06/17 13:24:32 INFO CodeGenerator: Code generated in 677.260409 ms
[2025-06-17T13:24:33.169+0200] {subprocess.py:93} INFO - 25/06/17 13:24:33 INFO CodecPool: Got brand-new decompressor [.bz2]
[2025-06-17T13:24:33.442+0200] {subprocess.py:93} INFO - 25/06/17 13:24:33 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1614 bytes result sent to driver
[2025-06-17T13:24:33.467+0200] {subprocess.py:93} INFO - 25/06/17 13:24:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1837 ms on 138.4.31.19 (executor driver) (1/1)
[2025-06-17T13:24:33.467+0200] {subprocess.py:93} INFO - 25/06/17 13:24:33 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-06-17T13:24:33.484+0200] {subprocess.py:93} INFO - 25/06/17 13:24:33 INFO DAGScheduler: ResultStage 0 (first at /home/monica.fernandez/practica_creativa/resources/train_spark_mllib_model.py:55) finished in 2,327 s
[2025-06-17T13:24:33.501+0200] {subprocess.py:93} INFO - 25/06/17 13:24:33 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-06-17T13:24:33.503+0200] {subprocess.py:93} INFO - 25/06/17 13:24:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2025-06-17T13:24:33.510+0200] {subprocess.py:93} INFO - 25/06/17 13:24:33 INFO DAGScheduler: Job 0 finished: first at /home/monica.fernandez/practica_creativa/resources/train_spark_mllib_model.py:55, took 2,466209 s
[2025-06-17T13:24:33.845+0200] {subprocess.py:93} INFO - 25/06/17 13:24:33 INFO FileSourceStrategy: Pushed Filters: IsNull(ArrDelay)
[2025-06-17T13:24:33.845+0200] {subprocess.py:93} INFO - 25/06/17 13:24:33 INFO FileSourceStrategy: Post-Scan Filters: isnull(ArrDelay#0)
[2025-06-17T13:24:34.151+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO CodeGenerator: Code generated in 67.869232 ms
[2025-06-17T13:24:34.176+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 199.2 KiB, free 434.0 MiB)
[2025-06-17T13:24:34.222+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.9 MiB)
[2025-06-17T13:24:34.223+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 138.4.31.19:45769 (size: 34.3 KiB, free: 434.3 MiB)
[2025-06-17T13:24:34.224+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO SparkContext: Created broadcast 2 from count at NativeMethodAccessorImpl.java:0
[2025-06-17T13:24:34.236+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-06-17T13:24:34.363+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO DAGScheduler: Registering RDD 6 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2025-06-17T13:24:34.367+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-06-17T13:24:34.368+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
[2025-06-17T13:24:34.369+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO DAGScheduler: Parents of final stage: List()
[2025-06-17T13:24:34.371+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO DAGScheduler: Missing parents: List()
[2025-06-17T13:24:34.373+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-06-17T13:24:34.541+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 17.8 KiB, free 433.9 MiB)
[2025-06-17T13:24:34.587+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.9 MiB)
[2025-06-17T13:24:34.588+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 138.4.31.19:45769 (size: 8.6 KiB, free: 434.3 MiB)
[2025-06-17T13:24:34.589+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
[2025-06-17T13:24:34.602+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-06-17T13:24:34.603+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks resource profile 0
[2025-06-17T13:24:34.619+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (138.4.31.19, executor driver, partition 0, PROCESS_LOCAL, 9642 bytes)
[2025-06-17T13:24:34.627+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (138.4.31.19, executor driver, partition 1, PROCESS_LOCAL, 9642 bytes)
[2025-06-17T13:24:34.627+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
[2025-06-17T13:24:34.664+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
[2025-06-17T13:24:34.848+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO CodeGenerator: Code generated in 116.908763 ms
[2025-06-17T13:24:34.884+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-06-17T13:24:34.885+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-06-17T13:24:34.922+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO CodeGenerator: Code generated in 29.602517 ms
[2025-06-17T13:24:34.943+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO CodeGenerator: Code generated in 17.343045 ms
[2025-06-17T13:24:34.966+0200] {subprocess.py:93} INFO - 25/06/17 13:24:34 INFO CodecPool: Got brand-new decompressor [.bz2]
[2025-06-17T13:24:37.113+0200] {subprocess.py:93} INFO - 25/06/17 13:24:37 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 138.4.31.19:45769 in memory (size: 6.3 KiB, free: 434.3 MiB)
[2025-06-17T13:24:37.424+0200] {subprocess.py:93} INFO - 25/06/17 13:24:37 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2026 bytes result sent to driver
[2025-06-17T13:24:37.449+0200] {subprocess.py:93} INFO - 25/06/17 13:24:37 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 2819 ms on 138.4.31.19 (executor driver) (1/2)
[2025-06-17T13:24:44.157+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2026 bytes result sent to driver
[2025-06-17T13:24:44.164+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 9546 ms on 138.4.31.19 (executor driver) (2/2)
[2025-06-17T13:24:44.165+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2025-06-17T13:24:44.172+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 9,767 s
[2025-06-17T13:24:44.173+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO DAGScheduler: looking for newly runnable stages
[2025-06-17T13:24:44.173+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO DAGScheduler: running: Set()
[2025-06-17T13:24:44.173+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO DAGScheduler: waiting: Set()
[2025-06-17T13:24:44.173+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO DAGScheduler: failed: Set()
[2025-06-17T13:24:44.257+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO CodeGenerator: Code generated in 12.34992 ms
[2025-06-17T13:24:44.308+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-06-17T13:24:44.314+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO DAGScheduler: Got job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-06-17T13:24:44.314+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO DAGScheduler: Final stage: ResultStage 3 (count at NativeMethodAccessorImpl.java:0)
[2025-06-17T13:24:44.314+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
[2025-06-17T13:24:44.314+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO DAGScheduler: Missing parents: List()
[2025-06-17T13:24:44.315+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[9] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-06-17T13:24:44.322+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)
[2025-06-17T13:24:44.343+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.9 MiB)
[2025-06-17T13:24:44.343+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 138.4.31.19:45769 (size: 5.9 KiB, free: 434.3 MiB)
[2025-06-17T13:24:44.344+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
[2025-06-17T13:24:44.349+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-06-17T13:24:44.353+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2025-06-17T13:24:44.358+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (138.4.31.19, executor driver, partition 0, NODE_LOCAL, 8999 bytes)
[2025-06-17T13:24:44.361+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
[2025-06-17T13:24:44.472+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-06-17T13:24:44.476+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 21 ms
[2025-06-17T13:24:44.511+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO CodeGenerator: Code generated in 29.978345 ms
[2025-06-17T13:24:44.545+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 3988 bytes result sent to driver
[2025-06-17T13:24:44.572+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 215 ms on 138.4.31.19 (executor driver) (1/1)
[2025-06-17T13:24:44.575+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO DAGScheduler: ResultStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0,253 s
[2025-06-17T13:24:44.575+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-06-17T13:24:44.575+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-06-17T13:24:44.576+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
[2025-06-17T13:24:44.577+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO DAGScheduler: Job 2 finished: count at NativeMethodAccessorImpl.java:0, took 0,273963 s
[2025-06-17T13:24:44.672+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO FileSourceStrategy: Pushed Filters: IsNull(CRSArrTime)
[2025-06-17T13:24:44.672+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO FileSourceStrategy: Post-Scan Filters: isnull(CRSArrTime#1)
[2025-06-17T13:24:44.783+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO CodeGenerator: Code generated in 49.213339 ms
[2025-06-17T13:24:44.786+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)
[2025-06-17T13:24:44.798+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 138.4.31.19:45769 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-06-17T13:24:44.841+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.7 MiB)
[2025-06-17T13:24:44.842+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 138.4.31.19:45769 (size: 34.3 KiB, free: 434.3 MiB)
[2025-06-17T13:24:44.842+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO SparkContext: Created broadcast 5 from count at NativeMethodAccessorImpl.java:0
[2025-06-17T13:24:44.844+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-06-17T13:24:44.855+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2025-06-17T13:24:44.856+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-06-17T13:24:44.858+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)
[2025-06-17T13:24:44.858+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO DAGScheduler: Parents of final stage: List()
[2025-06-17T13:24:44.858+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO DAGScheduler: Missing parents: List()
[2025-06-17T13:24:44.858+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-06-17T13:24:44.860+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 138.4.31.19:45769 in memory (size: 8.6 KiB, free: 434.3 MiB)
[2025-06-17T13:24:44.862+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 17.8 KiB, free 433.7 MiB)
[2025-06-17T13:24:44.864+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 433.7 MiB)
[2025-06-17T13:24:44.865+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 138.4.31.19:45769 (size: 8.7 KiB, free: 434.3 MiB)
[2025-06-17T13:24:44.866+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585
[2025-06-17T13:24:44.867+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-06-17T13:24:44.870+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks resource profile 0
[2025-06-17T13:24:44.873+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (138.4.31.19, executor driver, partition 0, PROCESS_LOCAL, 9642 bytes)
[2025-06-17T13:24:44.873+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 5) (138.4.31.19, executor driver, partition 1, PROCESS_LOCAL, 9642 bytes)
[2025-06-17T13:24:44.873+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO Executor: Running task 1.0 in stage 4.0 (TID 5)
[2025-06-17T13:24:44.873+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
[2025-06-17T13:24:44.913+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 138.4.31.19:45769 in memory (size: 34.3 KiB, free: 434.3 MiB)
[2025-06-17T13:24:44.947+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO CodeGenerator: Code generated in 61.964875 ms
[2025-06-17T13:24:44.949+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-06-17T13:24:44.959+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO CodeGenerator: Code generated in 7.929304 ms
[2025-06-17T13:24:44.969+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-06-17T13:24:45.001+0200] {subprocess.py:93} INFO - 25/06/17 13:24:44 INFO CodeGenerator: Code generated in 24.481978 ms
[2025-06-17T13:24:47.482+0200] {subprocess.py:93} INFO - 25/06/17 13:24:47 INFO Executor: Finished task 1.0 in stage 4.0 (TID 5). 1983 bytes result sent to driver
[2025-06-17T13:24:47.482+0200] {subprocess.py:93} INFO - 25/06/17 13:24:47 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 5) in 2603 ms on 138.4.31.19 (executor driver) (1/2)
[2025-06-17T13:24:55.948+0200] {subprocess.py:93} INFO - 25/06/17 13:24:55 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1983 bytes result sent to driver
[2025-06-17T13:24:55.953+0200] {subprocess.py:93} INFO - 25/06/17 13:24:55 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 11078 ms on 138.4.31.19 (executor driver) (2/2)
[2025-06-17T13:24:55.954+0200] {subprocess.py:93} INFO - 25/06/17 13:24:55 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2025-06-17T13:24:55.957+0200] {subprocess.py:93} INFO - 25/06/17 13:24:55 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 11,102 s
[2025-06-17T13:24:55.957+0200] {subprocess.py:93} INFO - 25/06/17 13:24:55 INFO DAGScheduler: looking for newly runnable stages
[2025-06-17T13:24:55.957+0200] {subprocess.py:93} INFO - 25/06/17 13:24:55 INFO DAGScheduler: running: Set()
[2025-06-17T13:24:55.957+0200] {subprocess.py:93} INFO - 25/06/17 13:24:55 INFO DAGScheduler: waiting: Set()
[2025-06-17T13:24:55.957+0200] {subprocess.py:93} INFO - 25/06/17 13:24:55 INFO DAGScheduler: failed: Set()
[2025-06-17T13:24:56.014+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-06-17T13:24:56.023+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-06-17T13:24:56.023+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
[2025-06-17T13:24:56.023+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
[2025-06-17T13:24:56.023+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO DAGScheduler: Missing parents: List()
[2025-06-17T13:24:56.023+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-06-17T13:24:56.036+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)
[2025-06-17T13:24:56.039+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.9 MiB)
[2025-06-17T13:24:56.040+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 138.4.31.19:45769 (size: 5.9 KiB, free: 434.3 MiB)
[2025-06-17T13:24:56.041+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585
[2025-06-17T13:24:56.044+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-06-17T13:24:56.044+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
[2025-06-17T13:24:56.047+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (138.4.31.19, executor driver, partition 0, NODE_LOCAL, 8999 bytes)
[2025-06-17T13:24:56.047+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
[2025-06-17T13:24:56.060+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-06-17T13:24:56.063+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-06-17T13:24:56.074+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 3988 bytes result sent to driver
[2025-06-17T13:24:56.091+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 41 ms on 138.4.31.19 (executor driver) (1/1)
[2025-06-17T13:24:56.091+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2025-06-17T13:24:56.102+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0,067 s
[2025-06-17T13:24:56.102+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-06-17T13:24:56.102+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
[2025-06-17T13:24:56.103+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0,088196 s
[2025-06-17T13:24:56.202+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO FileSourceStrategy: Pushed Filters: IsNull(CRSDepTime)
[2025-06-17T13:24:56.203+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO FileSourceStrategy: Post-Scan Filters: isnull(CRSDepTime#2)
[2025-06-17T13:24:56.221+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)
[2025-06-17T13:24:56.250+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 34.3 KiB, free 433.7 MiB)
[2025-06-17T13:24:56.251+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 138.4.31.19:45769 (size: 34.3 KiB, free: 434.3 MiB)
[2025-06-17T13:24:56.251+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 138.4.31.19:45769 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-06-17T13:24:56.257+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO SparkContext: Created broadcast 8 from count at NativeMethodAccessorImpl.java:0
[2025-06-17T13:24:56.262+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-06-17T13:24:56.281+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
[2025-06-17T13:24:56.281+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO DAGScheduler: Got map stage job 5 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-06-17T13:24:56.281+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0)
[2025-06-17T13:24:56.281+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO DAGScheduler: Parents of final stage: List()
[2025-06-17T13:24:56.281+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO DAGScheduler: Missing parents: List()
[2025-06-17T13:24:56.281+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-06-17T13:24:56.284+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 17.8 KiB, free 433.7 MiB)
[2025-06-17T13:24:56.285+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.7 MiB)
[2025-06-17T13:24:56.286+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 138.4.31.19:45769 (size: 8.6 KiB, free: 434.3 MiB)
[2025-06-17T13:24:56.287+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585
[2025-06-17T13:24:56.288+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-06-17T13:24:56.288+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO TaskSchedulerImpl: Adding task set 7.0 with 2 tasks resource profile 0
[2025-06-17T13:24:56.293+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (138.4.31.19, executor driver, partition 0, PROCESS_LOCAL, 9642 bytes)
[2025-06-17T13:24:56.293+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 8) (138.4.31.19, executor driver, partition 1, PROCESS_LOCAL, 9642 bytes)
[2025-06-17T13:24:56.293+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
[2025-06-17T13:24:56.293+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO Executor: Running task 1.0 in stage 7.0 (TID 8)
[2025-06-17T13:24:56.299+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-06-17T13:24:56.299+0200] {subprocess.py:93} INFO - 25/06/17 13:24:56 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-06-17T13:24:57.855+0200] {subprocess.py:93} INFO - 25/06/17 13:24:57 INFO Executor: Finished task 1.0 in stage 7.0 (TID 8). 1983 bytes result sent to driver
[2025-06-17T13:24:57.855+0200] {subprocess.py:93} INFO - 25/06/17 13:24:57 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 8) in 1562 ms on 138.4.31.19 (executor driver) (1/2)
[2025-06-17T13:25:03.855+0200] {local_task_job.py:272} WARNING - State of this instance has been externally set to queued. Terminating instance.
[2025-06-17T13:25:03.875+0200] {process_utils.py:129} INFO - Sending 15 to group 94423. PIDs of all processes in the group: [94425, 94535, 94423]
[2025-06-17T13:25:03.875+0200] {process_utils.py:84} INFO - Sending the signal 15 to group 94423
[2025-06-17T13:25:03.876+0200] {taskinstance.py:1479} ERROR - Received SIGTERM. Terminating subprocesses.
[2025-06-17T13:25:03.876+0200] {subprocess.py:104} INFO - Sending SIGTERM signal to process group
[2025-06-17T13:25:03.899+0200] {taskinstance.py:1768} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/monica.fernandez/practica_creativa/venv-airflow/lib/python3.11/site-packages/airflow/operators/bash.py", line 187, in execute
    result = self.subprocess_hook.run_command(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/monica.fernandez/practica_creativa/venv-airflow/lib/python3.11/site-packages/airflow/hooks/subprocess.py", line 91, in run_command
    for raw_line in iter(self.sub_process.stdout.readline, b""):
  File "/home/monica.fernandez/practica_creativa/venv-airflow/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 1481, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2025-06-17T13:25:03.907+0200] {taskinstance.py:1318} INFO - Marking task as UP_FOR_RETRY. dag_id=agile_data_science_batch_prediction_model_training, task_id=pyspark_train_classifier_model, execution_date=20250617T111525, start_date=20250617T112402, end_date=20250617T112503
[2025-06-17T13:25:03.964+0200] {standard_task_runner.py:100} ERROR - Failed to execute job 35 for task pyspark_train_classifier_model (Task received SIGTERM signal; 94423)
[2025-06-17T13:25:04.243+0200] {process_utils.py:79} INFO - Process psutil.Process(pid=94423, status='terminated', exitcode=1, started='13:24:02') (94423) terminated with exit code 1
[2025-06-17T13:25:04.243+0200] {process_utils.py:79} INFO - Process psutil.Process(pid=94535, status='terminated', started='13:24:07') (94535) terminated with exit code None
[2025-06-17T13:25:04.557+0200] {process_utils.py:79} INFO - Process psutil.Process(pid=94425, status='terminated', started='13:24:02') (94425) terminated with exit code None
