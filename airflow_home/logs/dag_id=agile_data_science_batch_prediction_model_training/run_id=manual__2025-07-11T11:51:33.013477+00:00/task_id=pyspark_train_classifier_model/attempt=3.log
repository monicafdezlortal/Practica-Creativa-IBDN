[2025-07-11T14:02:25.642+0200] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: agile_data_science_batch_prediction_model_training.pyspark_train_classifier_model manual__2025-07-11T11:51:33.013477+00:00 [queued]>
[2025-07-11T14:02:25.670+0200] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: agile_data_science_batch_prediction_model_training.pyspark_train_classifier_model manual__2025-07-11T11:51:33.013477+00:00 [queued]>
[2025-07-11T14:02:25.670+0200] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2025-07-11T14:02:25.670+0200] {taskinstance.py:1280} INFO - Starting attempt 3 of 4
[2025-07-11T14:02:25.670+0200] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2025-07-11T14:02:25.698+0200] {taskinstance.py:1300} INFO - Executing <Task(BashOperator): pyspark_train_classifier_model> on 2025-07-11 11:51:33.013477+00:00
[2025-07-11T14:02:25.703+0200] {standard_task_runner.py:55} INFO - Started process 169119 to run task
[2025-07-11T14:02:25.707+0200] {standard_task_runner.py:82} INFO - Running: ['airflow', 'tasks', 'run', 'agile_data_science_batch_prediction_model_training', 'pyspark_train_classifier_model', 'manual__2025-07-11T11:51:33.013477+00:00', '--job-id', '187', '--raw', '--subdir', 'DAGS_FOLDER/setup.py', '--cfg-path', '/tmp/tmppxys6gv6']
[2025-07-11T14:02:25.709+0200] {standard_task_runner.py:83} INFO - Job 187: Subtask pyspark_train_classifier_model
[2025-07-11T14:02:25.813+0200] {task_command.py:388} INFO - Running <TaskInstance: agile_data_science_batch_prediction_model_training.pyspark_train_classifier_model manual__2025-07-11T11:51:33.013477+00:00 [running]> on host l023.lab.dit.upm.es
[2025-07-11T14:02:25.933+0200] {taskinstance.py:1507} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=agile_data_science_batch_prediction_model_training
AIRFLOW_CTX_TASK_ID=pyspark_train_classifier_model
AIRFLOW_CTX_EXECUTION_DATE=2025-07-11T11:51:33.013477+00:00
AIRFLOW_CTX_TRY_NUMBER=3
AIRFLOW_CTX_DAG_RUN_ID=manual__2025-07-11T11:51:33.013477+00:00
[2025-07-11T14:02:25.935+0200] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-11T14:02:25.936+0200] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', '\nsource /home/monica.fernandez/practica_creativa/venv-airflow/bin/activate && export PYSPARK_PYTHON=/home/monica.fernandez/practica_creativa/venv-airflow/bin/python && spark-submit   --master local[4]   --packages com.datastax.spark:spark-cassandra-connector_2.12:3.5.0,com.github.jnr:jnr-posix:3.1.15   /home/monica.fernandez/practica_creativa/resources/train_spark_mllib_model.py   /home/monica.fernandez/practica_creativa']
[2025-07-11T14:02:25.948+0200] {subprocess.py:86} INFO - Output:
[2025-07-11T14:02:27.970+0200] {subprocess.py:93} INFO - 25/07/11 14:02:27 WARN Utils: Your hostname, l023 resolves to a loopback address: 127.0.1.1; using 138.4.31.23 instead (on interface enp1s0)
[2025-07-11T14:02:27.976+0200] {subprocess.py:93} INFO - 25/07/11 14:02:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
[2025-07-11T14:02:28.225+0200] {subprocess.py:93} INFO - :: loading settings :: url = jar:file:/home/monica.fernandez/.sdkman/candidates/spark/3.5.3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-07-11T14:02:28.308+0200] {subprocess.py:93} INFO - Ivy Default Cache set to: /home/monica.fernandez/.ivy2/cache
[2025-07-11T14:02:28.308+0200] {subprocess.py:93} INFO - The jars for the packages stored in: /home/monica.fernandez/.ivy2/jars
[2025-07-11T14:02:28.316+0200] {subprocess.py:93} INFO - com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency
[2025-07-11T14:02:28.316+0200] {subprocess.py:93} INFO - com.github.jnr#jnr-posix added as a dependency
[2025-07-11T14:02:28.318+0200] {subprocess.py:93} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-e00f469d-6916-4f5b-ab26-15dcfd525cda;1.0
[2025-07-11T14:02:28.318+0200] {subprocess.py:93} INFO - 	confs: [default]
[2025-07-11T14:02:28.514+0200] {subprocess.py:93} INFO - 	found com.datastax.spark#spark-cassandra-connector_2.12;3.5.0 in central
[2025-07-11T14:02:28.557+0200] {subprocess.py:93} INFO - 	found com.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.0 in central
[2025-07-11T14:02:28.600+0200] {subprocess.py:93} INFO - 	found org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 in central
[2025-07-11T14:02:28.643+0200] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-core-shaded;4.13.0 in central
[2025-07-11T14:02:28.681+0200] {subprocess.py:93} INFO - 	found com.datastax.oss#native-protocol;1.5.0 in central
[2025-07-11T14:02:28.715+0200] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central
[2025-07-11T14:02:28.760+0200] {subprocess.py:93} INFO - 	found com.typesafe#config;1.4.1 in central
[2025-07-11T14:02:28.815+0200] {subprocess.py:93} INFO - 	found org.slf4j#slf4j-api;1.7.26 in central
[2025-07-11T14:02:28.851+0200] {subprocess.py:93} INFO - 	found io.dropwizard.metrics#metrics-core;4.1.18 in central
[2025-07-11T14:02:28.889+0200] {subprocess.py:93} INFO - 	found org.hdrhistogram#HdrHistogram;2.1.12 in central
[2025-07-11T14:02:28.924+0200] {subprocess.py:93} INFO - 	found org.reactivestreams#reactive-streams;1.0.3 in central
[2025-07-11T14:02:28.958+0200] {subprocess.py:93} INFO - 	found com.github.stephenc.jcip#jcip-annotations;1.0-1 in central
[2025-07-11T14:02:28.984+0200] {subprocess.py:93} INFO - 	found com.github.spotbugs#spotbugs-annotations;3.1.12 in central
[2025-07-11T14:02:29.014+0200] {subprocess.py:93} INFO - 	found com.google.code.findbugs#jsr305;3.0.2 in central
[2025-07-11T14:02:29.056+0200] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central
[2025-07-11T14:02:29.095+0200] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-query-builder;4.13.0 in central
[2025-07-11T14:02:29.170+0200] {subprocess.py:93} INFO - 	found org.apache.commons#commons-lang3;3.10 in central
[2025-07-11T14:02:29.197+0200] {subprocess.py:93} INFO - 	found com.thoughtworks.paranamer#paranamer;2.8 in central
[2025-07-11T14:02:29.231+0200] {subprocess.py:93} INFO - 	found org.scala-lang#scala-reflect;2.12.11 in central
[2025-07-11T14:02:29.279+0200] {subprocess.py:93} INFO - 	found com.github.jnr#jnr-posix;3.1.15 in central
[2025-07-11T14:02:29.321+0200] {subprocess.py:93} INFO - 	found com.github.jnr#jnr-ffi;2.2.11 in central
[2025-07-11T14:02:29.341+0200] {subprocess.py:93} INFO - 	found com.github.jnr#jffi;1.3.9 in central
[2025-07-11T14:02:29.369+0200] {subprocess.py:93} INFO - 	found org.ow2.asm#asm;9.2 in central
[2025-07-11T14:02:29.399+0200] {subprocess.py:93} INFO - 	found org.ow2.asm#asm-commons;9.2 in central
[2025-07-11T14:02:29.439+0200] {subprocess.py:93} INFO - 	found org.ow2.asm#asm-tree;9.2 in central
[2025-07-11T14:02:29.476+0200] {subprocess.py:93} INFO - 	found org.ow2.asm#asm-analysis;9.2 in central
[2025-07-11T14:02:29.539+0200] {subprocess.py:93} INFO - 	found org.ow2.asm#asm-util;9.2 in central
[2025-07-11T14:02:29.571+0200] {subprocess.py:93} INFO - 	found com.github.jnr#jnr-a64asm;1.0.0 in central
[2025-07-11T14:02:29.605+0200] {subprocess.py:93} INFO - 	found com.github.jnr#jnr-x86asm;1.0.2 in central
[2025-07-11T14:02:29.632+0200] {subprocess.py:93} INFO - 	found com.github.jnr#jnr-constants;0.10.3 in central
[2025-07-11T14:02:29.757+0200] {subprocess.py:93} INFO - :: resolution report :: resolve 1335ms :: artifacts dl 103ms
[2025-07-11T14:02:29.758+0200] {subprocess.py:93} INFO - 	:: modules in use:
[2025-07-11T14:02:29.759+0200] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]
[2025-07-11T14:02:29.759+0200] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]
[2025-07-11T14:02:29.760+0200] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]
[2025-07-11T14:02:29.760+0200] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]
[2025-07-11T14:02:29.762+0200] {subprocess.py:93} INFO - 	com.datastax.oss#native-protocol;1.5.0 from central in [default]
[2025-07-11T14:02:29.762+0200] {subprocess.py:93} INFO - 	com.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.0 from central in [default]
[2025-07-11T14:02:29.762+0200] {subprocess.py:93} INFO - 	com.datastax.spark#spark-cassandra-connector_2.12;3.5.0 from central in [default]
[2025-07-11T14:02:29.763+0200] {subprocess.py:93} INFO - 	com.github.jnr#jffi;1.3.9 from central in [default]
[2025-07-11T14:02:29.763+0200] {subprocess.py:93} INFO - 	com.github.jnr#jnr-a64asm;1.0.0 from central in [default]
[2025-07-11T14:02:29.764+0200] {subprocess.py:93} INFO - 	com.github.jnr#jnr-constants;0.10.3 from central in [default]
[2025-07-11T14:02:29.764+0200] {subprocess.py:93} INFO - 	com.github.jnr#jnr-ffi;2.2.11 from central in [default]
[2025-07-11T14:02:29.765+0200] {subprocess.py:93} INFO - 	com.github.jnr#jnr-posix;3.1.15 from central in [default]
[2025-07-11T14:02:29.765+0200] {subprocess.py:93} INFO - 	com.github.jnr#jnr-x86asm;1.0.2 from central in [default]
[2025-07-11T14:02:29.767+0200] {subprocess.py:93} INFO - 	com.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]
[2025-07-11T14:02:29.771+0200] {subprocess.py:93} INFO - 	com.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]
[2025-07-11T14:02:29.771+0200] {subprocess.py:93} INFO - 	com.google.code.findbugs#jsr305;3.0.2 from central in [default]
[2025-07-11T14:02:29.772+0200] {subprocess.py:93} INFO - 	com.thoughtworks.paranamer#paranamer;2.8 from central in [default]
[2025-07-11T14:02:29.772+0200] {subprocess.py:93} INFO - 	com.typesafe#config;1.4.1 from central in [default]
[2025-07-11T14:02:29.773+0200] {subprocess.py:93} INFO - 	io.dropwizard.metrics#metrics-core;4.1.18 from central in [default]
[2025-07-11T14:02:29.774+0200] {subprocess.py:93} INFO - 	org.apache.commons#commons-lang3;3.10 from central in [default]
[2025-07-11T14:02:29.774+0200] {subprocess.py:93} INFO - 	org.hdrhistogram#HdrHistogram;2.1.12 from central in [default]
[2025-07-11T14:02:29.775+0200] {subprocess.py:93} INFO - 	org.ow2.asm#asm;9.2 from central in [default]
[2025-07-11T14:02:29.775+0200] {subprocess.py:93} INFO - 	org.ow2.asm#asm-analysis;9.2 from central in [default]
[2025-07-11T14:02:29.775+0200] {subprocess.py:93} INFO - 	org.ow2.asm#asm-commons;9.2 from central in [default]
[2025-07-11T14:02:29.776+0200] {subprocess.py:93} INFO - 	org.ow2.asm#asm-tree;9.2 from central in [default]
[2025-07-11T14:02:29.776+0200] {subprocess.py:93} INFO - 	org.ow2.asm#asm-util;9.2 from central in [default]
[2025-07-11T14:02:29.777+0200] {subprocess.py:93} INFO - 	org.reactivestreams#reactive-streams;1.0.3 from central in [default]
[2025-07-11T14:02:29.778+0200] {subprocess.py:93} INFO - 	org.scala-lang#scala-reflect;2.12.11 from central in [default]
[2025-07-11T14:02:29.778+0200] {subprocess.py:93} INFO - 	org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 from central in [default]
[2025-07-11T14:02:29.780+0200] {subprocess.py:93} INFO - 	org.slf4j#slf4j-api;1.7.26 from central in [default]
[2025-07-11T14:02:29.780+0200] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-07-11T14:02:29.781+0200] {subprocess.py:93} INFO - 	|                  |            modules            ||   artifacts   |
[2025-07-11T14:02:29.782+0200] {subprocess.py:93} INFO - 	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-07-11T14:02:29.782+0200] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-07-11T14:02:29.783+0200] {subprocess.py:93} INFO - 	|      default     |   30  |   0   |   0   |   0   ||   30  |   0   |
[2025-07-11T14:02:29.783+0200] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-07-11T14:02:29.807+0200] {subprocess.py:93} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-e00f469d-6916-4f5b-ab26-15dcfd525cda
[2025-07-11T14:02:29.808+0200] {subprocess.py:93} INFO - 	confs: [default]
[2025-07-11T14:02:29.845+0200] {subprocess.py:93} INFO - 	0 artifacts copied, 30 already retrieved (0kB/37ms)
[2025-07-11T14:02:30.123+0200] {subprocess.py:93} INFO - 25/07/11 14:02:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-07-11T14:02:34.120+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Running Spark version 3.5.3
[2025-07-11T14:02:34.121+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: OS info Linux, 6.1.0-35-amd64, amd64
[2025-07-11T14:02:34.121+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Java version 17.0.14
[2025-07-11T14:02:34.147+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO ResourceUtils: ==============================================================
[2025-07-11T14:02:34.148+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-07-11T14:02:34.149+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO ResourceUtils: ==============================================================
[2025-07-11T14:02:34.150+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Submitted application: train_spark_mllib_model.py
[2025-07-11T14:02:34.173+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-07-11T14:02:34.182+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO ResourceProfile: Limiting resource is cpu
[2025-07-11T14:02:34.184+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-07-11T14:02:34.243+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SecurityManager: Changing view acls to: monica.fernandez
[2025-07-11T14:02:34.246+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SecurityManager: Changing modify acls to: monica.fernandez
[2025-07-11T14:02:34.247+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SecurityManager: Changing view acls groups to:
[2025-07-11T14:02:34.247+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SecurityManager: Changing modify acls groups to:
[2025-07-11T14:02:34.248+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: monica.fernandez; groups with view permissions: EMPTY; users with modify permissions: monica.fernandez; groups with modify permissions: EMPTY
[2025-07-11T14:02:34.496+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Successfully started service 'sparkDriver' on port 42969.
[2025-07-11T14:02:34.522+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkEnv: Registering MapOutputTracker
[2025-07-11T14:02:34.560+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkEnv: Registering BlockManagerMaster
[2025-07-11T14:02:34.580+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-07-11T14:02:34.581+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-07-11T14:02:34.586+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-07-11T14:02:34.608+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2354cc4f-6c3b-4672-a0cf-7fee59d503b3
[2025-07-11T14:02:34.625+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-07-11T14:02:34.638+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-07-11T14:02:34.762+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-07-11T14:02:34.815+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[2025-07-11T14:02:34.823+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Successfully started service 'SparkUI' on port 4041.
[2025-07-11T14:02:34.860+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar at spark://138.4.31.23:42969/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1752235354113
[2025-07-11T14:02:34.860+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-posix-3.1.15.jar at spark://138.4.31.23:42969/jars/com.github.jnr_jnr-posix-3.1.15.jar with timestamp 1752235354113
[2025-07-11T14:02:34.860+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar at spark://138.4.31.23:42969/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1752235354113
[2025-07-11T14:02:34.860+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar at spark://138.4.31.23:42969/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1752235354113
[2025-07-11T14:02:34.860+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar at spark://138.4.31.23:42969/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1752235354113
[2025-07-11T14:02:34.861+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar at spark://138.4.31.23:42969/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1752235354113
[2025-07-11T14:02:34.861+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar at spark://138.4.31.23:42969/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1752235354113
[2025-07-11T14:02:34.861+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar at spark://138.4.31.23:42969/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1752235354113
[2025-07-11T14:02:34.861+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar at spark://138.4.31.23:42969/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1752235354113
[2025-07-11T14:02:34.861+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar at spark://138.4.31.23:42969/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1752235354113
[2025-07-11T14:02:34.862+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar at spark://138.4.31.23:42969/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1752235354113
[2025-07-11T14:02:34.862+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.typesafe_config-1.4.1.jar at spark://138.4.31.23:42969/jars/com.typesafe_config-1.4.1.jar with timestamp 1752235354113
[2025-07-11T14:02:34.862+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.slf4j_slf4j-api-1.7.26.jar at spark://138.4.31.23:42969/jars/org.slf4j_slf4j-api-1.7.26.jar with timestamp 1752235354113
[2025-07-11T14:02:34.862+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar at spark://138.4.31.23:42969/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1752235354113
[2025-07-11T14:02:34.862+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar at spark://138.4.31.23:42969/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1752235354113
[2025-07-11T14:02:34.862+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar at spark://138.4.31.23:42969/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1752235354113
[2025-07-11T14:02:34.863+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar at spark://138.4.31.23:42969/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1752235354113
[2025-07-11T14:02:34.863+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar at spark://138.4.31.23:42969/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1752235354113
[2025-07-11T14:02:34.863+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar at spark://138.4.31.23:42969/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1752235354113
[2025-07-11T14:02:34.863+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar at spark://138.4.31.23:42969/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1752235354113
[2025-07-11T14:02:34.863+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-ffi-2.2.11.jar at spark://138.4.31.23:42969/jars/com.github.jnr_jnr-ffi-2.2.11.jar with timestamp 1752235354113
[2025-07-11T14:02:34.863+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-constants-0.10.3.jar at spark://138.4.31.23:42969/jars/com.github.jnr_jnr-constants-0.10.3.jar with timestamp 1752235354113
[2025-07-11T14:02:34.863+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jffi-1.3.9-native.jar at spark://138.4.31.23:42969/jars/com.github.jnr_jffi-1.3.9-native.jar with timestamp 1752235354113
[2025-07-11T14:02:34.864+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-9.2.jar at spark://138.4.31.23:42969/jars/org.ow2.asm_asm-9.2.jar with timestamp 1752235354113
[2025-07-11T14:02:34.864+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-commons-9.2.jar at spark://138.4.31.23:42969/jars/org.ow2.asm_asm-commons-9.2.jar with timestamp 1752235354113
[2025-07-11T14:02:34.864+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-analysis-9.2.jar at spark://138.4.31.23:42969/jars/org.ow2.asm_asm-analysis-9.2.jar with timestamp 1752235354113
[2025-07-11T14:02:34.864+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-tree-9.2.jar at spark://138.4.31.23:42969/jars/org.ow2.asm_asm-tree-9.2.jar with timestamp 1752235354113
[2025-07-11T14:02:34.864+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-util-9.2.jar at spark://138.4.31.23:42969/jars/org.ow2.asm_asm-util-9.2.jar with timestamp 1752235354113
[2025-07-11T14:02:34.864+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-a64asm-1.0.0.jar at spark://138.4.31.23:42969/jars/com.github.jnr_jnr-a64asm-1.0.0.jar with timestamp 1752235354113
[2025-07-11T14:02:34.864+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added JAR file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-x86asm-1.0.2.jar at spark://138.4.31.23:42969/jars/com.github.jnr_jnr-x86asm-1.0.2.jar with timestamp 1752235354113
[2025-07-11T14:02:34.867+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar at file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1752235354113
[2025-07-11T14:02:34.869+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar
[2025-07-11T14:02:34.878+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-posix-3.1.15.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-posix-3.1.15.jar with timestamp 1752235354113
[2025-07-11T14:02:34.878+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-posix-3.1.15.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jnr-posix-3.1.15.jar
[2025-07-11T14:02:34.883+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar at file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1752235354113
[2025-07-11T14:02:34.883+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar
[2025-07-11T14:02:34.888+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar at file:///home/monica.fernandez/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1752235354113
[2025-07-11T14:02:34.888+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar
[2025-07-11T14:02:34.893+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar at file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1752235354113
[2025-07-11T14:02:34.893+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.oss_java-driver-core-shaded-4.13.0.jar
[2025-07-11T14:02:34.901+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar at file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1752235354113
[2025-07-11T14:02:34.902+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar
[2025-07-11T14:02:34.905+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar at file:///home/monica.fernandez/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1752235354113
[2025-07-11T14:02:34.905+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.apache.commons_commons-lang3-3.10.jar
[2025-07-11T14:02:34.909+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar at file:///home/monica.fernandez/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1752235354113
[2025-07-11T14:02:34.909+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.thoughtworks.paranamer_paranamer-2.8.jar
[2025-07-11T14:02:34.915+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar at file:///home/monica.fernandez/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1752235354113
[2025-07-11T14:02:34.915+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.scala-lang_scala-reflect-2.12.11.jar
[2025-07-11T14:02:34.920+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar at file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1752235354113
[2025-07-11T14:02:34.920+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.oss_native-protocol-1.5.0.jar
[2025-07-11T14:02:34.925+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar at file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1752235354113
[2025-07-11T14:02:34.925+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar
[2025-07-11T14:02:34.930+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.typesafe_config-1.4.1.jar at file:///home/monica.fernandez/.ivy2/jars/com.typesafe_config-1.4.1.jar with timestamp 1752235354113
[2025-07-11T14:02:34.930+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.typesafe_config-1.4.1.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.typesafe_config-1.4.1.jar
[2025-07-11T14:02:34.934+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.slf4j_slf4j-api-1.7.26.jar at file:///home/monica.fernandez/.ivy2/jars/org.slf4j_slf4j-api-1.7.26.jar with timestamp 1752235354113
[2025-07-11T14:02:34.934+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.slf4j_slf4j-api-1.7.26.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.slf4j_slf4j-api-1.7.26.jar
[2025-07-11T14:02:34.939+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar at file:///home/monica.fernandez/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1752235354113
[2025-07-11T14:02:34.940+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/io.dropwizard.metrics_metrics-core-4.1.18.jar
[2025-07-11T14:02:34.943+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar at file:///home/monica.fernandez/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1752235354113
[2025-07-11T14:02:34.943+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.hdrhistogram_HdrHistogram-2.1.12.jar
[2025-07-11T14:02:34.948+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar at file:///home/monica.fernandez/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1752235354113
[2025-07-11T14:02:34.948+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.reactivestreams_reactive-streams-1.0.3.jar
[2025-07-11T14:02:34.952+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1752235354113
[2025-07-11T14:02:34.952+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar
[2025-07-11T14:02:34.955+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1752235354113
[2025-07-11T14:02:34.955+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.spotbugs_spotbugs-annotations-3.1.12.jar
[2025-07-11T14:02:34.960+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar at file:///home/monica.fernandez/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1752235354113
[2025-07-11T14:02:34.960+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.google.code.findbugs_jsr305-3.0.2.jar
[2025-07-11T14:02:34.963+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar at file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1752235354113
[2025-07-11T14:02:34.963+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.oss_java-driver-query-builder-4.13.0.jar
[2025-07-11T14:02:34.969+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-ffi-2.2.11.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-ffi-2.2.11.jar with timestamp 1752235354113
[2025-07-11T14:02:34.969+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-ffi-2.2.11.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jnr-ffi-2.2.11.jar
[2025-07-11T14:02:34.973+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-constants-0.10.3.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-constants-0.10.3.jar with timestamp 1752235354113
[2025-07-11T14:02:34.973+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-constants-0.10.3.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jnr-constants-0.10.3.jar
[2025-07-11T14:02:34.977+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jffi-1.3.9-native.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jffi-1.3.9-native.jar with timestamp 1752235354113
[2025-07-11T14:02:34.978+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.jnr_jffi-1.3.9-native.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jffi-1.3.9-native.jar
[2025-07-11T14:02:34.982+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-9.2.jar at file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-9.2.jar with timestamp 1752235354113
[2025-07-11T14:02:34.982+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-9.2.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.ow2.asm_asm-9.2.jar
[2025-07-11T14:02:34.986+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-commons-9.2.jar at file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-commons-9.2.jar with timestamp 1752235354113
[2025-07-11T14:02:34.986+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-commons-9.2.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.ow2.asm_asm-commons-9.2.jar
[2025-07-11T14:02:34.991+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-analysis-9.2.jar at file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-analysis-9.2.jar with timestamp 1752235354113
[2025-07-11T14:02:34.991+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-analysis-9.2.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.ow2.asm_asm-analysis-9.2.jar
[2025-07-11T14:02:34.995+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-tree-9.2.jar at file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-tree-9.2.jar with timestamp 1752235354113
[2025-07-11T14:02:34.995+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-tree-9.2.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.ow2.asm_asm-tree-9.2.jar
[2025-07-11T14:02:35.000+0200] {subprocess.py:93} INFO - 25/07/11 14:02:34 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-util-9.2.jar at file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-util-9.2.jar with timestamp 1752235354113
[2025-07-11T14:02:35.000+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-util-9.2.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.ow2.asm_asm-util-9.2.jar
[2025-07-11T14:02:35.003+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-a64asm-1.0.0.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-a64asm-1.0.0.jar with timestamp 1752235354113
[2025-07-11T14:02:35.004+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-a64asm-1.0.0.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jnr-a64asm-1.0.0.jar
[2025-07-11T14:02:35.007+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO SparkContext: Added file file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-x86asm-1.0.2.jar at file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-x86asm-1.0.2.jar with timestamp 1752235354113
[2025-07-11T14:02:35.008+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Copying /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-x86asm-1.0.2.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jnr-x86asm-1.0.2.jar
[2025-07-11T14:02:35.066+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Starting executor ID driver on host 138.4.31.23
[2025-07-11T14:02:35.067+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: OS info Linux, 6.1.0-35-amd64, amd64
[2025-07-11T14:02:35.067+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Java version 17.0.14
[2025-07-11T14:02:35.072+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-07-11T14:02:35.072+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@510737a9 for default.
[2025-07-11T14:02:35.084+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1752235354113
[2025-07-11T14:02:35.104+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar
[2025-07-11T14:02:35.108+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1752235354113
[2025-07-11T14:02:35.108+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.google.code.findbugs_jsr305-3.0.2.jar
[2025-07-11T14:02:35.112+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.typesafe_config-1.4.1.jar with timestamp 1752235354113
[2025-07-11T14:02:35.113+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.typesafe_config-1.4.1.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.typesafe_config-1.4.1.jar
[2025-07-11T14:02:35.116+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1752235354113
[2025-07-11T14:02:35.116+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.thoughtworks.paranamer_paranamer-2.8.jar
[2025-07-11T14:02:35.119+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1752235354113
[2025-07-11T14:02:35.120+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.hdrhistogram_HdrHistogram-2.1.12.jar
[2025-07-11T14:02:35.124+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-a64asm-1.0.0.jar with timestamp 1752235354113
[2025-07-11T14:02:35.124+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-a64asm-1.0.0.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jnr-a64asm-1.0.0.jar
[2025-07-11T14:02:35.127+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jffi-1.3.9-native.jar with timestamp 1752235354113
[2025-07-11T14:02:35.128+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.jnr_jffi-1.3.9-native.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jffi-1.3.9-native.jar
[2025-07-11T14:02:35.132+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1752235354113
[2025-07-11T14:02:35.133+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.spotbugs_spotbugs-annotations-3.1.12.jar
[2025-07-11T14:02:35.136+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1752235354113
[2025-07-11T14:02:35.138+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.apache.commons_commons-lang3-3.10.jar
[2025-07-11T14:02:35.141+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1752235354113
[2025-07-11T14:02:35.142+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/io.dropwizard.metrics_metrics-core-4.1.18.jar
[2025-07-11T14:02:35.145+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1752235354113
[2025-07-11T14:02:35.149+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar
[2025-07-11T14:02:35.152+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-util-9.2.jar with timestamp 1752235354113
[2025-07-11T14:02:35.153+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-util-9.2.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.ow2.asm_asm-util-9.2.jar
[2025-07-11T14:02:35.156+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-9.2.jar with timestamp 1752235354113
[2025-07-11T14:02:35.157+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-9.2.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.ow2.asm_asm-9.2.jar
[2025-07-11T14:02:35.160+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1752235354113
[2025-07-11T14:02:35.170+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.oss_java-driver-core-shaded-4.13.0.jar
[2025-07-11T14:02:35.173+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1752235354113
[2025-07-11T14:02:35.174+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.oss_native-protocol-1.5.0.jar
[2025-07-11T14:02:35.178+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-tree-9.2.jar with timestamp 1752235354113
[2025-07-11T14:02:35.178+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-tree-9.2.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.ow2.asm_asm-tree-9.2.jar
[2025-07-11T14:02:35.181+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.slf4j_slf4j-api-1.7.26.jar with timestamp 1752235354113
[2025-07-11T14:02:35.182+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.slf4j_slf4j-api-1.7.26.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.slf4j_slf4j-api-1.7.26.jar
[2025-07-11T14:02:35.185+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-ffi-2.2.11.jar with timestamp 1752235354113
[2025-07-11T14:02:35.186+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-ffi-2.2.11.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jnr-ffi-2.2.11.jar
[2025-07-11T14:02:35.190+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1752235354113
[2025-07-11T14:02:35.191+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar
[2025-07-11T14:02:35.194+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1752235354113
[2025-07-11T14:02:35.197+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar
[2025-07-11T14:02:35.200+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1752235354113
[2025-07-11T14:02:35.201+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.oss_java-driver-query-builder-4.13.0.jar
[2025-07-11T14:02:35.204+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1752235354113
[2025-07-11T14:02:35.204+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar
[2025-07-11T14:02:35.207+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-analysis-9.2.jar with timestamp 1752235354113
[2025-07-11T14:02:35.208+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-analysis-9.2.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.ow2.asm_asm-analysis-9.2.jar
[2025-07-11T14:02:35.211+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1752235354113
[2025-07-11T14:02:35.212+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.reactivestreams_reactive-streams-1.0.3.jar
[2025-07-11T14:02:35.215+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-x86asm-1.0.2.jar with timestamp 1752235354113
[2025-07-11T14:02:35.215+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-x86asm-1.0.2.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jnr-x86asm-1.0.2.jar
[2025-07-11T14:02:35.220+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1752235354113
[2025-07-11T14:02:35.221+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar
[2025-07-11T14:02:35.225+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-commons-9.2.jar with timestamp 1752235354113
[2025-07-11T14:02:35.225+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.ow2.asm_asm-commons-9.2.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.ow2.asm_asm-commons-9.2.jar
[2025-07-11T14:02:35.230+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1752235354113
[2025-07-11T14:02:35.236+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.scala-lang_scala-reflect-2.12.11.jar
[2025-07-11T14:02:35.239+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-posix-3.1.15.jar with timestamp 1752235354113
[2025-07-11T14:02:35.240+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-posix-3.1.15.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jnr-posix-3.1.15.jar
[2025-07-11T14:02:35.243+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching file:///home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-constants-0.10.3.jar with timestamp 1752235354113
[2025-07-11T14:02:35.246+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /home/monica.fernandez/.ivy2/jars/com.github.jnr_jnr-constants-0.10.3.jar has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jnr-constants-0.10.3.jar
[2025-07-11T14:02:35.251+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1752235354113
[2025-07-11T14:02:35.285+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO TransportClientFactory: Successfully created connection to /138.4.31.23:42969 after 22 ms (0 ms spent in bootstraps)
[2025-07-11T14:02:35.291+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp3357543570254462871.tmp
[2025-07-11T14:02:35.319+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp3357543570254462871.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar
[2025-07-11T14:02:35.323+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar to class loader default
[2025-07-11T14:02:35.323+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/com.github.jnr_jnr-constants-0.10.3.jar with timestamp 1752235354113
[2025-07-11T14:02:35.324+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/com.github.jnr_jnr-constants-0.10.3.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp14654320492702895944.tmp
[2025-07-11T14:02:35.331+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp14654320492702895944.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jnr-constants-0.10.3.jar
[2025-07-11T14:02:35.334+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jnr-constants-0.10.3.jar to class loader default
[2025-07-11T14:02:35.334+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1752235354113
[2025-07-11T14:02:35.335+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/org.scala-lang_scala-reflect-2.12.11.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp16219741722624897249.tmp
[2025-07-11T14:02:35.351+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp16219741722624897249.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.scala-lang_scala-reflect-2.12.11.jar
[2025-07-11T14:02:35.355+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.scala-lang_scala-reflect-2.12.11.jar to class loader default
[2025-07-11T14:02:35.356+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/com.typesafe_config-1.4.1.jar with timestamp 1752235354113
[2025-07-11T14:02:35.356+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/com.typesafe_config-1.4.1.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp9043101605928927315.tmp
[2025-07-11T14:02:35.358+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp9043101605928927315.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.typesafe_config-1.4.1.jar
[2025-07-11T14:02:35.361+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.typesafe_config-1.4.1.jar to class loader default
[2025-07-11T14:02:35.361+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1752235354113
[2025-07-11T14:02:35.362+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp14719243072265642940.tmp
[2025-07-11T14:02:35.364+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp14719243072265642940.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar
[2025-07-11T14:02:35.367+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar to class loader default
[2025-07-11T14:02:35.367+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1752235354113
[2025-07-11T14:02:35.367+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp13983900208386385820.tmp
[2025-07-11T14:02:35.372+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp13983900208386385820.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar
[2025-07-11T14:02:35.375+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar to class loader default
[2025-07-11T14:02:35.375+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1752235354113
[2025-07-11T14:02:35.376+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp10833221739256476544.tmp
[2025-07-11T14:02:35.377+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp10833221739256476544.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar
[2025-07-11T14:02:35.380+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar to class loader default
[2025-07-11T14:02:35.380+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/com.github.jnr_jnr-x86asm-1.0.2.jar with timestamp 1752235354113
[2025-07-11T14:02:35.381+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/com.github.jnr_jnr-x86asm-1.0.2.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp13795088894431561657.tmp
[2025-07-11T14:02:35.383+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp13795088894431561657.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jnr-x86asm-1.0.2.jar
[2025-07-11T14:02:35.386+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jnr-x86asm-1.0.2.jar to class loader default
[2025-07-11T14:02:35.386+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/com.github.jnr_jnr-a64asm-1.0.0.jar with timestamp 1752235354113
[2025-07-11T14:02:35.386+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/com.github.jnr_jnr-a64asm-1.0.0.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp5094549675569789955.tmp
[2025-07-11T14:02:35.388+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp5094549675569789955.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jnr-a64asm-1.0.0.jar
[2025-07-11T14:02:35.391+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jnr-a64asm-1.0.0.jar to class loader default
[2025-07-11T14:02:35.392+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/org.ow2.asm_asm-util-9.2.jar with timestamp 1752235354113
[2025-07-11T14:02:35.392+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/org.ow2.asm_asm-util-9.2.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp18178362699468887613.tmp
[2025-07-11T14:02:35.394+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp18178362699468887613.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.ow2.asm_asm-util-9.2.jar
[2025-07-11T14:02:35.397+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.ow2.asm_asm-util-9.2.jar to class loader default
[2025-07-11T14:02:35.397+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1752235354113
[2025-07-11T14:02:35.397+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp6742768600440413292.tmp
[2025-07-11T14:02:35.399+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp6742768600440413292.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar
[2025-07-11T14:02:35.402+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar to class loader default
[2025-07-11T14:02:35.402+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1752235354113
[2025-07-11T14:02:35.402+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp5191529017919215776.tmp
[2025-07-11T14:02:35.404+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp5191529017919215776.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.oss_java-driver-query-builder-4.13.0.jar
[2025-07-11T14:02:35.408+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.oss_java-driver-query-builder-4.13.0.jar to class loader default
[2025-07-11T14:02:35.408+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/com.github.jnr_jnr-posix-3.1.15.jar with timestamp 1752235354113
[2025-07-11T14:02:35.408+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/com.github.jnr_jnr-posix-3.1.15.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp7690953888576058571.tmp
[2025-07-11T14:02:35.410+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp7690953888576058571.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jnr-posix-3.1.15.jar
[2025-07-11T14:02:35.413+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jnr-posix-3.1.15.jar to class loader default
[2025-07-11T14:02:35.414+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/org.ow2.asm_asm-9.2.jar with timestamp 1752235354113
[2025-07-11T14:02:35.414+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/org.ow2.asm_asm-9.2.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp16506857959980310369.tmp
[2025-07-11T14:02:35.416+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp16506857959980310369.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.ow2.asm_asm-9.2.jar
[2025-07-11T14:02:35.419+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.ow2.asm_asm-9.2.jar to class loader default
[2025-07-11T14:02:35.419+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1752235354113
[2025-07-11T14:02:35.420+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp18332988586342828538.tmp
[2025-07-11T14:02:35.421+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp18332988586342828538.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/io.dropwizard.metrics_metrics-core-4.1.18.jar
[2025-07-11T14:02:35.424+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/io.dropwizard.metrics_metrics-core-4.1.18.jar to class loader default
[2025-07-11T14:02:35.424+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1752235354113
[2025-07-11T14:02:35.425+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/org.reactivestreams_reactive-streams-1.0.3.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp1816252366307724382.tmp
[2025-07-11T14:02:35.426+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp1816252366307724382.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.reactivestreams_reactive-streams-1.0.3.jar
[2025-07-11T14:02:35.430+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.reactivestreams_reactive-streams-1.0.3.jar to class loader default
[2025-07-11T14:02:35.430+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/org.ow2.asm_asm-commons-9.2.jar with timestamp 1752235354113
[2025-07-11T14:02:35.430+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/org.ow2.asm_asm-commons-9.2.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp4153618122837308206.tmp
[2025-07-11T14:02:35.432+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp4153618122837308206.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.ow2.asm_asm-commons-9.2.jar
[2025-07-11T14:02:35.435+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.ow2.asm_asm-commons-9.2.jar to class loader default
[2025-07-11T14:02:35.435+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1752235354113
[2025-07-11T14:02:35.436+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp4970140526064079286.tmp
[2025-07-11T14:02:35.445+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp4970140526064079286.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar
[2025-07-11T14:02:35.449+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar to class loader default
[2025-07-11T14:02:35.449+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1752235354113
[2025-07-11T14:02:35.450+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp10004245455334534968.tmp
[2025-07-11T14:02:35.451+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp10004245455334534968.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.hdrhistogram_HdrHistogram-2.1.12.jar
[2025-07-11T14:02:35.455+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.hdrhistogram_HdrHistogram-2.1.12.jar to class loader default
[2025-07-11T14:02:35.455+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1752235354113
[2025-07-11T14:02:35.455+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/com.google.code.findbugs_jsr305-3.0.2.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp10601547583947092658.tmp
[2025-07-11T14:02:35.456+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp10601547583947092658.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.google.code.findbugs_jsr305-3.0.2.jar
[2025-07-11T14:02:35.460+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.google.code.findbugs_jsr305-3.0.2.jar to class loader default
[2025-07-11T14:02:35.460+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/org.ow2.asm_asm-tree-9.2.jar with timestamp 1752235354113
[2025-07-11T14:02:35.461+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/org.ow2.asm_asm-tree-9.2.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp10754331270312013258.tmp
[2025-07-11T14:02:35.462+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp10754331270312013258.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.ow2.asm_asm-tree-9.2.jar
[2025-07-11T14:02:35.465+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.ow2.asm_asm-tree-9.2.jar to class loader default
[2025-07-11T14:02:35.465+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1752235354113
[2025-07-11T14:02:35.466+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp6218874083538920100.tmp
[2025-07-11T14:02:35.467+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp6218874083538920100.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.spotbugs_spotbugs-annotations-3.1.12.jar
[2025-07-11T14:02:35.471+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.spotbugs_spotbugs-annotations-3.1.12.jar to class loader default
[2025-07-11T14:02:35.471+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1752235354113
[2025-07-11T14:02:35.471+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp7063324046208223306.tmp
[2025-07-11T14:02:35.496+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp7063324046208223306.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.oss_java-driver-core-shaded-4.13.0.jar
[2025-07-11T14:02:35.500+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.oss_java-driver-core-shaded-4.13.0.jar to class loader default
[2025-07-11T14:02:35.501+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1752235354113
[2025-07-11T14:02:35.501+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/com.datastax.oss_native-protocol-1.5.0.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp16801077741005403219.tmp
[2025-07-11T14:02:35.503+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp16801077741005403219.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.oss_native-protocol-1.5.0.jar
[2025-07-11T14:02:35.507+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.datastax.oss_native-protocol-1.5.0.jar to class loader default
[2025-07-11T14:02:35.507+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/com.github.jnr_jffi-1.3.9-native.jar with timestamp 1752235354113
[2025-07-11T14:02:35.507+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/com.github.jnr_jffi-1.3.9-native.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp17086416431638813772.tmp
[2025-07-11T14:02:35.512+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp17086416431638813772.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jffi-1.3.9-native.jar
[2025-07-11T14:02:35.515+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jffi-1.3.9-native.jar to class loader default
[2025-07-11T14:02:35.516+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/org.ow2.asm_asm-analysis-9.2.jar with timestamp 1752235354113
[2025-07-11T14:02:35.516+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/org.ow2.asm_asm-analysis-9.2.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp5397163880264351951.tmp
[2025-07-11T14:02:35.517+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp5397163880264351951.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.ow2.asm_asm-analysis-9.2.jar
[2025-07-11T14:02:35.521+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.ow2.asm_asm-analysis-9.2.jar to class loader default
[2025-07-11T14:02:35.521+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/org.slf4j_slf4j-api-1.7.26.jar with timestamp 1752235354113
[2025-07-11T14:02:35.521+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/org.slf4j_slf4j-api-1.7.26.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp3589471375150145189.tmp
[2025-07-11T14:02:35.522+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp3589471375150145189.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.slf4j_slf4j-api-1.7.26.jar
[2025-07-11T14:02:35.526+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.slf4j_slf4j-api-1.7.26.jar to class loader default
[2025-07-11T14:02:35.526+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1752235354113
[2025-07-11T14:02:35.526+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/com.thoughtworks.paranamer_paranamer-2.8.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp16802175152998373124.tmp
[2025-07-11T14:02:35.527+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp16802175152998373124.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.thoughtworks.paranamer_paranamer-2.8.jar
[2025-07-11T14:02:35.531+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.thoughtworks.paranamer_paranamer-2.8.jar to class loader default
[2025-07-11T14:02:35.532+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/com.github.jnr_jnr-ffi-2.2.11.jar with timestamp 1752235354113
[2025-07-11T14:02:35.532+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/com.github.jnr_jnr-ffi-2.2.11.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp6547561720459631651.tmp
[2025-07-11T14:02:35.536+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp6547561720459631651.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jnr-ffi-2.2.11.jar
[2025-07-11T14:02:35.539+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/com.github.jnr_jnr-ffi-2.2.11.jar to class loader default
[2025-07-11T14:02:35.540+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Fetching spark://138.4.31.23:42969/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1752235354113
[2025-07-11T14:02:35.540+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Fetching spark://138.4.31.23:42969/jars/org.apache.commons_commons-lang3-3.10.jar to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp7695249785110305692.tmp
[2025-07-11T14:02:35.542+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/fetchFileTemp7695249785110305692.tmp has been previously copied to /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.apache.commons_commons-lang3-3.10.jar
[2025-07-11T14:02:35.546+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Executor: Adding file:/tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/userFiles-0846bf26-d05d-4d0e-8511-1cc2429d4f4c/org.apache.commons_commons-lang3-3.10.jar to class loader default
[2025-07-11T14:02:35.555+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41705.
[2025-07-11T14:02:35.555+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO NettyBlockTransferService: Server created on 138.4.31.23:41705
[2025-07-11T14:02:35.558+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-07-11T14:02:35.563+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 138.4.31.23, 41705, None)
[2025-07-11T14:02:35.566+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO BlockManagerMasterEndpoint: Registering block manager 138.4.31.23:41705 with 434.4 MiB RAM, BlockManagerId(driver, 138.4.31.23, 41705, None)
[2025-07-11T14:02:35.569+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 138.4.31.23, 41705, None)
[2025-07-11T14:02:35.570+0200] {subprocess.py:93} INFO - 25/07/11 14:02:35 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 138.4.31.23, 41705, None)
[2025-07-11T14:02:36.277+0200] {subprocess.py:93} INFO - 25/07/11 14:02:36 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-07-11T14:02:36.283+0200] {subprocess.py:93} INFO - 25/07/11 14:02:36 INFO SharedState: Warehouse path is 'file:/tmp/airflowtmpl24rqmps/spark-warehouse'.
[2025-07-11T14:02:36.958+0200] {subprocess.py:93} INFO - 25/07/11 14:02:36 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.
[2025-07-11T14:02:38.475+0200] {subprocess.py:93} INFO - MLflow Run ID: 8fc206c246544447bcde74a456182c78
[2025-07-11T14:02:38.475+0200] {subprocess.py:93} INFO - MLflow Tracking URI: file:///home/monica.fernandez/practica_creativa/mlruns
[2025-07-11T14:02:38.638+0200] {subprocess.py:93} INFO - 25/07/11 14:02:38 INFO InMemoryFileIndex: It took 37 ms to list leaf files for 1 paths.
[2025-07-11T14:02:40.851+0200] {subprocess.py:93} INFO - 25/07/11 14:02:40 INFO DefaultMavenCoordinates: DataStax Java driver for Apache Cassandra(R) (com.datastax.oss:java-driver-core-shaded) version 4.13.0
[2025-07-11T14:02:41.097+0200] {subprocess.py:93} INFO - 25/07/11 14:02:41 INFO Clock: Could not access native clock (see debug logs for details), falling back to Java system clock
[2025-07-11T14:02:41.634+0200] {subprocess.py:93} INFO - 25/07/11 14:02:41 INFO CassandraConnector: Connected to Cassandra cluster.
[2025-07-11T14:02:41.715+0200] {subprocess.py:93} INFO - Columnas tras join con Cassandra: ['origin', 'dest', 'ArrDelay', 'CRSArrTime', 'CRSDepTime', 'Carrier', 'DayOfMonth', 'DayOfWeek', 'DayOfYear', 'DepDelay', 'FlightDate', 'FlightNum', 'Route', 'distance']
[2025-07-11T14:02:42.399+0200] {subprocess.py:93} INFO - 25/07/11 14:02:42 INFO V2ScanRelationPushDown:
[2025-07-11T14:02:42.399+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:02:42.399+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:02:42.399+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:02:42.399+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:02:42.551+0200] {subprocess.py:93} INFO - 25/07/11 14:02:42 INFO V2ScanRelationPushDown:
[2025-07-11T14:02:42.551+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-11T14:02:42.551+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:02:42.900+0200] {subprocess.py:93} INFO - 25/07/11 14:02:42 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:02:42.902+0200] {subprocess.py:93} INFO - 25/07/11 14:02:42 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:02:43.641+0200] {subprocess.py:93} INFO - 25/07/11 14:02:43 INFO CodeGenerator: Code generated in 214.951292 ms
[2025-07-11T14:02:43.700+0200] {subprocess.py:93} INFO - 25/07/11 14:02:43 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 214.5 KiB, free 434.2 MiB)
[2025-07-11T14:02:43.770+0200] {subprocess.py:93} INFO - 25/07/11 14:02:43 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 434.2 MiB)
[2025-07-11T14:02:43.772+0200] {subprocess.py:93} INFO - 25/07/11 14:02:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 138.4.31.23:41705 (size: 38.9 KiB, free: 434.4 MiB)
[2025-07-11T14:02:43.777+0200] {subprocess.py:93} INFO - 25/07/11 14:02:43 INFO SparkContext: Created broadcast 0 from showString at NativeMethodAccessorImpl.java:0
[2025-07-11T14:02:43.800+0200] {subprocess.py:93} INFO - 25/07/11 14:02:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:02:43.962+0200] {subprocess.py:93} INFO - 25/07/11 14:02:43 INFO DAGScheduler: Registering RDD 3 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2025-07-11T14:02:43.969+0200] {subprocess.py:93} INFO - 25/07/11 14:02:43 INFO CodeGenerator: Code generated in 13.136995 ms
[2025-07-11T14:02:43.970+0200] {subprocess.py:93} INFO - 25/07/11 14:02:43 INFO DAGScheduler: Got map stage job 0 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-07-11T14:02:43.971+0200] {subprocess.py:93} INFO - 25/07/11 14:02:43 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:02:43.971+0200] {subprocess.py:93} INFO - 25/07/11 14:02:43 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:02:43.972+0200] {subprocess.py:93} INFO - 25/07/11 14:02:43 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:02:43.976+0200] {subprocess.py:93} INFO - 25/07/11 14:02:43 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:02:44.096+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 17.1 KiB, free 434.1 MiB)
[2025-07-11T14:02:44.103+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 434.1 MiB)
[2025-07-11T14:02:44.107+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 138.4.31.23:41705 (size: 8.3 KiB, free: 434.4 MiB)
[2025-07-11T14:02:44.108+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:02:44.127+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:02:44.129+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks resource profile 0
[2025-07-11T14:02:44.150+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO DAGScheduler: Registering RDD 7 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2025-07-11T14:02:44.151+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO DAGScheduler: Got map stage job 1 (showString at NativeMethodAccessorImpl.java:0) with 12 output partitions
[2025-07-11T14:02:44.151+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:02:44.151+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:02:44.152+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:02:44.154+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:02:44.202+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:02:44.216+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:02:44.235+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2025-07-11T14:02:44.235+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
[2025-07-11T14:02:44.239+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 18.7 KiB, free 434.1 MiB)
[2025-07-11T14:02:44.245+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 434.1 MiB)
[2025-07-11T14:02:44.246+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 138.4.31.23:41705 (size: 9.2 KiB, free: 434.3 MiB)
[2025-07-11T14:02:44.247+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:02:44.248+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
[2025-07-11T14:02:44.248+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO TaskSchedulerImpl: Adding task set 1.0 with 12 tasks resource profile 0
[2025-07-11T14:02:44.263+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2) (138.4.31.23, executor driver, partition 0, ANY, 16839 bytes)
[2025-07-11T14:02:44.263+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3) (138.4.31.23, executor driver, partition 1, ANY, 16839 bytes)
[2025-07-11T14:02:44.264+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
[2025-07-11T14:02:44.274+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
[2025-07-11T14:02:44.404+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO CodeGenerator: Code generated in 23.936906 ms
[2025-07-11T14:02:44.414+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO CodeGenerator: Code generated in 32.145928 ms
[2025-07-11T14:02:44.453+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO CodeGenerator: Code generated in 29.694775 ms
[2025-07-11T14:02:44.453+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO CodeGenerator: Code generated in 28.198454 ms
[2025-07-11T14:02:44.471+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:02:44.472+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:02:44.514+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO CodeGenerator: Code generated in 28.817777 ms
[2025-07-11T14:02:44.622+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO CodecPool: Got brand-new decompressor [.bz2]
[2025-07-11T14:02:44.623+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO CodecPool: Got brand-new decompressor [.bz2]
[2025-07-11T14:02:44.869+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO CodeGenerator: Code generated in 26.590213 ms
[2025-07-11T14:02:44.871+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2074 bytes result sent to driver
[2025-07-11T14:02:44.873+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2074 bytes result sent to driver
[2025-07-11T14:02:44.878+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 4) (138.4.31.23, executor driver, partition 2, ANY, 16715 bytes)
[2025-07-11T14:02:44.879+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO Executor: Running task 2.0 in stage 1.0 (TID 4)
[2025-07-11T14:02:44.884+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 5) (138.4.31.23, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-11T14:02:44.885+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO Executor: Running task 3.0 in stage 1.0 (TID 5)
[2025-07-11T14:02:44.895+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 727 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:02:44.912+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 693 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:02:44.915+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO DAGScheduler: ShuffleMapStage 0 (showString at NativeMethodAccessorImpl.java:0) finished in 0,916 s
[2025-07-11T14:02:44.916+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:02:44.919+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO DAGScheduler: running: Set(ShuffleMapStage 1)
[2025-07-11T14:02:44.919+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:02:44.927+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO DAGScheduler: failed: Set()
[2025-07-11T14:02:44.929+0200] {subprocess.py:93} INFO - 25/07/11 14:02:44 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-07-11T14:02:45.088+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1988 bytes result sent to driver
[2025-07-11T14:02:45.089+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 6) (138.4.31.23, executor driver, partition 4, ANY, 16839 bytes)
[2025-07-11T14:02:45.094+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO Executor: Running task 4.0 in stage 1.0 (TID 6)
[2025-07-11T14:02:45.104+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 849 ms on 138.4.31.23 (executor driver) (1/12)
[2025-07-11T14:02:45.191+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO Executor: Finished task 2.0 in stage 1.0 (TID 4). 2031 bytes result sent to driver
[2025-07-11T14:02:45.197+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1988 bytes result sent to driver
[2025-07-11T14:02:45.206+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 7) (138.4.31.23, executor driver, partition 5, ANY, 16719 bytes)
[2025-07-11T14:02:45.206+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO Executor: Running task 5.0 in stage 1.0 (TID 7)
[2025-07-11T14:02:45.208+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 8) (138.4.31.23, executor driver, partition 6, ANY, 16839 bytes)
[2025-07-11T14:02:45.208+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 945 ms on 138.4.31.23 (executor driver) (2/12)
[2025-07-11T14:02:45.208+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO Executor: Running task 6.0 in stage 1.0 (TID 8)
[2025-07-11T14:02:45.225+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 4) in 346 ms on 138.4.31.23 (executor driver) (3/12)
[2025-07-11T14:02:45.288+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO Executor: Finished task 3.0 in stage 1.0 (TID 5). 1988 bytes result sent to driver
[2025-07-11T14:02:45.290+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 9) (138.4.31.23, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-11T14:02:45.290+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 5) in 407 ms on 138.4.31.23 (executor driver) (4/12)
[2025-07-11T14:02:45.293+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO Executor: Running task 7.0 in stage 1.0 (TID 9)
[2025-07-11T14:02:45.406+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 138.4.31.23:41705 in memory (size: 8.3 KiB, free: 434.4 MiB)
[2025-07-11T14:02:45.460+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO Executor: Finished task 4.0 in stage 1.0 (TID 6). 1988 bytes result sent to driver
[2025-07-11T14:02:45.460+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 10) (138.4.31.23, executor driver, partition 8, ANY, 16719 bytes)
[2025-07-11T14:02:45.461+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO Executor: Running task 8.0 in stage 1.0 (TID 10)
[2025-07-11T14:02:45.462+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 6) in 373 ms on 138.4.31.23 (executor driver) (5/12)
[2025-07-11T14:02:45.588+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO Executor: Finished task 7.0 in stage 1.0 (TID 9). 1945 bytes result sent to driver
[2025-07-11T14:02:45.593+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO Executor: Finished task 6.0 in stage 1.0 (TID 8). 1988 bytes result sent to driver
[2025-07-11T14:02:45.594+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 11) (138.4.31.23, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-11T14:02:45.595+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO Executor: Running task 9.0 in stage 1.0 (TID 11)
[2025-07-11T14:02:45.605+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 12) (138.4.31.23, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-11T14:02:45.608+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 9) in 319 ms on 138.4.31.23 (executor driver) (6/12)
[2025-07-11T14:02:45.609+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 8) in 401 ms on 138.4.31.23 (executor driver) (7/12)
[2025-07-11T14:02:45.612+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO Executor: Running task 10.0 in stage 1.0 (TID 12)
[2025-07-11T14:02:45.620+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO Executor: Finished task 5.0 in stage 1.0 (TID 7). 1988 bytes result sent to driver
[2025-07-11T14:02:45.622+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO TaskSetManager: Starting task 11.0 in stage 1.0 (TID 13) (138.4.31.23, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-11T14:02:45.629+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 7) in 425 ms on 138.4.31.23 (executor driver) (8/12)
[2025-07-11T14:02:45.632+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO Executor: Running task 11.0 in stage 1.0 (TID 13)
[2025-07-11T14:02:45.643+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO Executor: Finished task 8.0 in stage 1.0 (TID 10). 1945 bytes result sent to driver
[2025-07-11T14:02:45.645+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 10) in 185 ms on 138.4.31.23 (executor driver) (9/12)
[2025-07-11T14:02:45.770+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO Executor: Finished task 9.0 in stage 1.0 (TID 11). 1988 bytes result sent to driver
[2025-07-11T14:02:45.771+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 11) in 178 ms on 138.4.31.23 (executor driver) (10/12)
[2025-07-11T14:02:45.784+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO Executor: Finished task 11.0 in stage 1.0 (TID 13). 1988 bytes result sent to driver
[2025-07-11T14:02:45.785+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO TaskSetManager: Finished task 11.0 in stage 1.0 (TID 13) in 165 ms on 138.4.31.23 (executor driver) (11/12)
[2025-07-11T14:02:45.785+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO Executor: Finished task 10.0 in stage 1.0 (TID 12). 1988 bytes result sent to driver
[2025-07-11T14:02:45.786+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 12) in 191 ms on 138.4.31.23 (executor driver) (12/12)
[2025-07-11T14:02:45.786+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2025-07-11T14:02:45.788+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO DAGScheduler: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 1,627 s
[2025-07-11T14:02:45.788+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:02:45.788+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO DAGScheduler: running: Set()
[2025-07-11T14:02:45.788+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:02:45.788+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO DAGScheduler: failed: Set()
[2025-07-11T14:02:45.818+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO ShufflePartitionsUtil: For shuffle(0, 1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:02:45.883+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO CodeGenerator: Code generated in 29.262694 ms
[2025-07-11T14:02:45.898+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO CodeGenerator: Code generated in 11.149502 ms
[2025-07-11T14:02:45.937+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO CodeGenerator: Code generated in 9.061128 ms
[2025-07-11T14:02:45.967+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2025-07-11T14:02:45.972+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO DAGScheduler: Got job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-07-11T14:02:45.973+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO DAGScheduler: Final stage: ResultStage 4 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:02:45.974+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2, ShuffleMapStage 3)
[2025-07-11T14:02:45.974+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:02:45.976+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[14] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:02:45.993+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 54.2 KiB, free 434.1 MiB)
[2025-07-11T14:02:45.994+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 25.2 KiB, free 434.0 MiB)
[2025-07-11T14:02:45.995+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 138.4.31.23:41705 (size: 25.2 KiB, free: 434.3 MiB)
[2025-07-11T14:02:45.996+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:02:45.997+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:02:45.997+0200] {subprocess.py:93} INFO - 25/07/11 14:02:45 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
[2025-07-11T14:02:46.002+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 14) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 15110 bytes)
[2025-07-11T14:02:46.002+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO Executor: Running task 0.0 in stage 4.0 (TID 14)
[2025-07-11T14:02:46.049+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO ShuffleBlockFetcherIterator: Getting 2 (512.0 B) non-empty blocks including 2 (512.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:02:46.056+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
[2025-07-11T14:02:46.068+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO CodeGenerator: Code generated in 9.082394 ms
[2025-07-11T14:02:46.086+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO CodeGenerator: Code generated in 10.198463 ms
[2025-07-11T14:02:46.113+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO CodeGenerator: Code generated in 11.006743 ms
[2025-07-11T14:02:46.141+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO ShuffleBlockFetcherIterator: Getting 12 (214.7 KiB) non-empty blocks including 12 (214.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:02:46.141+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
[2025-07-11T14:02:46.157+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO CodeGenerator: Code generated in 14.645547 ms
[2025-07-11T14:02:46.178+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO CodeGenerator: Code generated in 9.631047 ms
[2025-07-11T14:02:46.194+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO CodeGenerator: Code generated in 13.940296 ms
[2025-07-11T14:02:46.231+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO CodeGenerator: Code generated in 36.17063 ms
[2025-07-11T14:02:46.358+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO Executor: Finished task 0.0 in stage 4.0 (TID 14). 6329 bytes result sent to driver
[2025-07-11T14:02:46.360+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 14) in 361 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:02:46.360+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2025-07-11T14:02:46.366+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO DAGScheduler: ResultStage 4 (showString at NativeMethodAccessorImpl.java:0) finished in 0,377 s
[2025-07-11T14:02:46.366+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:02:46.366+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
[2025-07-11T14:02:46.369+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO DAGScheduler: Job 2 finished: showString at NativeMethodAccessorImpl.java:0, took 0,400856 s
[2025-07-11T14:02:46.414+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO CodeGenerator: Code generated in 9.117698 ms
[2025-07-11T14:02:46.439+0200] {subprocess.py:93} INFO - +------+----+--------+
[2025-07-11T14:02:46.439+0200] {subprocess.py:93} INFO - |origin|dest|distance|
[2025-07-11T14:02:46.439+0200] {subprocess.py:93} INFO - +------+----+--------+
[2025-07-11T14:02:46.439+0200] {subprocess.py:93} INFO - |   ABQ| DFW|   569.0|
[2025-07-11T14:02:46.439+0200] {subprocess.py:93} INFO - |   ABQ| DFW|   569.0|
[2025-07-11T14:02:46.439+0200] {subprocess.py:93} INFO - |   ABQ| DFW|   569.0|
[2025-07-11T14:02:46.440+0200] {subprocess.py:93} INFO - |   ATL| DFW|   731.0|
[2025-07-11T14:02:46.440+0200] {subprocess.py:93} INFO - |   ATL| DFW|   731.0|
[2025-07-11T14:02:46.440+0200] {subprocess.py:93} INFO - +------+----+--------+
[2025-07-11T14:02:46.440+0200] {subprocess.py:93} INFO - only showing top 5 rows
[2025-07-11T14:02:46.440+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:02:46.894+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO FileSystemOverwrite: Path /home/monica.fernandez/practica_creativa/models/arrival_bucketizer_2.0.bin already exists. It will be overwritten.
[2025-07-11T14:02:46.953+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
[2025-07-11T14:02:46.957+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:02:46.959+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:02:46.960+0200] {subprocess.py:93} INFO - 25/07/11 14:02:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:02:47.016+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-11T14:02:47.019+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: Got job 3 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-11T14:02:47.019+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: Final stage: ResultStage 5 (runJob at SparkHadoopWriter.scala:83)
[2025-07-11T14:02:47.019+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:02:47.019+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:02:47.019+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[16] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-11T14:02:47.040+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 101.3 KiB, free 433.9 MiB)
[2025-07-11T14:02:47.045+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 433.9 MiB)
[2025-07-11T14:02:47.046+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 138.4.31.23:41705 (size: 36.5 KiB, free: 434.3 MiB)
[2025-07-11T14:02:47.047+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:02:47.047+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[16] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:02:47.047+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2025-07-11T14:02:47.050+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 15) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15151 bytes)
[2025-07-11T14:02:47.050+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO Executor: Running task 0.0 in stage 5.0 (TID 15)
[2025-07-11T14:02:47.075+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:02:47.076+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:02:47.076+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:02:47.139+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO FileOutputCommitter: Saved output of task 'attempt_202507111402464336694308934162157_0016_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/arrival_bucketizer_2.0.bin/metadata/_temporary/0/task_202507111402464336694308934162157_0016_m_000000
[2025-07-11T14:02:47.140+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO SparkHadoopMapRedUtil: attempt_202507111402464336694308934162157_0016_m_000000_0: Committed. Elapsed time: 7 ms.
[2025-07-11T14:02:47.142+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO Executor: Finished task 0.0 in stage 5.0 (TID 15). 1213 bytes result sent to driver
[2025-07-11T14:02:47.145+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 15) in 97 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:02:47.145+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-07-11T14:02:47.146+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: ResultStage 5 (runJob at SparkHadoopWriter.scala:83) finished in 0,123 s
[2025-07-11T14:02:47.147+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:02:47.147+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-07-11T14:02:47.147+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: Job 3 finished: runJob at SparkHadoopWriter.scala:83, took 0,130216 s
[2025-07-11T14:02:47.148+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO SparkHadoopWriter: Start to commit write Job job_202507111402464336694308934162157_0016.
[2025-07-11T14:02:47.177+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO SparkHadoopWriter: Write Job job_202507111402464336694308934162157_0016 committed. Elapsed time: 28 ms.
[2025-07-11T14:02:47.443+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO V2ScanRelationPushDown:
[2025-07-11T14:02:47.443+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:02:47.443+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:02:47.443+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:02:47.443+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:02:47.476+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO V2ScanRelationPushDown:
[2025-07-11T14:02:47.476+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68
[2025-07-11T14:02:47.476+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:02:47.528+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:02:47.528+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:02:47.571+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO CodeGenerator: Code generated in 7.639708 ms
[2025-07-11T14:02:47.582+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 214.5 KiB, free 433.7 MiB)
[2025-07-11T14:02:47.596+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 433.7 MiB)
[2025-07-11T14:02:47.597+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 138.4.31.23:41705 (size: 38.9 KiB, free: 434.3 MiB)
[2025-07-11T14:02:47.598+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO SparkContext: Created broadcast 5 from collect at StringIndexer.scala:204
[2025-07-11T14:02:47.599+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:02:47.606+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: Registering RDD 20 (collect at StringIndexer.scala:204) as input to shuffle 2
[2025-07-11T14:02:47.606+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: Got map stage job 4 (collect at StringIndexer.scala:204) with 2 output partitions
[2025-07-11T14:02:47.606+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (collect at StringIndexer.scala:204)
[2025-07-11T14:02:47.606+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:02:47.606+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:02:47.607+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[20] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:02:47.609+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 17.4 KiB, free 433.6 MiB)
[2025-07-11T14:02:47.613+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 433.6 MiB)
[2025-07-11T14:02:47.614+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 138.4.31.23:41705 (size: 8.3 KiB, free: 434.2 MiB)
[2025-07-11T14:02:47.614+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:02:47.615+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[20] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:02:47.615+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO TaskSchedulerImpl: Adding task set 6.0 with 2 tasks resource profile 0
[2025-07-11T14:02:47.618+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 16) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:02:47.618+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 17) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:02:47.618+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO Executor: Running task 0.0 in stage 6.0 (TID 16)
[2025-07-11T14:02:47.618+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO Executor: Running task 1.0 in stage 6.0 (TID 17)
[2025-07-11T14:02:47.627+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO CodeGenerator: Code generated in 10.868562 ms
[2025-07-11T14:02:47.636+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: Registering RDD 24 (collect at StringIndexer.scala:204) as input to shuffle 3
[2025-07-11T14:02:47.636+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: Got map stage job 5 (collect at StringIndexer.scala:204) with 12 output partitions
[2025-07-11T14:02:47.636+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (collect at StringIndexer.scala:204)
[2025-07-11T14:02:47.637+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:02:47.637+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:02:47.638+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[24] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:02:47.639+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO CodeGenerator: Code generated in 12.73475 ms
[2025-07-11T14:02:47.642+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 18.2 KiB, free 433.6 MiB)
[2025-07-11T14:02:47.661+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.6 MiB)
[2025-07-11T14:02:47.662+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 138.4.31.23:41705 (size: 9.0 KiB, free: 434.2 MiB)
[2025-07-11T14:02:47.662+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO CodeGenerator: Code generated in 19.713333 ms
[2025-07-11T14:02:47.664+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:02:47.665+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[24] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
[2025-07-11T14:02:47.666+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO TaskSchedulerImpl: Adding task set 7.0 with 12 tasks resource profile 0
[2025-07-11T14:02:47.667+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:02:47.667+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:02:47.673+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 18) (138.4.31.23, executor driver, partition 0, ANY, 16719 bytes)
[2025-07-11T14:02:47.674+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 19) (138.4.31.23, executor driver, partition 1, ANY, 16719 bytes)
[2025-07-11T14:02:47.677+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO Executor: Running task 0.0 in stage 7.0 (TID 18)
[2025-07-11T14:02:47.677+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO Executor: Running task 1.0 in stage 7.0 (TID 19)
[2025-07-11T14:02:47.697+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO CodeGenerator: Code generated in 12.340563 ms
[2025-07-11T14:02:47.715+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO CodeGenerator: Code generated in 39.663927 ms
[2025-07-11T14:02:47.784+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 138.4.31.23:41705 in memory (size: 25.2 KiB, free: 434.3 MiB)
[2025-07-11T14:02:47.911+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 138.4.31.23:41705 in memory (size: 36.5 KiB, free: 434.3 MiB)
[2025-07-11T14:02:47.934+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO Executor: Finished task 1.0 in stage 7.0 (TID 19). 1988 bytes result sent to driver
[2025-07-11T14:02:47.936+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 20) (138.4.31.23, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-11T14:02:47.937+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO Executor: Finished task 0.0 in stage 7.0 (TID 18). 1988 bytes result sent to driver
[2025-07-11T14:02:47.937+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO Executor: Running task 2.0 in stage 7.0 (TID 20)
[2025-07-11T14:02:47.940+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 21) (138.4.31.23, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-11T14:02:47.940+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 18) in 267 ms on 138.4.31.23 (executor driver) (1/12)
[2025-07-11T14:02:47.941+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO Executor: Running task 3.0 in stage 7.0 (TID 21)
[2025-07-11T14:02:47.943+0200] {subprocess.py:93} INFO - 25/07/11 14:02:47 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 19) in 270 ms on 138.4.31.23 (executor driver) (2/12)
[2025-07-11T14:02:48.086+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO Executor: Finished task 2.0 in stage 7.0 (TID 20). 1945 bytes result sent to driver
[2025-07-11T14:02:48.087+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 22) (138.4.31.23, executor driver, partition 4, ANY, 16715 bytes)
[2025-07-11T14:02:48.088+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 20) in 153 ms on 138.4.31.23 (executor driver) (3/12)
[2025-07-11T14:02:48.090+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO Executor: Running task 4.0 in stage 7.0 (TID 22)
[2025-07-11T14:02:48.106+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO Executor: Finished task 3.0 in stage 7.0 (TID 21). 1945 bytes result sent to driver
[2025-07-11T14:02:48.114+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 23) (138.4.31.23, executor driver, partition 5, ANY, 16839 bytes)
[2025-07-11T14:02:48.116+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 21) in 180 ms on 138.4.31.23 (executor driver) (4/12)
[2025-07-11T14:02:48.117+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO Executor: Running task 5.0 in stage 7.0 (TID 23)
[2025-07-11T14:02:48.291+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO Executor: Finished task 4.0 in stage 7.0 (TID 22). 2031 bytes result sent to driver
[2025-07-11T14:02:48.291+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 24) (138.4.31.23, executor driver, partition 6, ANY, 16839 bytes)
[2025-07-11T14:02:48.291+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO Executor: Running task 6.0 in stage 7.0 (TID 24)
[2025-07-11T14:02:48.294+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 22) in 206 ms on 138.4.31.23 (executor driver) (5/12)
[2025-07-11T14:02:48.325+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO Executor: Finished task 5.0 in stage 7.0 (TID 23). 1988 bytes result sent to driver
[2025-07-11T14:02:48.327+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 25) (138.4.31.23, executor driver, partition 7, ANY, 16839 bytes)
[2025-07-11T14:02:48.337+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 23) in 218 ms on 138.4.31.23 (executor driver) (6/12)
[2025-07-11T14:02:48.337+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO Executor: Running task 7.0 in stage 7.0 (TID 25)
[2025-07-11T14:02:48.431+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 138.4.31.23:41705 in memory (size: 9.2 KiB, free: 434.3 MiB)
[2025-07-11T14:02:48.446+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO Executor: Finished task 7.0 in stage 7.0 (TID 25). 1945 bytes result sent to driver
[2025-07-11T14:02:48.451+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 26) (138.4.31.23, executor driver, partition 8, ANY, 16719 bytes)
[2025-07-11T14:02:48.451+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 25) in 123 ms on 138.4.31.23 (executor driver) (7/12)
[2025-07-11T14:02:48.451+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO Executor: Running task 8.0 in stage 7.0 (TID 26)
[2025-07-11T14:02:48.473+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO Executor: Finished task 6.0 in stage 7.0 (TID 24). 1945 bytes result sent to driver
[2025-07-11T14:02:48.474+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 27) (138.4.31.23, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-11T14:02:48.475+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 24) in 187 ms on 138.4.31.23 (executor driver) (8/12)
[2025-07-11T14:02:48.475+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO Executor: Running task 9.0 in stage 7.0 (TID 27)
[2025-07-11T14:02:48.604+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO Executor: Finished task 8.0 in stage 7.0 (TID 26). 1988 bytes result sent to driver
[2025-07-11T14:02:48.606+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO TaskSetManager: Starting task 10.0 in stage 7.0 (TID 28) (138.4.31.23, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-11T14:02:48.606+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO Executor: Running task 10.0 in stage 7.0 (TID 28)
[2025-07-11T14:02:48.607+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 26) in 159 ms on 138.4.31.23 (executor driver) (9/12)
[2025-07-11T14:02:48.615+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO Executor: Finished task 9.0 in stage 7.0 (TID 27). 1988 bytes result sent to driver
[2025-07-11T14:02:48.619+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO TaskSetManager: Starting task 11.0 in stage 7.0 (TID 29) (138.4.31.23, executor driver, partition 11, ANY, 16839 bytes)
[2025-07-11T14:02:48.619+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 27) in 145 ms on 138.4.31.23 (executor driver) (10/12)
[2025-07-11T14:02:48.622+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO Executor: Running task 11.0 in stage 7.0 (TID 29)
[2025-07-11T14:02:48.752+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO Executor: Finished task 10.0 in stage 7.0 (TID 28). 1988 bytes result sent to driver
[2025-07-11T14:02:48.753+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO TaskSetManager: Finished task 10.0 in stage 7.0 (TID 28) in 148 ms on 138.4.31.23 (executor driver) (11/12)
[2025-07-11T14:02:48.768+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO Executor: Finished task 11.0 in stage 7.0 (TID 29). 1988 bytes result sent to driver
[2025-07-11T14:02:48.769+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO TaskSetManager: Finished task 11.0 in stage 7.0 (TID 29) in 152 ms on 138.4.31.23 (executor driver) (12/12)
[2025-07-11T14:02:48.769+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2025-07-11T14:02:48.770+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO DAGScheduler: ShuffleMapStage 7 (collect at StringIndexer.scala:204) finished in 1,131 s
[2025-07-11T14:02:48.770+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:02:48.770+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO DAGScheduler: running: Set(ShuffleMapStage 6)
[2025-07-11T14:02:48.770+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:02:48.770+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO DAGScheduler: failed: Set()
[2025-07-11T14:02:48.819+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:02:48.908+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:02:48.913+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO DAGScheduler: Got job 6 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-11T14:02:48.913+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO DAGScheduler: Final stage: ResultStage 9 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-11T14:02:48.913+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
[2025-07-11T14:02:48.913+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:02:48.913+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[26] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-11T14:02:48.913+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 8.2 KiB, free 433.8 MiB)
[2025-07-11T14:02:48.913+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 433.8 MiB)
[2025-07-11T14:02:48.916+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 138.4.31.23:41705 (size: 4.2 KiB, free: 434.3 MiB)
[2025-07-11T14:02:48.925+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:02:48.925+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[26] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:02:48.926+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
[2025-07-11T14:02:48.927+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 30) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-11T14:02:48.929+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO Executor: Running task 0.0 in stage 9.0 (TID 30)
[2025-07-11T14:02:48.937+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO ShuffleBlockFetcherIterator: Getting 12 (193.3 KiB) non-empty blocks including 12 (193.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:02:48.937+0200] {subprocess.py:93} INFO - 25/07/11 14:02:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-11T14:02:49.001+0200] {subprocess.py:93} INFO - 25/07/11 14:02:49 INFO Executor: Finished task 0.0 in stage 9.0 (TID 30). 40693 bytes result sent to driver
[2025-07-11T14:02:49.009+0200] {subprocess.py:93} INFO - 25/07/11 14:02:49 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 30) in 82 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:02:49.010+0200] {subprocess.py:93} INFO - 25/07/11 14:02:49 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-07-11T14:02:49.013+0200] {subprocess.py:93} INFO - 25/07/11 14:02:49 INFO DAGScheduler: ResultStage 9 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,099 s
[2025-07-11T14:02:49.013+0200] {subprocess.py:93} INFO - 25/07/11 14:02:49 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:02:49.013+0200] {subprocess.py:93} INFO - 25/07/11 14:02:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
[2025-07-11T14:02:49.014+0200] {subprocess.py:93} INFO - 25/07/11 14:02:49 INFO DAGScheduler: Job 6 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,103155 s
[2025-07-11T14:02:49.055+0200] {subprocess.py:93} INFO - 25/07/11 14:02:49 INFO CodeGenerator: Code generated in 20.750377 ms
[2025-07-11T14:02:49.086+0200] {subprocess.py:93} INFO - 25/07/11 14:02:49 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 4.3 MiB, free 429.6 MiB)
[2025-07-11T14:02:49.102+0200] {subprocess.py:93} INFO - 25/07/11 14:02:49 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 89.6 KiB, free 429.5 MiB)
[2025-07-11T14:02:49.102+0200] {subprocess.py:93} INFO - 25/07/11 14:02:49 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 138.4.31.23:41705 (size: 89.6 KiB, free: 434.2 MiB)
[2025-07-11T14:02:49.103+0200] {subprocess.py:93} INFO - 25/07/11 14:02:49 INFO SparkContext: Created broadcast 9 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:02:50.185+0200] {subprocess.py:93} INFO - 25/07/11 14:02:50 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 138.4.31.23:41705 in memory (size: 4.2 KiB, free: 434.2 MiB)
[2025-07-11T14:02:50.400+0200] {subprocess.py:93} INFO - 25/07/11 14:02:50 INFO Executor: Finished task 1.0 in stage 6.0 (TID 17). 2031 bytes result sent to driver
[2025-07-11T14:02:50.402+0200] {subprocess.py:93} INFO - 25/07/11 14:02:50 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 17) in 2785 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:02:55.886+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO Executor: Finished task 0.0 in stage 6.0 (TID 16). 2031 bytes result sent to driver
[2025-07-11T14:02:55.887+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 16) in 8270 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:02:55.887+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2025-07-11T14:02:55.887+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO DAGScheduler: ShuffleMapStage 6 (collect at StringIndexer.scala:204) finished in 8,280 s
[2025-07-11T14:02:55.887+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:02:55.887+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO DAGScheduler: running: Set()
[2025-07-11T14:02:55.887+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:02:55.887+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO DAGScheduler: failed: Set()
[2025-07-11T14:02:55.897+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:02:55.923+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO CodeGenerator: Code generated in 7.213138 ms
[2025-07-11T14:02:55.929+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO DAGScheduler: Registering RDD 30 (collect at StringIndexer.scala:204) as input to shuffle 4
[2025-07-11T14:02:55.930+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO DAGScheduler: Got map stage job 7 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-11T14:02:55.930+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO DAGScheduler: Final stage: ShuffleMapStage 11 (collect at StringIndexer.scala:204)
[2025-07-11T14:02:55.930+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
[2025-07-11T14:02:55.930+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:02:55.930+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[30] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:02:55.953+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 50.7 KiB, free 429.5 MiB)
[2025-07-11T14:02:55.954+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 429.4 MiB)
[2025-07-11T14:02:55.954+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 138.4.31.23:41705 (size: 24.0 KiB, free: 434.2 MiB)
[2025-07-11T14:02:55.956+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:02:55.956+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[30] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:02:55.956+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
[2025-07-11T14:02:55.957+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 31) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14833 bytes)
[2025-07-11T14:02:55.957+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO Executor: Running task 0.0 in stage 11.0 (TID 31)
[2025-07-11T14:02:55.972+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO ShuffleBlockFetcherIterator: Getting 2 (1126.9 KiB) non-empty blocks including 2 (1126.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:02:55.972+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:02:55.980+0200] {subprocess.py:93} INFO - 25/07/11 14:02:55 INFO CodeGenerator: Code generated in 6.907626 ms
[2025-07-11T14:02:56.002+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO CodeGenerator: Code generated in 4.633216 ms
[2025-07-11T14:02:56.012+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO CodeGenerator: Code generated in 3.778763 ms
[2025-07-11T14:02:56.018+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO CodeGenerator: Code generated in 4.661481 ms
[2025-07-11T14:02:56.033+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO CodeGenerator: Code generated in 4.980379 ms
[2025-07-11T14:02:56.714+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO CodeGenerator: Code generated in 11.614966 ms
[2025-07-11T14:02:56.941+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO Executor: Finished task 0.0 in stage 11.0 (TID 31). 6543 bytes result sent to driver
[2025-07-11T14:02:56.942+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 31) in 986 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:02:56.943+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO DAGScheduler: ShuffleMapStage 11 (collect at StringIndexer.scala:204) finished in 1,012 s
[2025-07-11T14:02:56.943+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:02:56.943+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO DAGScheduler: running: Set()
[2025-07-11T14:02:56.943+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:02:56.943+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO DAGScheduler: failed: Set()
[2025-07-11T14:02:56.943+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2025-07-11T14:02:56.972+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
[2025-07-11T14:02:56.979+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO DAGScheduler: Got job 8 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-11T14:02:56.979+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO DAGScheduler: Final stage: ResultStage 14 (collect at StringIndexer.scala:204)
[2025-07-11T14:02:56.979+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
[2025-07-11T14:02:56.979+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:02:56.979+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[33] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:02:56.979+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 49.9 KiB, free 429.4 MiB)
[2025-07-11T14:02:56.979+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 429.4 MiB)
[2025-07-11T14:02:56.979+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 138.4.31.23:41705 (size: 23.6 KiB, free: 434.2 MiB)
[2025-07-11T14:02:56.980+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:02:56.980+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[33] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:02:56.980+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
[2025-07-11T14:02:56.981+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 32) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:02:56.982+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO Executor: Running task 0.0 in stage 14.0 (TID 32)
[2025-07-11T14:02:56.989+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:02:56.989+0200] {subprocess.py:93} INFO - 25/07/11 14:02:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:02:57.005+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO CodeGenerator: Code generated in 7.963959 ms
[2025-07-11T14:02:57.047+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO Executor: Finished task 0.0 in stage 14.0 (TID 32). 8145 bytes result sent to driver
[2025-07-11T14:02:57.050+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 32) in 67 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:02:57.050+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2025-07-11T14:02:57.051+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: ResultStage 14 (collect at StringIndexer.scala:204) finished in 0,073 s
[2025-07-11T14:02:57.051+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:02:57.051+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
[2025-07-11T14:02:57.051+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Job 8 finished: collect at StringIndexer.scala:204, took 0,077703 s
[2025-07-11T14:02:57.062+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO CodeGenerator: Code generated in 6.899709 ms
[2025-07-11T14:02:57.179+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO FileSystemOverwrite: Path /home/monica.fernandez/practica_creativa/models/string_indexer_model_Carrier.bin already exists. It will be overwritten.
[2025-07-11T14:02:57.198+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:02:57.198+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:02:57.198+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:02:57.230+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-11T14:02:57.231+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Got job 9 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-11T14:02:57.231+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Final stage: ResultStage 15 (runJob at SparkHadoopWriter.scala:83)
[2025-07-11T14:02:57.231+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:02:57.231+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:02:57.232+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[35] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-11T14:02:57.242+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 101.3 KiB, free 429.3 MiB)
[2025-07-11T14:02:57.243+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 429.2 MiB)
[2025-07-11T14:02:57.244+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 138.4.31.23:41705 (size: 36.5 KiB, free: 434.1 MiB)
[2025-07-11T14:02:57.249+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:02:57.249+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[35] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:02:57.249+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
[2025-07-11T14:02:57.249+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 33) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15158 bytes)
[2025-07-11T14:02:57.249+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO Executor: Running task 0.0 in stage 15.0 (TID 33)
[2025-07-11T14:02:57.256+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:02:57.256+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:02:57.256+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:02:57.284+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO FileOutputCommitter: Saved output of task 'attempt_20250711140257328693529606679184_0035_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Carrier.bin/metadata/_temporary/0/task_20250711140257328693529606679184_0035_m_000000
[2025-07-11T14:02:57.284+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO SparkHadoopMapRedUtil: attempt_20250711140257328693529606679184_0035_m_000000_0: Committed. Elapsed time: 1 ms.
[2025-07-11T14:02:57.285+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO Executor: Finished task 0.0 in stage 15.0 (TID 33). 1170 bytes result sent to driver
[2025-07-11T14:02:57.285+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 33) in 40 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:02:57.286+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2025-07-11T14:02:57.287+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: ResultStage 15 (runJob at SparkHadoopWriter.scala:83) finished in 0,054 s
[2025-07-11T14:02:57.287+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:02:57.287+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
[2025-07-11T14:02:57.287+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Job 9 finished: runJob at SparkHadoopWriter.scala:83, took 0,055984 s
[2025-07-11T14:02:57.287+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO SparkHadoopWriter: Start to commit write Job job_20250711140257328693529606679184_0035.
[2025-07-11T14:02:57.310+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO SparkHadoopWriter: Write Job job_20250711140257328693529606679184_0035 committed. Elapsed time: 23 ms.
[2025-07-11T14:02:57.437+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO CodeGenerator: Code generated in 10.319644 ms
[2025-07-11T14:02:57.445+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Registering RDD 38 (parquet at StringIndexer.scala:499) as input to shuffle 5
[2025-07-11T14:02:57.445+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Got map stage job 10 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-11T14:02:57.445+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Final stage: ShuffleMapStage 16 (parquet at StringIndexer.scala:499)
[2025-07-11T14:02:57.445+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:02:57.445+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:02:57.446+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[38] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-11T14:02:57.448+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 8.1 KiB, free 429.2 MiB)
[2025-07-11T14:02:57.448+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 429.2 MiB)
[2025-07-11T14:02:57.449+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 138.4.31.23:41705 (size: 4.4 KiB, free: 434.1 MiB)
[2025-07-11T14:02:57.449+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:02:57.450+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[38] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:02:57.450+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
[2025-07-11T14:02:57.451+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 34) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15256 bytes)
[2025-07-11T14:02:57.454+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO Executor: Running task 0.0 in stage 16.0 (TID 34)
[2025-07-11T14:02:57.457+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO Executor: Finished task 0.0 in stage 16.0 (TID 34). 1628 bytes result sent to driver
[2025-07-11T14:02:57.458+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 34) in 8 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:02:57.458+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool
[2025-07-11T14:02:57.459+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: ShuffleMapStage 16 (parquet at StringIndexer.scala:499) finished in 0,012 s
[2025-07-11T14:02:57.459+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:02:57.459+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: running: Set()
[2025-07-11T14:02:57.459+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:02:57.459+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: failed: Set()
[2025-07-11T14:02:57.504+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:02:57.521+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:02:57.521+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:02:57.522+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:02:57.522+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:02:57.522+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:02:57.522+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:02:57.547+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO SparkContext: Starting job: parquet at StringIndexer.scala:499
[2025-07-11T14:02:57.548+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Got job 11 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-11T14:02:57.548+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Final stage: ResultStage 18 (parquet at StringIndexer.scala:499)
[2025-07-11T14:02:57.548+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
[2025-07-11T14:02:57.548+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:02:57.548+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[40] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-11T14:02:57.581+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 239.5 KiB, free 429.0 MiB)
[2025-07-11T14:02:57.583+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 83.6 KiB, free 428.9 MiB)
[2025-07-11T14:02:57.583+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 138.4.31.23:41705 (size: 83.6 KiB, free: 434.1 MiB)
[2025-07-11T14:02:57.584+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:02:57.584+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[40] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:02:57.584+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
[2025-07-11T14:02:57.589+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 35) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:02:57.589+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO Executor: Running task 0.0 in stage 18.0 (TID 35)
[2025-07-11T14:02:57.614+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:02:57.615+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:02:57.616+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:02:57.616+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:02:57.616+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:02:57.616+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:02:57.617+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:02:57.617+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:02:57.621+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:02:57.626+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:02:57.660+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-11T14:02:57.687+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-11T14:02:57.687+0200] {subprocess.py:93} INFO - {
[2025-07-11T14:02:57.687+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-11T14:02:57.687+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-11T14:02:57.687+0200] {subprocess.py:93} INFO -     "name" : "labelsArray",
[2025-07-11T14:02:57.688+0200] {subprocess.py:93} INFO -     "type" : {
[2025-07-11T14:02:57.688+0200] {subprocess.py:93} INFO -       "type" : "array",
[2025-07-11T14:02:57.688+0200] {subprocess.py:93} INFO -       "elementType" : {
[2025-07-11T14:02:57.688+0200] {subprocess.py:93} INFO -         "type" : "array",
[2025-07-11T14:02:57.688+0200] {subprocess.py:93} INFO -         "elementType" : "string",
[2025-07-11T14:02:57.688+0200] {subprocess.py:93} INFO -         "containsNull" : true
[2025-07-11T14:02:57.688+0200] {subprocess.py:93} INFO -       },
[2025-07-11T14:02:57.688+0200] {subprocess.py:93} INFO -       "containsNull" : true
[2025-07-11T14:02:57.688+0200] {subprocess.py:93} INFO -     },
[2025-07-11T14:02:57.688+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-11T14:02:57.688+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:02:57.688+0200] {subprocess.py:93} INFO -   } ]
[2025-07-11T14:02:57.688+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:02:57.688+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-11T14:02:57.688+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-11T14:02:57.688+0200] {subprocess.py:93} INFO -   optional group labelsArray (LIST) {
[2025-07-11T14:02:57.689+0200] {subprocess.py:93} INFO -     repeated group list {
[2025-07-11T14:02:57.689+0200] {subprocess.py:93} INFO -       optional group element (LIST) {
[2025-07-11T14:02:57.689+0200] {subprocess.py:93} INFO -         repeated group list {
[2025-07-11T14:02:57.689+0200] {subprocess.py:93} INFO -           optional binary element (STRING);
[2025-07-11T14:02:57.689+0200] {subprocess.py:93} INFO -         }
[2025-07-11T14:02:57.689+0200] {subprocess.py:93} INFO -       }
[2025-07-11T14:02:57.689+0200] {subprocess.py:93} INFO -     }
[2025-07-11T14:02:57.689+0200] {subprocess.py:93} INFO -   }
[2025-07-11T14:02:57.689+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:02:57.689+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:02:57.689+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:02:57.817+0200] {subprocess.py:93} INFO - 25/07/11 14:02:57 INFO CodecPool: Got brand-new compressor [.snappy]
[2025-07-11T14:02:58.477+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO FileOutputCommitter: Saved output of task 'attempt_20250711140257934320123356577854_0018_m_000000_35' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Carrier.bin/data/_temporary/0/task_20250711140257934320123356577854_0018_m_000000
[2025-07-11T14:02:58.477+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO SparkHadoopMapRedUtil: attempt_20250711140257934320123356577854_0018_m_000000_35: Committed. Elapsed time: 1 ms.
[2025-07-11T14:02:58.480+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO Executor: Finished task 0.0 in stage 18.0 (TID 35). 4783 bytes result sent to driver
[2025-07-11T14:02:58.481+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 35) in 896 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:02:58.481+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool
[2025-07-11T14:02:58.482+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO DAGScheduler: ResultStage 18 (parquet at StringIndexer.scala:499) finished in 0,932 s
[2025-07-11T14:02:58.482+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:02:58.483+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
[2025-07-11T14:02:58.484+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO DAGScheduler: Job 11 finished: parquet at StringIndexer.scala:499, took 0,935301 s
[2025-07-11T14:02:58.485+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO FileFormatWriter: Start to commit write Job 0b4ef181-8a11-4110-91eb-4d8f69a7d0c2.
[2025-07-11T14:02:58.507+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO FileFormatWriter: Write Job 0b4ef181-8a11-4110-91eb-4d8f69a7d0c2 committed. Elapsed time: 21 ms.
[2025-07-11T14:02:58.510+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO FileFormatWriter: Finished processing stats for write job 0b4ef181-8a11-4110-91eb-4d8f69a7d0c2.
[2025-07-11T14:02:58.556+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO V2ScanRelationPushDown:
[2025-07-11T14:02:58.556+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:02:58.556+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:02:58.556+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:02:58.556+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:02:58.586+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO V2ScanRelationPushDown:
[2025-07-11T14:02:58.586+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68
[2025-07-11T14:02:58.586+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:02:58.602+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:02:58.603+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:02:58.628+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO CodeGenerator: Code generated in 5.166473 ms
[2025-07-11T14:02:58.631+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 214.5 KiB, free 428.7 MiB)
[2025-07-11T14:02:58.640+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 428.7 MiB)
[2025-07-11T14:02:58.641+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 138.4.31.23:41705 (size: 38.9 KiB, free: 434.0 MiB)
[2025-07-11T14:02:58.641+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO SparkContext: Created broadcast 15 from collect at StringIndexer.scala:204
[2025-07-11T14:02:58.642+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:02:58.652+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO DAGScheduler: Registering RDD 44 (collect at StringIndexer.scala:204) as input to shuffle 6
[2025-07-11T14:02:58.652+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO DAGScheduler: Got map stage job 12 (collect at StringIndexer.scala:204) with 2 output partitions
[2025-07-11T14:02:58.654+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO DAGScheduler: Final stage: ShuffleMapStage 19 (collect at StringIndexer.scala:204)
[2025-07-11T14:02:58.654+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:02:58.654+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:02:58.654+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[44] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:02:58.654+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 16.9 KiB, free 428.6 MiB)
[2025-07-11T14:02:58.664+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 428.6 MiB)
[2025-07-11T14:02:58.664+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 138.4.31.23:41705 (size: 8.2 KiB, free: 434.0 MiB)
[2025-07-11T14:02:58.664+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:02:58.664+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[44] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:02:58.664+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO TaskSchedulerImpl: Adding task set 19.0 with 2 tasks resource profile 0
[2025-07-11T14:02:58.664+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 36) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:02:58.664+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 37) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:02:58.664+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO Executor: Running task 1.0 in stage 19.0 (TID 37)
[2025-07-11T14:02:58.664+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO DAGScheduler: Registering RDD 48 (collect at StringIndexer.scala:204) as input to shuffle 7
[2025-07-11T14:02:58.664+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO DAGScheduler: Got map stage job 13 (collect at StringIndexer.scala:204) with 12 output partitions
[2025-07-11T14:02:58.664+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO DAGScheduler: Final stage: ShuffleMapStage 20 (collect at StringIndexer.scala:204)
[2025-07-11T14:02:58.665+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:02:58.665+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:02:58.665+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[48] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:02:58.665+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO Executor: Running task 0.0 in stage 19.0 (TID 36)
[2025-07-11T14:02:58.665+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 18.2 KiB, free 428.6 MiB)
[2025-07-11T14:02:58.665+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 428.6 MiB)
[2025-07-11T14:02:58.665+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 138.4.31.23:41705 (size: 9.0 KiB, free: 434.0 MiB)
[2025-07-11T14:02:58.665+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:02:58.665+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[48] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
[2025-07-11T14:02:58.665+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO TaskSchedulerImpl: Adding task set 20.0 with 12 tasks resource profile 0
[2025-07-11T14:02:58.668+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO CodeGenerator: Code generated in 5.86998 ms
[2025-07-11T14:02:58.671+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:02:58.677+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:02:58.677+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 38) (138.4.31.23, executor driver, partition 0, ANY, 16719 bytes)
[2025-07-11T14:02:58.679+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 39) (138.4.31.23, executor driver, partition 1, ANY, 16719 bytes)
[2025-07-11T14:02:58.680+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO Executor: Running task 0.0 in stage 20.0 (TID 38)
[2025-07-11T14:02:58.680+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO Executor: Running task 1.0 in stage 20.0 (TID 39)
[2025-07-11T14:02:58.792+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO Executor: Finished task 0.0 in stage 20.0 (TID 38). 1945 bytes result sent to driver
[2025-07-11T14:02:58.794+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 40) (138.4.31.23, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-11T14:02:58.794+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO Executor: Finished task 1.0 in stage 20.0 (TID 39). 1945 bytes result sent to driver
[2025-07-11T14:02:58.794+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 38) in 123 ms on 138.4.31.23 (executor driver) (1/12)
[2025-07-11T14:02:58.794+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO Executor: Running task 2.0 in stage 20.0 (TID 40)
[2025-07-11T14:02:58.796+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 41) (138.4.31.23, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-11T14:02:58.797+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 39) in 119 ms on 138.4.31.23 (executor driver) (2/12)
[2025-07-11T14:02:58.798+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO Executor: Running task 3.0 in stage 20.0 (TID 41)
[2025-07-11T14:02:58.894+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO Executor: Finished task 3.0 in stage 20.0 (TID 41). 1988 bytes result sent to driver
[2025-07-11T14:02:58.900+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO TaskSetManager: Starting task 4.0 in stage 20.0 (TID 42) (138.4.31.23, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-11T14:02:58.901+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 41) in 104 ms on 138.4.31.23 (executor driver) (3/12)
[2025-07-11T14:02:58.904+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO Executor: Running task 4.0 in stage 20.0 (TID 42)
[2025-07-11T14:02:58.916+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO Executor: Finished task 2.0 in stage 20.0 (TID 40). 1945 bytes result sent to driver
[2025-07-11T14:02:58.918+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO TaskSetManager: Starting task 5.0 in stage 20.0 (TID 43) (138.4.31.23, executor driver, partition 5, ANY, 16839 bytes)
[2025-07-11T14:02:58.924+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 40) in 130 ms on 138.4.31.23 (executor driver) (4/12)
[2025-07-11T14:02:58.925+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO Executor: Running task 5.0 in stage 20.0 (TID 43)
[2025-07-11T14:02:58.969+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO Executor: Finished task 4.0 in stage 20.0 (TID 42). 1945 bytes result sent to driver
[2025-07-11T14:02:58.971+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO TaskSetManager: Starting task 6.0 in stage 20.0 (TID 44) (138.4.31.23, executor driver, partition 6, ANY, 16719 bytes)
[2025-07-11T14:02:58.971+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO Executor: Running task 6.0 in stage 20.0 (TID 44)
[2025-07-11T14:02:58.972+0200] {subprocess.py:93} INFO - 25/07/11 14:02:58 INFO TaskSetManager: Finished task 4.0 in stage 20.0 (TID 42) in 72 ms on 138.4.31.23 (executor driver) (5/12)
[2025-07-11T14:02:59.030+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO Executor: Finished task 5.0 in stage 20.0 (TID 43). 1945 bytes result sent to driver
[2025-07-11T14:02:59.032+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO TaskSetManager: Starting task 7.0 in stage 20.0 (TID 45) (138.4.31.23, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-11T14:02:59.032+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO TaskSetManager: Finished task 5.0 in stage 20.0 (TID 43) in 115 ms on 138.4.31.23 (executor driver) (6/12)
[2025-07-11T14:02:59.044+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO Executor: Running task 7.0 in stage 20.0 (TID 45)
[2025-07-11T14:02:59.073+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO Executor: Finished task 6.0 in stage 20.0 (TID 44). 1945 bytes result sent to driver
[2025-07-11T14:02:59.079+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO TaskSetManager: Starting task 8.0 in stage 20.0 (TID 46) (138.4.31.23, executor driver, partition 8, ANY, 16839 bytes)
[2025-07-11T14:02:59.079+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO TaskSetManager: Finished task 6.0 in stage 20.0 (TID 44) in 109 ms on 138.4.31.23 (executor driver) (7/12)
[2025-07-11T14:02:59.079+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO Executor: Running task 8.0 in stage 20.0 (TID 46)
[2025-07-11T14:02:59.165+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 138.4.31.23:41705 in memory (size: 83.6 KiB, free: 434.1 MiB)
[2025-07-11T14:02:59.186+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO Executor: Finished task 8.0 in stage 20.0 (TID 46). 1988 bytes result sent to driver
[2025-07-11T14:02:59.188+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO TaskSetManager: Starting task 9.0 in stage 20.0 (TID 47) (138.4.31.23, executor driver, partition 9, ANY, 16839 bytes)
[2025-07-11T14:02:59.190+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO TaskSetManager: Finished task 8.0 in stage 20.0 (TID 46) in 111 ms on 138.4.31.23 (executor driver) (8/12)
[2025-07-11T14:02:59.200+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO Executor: Running task 9.0 in stage 20.0 (TID 47)
[2025-07-11T14:02:59.212+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO Executor: Finished task 7.0 in stage 20.0 (TID 45). 1988 bytes result sent to driver
[2025-07-11T14:02:59.215+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO TaskSetManager: Starting task 10.0 in stage 20.0 (TID 48) (138.4.31.23, executor driver, partition 10, ANY, 16839 bytes)
[2025-07-11T14:02:59.216+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO TaskSetManager: Finished task 7.0 in stage 20.0 (TID 45) in 185 ms on 138.4.31.23 (executor driver) (9/12)
[2025-07-11T14:02:59.221+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO Executor: Running task 10.0 in stage 20.0 (TID 48)
[2025-07-11T14:02:59.231+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 138.4.31.23:41705 in memory (size: 4.4 KiB, free: 434.1 MiB)
[2025-07-11T14:02:59.317+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO Executor: Finished task 9.0 in stage 20.0 (TID 47). 1988 bytes result sent to driver
[2025-07-11T14:02:59.318+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO TaskSetManager: Starting task 11.0 in stage 20.0 (TID 49) (138.4.31.23, executor driver, partition 11, ANY, 16715 bytes)
[2025-07-11T14:02:59.318+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 138.4.31.23:41705 in memory (size: 36.5 KiB, free: 434.1 MiB)
[2025-07-11T14:02:59.320+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO Executor: Running task 11.0 in stage 20.0 (TID 49)
[2025-07-11T14:02:59.320+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO TaskSetManager: Finished task 9.0 in stage 20.0 (TID 47) in 132 ms on 138.4.31.23 (executor driver) (10/12)
[2025-07-11T14:02:59.324+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO Executor: Finished task 10.0 in stage 20.0 (TID 48). 1945 bytes result sent to driver
[2025-07-11T14:02:59.325+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO TaskSetManager: Finished task 10.0 in stage 20.0 (TID 48) in 111 ms on 138.4.31.23 (executor driver) (11/12)
[2025-07-11T14:02:59.357+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 138.4.31.23:41705 in memory (size: 23.6 KiB, free: 434.1 MiB)
[2025-07-11T14:02:59.387+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO Executor: Finished task 11.0 in stage 20.0 (TID 49). 1945 bytes result sent to driver
[2025-07-11T14:02:59.389+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO TaskSetManager: Finished task 11.0 in stage 20.0 (TID 49) in 72 ms on 138.4.31.23 (executor driver) (12/12)
[2025-07-11T14:02:59.390+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool
[2025-07-11T14:02:59.390+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO DAGScheduler: ShuffleMapStage 20 (collect at StringIndexer.scala:204) finished in 0,730 s
[2025-07-11T14:02:59.390+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:02:59.390+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO DAGScheduler: running: Set(ShuffleMapStage 19)
[2025-07-11T14:02:59.390+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:02:59.390+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO DAGScheduler: failed: Set()
[2025-07-11T14:02:59.395+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 138.4.31.23:41705 in memory (size: 24.0 KiB, free: 434.2 MiB)
[2025-07-11T14:02:59.404+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:02:59.445+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:02:59.446+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO DAGScheduler: Got job 14 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-11T14:02:59.446+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO DAGScheduler: Final stage: ResultStage 22 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-11T14:02:59.446+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
[2025-07-11T14:02:59.446+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:02:59.447+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[50] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-11T14:02:59.448+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 8.2 KiB, free 429.2 MiB)
[2025-07-11T14:02:59.449+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 429.2 MiB)
[2025-07-11T14:02:59.449+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 138.4.31.23:41705 (size: 4.2 KiB, free: 434.2 MiB)
[2025-07-11T14:02:59.450+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:02:59.450+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[50] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:02:59.451+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
[2025-07-11T14:02:59.452+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 50) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-11T14:02:59.452+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO Executor: Running task 0.0 in stage 22.0 (TID 50)
[2025-07-11T14:02:59.458+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO ShuffleBlockFetcherIterator: Getting 12 (193.3 KiB) non-empty blocks including 12 (193.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:02:59.459+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-11T14:02:59.479+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO Executor: Finished task 0.0 in stage 22.0 (TID 50). 40667 bytes result sent to driver
[2025-07-11T14:02:59.480+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 50) in 28 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:02:59.480+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool
[2025-07-11T14:02:59.481+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO DAGScheduler: ResultStage 22 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,034 s
[2025-07-11T14:02:59.481+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:02:59.481+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
[2025-07-11T14:02:59.486+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO DAGScheduler: Job 14 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,035864 s
[2025-07-11T14:02:59.494+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 4.3 MiB, free 425.0 MiB)
[2025-07-11T14:02:59.498+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 89.6 KiB, free 424.9 MiB)
[2025-07-11T14:02:59.498+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 138.4.31.23:41705 (size: 89.6 KiB, free: 434.1 MiB)
[2025-07-11T14:02:59.499+0200] {subprocess.py:93} INFO - 25/07/11 14:02:59 INFO SparkContext: Created broadcast 19 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:03:00.221+0200] {subprocess.py:93} INFO - 25/07/11 14:03:00 INFO Executor: Finished task 1.0 in stage 19.0 (TID 37). 2031 bytes result sent to driver
[2025-07-11T14:03:00.222+0200] {subprocess.py:93} INFO - 25/07/11 14:03:00 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 37) in 1564 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:03:00.476+0200] {subprocess.py:93} INFO - 25/07/11 14:03:00 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 138.4.31.23:41705 in memory (size: 4.2 KiB, free: 434.1 MiB)
[2025-07-11T14:03:05.908+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO Executor: Finished task 0.0 in stage 19.0 (TID 36). 2031 bytes result sent to driver
[2025-07-11T14:03:05.908+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 36) in 7251 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:03:05.909+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool
[2025-07-11T14:03:05.909+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO DAGScheduler: ShuffleMapStage 19 (collect at StringIndexer.scala:204) finished in 7,257 s
[2025-07-11T14:03:05.909+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:03:05.909+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO DAGScheduler: running: Set()
[2025-07-11T14:03:05.910+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:03:05.910+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO DAGScheduler: failed: Set()
[2025-07-11T14:03:05.914+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO ShufflePartitionsUtil: For shuffle(6), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:03:05.933+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO CodeGenerator: Code generated in 6.625848 ms
[2025-07-11T14:03:05.938+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO DAGScheduler: Registering RDD 54 (collect at StringIndexer.scala:204) as input to shuffle 8
[2025-07-11T14:03:05.939+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO DAGScheduler: Got map stage job 15 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-11T14:03:05.939+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO DAGScheduler: Final stage: ShuffleMapStage 24 (collect at StringIndexer.scala:204)
[2025-07-11T14:03:05.939+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
[2025-07-11T14:03:05.939+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:05.939+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[54] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:03:05.941+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 50.6 KiB, free 424.8 MiB)
[2025-07-11T14:03:05.942+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 24.1 KiB, free 424.8 MiB)
[2025-07-11T14:03:05.942+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 138.4.31.23:41705 (size: 24.1 KiB, free: 434.1 MiB)
[2025-07-11T14:03:05.943+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:05.944+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[54] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:05.944+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
[2025-07-11T14:03:05.949+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 51) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14833 bytes)
[2025-07-11T14:03:05.949+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO Executor: Running task 0.0 in stage 24.0 (TID 51)
[2025-07-11T14:03:05.957+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO ShuffleBlockFetcherIterator: Getting 2 (887.5 KiB) non-empty blocks including 2 (887.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:05.957+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:05.964+0200] {subprocess.py:93} INFO - 25/07/11 14:03:05 INFO CodeGenerator: Code generated in 8.071009 ms
[2025-07-11T14:03:06.250+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO Executor: Finished task 0.0 in stage 24.0 (TID 51). 6500 bytes result sent to driver
[2025-07-11T14:03:06.252+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 51) in 304 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:06.253+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool
[2025-07-11T14:03:06.257+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: ShuffleMapStage 24 (collect at StringIndexer.scala:204) finished in 0,314 s
[2025-07-11T14:03:06.257+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:03:06.258+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: running: Set()
[2025-07-11T14:03:06.258+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:03:06.258+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: failed: Set()
[2025-07-11T14:03:06.276+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
[2025-07-11T14:03:06.277+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Got job 16 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-11T14:03:06.277+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Final stage: ResultStage 27 (collect at StringIndexer.scala:204)
[2025-07-11T14:03:06.277+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
[2025-07-11T14:03:06.277+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:06.277+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[57] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:03:06.280+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 49.7 KiB, free 424.8 MiB)
[2025-07-11T14:03:06.281+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 424.7 MiB)
[2025-07-11T14:03:06.281+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 138.4.31.23:41705 (size: 23.6 KiB, free: 434.0 MiB)
[2025-07-11T14:03:06.282+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:06.282+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[57] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:06.282+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
[2025-07-11T14:03:06.284+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 52) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:03:06.285+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO Executor: Running task 0.0 in stage 27.0 (TID 52)
[2025-07-11T14:03:06.293+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO ShuffleBlockFetcherIterator: Getting 1 (3.2 KiB) non-empty blocks including 1 (3.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:06.293+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:06.317+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO Executor: Finished task 0.0 in stage 27.0 (TID 52). 10936 bytes result sent to driver
[2025-07-11T14:03:06.317+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 52) in 33 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:06.317+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool
[2025-07-11T14:03:06.318+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: ResultStage 27 (collect at StringIndexer.scala:204) finished in 0,039 s
[2025-07-11T14:03:06.318+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:03:06.319+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
[2025-07-11T14:03:06.319+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Job 16 finished: collect at StringIndexer.scala:204, took 0,041912 s
[2025-07-11T14:03:06.375+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileSystemOverwrite: Path /home/monica.fernandez/practica_creativa/models/string_indexer_model_Origin.bin already exists. It will be overwritten.
[2025-07-11T14:03:06.389+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:03:06.390+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:03:06.390+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:03:06.421+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-11T14:03:06.421+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Got job 17 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-11T14:03:06.422+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Final stage: ResultStage 28 (runJob at SparkHadoopWriter.scala:83)
[2025-07-11T14:03:06.422+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:03:06.422+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:06.422+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[59] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-11T14:03:06.432+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 101.3 KiB, free 424.6 MiB)
[2025-07-11T14:03:06.433+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 424.6 MiB)
[2025-07-11T14:03:06.433+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 138.4.31.23:41705 (size: 36.5 KiB, free: 434.0 MiB)
[2025-07-11T14:03:06.433+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:06.433+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[59] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:06.433+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
[2025-07-11T14:03:06.434+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 53) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15156 bytes)
[2025-07-11T14:03:06.434+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO Executor: Running task 0.0 in stage 28.0 (TID 53)
[2025-07-11T14:03:06.441+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:03:06.441+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:03:06.441+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:03:06.468+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileOutputCommitter: Saved output of task 'attempt_20250711140306817252967931050600_0059_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Origin.bin/metadata/_temporary/0/task_20250711140306817252967931050600_0059_m_000000
[2025-07-11T14:03:06.468+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO SparkHadoopMapRedUtil: attempt_20250711140306817252967931050600_0059_m_000000_0: Committed. Elapsed time: 1 ms.
[2025-07-11T14:03:06.470+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO Executor: Finished task 0.0 in stage 28.0 (TID 53). 1170 bytes result sent to driver
[2025-07-11T14:03:06.470+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 53) in 36 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:06.470+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool
[2025-07-11T14:03:06.471+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: ResultStage 28 (runJob at SparkHadoopWriter.scala:83) finished in 0,049 s
[2025-07-11T14:03:06.472+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:03:06.472+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
[2025-07-11T14:03:06.472+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Job 17 finished: runJob at SparkHadoopWriter.scala:83, took 0,050796 s
[2025-07-11T14:03:06.472+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO SparkHadoopWriter: Start to commit write Job job_20250711140306817252967931050600_0059.
[2025-07-11T14:03:06.494+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO SparkHadoopWriter: Write Job job_20250711140306817252967931050600_0059 committed. Elapsed time: 21 ms.
[2025-07-11T14:03:06.528+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Registering RDD 62 (parquet at StringIndexer.scala:499) as input to shuffle 9
[2025-07-11T14:03:06.528+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Got map stage job 18 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-11T14:03:06.528+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Final stage: ShuffleMapStage 29 (parquet at StringIndexer.scala:499)
[2025-07-11T14:03:06.528+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:03:06.528+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:06.528+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[62] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-11T14:03:06.530+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 8.1 KiB, free 424.6 MiB)
[2025-07-11T14:03:06.531+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 424.6 MiB)
[2025-07-11T14:03:06.531+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 138.4.31.23:41705 (size: 4.4 KiB, free: 434.0 MiB)
[2025-07-11T14:03:06.531+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:06.532+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[62] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:06.532+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
[2025-07-11T14:03:06.533+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 54) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 20076 bytes)
[2025-07-11T14:03:06.533+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO Executor: Running task 0.0 in stage 29.0 (TID 54)
[2025-07-11T14:03:06.538+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO Executor: Finished task 0.0 in stage 29.0 (TID 54). 1628 bytes result sent to driver
[2025-07-11T14:03:06.538+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 54) in 6 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:06.538+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool
[2025-07-11T14:03:06.539+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: ShuffleMapStage 29 (parquet at StringIndexer.scala:499) finished in 0,009 s
[2025-07-11T14:03:06.539+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:03:06.539+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: running: Set()
[2025-07-11T14:03:06.539+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:03:06.539+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: failed: Set()
[2025-07-11T14:03:06.545+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:03:06.546+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:03:06.546+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:03:06.547+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:03:06.547+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:03:06.547+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:03:06.548+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:03:06.566+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO SparkContext: Starting job: parquet at StringIndexer.scala:499
[2025-07-11T14:03:06.567+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Got job 19 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-11T14:03:06.567+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Final stage: ResultStage 31 (parquet at StringIndexer.scala:499)
[2025-07-11T14:03:06.567+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)
[2025-07-11T14:03:06.569+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:06.569+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[64] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-11T14:03:06.592+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 239.5 KiB, free 424.4 MiB)
[2025-07-11T14:03:06.594+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 83.6 KiB, free 424.3 MiB)
[2025-07-11T14:03:06.595+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 138.4.31.23:41705 (size: 83.6 KiB, free: 433.9 MiB)
[2025-07-11T14:03:06.596+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:06.596+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[64] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:06.596+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
[2025-07-11T14:03:06.597+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 55) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:03:06.598+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO Executor: Running task 0.0 in stage 31.0 (TID 55)
[2025-07-11T14:03:06.613+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:06.614+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-11T14:03:06.615+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:03:06.615+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:03:06.615+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:03:06.615+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:03:06.616+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:03:06.616+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:03:06.617+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:03:06.617+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:03:06.618+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-11T14:03:06.619+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-11T14:03:06.619+0200] {subprocess.py:93} INFO - {
[2025-07-11T14:03:06.619+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-11T14:03:06.619+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-11T14:03:06.619+0200] {subprocess.py:93} INFO -     "name" : "labelsArray",
[2025-07-11T14:03:06.619+0200] {subprocess.py:93} INFO -     "type" : {
[2025-07-11T14:03:06.619+0200] {subprocess.py:93} INFO -       "type" : "array",
[2025-07-11T14:03:06.619+0200] {subprocess.py:93} INFO -       "elementType" : {
[2025-07-11T14:03:06.619+0200] {subprocess.py:93} INFO -         "type" : "array",
[2025-07-11T14:03:06.619+0200] {subprocess.py:93} INFO -         "elementType" : "string",
[2025-07-11T14:03:06.619+0200] {subprocess.py:93} INFO -         "containsNull" : true
[2025-07-11T14:03:06.619+0200] {subprocess.py:93} INFO -       },
[2025-07-11T14:03:06.619+0200] {subprocess.py:93} INFO -       "containsNull" : true
[2025-07-11T14:03:06.620+0200] {subprocess.py:93} INFO -     },
[2025-07-11T14:03:06.620+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-11T14:03:06.620+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:03:06.620+0200] {subprocess.py:93} INFO -   } ]
[2025-07-11T14:03:06.620+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:03:06.620+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-11T14:03:06.620+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-11T14:03:06.620+0200] {subprocess.py:93} INFO -   optional group labelsArray (LIST) {
[2025-07-11T14:03:06.620+0200] {subprocess.py:93} INFO -     repeated group list {
[2025-07-11T14:03:06.620+0200] {subprocess.py:93} INFO -       optional group element (LIST) {
[2025-07-11T14:03:06.620+0200] {subprocess.py:93} INFO -         repeated group list {
[2025-07-11T14:03:06.620+0200] {subprocess.py:93} INFO -           optional binary element (STRING);
[2025-07-11T14:03:06.620+0200] {subprocess.py:93} INFO -         }
[2025-07-11T14:03:06.620+0200] {subprocess.py:93} INFO -       }
[2025-07-11T14:03:06.620+0200] {subprocess.py:93} INFO -     }
[2025-07-11T14:03:06.620+0200] {subprocess.py:93} INFO -   }
[2025-07-11T14:03:06.620+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:03:06.620+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:03:06.621+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:03:06.662+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileOutputCommitter: Saved output of task 'attempt_202507111403066605491686598548335_0031_m_000000_55' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Origin.bin/data/_temporary/0/task_202507111403066605491686598548335_0031_m_000000
[2025-07-11T14:03:06.662+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO SparkHadoopMapRedUtil: attempt_202507111403066605491686598548335_0031_m_000000_55: Committed. Elapsed time: 1 ms.
[2025-07-11T14:03:06.663+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO Executor: Finished task 0.0 in stage 31.0 (TID 55). 4740 bytes result sent to driver
[2025-07-11T14:03:06.664+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 55) in 67 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:06.665+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool
[2025-07-11T14:03:06.665+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: ResultStage 31 (parquet at StringIndexer.scala:499) finished in 0,093 s
[2025-07-11T14:03:06.665+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:03:06.665+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
[2025-07-11T14:03:06.666+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Job 19 finished: parquet at StringIndexer.scala:499, took 0,099549 s
[2025-07-11T14:03:06.666+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileFormatWriter: Start to commit write Job 55f1521d-6785-4f4c-989a-0015b58a6e4e.
[2025-07-11T14:03:06.690+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileFormatWriter: Write Job 55f1521d-6785-4f4c-989a-0015b58a6e4e committed. Elapsed time: 23 ms.
[2025-07-11T14:03:06.690+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileFormatWriter: Finished processing stats for write job 55f1521d-6785-4f4c-989a-0015b58a6e4e.
[2025-07-11T14:03:06.789+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO V2ScanRelationPushDown:
[2025-07-11T14:03:06.789+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:03:06.789+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:03:06.789+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:03:06.789+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:03:06.801+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO V2ScanRelationPushDown:
[2025-07-11T14:03:06.801+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68
[2025-07-11T14:03:06.801+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:03:06.823+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:03:06.823+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:03:06.846+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 214.5 KiB, free 424.1 MiB)
[2025-07-11T14:03:06.855+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 424.0 MiB)
[2025-07-11T14:03:06.855+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 138.4.31.23:41705 (size: 38.9 KiB, free: 433.9 MiB)
[2025-07-11T14:03:06.856+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO SparkContext: Created broadcast 25 from collect at StringIndexer.scala:204
[2025-07-11T14:03:06.857+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:03:06.863+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Registering RDD 68 (collect at StringIndexer.scala:204) as input to shuffle 10
[2025-07-11T14:03:06.863+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Got map stage job 20 (collect at StringIndexer.scala:204) with 2 output partitions
[2025-07-11T14:03:06.863+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Final stage: ShuffleMapStage 32 (collect at StringIndexer.scala:204)
[2025-07-11T14:03:06.863+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:03:06.863+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:06.863+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[68] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:03:06.865+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 16.9 KiB, free 424.0 MiB)
[2025-07-11T14:03:06.866+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 424.0 MiB)
[2025-07-11T14:03:06.866+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 138.4.31.23:41705 (size: 8.2 KiB, free: 433.9 MiB)
[2025-07-11T14:03:06.867+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:06.867+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[68] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:03:06.868+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSchedulerImpl: Adding task set 32.0 with 2 tasks resource profile 0
[2025-07-11T14:03:06.870+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 56) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:03:06.870+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 57) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:03:06.870+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO Executor: Running task 0.0 in stage 32.0 (TID 56)
[2025-07-11T14:03:06.871+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO Executor: Running task 1.0 in stage 32.0 (TID 57)
[2025-07-11T14:03:06.877+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:03:06.880+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Registering RDD 72 (collect at StringIndexer.scala:204) as input to shuffle 11
[2025-07-11T14:03:06.881+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Got map stage job 21 (collect at StringIndexer.scala:204) with 12 output partitions
[2025-07-11T14:03:06.881+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Final stage: ShuffleMapStage 33 (collect at StringIndexer.scala:204)
[2025-07-11T14:03:06.881+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:03:06.881+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:06.881+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[72] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:03:06.883+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 18.2 KiB, free 424.0 MiB)
[2025-07-11T14:03:06.884+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 424.0 MiB)
[2025-07-11T14:03:06.884+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 138.4.31.23:41705 (size: 9.1 KiB, free: 433.9 MiB)
[2025-07-11T14:03:06.884+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:06.885+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[72] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
[2025-07-11T14:03:06.885+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSchedulerImpl: Adding task set 33.0 with 12 tasks resource profile 0
[2025-07-11T14:03:06.885+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:03:06.887+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 58) (138.4.31.23, executor driver, partition 0, ANY, 16839 bytes)
[2025-07-11T14:03:06.887+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 59) (138.4.31.23, executor driver, partition 1, ANY, 16839 bytes)
[2025-07-11T14:03:06.887+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO Executor: Running task 1.0 in stage 33.0 (TID 59)
[2025-07-11T14:03:06.889+0200] {subprocess.py:93} INFO - 25/07/11 14:03:06 INFO Executor: Running task 0.0 in stage 33.0 (TID 58)
[2025-07-11T14:03:07.082+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Finished task 0.0 in stage 33.0 (TID 58). 1945 bytes result sent to driver
[2025-07-11T14:03:07.087+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 60) (138.4.31.23, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-11T14:03:07.088+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 58) in 202 ms on 138.4.31.23 (executor driver) (1/12)
[2025-07-11T14:03:07.089+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Running task 2.0 in stage 33.0 (TID 60)
[2025-07-11T14:03:07.101+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Finished task 1.0 in stage 33.0 (TID 59). 1945 bytes result sent to driver
[2025-07-11T14:03:07.103+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Starting task 3.0 in stage 33.0 (TID 61) (138.4.31.23, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-11T14:03:07.104+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 59) in 216 ms on 138.4.31.23 (executor driver) (2/12)
[2025-07-11T14:03:07.104+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Running task 3.0 in stage 33.0 (TID 61)
[2025-07-11T14:03:07.195+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Finished task 2.0 in stage 33.0 (TID 60). 1945 bytes result sent to driver
[2025-07-11T14:03:07.204+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Starting task 4.0 in stage 33.0 (TID 62) (138.4.31.23, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-11T14:03:07.205+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Running task 4.0 in stage 33.0 (TID 62)
[2025-07-11T14:03:07.209+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 60) in 121 ms on 138.4.31.23 (executor driver) (3/12)
[2025-07-11T14:03:07.243+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Finished task 3.0 in stage 33.0 (TID 61). 2031 bytes result sent to driver
[2025-07-11T14:03:07.246+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Starting task 5.0 in stage 33.0 (TID 63) (138.4.31.23, executor driver, partition 5, ANY, 16715 bytes)
[2025-07-11T14:03:07.246+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 138.4.31.23:41705 in memory (size: 36.5 KiB, free: 433.9 MiB)
[2025-07-11T14:03:07.246+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Finished task 3.0 in stage 33.0 (TID 61) in 144 ms on 138.4.31.23 (executor driver) (4/12)
[2025-07-11T14:03:07.249+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Running task 5.0 in stage 33.0 (TID 63)
[2025-07-11T14:03:07.256+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 138.4.31.23:41705 in memory (size: 4.4 KiB, free: 433.9 MiB)
[2025-07-11T14:03:07.285+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 138.4.31.23:41705 in memory (size: 83.6 KiB, free: 434.0 MiB)
[2025-07-11T14:03:07.335+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Finished task 5.0 in stage 33.0 (TID 63). 1945 bytes result sent to driver
[2025-07-11T14:03:07.336+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Starting task 6.0 in stage 33.0 (TID 64) (138.4.31.23, executor driver, partition 6, ANY, 16719 bytes)
[2025-07-11T14:03:07.337+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Finished task 5.0 in stage 33.0 (TID 63) in 91 ms on 138.4.31.23 (executor driver) (5/12)
[2025-07-11T14:03:07.344+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Running task 6.0 in stage 33.0 (TID 64)
[2025-07-11T14:03:07.355+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Finished task 4.0 in stage 33.0 (TID 62). 1988 bytes result sent to driver
[2025-07-11T14:03:07.357+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Starting task 7.0 in stage 33.0 (TID 65) (138.4.31.23, executor driver, partition 7, ANY, 16839 bytes)
[2025-07-11T14:03:07.357+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Running task 7.0 in stage 33.0 (TID 65)
[2025-07-11T14:03:07.357+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Finished task 4.0 in stage 33.0 (TID 62) in 153 ms on 138.4.31.23 (executor driver) (6/12)
[2025-07-11T14:03:07.387+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 138.4.31.23:41705 in memory (size: 23.6 KiB, free: 434.0 MiB)
[2025-07-11T14:03:07.440+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Finished task 6.0 in stage 33.0 (TID 64). 1945 bytes result sent to driver
[2025-07-11T14:03:07.442+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Starting task 8.0 in stage 33.0 (TID 66) (138.4.31.23, executor driver, partition 8, ANY, 16719 bytes)
[2025-07-11T14:03:07.442+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Finished task 6.0 in stage 33.0 (TID 64) in 107 ms on 138.4.31.23 (executor driver) (7/12)
[2025-07-11T14:03:07.445+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Running task 8.0 in stage 33.0 (TID 66)
[2025-07-11T14:03:07.453+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 138.4.31.23:41705 in memory (size: 24.1 KiB, free: 434.0 MiB)
[2025-07-11T14:03:07.464+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Finished task 7.0 in stage 33.0 (TID 65). 1988 bytes result sent to driver
[2025-07-11T14:03:07.465+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Starting task 9.0 in stage 33.0 (TID 67) (138.4.31.23, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-11T14:03:07.465+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Finished task 7.0 in stage 33.0 (TID 65) in 109 ms on 138.4.31.23 (executor driver) (8/12)
[2025-07-11T14:03:07.465+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Running task 9.0 in stage 33.0 (TID 67)
[2025-07-11T14:03:07.559+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Finished task 8.0 in stage 33.0 (TID 66). 1945 bytes result sent to driver
[2025-07-11T14:03:07.561+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Starting task 10.0 in stage 33.0 (TID 68) (138.4.31.23, executor driver, partition 10, ANY, 16839 bytes)
[2025-07-11T14:03:07.562+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Running task 10.0 in stage 33.0 (TID 68)
[2025-07-11T14:03:07.562+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Finished task 8.0 in stage 33.0 (TID 66) in 119 ms on 138.4.31.23 (executor driver) (9/12)
[2025-07-11T14:03:07.578+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Finished task 9.0 in stage 33.0 (TID 67). 1945 bytes result sent to driver
[2025-07-11T14:03:07.579+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Starting task 11.0 in stage 33.0 (TID 69) (138.4.31.23, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-11T14:03:07.581+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Finished task 9.0 in stage 33.0 (TID 67) in 116 ms on 138.4.31.23 (executor driver) (10/12)
[2025-07-11T14:03:07.582+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Running task 11.0 in stage 33.0 (TID 69)
[2025-07-11T14:03:07.672+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Finished task 11.0 in stage 33.0 (TID 69). 1945 bytes result sent to driver
[2025-07-11T14:03:07.673+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Finished task 11.0 in stage 33.0 (TID 69) in 94 ms on 138.4.31.23 (executor driver) (11/12)
[2025-07-11T14:03:07.682+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Finished task 10.0 in stage 33.0 (TID 68). 1945 bytes result sent to driver
[2025-07-11T14:03:07.683+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Finished task 10.0 in stage 33.0 (TID 68) in 122 ms on 138.4.31.23 (executor driver) (12/12)
[2025-07-11T14:03:07.683+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool
[2025-07-11T14:03:07.684+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO DAGScheduler: ShuffleMapStage 33 (collect at StringIndexer.scala:204) finished in 0,803 s
[2025-07-11T14:03:07.684+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:03:07.685+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO DAGScheduler: running: Set(ShuffleMapStage 32)
[2025-07-11T14:03:07.685+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:03:07.685+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO DAGScheduler: failed: Set()
[2025-07-11T14:03:07.696+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO ShufflePartitionsUtil: For shuffle(11), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:03:07.722+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:03:07.723+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO DAGScheduler: Got job 22 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-11T14:03:07.723+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO DAGScheduler: Final stage: ResultStage 35 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-11T14:03:07.724+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
[2025-07-11T14:03:07.724+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:07.724+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[74] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-11T14:03:07.725+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 8.2 KiB, free 424.6 MiB)
[2025-07-11T14:03:07.726+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 424.6 MiB)
[2025-07-11T14:03:07.727+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 138.4.31.23:41705 (size: 4.2 KiB, free: 434.0 MiB)
[2025-07-11T14:03:07.728+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:07.728+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[74] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:07.728+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0
[2025-07-11T14:03:07.734+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 70) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-11T14:03:07.734+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Running task 0.0 in stage 35.0 (TID 70)
[2025-07-11T14:03:07.736+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO ShuffleBlockFetcherIterator: Getting 12 (193.3 KiB) non-empty blocks including 12 (193.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:07.736+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-11T14:03:07.761+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO Executor: Finished task 0.0 in stage 35.0 (TID 70). 40669 bytes result sent to driver
[2025-07-11T14:03:07.763+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 70) in 33 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:07.763+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool
[2025-07-11T14:03:07.764+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO DAGScheduler: ResultStage 35 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,038 s
[2025-07-11T14:03:07.764+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:03:07.764+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
[2025-07-11T14:03:07.764+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO DAGScheduler: Job 22 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,040210 s
[2025-07-11T14:03:07.773+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 4.3 MiB, free 420.3 MiB)
[2025-07-11T14:03:07.777+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 89.6 KiB, free 420.2 MiB)
[2025-07-11T14:03:07.777+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 138.4.31.23:41705 (size: 89.6 KiB, free: 433.9 MiB)
[2025-07-11T14:03:07.779+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO SparkContext: Created broadcast 29 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:03:07.858+0200] {subprocess.py:93} INFO - 25/07/11 14:03:07 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 138.4.31.23:41705 in memory (size: 4.2 KiB, free: 433.9 MiB)
[2025-07-11T14:03:08.375+0200] {subprocess.py:93} INFO - 25/07/11 14:03:08 INFO Executor: Finished task 1.0 in stage 32.0 (TID 57). 2031 bytes result sent to driver
[2025-07-11T14:03:08.377+0200] {subprocess.py:93} INFO - 25/07/11 14:03:08 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 57) in 1508 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:03:14.151+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO Executor: Finished task 0.0 in stage 32.0 (TID 56). 2031 bytes result sent to driver
[2025-07-11T14:03:14.152+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 56) in 7283 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:03:14.152+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool
[2025-07-11T14:03:14.152+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: ShuffleMapStage 32 (collect at StringIndexer.scala:204) finished in 7,288 s
[2025-07-11T14:03:14.152+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:03:14.153+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: running: Set()
[2025-07-11T14:03:14.153+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:03:14.153+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: failed: Set()
[2025-07-11T14:03:14.158+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:03:14.176+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO CodeGenerator: Code generated in 6.769772 ms
[2025-07-11T14:03:14.179+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Registering RDD 78 (collect at StringIndexer.scala:204) as input to shuffle 12
[2025-07-11T14:03:14.179+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Got map stage job 23 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-11T14:03:14.179+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Final stage: ShuffleMapStage 37 (collect at StringIndexer.scala:204)
[2025-07-11T14:03:14.180+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)
[2025-07-11T14:03:14.180+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:14.180+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[78] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:03:14.184+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 50.6 KiB, free 420.2 MiB)
[2025-07-11T14:03:14.187+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 24.1 KiB, free 420.2 MiB)
[2025-07-11T14:03:14.187+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 138.4.31.23:41705 (size: 24.1 KiB, free: 433.9 MiB)
[2025-07-11T14:03:14.188+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:14.188+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[78] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:14.188+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0
[2025-07-11T14:03:14.189+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 71) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14833 bytes)
[2025-07-11T14:03:14.190+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO Executor: Running task 0.0 in stage 37.0 (TID 71)
[2025-07-11T14:03:14.195+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO ShuffleBlockFetcherIterator: Getting 2 (887.5 KiB) non-empty blocks including 2 (887.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:14.195+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:14.201+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO CodeGenerator: Code generated in 5.88405 ms
[2025-07-11T14:03:14.440+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO Executor: Finished task 0.0 in stage 37.0 (TID 71). 6586 bytes result sent to driver
[2025-07-11T14:03:14.440+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 71) in 251 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:14.440+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool
[2025-07-11T14:03:14.441+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: ShuffleMapStage 37 (collect at StringIndexer.scala:204) finished in 0,261 s
[2025-07-11T14:03:14.441+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:03:14.441+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: running: Set()
[2025-07-11T14:03:14.442+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:03:14.442+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: failed: Set()
[2025-07-11T14:03:14.456+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
[2025-07-11T14:03:14.459+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Got job 24 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-11T14:03:14.459+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Final stage: ResultStage 40 (collect at StringIndexer.scala:204)
[2025-07-11T14:03:14.459+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)
[2025-07-11T14:03:14.459+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:14.459+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[81] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:03:14.461+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 49.7 KiB, free 420.1 MiB)
[2025-07-11T14:03:14.466+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 420.1 MiB)
[2025-07-11T14:03:14.466+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 138.4.31.23:41705 (size: 23.6 KiB, free: 433.9 MiB)
[2025-07-11T14:03:14.467+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 138.4.31.23:41705 in memory (size: 24.1 KiB, free: 433.9 MiB)
[2025-07-11T14:03:14.467+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:14.467+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[81] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:14.467+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
[2025-07-11T14:03:14.468+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 72) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:03:14.468+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO Executor: Running task 0.0 in stage 40.0 (TID 72)
[2025-07-11T14:03:14.473+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO ShuffleBlockFetcherIterator: Getting 1 (3.2 KiB) non-empty blocks including 1 (3.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:14.473+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:14.493+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO Executor: Finished task 0.0 in stage 40.0 (TID 72). 11006 bytes result sent to driver
[2025-07-11T14:03:14.494+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 72) in 27 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:14.494+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool
[2025-07-11T14:03:14.496+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: ResultStage 40 (collect at StringIndexer.scala:204) finished in 0,038 s
[2025-07-11T14:03:14.496+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:03:14.497+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
[2025-07-11T14:03:14.497+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Job 24 finished: collect at StringIndexer.scala:204, took 0,040445 s
[2025-07-11T14:03:14.550+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO FileSystemOverwrite: Path /home/monica.fernandez/practica_creativa/models/string_indexer_model_Dest.bin already exists. It will be overwritten.
[2025-07-11T14:03:14.568+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:03:14.568+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:03:14.568+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:03:14.597+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-11T14:03:14.599+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Got job 25 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-11T14:03:14.599+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Final stage: ResultStage 41 (runJob at SparkHadoopWriter.scala:83)
[2025-07-11T14:03:14.599+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:03:14.599+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:14.599+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[83] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-11T14:03:14.607+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 101.3 KiB, free 420.1 MiB)
[2025-07-11T14:03:14.613+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 420.0 MiB)
[2025-07-11T14:03:14.613+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 138.4.31.23:41705 (size: 36.5 KiB, free: 433.9 MiB)
[2025-07-11T14:03:14.614+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:14.614+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[83] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:14.614+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
[2025-07-11T14:03:14.615+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 73) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15152 bytes)
[2025-07-11T14:03:14.618+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO Executor: Running task 0.0 in stage 41.0 (TID 73)
[2025-07-11T14:03:14.622+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:03:14.622+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:03:14.622+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:03:14.623+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 138.4.31.23:41705 in memory (size: 23.6 KiB, free: 433.9 MiB)
[2025-07-11T14:03:14.650+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO FileOutputCommitter: Saved output of task 'attempt_202507111403145112821652869608006_0083_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Dest.bin/metadata/_temporary/0/task_202507111403145112821652869608006_0083_m_000000
[2025-07-11T14:03:14.650+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO SparkHadoopMapRedUtil: attempt_202507111403145112821652869608006_0083_m_000000_0: Committed. Elapsed time: 1 ms.
[2025-07-11T14:03:14.655+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO Executor: Finished task 0.0 in stage 41.0 (TID 73). 1256 bytes result sent to driver
[2025-07-11T14:03:14.656+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 73) in 41 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:14.656+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool
[2025-07-11T14:03:14.656+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: ResultStage 41 (runJob at SparkHadoopWriter.scala:83) finished in 0,057 s
[2025-07-11T14:03:14.657+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:03:14.657+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished
[2025-07-11T14:03:14.657+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Job 25 finished: runJob at SparkHadoopWriter.scala:83, took 0,058658 s
[2025-07-11T14:03:14.657+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO SparkHadoopWriter: Start to commit write Job job_202507111403145112821652869608006_0083.
[2025-07-11T14:03:14.678+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO SparkHadoopWriter: Write Job job_202507111403145112821652869608006_0083 committed. Elapsed time: 21 ms.
[2025-07-11T14:03:14.707+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Registering RDD 86 (parquet at StringIndexer.scala:499) as input to shuffle 13
[2025-07-11T14:03:14.708+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Got map stage job 26 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-11T14:03:14.708+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Final stage: ShuffleMapStage 42 (parquet at StringIndexer.scala:499)
[2025-07-11T14:03:14.708+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:03:14.708+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:14.708+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[86] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-11T14:03:14.709+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 8.1 KiB, free 420.1 MiB)
[2025-07-11T14:03:14.712+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 420.1 MiB)
[2025-07-11T14:03:14.713+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 138.4.31.23:41705 (size: 4.4 KiB, free: 433.9 MiB)
[2025-07-11T14:03:14.714+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:14.715+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 138.4.31.23:41705 in memory (size: 36.5 KiB, free: 433.9 MiB)
[2025-07-11T14:03:14.716+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[86] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:14.716+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
[2025-07-11T14:03:14.718+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 74) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 20076 bytes)
[2025-07-11T14:03:14.718+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO Executor: Running task 0.0 in stage 42.0 (TID 74)
[2025-07-11T14:03:14.729+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO Executor: Finished task 0.0 in stage 42.0 (TID 74). 1714 bytes result sent to driver
[2025-07-11T14:03:14.730+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 74) in 13 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:14.730+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool
[2025-07-11T14:03:14.731+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: ShuffleMapStage 42 (parquet at StringIndexer.scala:499) finished in 0,023 s
[2025-07-11T14:03:14.731+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:03:14.731+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: running: Set()
[2025-07-11T14:03:14.734+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:03:14.734+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: failed: Set()
[2025-07-11T14:03:14.737+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:03:14.738+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:03:14.738+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:03:14.738+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:03:14.738+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:03:14.739+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:03:14.739+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:03:14.757+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO SparkContext: Starting job: parquet at StringIndexer.scala:499
[2025-07-11T14:03:14.759+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Got job 27 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-11T14:03:14.759+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Final stage: ResultStage 44 (parquet at StringIndexer.scala:499)
[2025-07-11T14:03:14.759+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
[2025-07-11T14:03:14.759+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:14.759+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[88] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-11T14:03:14.775+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 239.5 KiB, free 420.0 MiB)
[2025-07-11T14:03:14.783+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 83.6 KiB, free 419.9 MiB)
[2025-07-11T14:03:14.783+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 138.4.31.23:41705 in memory (size: 4.4 KiB, free: 433.9 MiB)
[2025-07-11T14:03:14.783+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 138.4.31.23:41705 (size: 83.6 KiB, free: 433.9 MiB)
[2025-07-11T14:03:14.783+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:14.783+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[88] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:14.783+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
[2025-07-11T14:03:14.785+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 75) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:03:14.785+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO Executor: Running task 0.0 in stage 44.0 (TID 75)
[2025-07-11T14:03:14.798+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO ShuffleBlockFetcherIterator: Getting 1 (2.9 KiB) non-empty blocks including 1 (2.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:14.798+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:14.799+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:03:14.799+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:03:14.799+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:03:14.799+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:03:14.799+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:03:14.800+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:03:14.800+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:03:14.800+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:03:14.801+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-11T14:03:14.802+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-11T14:03:14.802+0200] {subprocess.py:93} INFO - {
[2025-07-11T14:03:14.802+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-11T14:03:14.802+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-11T14:03:14.802+0200] {subprocess.py:93} INFO -     "name" : "labelsArray",
[2025-07-11T14:03:14.802+0200] {subprocess.py:93} INFO -     "type" : {
[2025-07-11T14:03:14.802+0200] {subprocess.py:93} INFO -       "type" : "array",
[2025-07-11T14:03:14.802+0200] {subprocess.py:93} INFO -       "elementType" : {
[2025-07-11T14:03:14.802+0200] {subprocess.py:93} INFO -         "type" : "array",
[2025-07-11T14:03:14.802+0200] {subprocess.py:93} INFO -         "elementType" : "string",
[2025-07-11T14:03:14.802+0200] {subprocess.py:93} INFO -         "containsNull" : true
[2025-07-11T14:03:14.803+0200] {subprocess.py:93} INFO -       },
[2025-07-11T14:03:14.803+0200] {subprocess.py:93} INFO -       "containsNull" : true
[2025-07-11T14:03:14.803+0200] {subprocess.py:93} INFO -     },
[2025-07-11T14:03:14.803+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-11T14:03:14.803+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:03:14.803+0200] {subprocess.py:93} INFO -   } ]
[2025-07-11T14:03:14.803+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:03:14.803+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-11T14:03:14.803+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-11T14:03:14.803+0200] {subprocess.py:93} INFO -   optional group labelsArray (LIST) {
[2025-07-11T14:03:14.803+0200] {subprocess.py:93} INFO -     repeated group list {
[2025-07-11T14:03:14.803+0200] {subprocess.py:93} INFO -       optional group element (LIST) {
[2025-07-11T14:03:14.803+0200] {subprocess.py:93} INFO -         repeated group list {
[2025-07-11T14:03:14.803+0200] {subprocess.py:93} INFO -           optional binary element (STRING);
[2025-07-11T14:03:14.803+0200] {subprocess.py:93} INFO -         }
[2025-07-11T14:03:14.803+0200] {subprocess.py:93} INFO -       }
[2025-07-11T14:03:14.804+0200] {subprocess.py:93} INFO -     }
[2025-07-11T14:03:14.804+0200] {subprocess.py:93} INFO -   }
[2025-07-11T14:03:14.804+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:03:14.804+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:03:14.804+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:03:14.845+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO FileOutputCommitter: Saved output of task 'attempt_202507111403142478715444671117618_0044_m_000000_75' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Dest.bin/data/_temporary/0/task_202507111403142478715444671117618_0044_m_000000
[2025-07-11T14:03:14.846+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO SparkHadoopMapRedUtil: attempt_202507111403142478715444671117618_0044_m_000000_75: Committed. Elapsed time: 1 ms.
[2025-07-11T14:03:14.846+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO Executor: Finished task 0.0 in stage 44.0 (TID 75). 4783 bytes result sent to driver
[2025-07-11T14:03:14.847+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 75) in 63 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:14.847+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool
[2025-07-11T14:03:14.849+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: ResultStage 44 (parquet at StringIndexer.scala:499) finished in 0,088 s
[2025-07-11T14:03:14.850+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:03:14.850+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
[2025-07-11T14:03:14.851+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Job 27 finished: parquet at StringIndexer.scala:499, took 0,090379 s
[2025-07-11T14:03:14.851+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO FileFormatWriter: Start to commit write Job 1744caff-03b9-4c3d-85ad-5b1a2a3767c0.
[2025-07-11T14:03:14.874+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO FileFormatWriter: Write Job 1744caff-03b9-4c3d-85ad-5b1a2a3767c0 committed. Elapsed time: 25 ms.
[2025-07-11T14:03:14.875+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO FileFormatWriter: Finished processing stats for write job 1744caff-03b9-4c3d-85ad-5b1a2a3767c0.
[2025-07-11T14:03:14.925+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO V2ScanRelationPushDown:
[2025-07-11T14:03:14.926+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:03:14.926+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:03:14.926+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:03:14.928+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:03:14.933+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO V2ScanRelationPushDown:
[2025-07-11T14:03:14.933+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68
[2025-07-11T14:03:14.933+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:03:14.947+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:03:14.947+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:03:14.977+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO CodeGenerator: Code generated in 6.930814 ms
[2025-07-11T14:03:14.979+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 214.5 KiB, free 419.7 MiB)
[2025-07-11T14:03:14.989+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 419.7 MiB)
[2025-07-11T14:03:14.989+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 138.4.31.23:41705 (size: 38.9 KiB, free: 433.8 MiB)
[2025-07-11T14:03:14.989+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO SparkContext: Created broadcast 35 from collect at StringIndexer.scala:204
[2025-07-11T14:03:14.990+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:03:14.995+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Registering RDD 92 (collect at StringIndexer.scala:204) as input to shuffle 14
[2025-07-11T14:03:14.995+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Got map stage job 28 (collect at StringIndexer.scala:204) with 2 output partitions
[2025-07-11T14:03:14.995+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Final stage: ShuffleMapStage 45 (collect at StringIndexer.scala:204)
[2025-07-11T14:03:14.995+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:03:14.995+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:14.995+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[92] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:03:14.998+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 18.1 KiB, free 419.7 MiB)
[2025-07-11T14:03:14.999+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 419.7 MiB)
[2025-07-11T14:03:14.999+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 138.4.31.23:41705 (size: 8.7 KiB, free: 433.8 MiB)
[2025-07-11T14:03:15.000+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:15.000+0200] {subprocess.py:93} INFO - 25/07/11 14:03:14 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[92] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:03:15.000+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSchedulerImpl: Adding task set 45.0 with 2 tasks resource profile 0
[2025-07-11T14:03:15.003+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 76) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:03:15.003+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 77) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:03:15.003+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Running task 0.0 in stage 45.0 (TID 76)
[2025-07-11T14:03:15.003+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Running task 1.0 in stage 45.0 (TID 77)
[2025-07-11T14:03:15.010+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO DAGScheduler: Registering RDD 96 (collect at StringIndexer.scala:204) as input to shuffle 15
[2025-07-11T14:03:15.010+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO DAGScheduler: Got map stage job 29 (collect at StringIndexer.scala:204) with 12 output partitions
[2025-07-11T14:03:15.010+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO DAGScheduler: Final stage: ShuffleMapStage 46 (collect at StringIndexer.scala:204)
[2025-07-11T14:03:15.010+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:03:15.010+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:15.010+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[96] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:03:15.012+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 18.2 KiB, free 419.6 MiB)
[2025-07-11T14:03:15.013+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 419.6 MiB)
[2025-07-11T14:03:15.013+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 138.4.31.23:41705 (size: 9.0 KiB, free: 433.8 MiB)
[2025-07-11T14:03:15.013+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:15.014+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO CodeGenerator: Code generated in 6.886196 ms
[2025-07-11T14:03:15.014+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[96] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
[2025-07-11T14:03:15.014+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSchedulerImpl: Adding task set 46.0 with 12 tasks resource profile 0
[2025-07-11T14:03:15.017+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 78) (138.4.31.23, executor driver, partition 0, ANY, 16719 bytes)
[2025-07-11T14:03:15.017+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Starting task 1.0 in stage 46.0 (TID 79) (138.4.31.23, executor driver, partition 1, ANY, 16719 bytes)
[2025-07-11T14:03:15.018+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Running task 1.0 in stage 46.0 (TID 79)
[2025-07-11T14:03:15.018+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:03:15.018+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Running task 0.0 in stage 46.0 (TID 78)
[2025-07-11T14:03:15.025+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:03:15.115+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Finished task 1.0 in stage 46.0 (TID 79). 1988 bytes result sent to driver
[2025-07-11T14:03:15.116+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Starting task 2.0 in stage 46.0 (TID 80) (138.4.31.23, executor driver, partition 2, ANY, 16839 bytes)
[2025-07-11T14:03:15.116+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Running task 2.0 in stage 46.0 (TID 80)
[2025-07-11T14:03:15.116+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Finished task 1.0 in stage 46.0 (TID 79) in 99 ms on 138.4.31.23 (executor driver) (1/12)
[2025-07-11T14:03:15.154+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Finished task 0.0 in stage 46.0 (TID 78). 1988 bytes result sent to driver
[2025-07-11T14:03:15.157+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Starting task 3.0 in stage 46.0 (TID 81) (138.4.31.23, executor driver, partition 3, ANY, 16715 bytes)
[2025-07-11T14:03:15.158+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 78) in 142 ms on 138.4.31.23 (executor driver) (2/12)
[2025-07-11T14:03:15.159+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Running task 3.0 in stage 46.0 (TID 81)
[2025-07-11T14:03:15.168+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Finished task 2.0 in stage 46.0 (TID 80). 1945 bytes result sent to driver
[2025-07-11T14:03:15.170+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Starting task 4.0 in stage 46.0 (TID 82) (138.4.31.23, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-11T14:03:15.175+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Finished task 2.0 in stage 46.0 (TID 80) in 56 ms on 138.4.31.23 (executor driver) (3/12)
[2025-07-11T14:03:15.180+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Running task 4.0 in stage 46.0 (TID 82)
[2025-07-11T14:03:15.254+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Finished task 3.0 in stage 46.0 (TID 81). 1945 bytes result sent to driver
[2025-07-11T14:03:15.256+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Starting task 5.0 in stage 46.0 (TID 83) (138.4.31.23, executor driver, partition 5, ANY, 16839 bytes)
[2025-07-11T14:03:15.256+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Finished task 3.0 in stage 46.0 (TID 81) in 101 ms on 138.4.31.23 (executor driver) (4/12)
[2025-07-11T14:03:15.256+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Running task 5.0 in stage 46.0 (TID 83)
[2025-07-11T14:03:15.303+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Finished task 4.0 in stage 46.0 (TID 82). 2031 bytes result sent to driver
[2025-07-11T14:03:15.304+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Starting task 6.0 in stage 46.0 (TID 84) (138.4.31.23, executor driver, partition 6, ANY, 16719 bytes)
[2025-07-11T14:03:15.304+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Finished task 4.0 in stage 46.0 (TID 82) in 135 ms on 138.4.31.23 (executor driver) (5/12)
[2025-07-11T14:03:15.305+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Running task 6.0 in stage 46.0 (TID 84)
[2025-07-11T14:03:15.317+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 138.4.31.23:41705 in memory (size: 83.6 KiB, free: 433.9 MiB)
[2025-07-11T14:03:15.402+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Finished task 6.0 in stage 46.0 (TID 84). 1945 bytes result sent to driver
[2025-07-11T14:03:15.408+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Starting task 7.0 in stage 46.0 (TID 85) (138.4.31.23, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-11T14:03:15.408+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Running task 7.0 in stage 46.0 (TID 85)
[2025-07-11T14:03:15.409+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Finished task 6.0 in stage 46.0 (TID 84) in 105 ms on 138.4.31.23 (executor driver) (6/12)
[2025-07-11T14:03:15.415+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Finished task 5.0 in stage 46.0 (TID 83). 1988 bytes result sent to driver
[2025-07-11T14:03:15.418+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Starting task 8.0 in stage 46.0 (TID 86) (138.4.31.23, executor driver, partition 8, ANY, 16719 bytes)
[2025-07-11T14:03:15.419+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Running task 8.0 in stage 46.0 (TID 86)
[2025-07-11T14:03:15.419+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Finished task 5.0 in stage 46.0 (TID 83) in 164 ms on 138.4.31.23 (executor driver) (7/12)
[2025-07-11T14:03:15.475+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Finished task 7.0 in stage 46.0 (TID 85). 1945 bytes result sent to driver
[2025-07-11T14:03:15.476+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Starting task 9.0 in stage 46.0 (TID 87) (138.4.31.23, executor driver, partition 9, ANY, 16839 bytes)
[2025-07-11T14:03:15.476+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Running task 9.0 in stage 46.0 (TID 87)
[2025-07-11T14:03:15.477+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Finished task 7.0 in stage 46.0 (TID 85) in 69 ms on 138.4.31.23 (executor driver) (8/12)
[2025-07-11T14:03:15.512+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Finished task 8.0 in stage 46.0 (TID 86). 1945 bytes result sent to driver
[2025-07-11T14:03:15.514+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Starting task 10.0 in stage 46.0 (TID 88) (138.4.31.23, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-11T14:03:15.514+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Finished task 8.0 in stage 46.0 (TID 86) in 95 ms on 138.4.31.23 (executor driver) (9/12)
[2025-07-11T14:03:15.519+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Running task 10.0 in stage 46.0 (TID 88)
[2025-07-11T14:03:15.574+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Finished task 9.0 in stage 46.0 (TID 87). 1945 bytes result sent to driver
[2025-07-11T14:03:15.575+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Starting task 11.0 in stage 46.0 (TID 89) (138.4.31.23, executor driver, partition 11, ANY, 16839 bytes)
[2025-07-11T14:03:15.576+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Running task 11.0 in stage 46.0 (TID 89)
[2025-07-11T14:03:15.576+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Finished task 9.0 in stage 46.0 (TID 87) in 100 ms on 138.4.31.23 (executor driver) (10/12)
[2025-07-11T14:03:15.613+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Finished task 10.0 in stage 46.0 (TID 88). 2031 bytes result sent to driver
[2025-07-11T14:03:15.614+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Finished task 10.0 in stage 46.0 (TID 88) in 102 ms on 138.4.31.23 (executor driver) (11/12)
[2025-07-11T14:03:15.708+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Finished task 11.0 in stage 46.0 (TID 89). 1988 bytes result sent to driver
[2025-07-11T14:03:15.709+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Finished task 11.0 in stage 46.0 (TID 89) in 134 ms on 138.4.31.23 (executor driver) (12/12)
[2025-07-11T14:03:15.710+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool
[2025-07-11T14:03:15.710+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO DAGScheduler: ShuffleMapStage 46 (collect at StringIndexer.scala:204) finished in 0,698 s
[2025-07-11T14:03:15.710+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:03:15.710+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO DAGScheduler: running: Set(ShuffleMapStage 45)
[2025-07-11T14:03:15.710+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:03:15.710+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO DAGScheduler: failed: Set()
[2025-07-11T14:03:15.737+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:03:15.744+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 138.4.31.23:41705 in memory (size: 8.3 KiB, free: 433.9 MiB)
[2025-07-11T14:03:15.795+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:03:15.796+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO DAGScheduler: Got job 30 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-11T14:03:15.796+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO DAGScheduler: Final stage: ResultStage 48 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-11T14:03:15.796+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
[2025-07-11T14:03:15.796+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:15.799+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[98] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-11T14:03:15.799+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 8.2 KiB, free 420.0 MiB)
[2025-07-11T14:03:15.801+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 420.0 MiB)
[2025-07-11T14:03:15.801+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 138.4.31.23:41705 (size: 4.2 KiB, free: 433.9 MiB)
[2025-07-11T14:03:15.803+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:15.804+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[98] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:15.804+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
[2025-07-11T14:03:15.807+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 90) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-11T14:03:15.807+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Running task 0.0 in stage 48.0 (TID 90)
[2025-07-11T14:03:15.811+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO ShuffleBlockFetcherIterator: Getting 12 (193.3 KiB) non-empty blocks including 12 (193.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:15.811+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-11T14:03:15.826+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 138.4.31.23:41705 in memory (size: 38.9 KiB, free: 433.9 MiB)
[2025-07-11T14:03:15.835+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO Executor: Finished task 0.0 in stage 48.0 (TID 90). 40615 bytes result sent to driver
[2025-07-11T14:03:15.836+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 90) in 30 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:15.836+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool
[2025-07-11T14:03:15.836+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO DAGScheduler: ResultStage 48 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,039 s
[2025-07-11T14:03:15.836+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:03:15.836+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
[2025-07-11T14:03:15.837+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO DAGScheduler: Job 30 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,041642 s
[2025-07-11T14:03:15.845+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 4.3 MiB, free 416.0 MiB)
[2025-07-11T14:03:15.849+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 89.9 KiB, free 415.9 MiB)
[2025-07-11T14:03:15.852+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 138.4.31.23:41705 (size: 89.9 KiB, free: 433.8 MiB)
[2025-07-11T14:03:15.852+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO SparkContext: Created broadcast 39 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:03:15.864+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 138.4.31.23:41705 in memory (size: 89.6 KiB, free: 433.9 MiB)
[2025-07-11T14:03:15.867+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 138.4.31.23:41705 in memory (size: 38.9 KiB, free: 434.0 MiB)
[2025-07-11T14:03:15.871+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 138.4.31.23:41705 in memory (size: 9.0 KiB, free: 434.0 MiB)
[2025-07-11T14:03:15.877+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 138.4.31.23:41705 in memory (size: 8.2 KiB, free: 434.0 MiB)
[2025-07-11T14:03:15.881+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 138.4.31.23:41705 in memory (size: 89.6 KiB, free: 434.1 MiB)
[2025-07-11T14:03:15.889+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 138.4.31.23:41705 in memory (size: 9.1 KiB, free: 434.1 MiB)
[2025-07-11T14:03:15.891+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 138.4.31.23:41705 in memory (size: 8.2 KiB, free: 434.1 MiB)
[2025-07-11T14:03:15.896+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 138.4.31.23:41705 in memory (size: 9.0 KiB, free: 434.1 MiB)
[2025-07-11T14:03:15.905+0200] {subprocess.py:93} INFO - 25/07/11 14:03:15 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 138.4.31.23:41705 in memory (size: 38.9 KiB, free: 434.1 MiB)
[2025-07-11T14:03:16.522+0200] {subprocess.py:93} INFO - 25/07/11 14:03:16 INFO Executor: Finished task 1.0 in stage 45.0 (TID 77). 2031 bytes result sent to driver
[2025-07-11T14:03:16.523+0200] {subprocess.py:93} INFO - 25/07/11 14:03:16 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 77) in 1521 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:03:17.271+0200] {subprocess.py:93} INFO - 25/07/11 14:03:17 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 138.4.31.23:41705 in memory (size: 4.2 KiB, free: 434.1 MiB)
[2025-07-11T14:03:22.413+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO Executor: Finished task 0.0 in stage 45.0 (TID 76). 2074 bytes result sent to driver
[2025-07-11T14:03:22.415+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 76) in 7414 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:03:22.415+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool
[2025-07-11T14:03:22.415+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: ShuffleMapStage 45 (collect at StringIndexer.scala:204) finished in 7,418 s
[2025-07-11T14:03:22.415+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:03:22.415+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: running: Set()
[2025-07-11T14:03:22.415+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:03:22.415+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: failed: Set()
[2025-07-11T14:03:22.418+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:03:22.453+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO CodeGenerator: Code generated in 8.742623 ms
[2025-07-11T14:03:22.456+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: Registering RDD 102 (collect at StringIndexer.scala:204) as input to shuffle 16
[2025-07-11T14:03:22.457+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: Got map stage job 31 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-11T14:03:22.457+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: Final stage: ShuffleMapStage 50 (collect at StringIndexer.scala:204)
[2025-07-11T14:03:22.457+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 49)
[2025-07-11T14:03:22.457+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:22.458+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[102] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:03:22.463+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 51.4 KiB, free 425.1 MiB)
[2025-07-11T14:03:22.463+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 425.1 MiB)
[2025-07-11T14:03:22.464+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 138.4.31.23:41705 (size: 24.3 KiB, free: 434.1 MiB)
[2025-07-11T14:03:22.464+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:22.464+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[102] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:22.464+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks resource profile 0
[2025-07-11T14:03:22.465+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 91) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14833 bytes)
[2025-07-11T14:03:22.467+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO Executor: Running task 0.0 in stage 50.0 (TID 91)
[2025-07-11T14:03:22.473+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO ShuffleBlockFetcherIterator: Getting 2 (1220.4 KiB) non-empty blocks including 2 (1220.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:22.474+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:22.477+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO CodeGenerator: Code generated in 6.425753 ms
[2025-07-11T14:03:22.530+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 138.4.31.23:41705 in memory (size: 89.6 KiB, free: 434.2 MiB)
[2025-07-11T14:03:22.546+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 138.4.31.23:41705 in memory (size: 9.0 KiB, free: 434.2 MiB)
[2025-07-11T14:03:22.562+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 138.4.31.23:41705 in memory (size: 38.9 KiB, free: 434.2 MiB)
[2025-07-11T14:03:22.771+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO Executor: Finished task 0.0 in stage 50.0 (TID 91). 6500 bytes result sent to driver
[2025-07-11T14:03:22.772+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 91) in 307 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:22.772+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool
[2025-07-11T14:03:22.773+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: ShuffleMapStage 50 (collect at StringIndexer.scala:204) finished in 0,315 s
[2025-07-11T14:03:22.773+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:03:22.773+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: running: Set()
[2025-07-11T14:03:22.773+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:03:22.773+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: failed: Set()
[2025-07-11T14:03:22.789+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO SparkContext: Starting job: collect at StringIndexer.scala:204
[2025-07-11T14:03:22.790+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: Got job 32 (collect at StringIndexer.scala:204) with 1 output partitions
[2025-07-11T14:03:22.790+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: Final stage: ResultStage 53 (collect at StringIndexer.scala:204)
[2025-07-11T14:03:22.790+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
[2025-07-11T14:03:22.790+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:22.790+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[105] at collect at StringIndexer.scala:204), which has no missing parents
[2025-07-11T14:03:22.793+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 50.5 KiB, free 429.7 MiB)
[2025-07-11T14:03:22.794+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 429.6 MiB)
[2025-07-11T14:03:22.794+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 138.4.31.23:41705 (size: 24.0 KiB, free: 434.2 MiB)
[2025-07-11T14:03:22.795+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:22.795+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[105] at collect at StringIndexer.scala:204) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:22.795+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0
[2025-07-11T14:03:22.795+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 92) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:03:22.796+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO Executor: Running task 0.0 in stage 53.0 (TID 92)
[2025-07-11T14:03:22.801+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO ShuffleBlockFetcherIterator: Getting 1 (46.5 KiB) non-empty blocks including 1 (46.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:22.801+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:22.829+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO Executor: Finished task 0.0 in stage 53.0 (TID 92). 53379 bytes result sent to driver
[2025-07-11T14:03:22.829+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 92) in 34 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:22.829+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool
[2025-07-11T14:03:22.830+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: ResultStage 53 (collect at StringIndexer.scala:204) finished in 0,039 s
[2025-07-11T14:03:22.830+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:03:22.831+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
[2025-07-11T14:03:22.831+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: Job 32 finished: collect at StringIndexer.scala:204, took 0,041114 s
[2025-07-11T14:03:22.913+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO FileSystemOverwrite: Path /home/monica.fernandez/practica_creativa/models/string_indexer_model_Route.bin already exists. It will be overwritten.
[2025-07-11T14:03:22.930+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:03:22.930+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:03:22.930+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:03:22.963+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-11T14:03:22.963+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: Got job 33 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-11T14:03:22.963+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: Final stage: ResultStage 54 (runJob at SparkHadoopWriter.scala:83)
[2025-07-11T14:03:22.963+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:03:22.964+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:22.964+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[107] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-11T14:03:22.975+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 101.3 KiB, free 429.5 MiB)
[2025-07-11T14:03:22.976+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 429.5 MiB)
[2025-07-11T14:03:22.976+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 138.4.31.23:41705 (size: 36.5 KiB, free: 434.2 MiB)
[2025-07-11T14:03:22.976+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:22.977+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[107] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:22.977+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks resource profile 0
[2025-07-11T14:03:22.978+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 93) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15154 bytes)
[2025-07-11T14:03:22.978+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO Executor: Running task 0.0 in stage 54.0 (TID 93)
[2025-07-11T14:03:22.983+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:03:22.983+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:03:22.983+0200] {subprocess.py:93} INFO - 25/07/11 14:03:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:03:23.012+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileOutputCommitter: Saved output of task 'attempt_202507111403221142858313470731060_0107_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Route.bin/metadata/_temporary/0/task_202507111403221142858313470731060_0107_m_000000
[2025-07-11T14:03:23.012+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO SparkHadoopMapRedUtil: attempt_202507111403221142858313470731060_0107_m_000000_0: Committed. Elapsed time: 1 ms.
[2025-07-11T14:03:23.013+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Finished task 0.0 in stage 54.0 (TID 93). 1170 bytes result sent to driver
[2025-07-11T14:03:23.013+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 93) in 36 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:23.013+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool
[2025-07-11T14:03:23.013+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: ResultStage 54 (runJob at SparkHadoopWriter.scala:83) finished in 0,049 s
[2025-07-11T14:03:23.013+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:03:23.014+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished
[2025-07-11T14:03:23.014+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Job 33 finished: runJob at SparkHadoopWriter.scala:83, took 0,050903 s
[2025-07-11T14:03:23.014+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO SparkHadoopWriter: Start to commit write Job job_202507111403221142858313470731060_0107.
[2025-07-11T14:03:23.035+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO SparkHadoopWriter: Write Job job_202507111403221142858313470731060_0107 committed. Elapsed time: 20 ms.
[2025-07-11T14:03:23.065+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Registering RDD 110 (parquet at StringIndexer.scala:499) as input to shuffle 17
[2025-07-11T14:03:23.065+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Got map stage job 34 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-11T14:03:23.065+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Final stage: ShuffleMapStage 55 (parquet at StringIndexer.scala:499)
[2025-07-11T14:03:23.065+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:03:23.065+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:23.066+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Submitting ShuffleMapStage 55 (MapPartitionsRDD[110] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-11T14:03:23.066+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 8.1 KiB, free 429.5 MiB)
[2025-07-11T14:03:23.067+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 429.5 MiB)
[2025-07-11T14:03:23.068+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 138.4.31.23:41705 (size: 4.4 KiB, free: 434.2 MiB)
[2025-07-11T14:03:23.068+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:23.068+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 55 (MapPartitionsRDD[110] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:23.068+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0
[2025-07-11T14:03:23.069+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 94) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 82517 bytes)
[2025-07-11T14:03:23.073+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Running task 0.0 in stage 55.0 (TID 94)
[2025-07-11T14:03:23.076+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Finished task 0.0 in stage 55.0 (TID 94). 1628 bytes result sent to driver
[2025-07-11T14:03:23.076+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 94) in 7 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:23.077+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool
[2025-07-11T14:03:23.080+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: ShuffleMapStage 55 (parquet at StringIndexer.scala:499) finished in 0,014 s
[2025-07-11T14:03:23.081+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:03:23.081+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: running: Set()
[2025-07-11T14:03:23.081+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:03:23.081+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: failed: Set()
[2025-07-11T14:03:23.085+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:03:23.086+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:03:23.086+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:03:23.086+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:03:23.086+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:03:23.086+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:03:23.086+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:03:23.107+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO SparkContext: Starting job: parquet at StringIndexer.scala:499
[2025-07-11T14:03:23.108+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Got job 35 (parquet at StringIndexer.scala:499) with 1 output partitions
[2025-07-11T14:03:23.108+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Final stage: ResultStage 57 (parquet at StringIndexer.scala:499)
[2025-07-11T14:03:23.108+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
[2025-07-11T14:03:23.108+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:23.108+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[112] at parquet at StringIndexer.scala:499), which has no missing parents
[2025-07-11T14:03:23.133+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 239.5 KiB, free 429.3 MiB)
[2025-07-11T14:03:23.134+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 83.6 KiB, free 429.2 MiB)
[2025-07-11T14:03:23.135+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 138.4.31.23:41705 (size: 83.6 KiB, free: 434.1 MiB)
[2025-07-11T14:03:23.137+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:23.137+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[112] at parquet at StringIndexer.scala:499) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:23.137+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0
[2025-07-11T14:03:23.139+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 95) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:03:23.140+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Running task 0.0 in stage 57.0 (TID 95)
[2025-07-11T14:03:23.152+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO ShuffleBlockFetcherIterator: Getting 1 (42.2 KiB) non-empty blocks including 1 (42.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:23.152+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:23.153+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:03:23.153+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:03:23.153+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:03:23.153+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:03:23.153+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:03:23.153+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:03:23.153+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:03:23.153+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:03:23.153+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-11T14:03:23.154+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-11T14:03:23.154+0200] {subprocess.py:93} INFO - {
[2025-07-11T14:03:23.154+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-11T14:03:23.154+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-11T14:03:23.154+0200] {subprocess.py:93} INFO -     "name" : "labelsArray",
[2025-07-11T14:03:23.154+0200] {subprocess.py:93} INFO -     "type" : {
[2025-07-11T14:03:23.154+0200] {subprocess.py:93} INFO -       "type" : "array",
[2025-07-11T14:03:23.154+0200] {subprocess.py:93} INFO -       "elementType" : {
[2025-07-11T14:03:23.154+0200] {subprocess.py:93} INFO -         "type" : "array",
[2025-07-11T14:03:23.154+0200] {subprocess.py:93} INFO -         "elementType" : "string",
[2025-07-11T14:03:23.154+0200] {subprocess.py:93} INFO -         "containsNull" : true
[2025-07-11T14:03:23.154+0200] {subprocess.py:93} INFO -       },
[2025-07-11T14:03:23.154+0200] {subprocess.py:93} INFO -       "containsNull" : true
[2025-07-11T14:03:23.154+0200] {subprocess.py:93} INFO -     },
[2025-07-11T14:03:23.154+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-11T14:03:23.155+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:03:23.155+0200] {subprocess.py:93} INFO -   } ]
[2025-07-11T14:03:23.155+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:03:23.155+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-11T14:03:23.155+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-11T14:03:23.155+0200] {subprocess.py:93} INFO -   optional group labelsArray (LIST) {
[2025-07-11T14:03:23.155+0200] {subprocess.py:93} INFO -     repeated group list {
[2025-07-11T14:03:23.155+0200] {subprocess.py:93} INFO -       optional group element (LIST) {
[2025-07-11T14:03:23.155+0200] {subprocess.py:93} INFO -         repeated group list {
[2025-07-11T14:03:23.155+0200] {subprocess.py:93} INFO -           optional binary element (STRING);
[2025-07-11T14:03:23.155+0200] {subprocess.py:93} INFO -         }
[2025-07-11T14:03:23.155+0200] {subprocess.py:93} INFO -       }
[2025-07-11T14:03:23.155+0200] {subprocess.py:93} INFO -     }
[2025-07-11T14:03:23.155+0200] {subprocess.py:93} INFO -   }
[2025-07-11T14:03:23.156+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:03:23.156+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:03:23.156+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:03:23.217+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileOutputCommitter: Saved output of task 'attempt_202507111403233458449108426854161_0057_m_000000_95' to file:/home/monica.fernandez/practica_creativa/models/string_indexer_model_Route.bin/data/_temporary/0/task_202507111403233458449108426854161_0057_m_000000
[2025-07-11T14:03:23.217+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO SparkHadoopMapRedUtil: attempt_202507111403233458449108426854161_0057_m_000000_95: Committed. Elapsed time: 1 ms.
[2025-07-11T14:03:23.218+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Finished task 0.0 in stage 57.0 (TID 95). 4740 bytes result sent to driver
[2025-07-11T14:03:23.219+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 95) in 80 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:23.219+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool
[2025-07-11T14:03:23.219+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: ResultStage 57 (parquet at StringIndexer.scala:499) finished in 0,111 s
[2025-07-11T14:03:23.220+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:03:23.220+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
[2025-07-11T14:03:23.220+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Job 35 finished: parquet at StringIndexer.scala:499, took 0,112748 s
[2025-07-11T14:03:23.221+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileFormatWriter: Start to commit write Job 765e60e1-6c0f-416b-ac16-2014d8558fbd.
[2025-07-11T14:03:23.245+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileFormatWriter: Write Job 765e60e1-6c0f-416b-ac16-2014d8558fbd committed. Elapsed time: 24 ms.
[2025-07-11T14:03:23.245+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileFormatWriter: Finished processing stats for write job 765e60e1-6c0f-416b-ac16-2014d8558fbd.
[2025-07-11T14:03:23.311+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileSystemOverwrite: Path /home/monica.fernandez/practica_creativa/models/numeric_vector_assembler.bin already exists. It will be overwritten.
[2025-07-11T14:03:23.323+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:03:23.323+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:03:23.323+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:03:23.354+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-11T14:03:23.354+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Got job 36 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-11T14:03:23.354+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Final stage: ResultStage 58 (runJob at SparkHadoopWriter.scala:83)
[2025-07-11T14:03:23.354+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:03:23.354+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:23.354+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[114] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-11T14:03:23.362+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 101.3 KiB, free 429.1 MiB)
[2025-07-11T14:03:23.363+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 429.0 MiB)
[2025-07-11T14:03:23.363+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 138.4.31.23:41705 (size: 36.5 KiB, free: 434.1 MiB)
[2025-07-11T14:03:23.363+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:23.363+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[114] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:23.364+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0
[2025-07-11T14:03:23.364+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 96) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15234 bytes)
[2025-07-11T14:03:23.364+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Running task 0.0 in stage 58.0 (TID 96)
[2025-07-11T14:03:23.370+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:03:23.370+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:03:23.370+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:03:23.394+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileOutputCommitter: Saved output of task 'attempt_202507111403235997733280835099110_0114_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/numeric_vector_assembler.bin/metadata/_temporary/0/task_202507111403235997733280835099110_0114_m_000000
[2025-07-11T14:03:23.395+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO SparkHadoopMapRedUtil: attempt_202507111403235997733280835099110_0114_m_000000_0: Committed. Elapsed time: 1 ms.
[2025-07-11T14:03:23.395+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Finished task 0.0 in stage 58.0 (TID 96). 1170 bytes result sent to driver
[2025-07-11T14:03:23.396+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 96) in 31 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:23.396+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool
[2025-07-11T14:03:23.396+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: ResultStage 58 (runJob at SparkHadoopWriter.scala:83) finished in 0,042 s
[2025-07-11T14:03:23.396+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:03:23.397+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 58: Stage finished
[2025-07-11T14:03:23.397+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Job 36 finished: runJob at SparkHadoopWriter.scala:83, took 0,042563 s
[2025-07-11T14:03:23.397+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO SparkHadoopWriter: Start to commit write Job job_202507111403235997733280835099110_0114.
[2025-07-11T14:03:23.415+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO SparkHadoopWriter: Write Job job_202507111403235997733280835099110_0114 committed. Elapsed time: 18 ms.
[2025-07-11T14:03:23.509+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO V2ScanRelationPushDown:
[2025-07-11T14:03:23.510+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:03:23.510+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:03:23.510+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:03:23.510+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:03:23.518+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO V2ScanRelationPushDown:
[2025-07-11T14:03:23.518+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-11T14:03:23.518+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:03:23.544+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:03:23.544+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:03:23.583+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO CodeGenerator: Code generated in 8.800252 ms
[2025-07-11T14:03:23.586+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 214.5 KiB, free 428.8 MiB)
[2025-07-11T14:03:23.593+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 428.8 MiB)
[2025-07-11T14:03:23.593+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 138.4.31.23:41705 (size: 38.9 KiB, free: 434.0 MiB)
[2025-07-11T14:03:23.593+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO SparkContext: Created broadcast 46 from showString at NativeMethodAccessorImpl.java:0
[2025-07-11T14:03:23.594+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:03:23.597+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Registering RDD 118 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 18
[2025-07-11T14:03:23.597+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Got map stage job 37 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-07-11T14:03:23.597+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Final stage: ShuffleMapStage 59 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:03:23.598+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:03:23.598+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:23.599+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Submitting ShuffleMapStage 59 (MapPartitionsRDD[118] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:03:23.604+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 22.8 KiB, free 428.8 MiB)
[2025-07-11T14:03:23.604+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 428.8 MiB)
[2025-07-11T14:03:23.605+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 138.4.31.23:41705 (size: 9.9 KiB, free: 434.0 MiB)
[2025-07-11T14:03:23.605+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:23.605+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 59 (MapPartitionsRDD[118] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:03:23.605+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSchedulerImpl: Adding task set 59.0 with 2 tasks resource profile 0
[2025-07-11T14:03:23.607+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Registering RDD 122 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 19
[2025-07-11T14:03:23.607+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Got map stage job 38 (showString at NativeMethodAccessorImpl.java:0) with 12 output partitions
[2025-07-11T14:03:23.607+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Final stage: ShuffleMapStage 60 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:03:23.607+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:03:23.607+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:23.607+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 97) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:03:23.607+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[122] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:03:23.607+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Starting task 1.0 in stage 59.0 (TID 98) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:03:23.608+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Running task 0.0 in stage 59.0 (TID 97)
[2025-07-11T14:03:23.608+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Running task 1.0 in stage 59.0 (TID 98)
[2025-07-11T14:03:23.609+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 18.7 KiB, free 428.7 MiB)
[2025-07-11T14:03:23.610+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 428.7 MiB)
[2025-07-11T14:03:23.611+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 138.4.31.23:41705 (size: 9.2 KiB, free: 434.0 MiB)
[2025-07-11T14:03:23.612+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:23.612+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[122] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
[2025-07-11T14:03:23.612+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSchedulerImpl: Adding task set 60.0 with 12 tasks resource profile 0
[2025-07-11T14:03:23.616+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 99) (138.4.31.23, executor driver, partition 0, ANY, 16839 bytes)
[2025-07-11T14:03:23.616+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 100) (138.4.31.23, executor driver, partition 1, ANY, 16719 bytes)
[2025-07-11T14:03:23.616+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Running task 0.0 in stage 60.0 (TID 99)
[2025-07-11T14:03:23.616+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Running task 1.0 in stage 60.0 (TID 100)
[2025-07-11T14:03:23.621+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO CodeGenerator: Code generated in 10.322386 ms
[2025-07-11T14:03:23.633+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO CodeGenerator: Code generated in 8.001293 ms
[2025-07-11T14:03:23.635+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:03:23.636+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:03:23.651+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO CodeGenerator: Code generated in 8.307496 ms
[2025-07-11T14:03:23.703+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Finished task 1.0 in stage 60.0 (TID 100). 1945 bytes result sent to driver
[2025-07-11T14:03:23.705+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Starting task 2.0 in stage 60.0 (TID 101) (138.4.31.23, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-11T14:03:23.706+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 100) in 91 ms on 138.4.31.23 (executor driver) (1/12)
[2025-07-11T14:03:23.706+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Running task 2.0 in stage 60.0 (TID 101)
[2025-07-11T14:03:23.718+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Finished task 0.0 in stage 60.0 (TID 99). 1988 bytes result sent to driver
[2025-07-11T14:03:23.719+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Starting task 3.0 in stage 60.0 (TID 102) (138.4.31.23, executor driver, partition 3, ANY, 16715 bytes)
[2025-07-11T14:03:23.720+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 99) in 106 ms on 138.4.31.23 (executor driver) (2/12)
[2025-07-11T14:03:23.720+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Running task 3.0 in stage 60.0 (TID 102)
[2025-07-11T14:03:23.763+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Finished task 2.0 in stage 60.0 (TID 101). 1945 bytes result sent to driver
[2025-07-11T14:03:23.765+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Starting task 4.0 in stage 60.0 (TID 103) (138.4.31.23, executor driver, partition 4, ANY, 16839 bytes)
[2025-07-11T14:03:23.765+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Running task 4.0 in stage 60.0 (TID 103)
[2025-07-11T14:03:23.769+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Finished task 2.0 in stage 60.0 (TID 101) in 60 ms on 138.4.31.23 (executor driver) (3/12)
[2025-07-11T14:03:23.828+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Finished task 3.0 in stage 60.0 (TID 102). 1945 bytes result sent to driver
[2025-07-11T14:03:23.830+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Starting task 5.0 in stage 60.0 (TID 104) (138.4.31.23, executor driver, partition 5, ANY, 16839 bytes)
[2025-07-11T14:03:23.830+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Running task 5.0 in stage 60.0 (TID 104)
[2025-07-11T14:03:23.833+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Finished task 3.0 in stage 60.0 (TID 102) in 114 ms on 138.4.31.23 (executor driver) (4/12)
[2025-07-11T14:03:23.868+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Finished task 4.0 in stage 60.0 (TID 103). 1945 bytes result sent to driver
[2025-07-11T14:03:23.870+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Starting task 6.0 in stage 60.0 (TID 105) (138.4.31.23, executor driver, partition 6, ANY, 16719 bytes)
[2025-07-11T14:03:23.871+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Finished task 4.0 in stage 60.0 (TID 103) in 106 ms on 138.4.31.23 (executor driver) (5/12)
[2025-07-11T14:03:23.872+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Running task 6.0 in stage 60.0 (TID 105)
[2025-07-11T14:03:23.966+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Finished task 5.0 in stage 60.0 (TID 104). 2031 bytes result sent to driver
[2025-07-11T14:03:23.966+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Starting task 7.0 in stage 60.0 (TID 106) (138.4.31.23, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-11T14:03:23.966+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO TaskSetManager: Finished task 5.0 in stage 60.0 (TID 104) in 137 ms on 138.4.31.23 (executor driver) (6/12)
[2025-07-11T14:03:23.968+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 138.4.31.23:41705 in memory (size: 36.5 KiB, free: 434.0 MiB)
[2025-07-11T14:03:23.969+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO Executor: Running task 7.0 in stage 60.0 (TID 106)
[2025-07-11T14:03:23.974+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 138.4.31.23:41705 in memory (size: 83.6 KiB, free: 434.1 MiB)
[2025-07-11T14:03:23.979+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 138.4.31.23:41705 in memory (size: 4.4 KiB, free: 434.1 MiB)
[2025-07-11T14:03:23.989+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 138.4.31.23:41705 in memory (size: 24.0 KiB, free: 434.1 MiB)
[2025-07-11T14:03:23.992+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 138.4.31.23:41705 in memory (size: 24.3 KiB, free: 434.2 MiB)
[2025-07-11T14:03:23.995+0200] {subprocess.py:93} INFO - 25/07/11 14:03:23 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 138.4.31.23:41705 in memory (size: 36.5 KiB, free: 434.2 MiB)
[2025-07-11T14:03:24.025+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO Executor: Finished task 6.0 in stage 60.0 (TID 105). 1988 bytes result sent to driver
[2025-07-11T14:03:24.026+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO TaskSetManager: Starting task 8.0 in stage 60.0 (TID 107) (138.4.31.23, executor driver, partition 8, ANY, 16839 bytes)
[2025-07-11T14:03:24.026+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO Executor: Running task 8.0 in stage 60.0 (TID 107)
[2025-07-11T14:03:24.026+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO TaskSetManager: Finished task 6.0 in stage 60.0 (TID 105) in 157 ms on 138.4.31.23 (executor driver) (7/12)
[2025-07-11T14:03:24.046+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO Executor: Finished task 7.0 in stage 60.0 (TID 106). 1945 bytes result sent to driver
[2025-07-11T14:03:24.046+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO TaskSetManager: Starting task 9.0 in stage 60.0 (TID 108) (138.4.31.23, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-11T14:03:24.047+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO TaskSetManager: Finished task 7.0 in stage 60.0 (TID 106) in 82 ms on 138.4.31.23 (executor driver) (8/12)
[2025-07-11T14:03:24.048+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO Executor: Running task 9.0 in stage 60.0 (TID 108)
[2025-07-11T14:03:24.099+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO Executor: Finished task 9.0 in stage 60.0 (TID 108). 1945 bytes result sent to driver
[2025-07-11T14:03:24.100+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO TaskSetManager: Starting task 10.0 in stage 60.0 (TID 109) (138.4.31.23, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-11T14:03:24.100+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO Executor: Running task 10.0 in stage 60.0 (TID 109)
[2025-07-11T14:03:24.101+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO TaskSetManager: Finished task 9.0 in stage 60.0 (TID 108) in 54 ms on 138.4.31.23 (executor driver) (9/12)
[2025-07-11T14:03:24.150+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO Executor: Finished task 8.0 in stage 60.0 (TID 107). 1988 bytes result sent to driver
[2025-07-11T14:03:24.151+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO TaskSetManager: Starting task 11.0 in stage 60.0 (TID 110) (138.4.31.23, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-11T14:03:24.151+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO TaskSetManager: Finished task 8.0 in stage 60.0 (TID 107) in 126 ms on 138.4.31.23 (executor driver) (10/12)
[2025-07-11T14:03:24.151+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO Executor: Running task 11.0 in stage 60.0 (TID 110)
[2025-07-11T14:03:24.187+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO Executor: Finished task 10.0 in stage 60.0 (TID 109). 1945 bytes result sent to driver
[2025-07-11T14:03:24.194+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO TaskSetManager: Finished task 10.0 in stage 60.0 (TID 109) in 94 ms on 138.4.31.23 (executor driver) (11/12)
[2025-07-11T14:03:24.206+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO Executor: Finished task 11.0 in stage 60.0 (TID 110). 1945 bytes result sent to driver
[2025-07-11T14:03:24.207+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO TaskSetManager: Finished task 11.0 in stage 60.0 (TID 110) in 57 ms on 138.4.31.23 (executor driver) (12/12)
[2025-07-11T14:03:24.207+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool
[2025-07-11T14:03:24.213+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO DAGScheduler: ShuffleMapStage 60 (showString at NativeMethodAccessorImpl.java:0) finished in 0,599 s
[2025-07-11T14:03:24.213+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:03:24.213+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO DAGScheduler: running: Set(ShuffleMapStage 59)
[2025-07-11T14:03:24.213+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:03:24.213+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO DAGScheduler: failed: Set()
[2025-07-11T14:03:24.244+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO ShufflePartitionsUtil: For shuffle(19), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:03:24.273+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:03:24.275+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO DAGScheduler: Got job 39 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-11T14:03:24.275+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO DAGScheduler: Final stage: ResultStage 62 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-11T14:03:24.275+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)
[2025-07-11T14:03:24.275+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:24.275+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[124] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-11T14:03:24.276+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 8.2 KiB, free 429.5 MiB)
[2025-07-11T14:03:24.277+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 429.5 MiB)
[2025-07-11T14:03:24.277+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 138.4.31.23:41705 (size: 4.2 KiB, free: 434.2 MiB)
[2025-07-11T14:03:24.279+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:24.279+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[124] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:24.279+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0
[2025-07-11T14:03:24.279+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 111) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-11T14:03:24.289+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO Executor: Running task 0.0 in stage 62.0 (TID 111)
[2025-07-11T14:03:24.296+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO ShuffleBlockFetcherIterator: Getting 12 (214.7 KiB) non-empty blocks including 12 (214.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:24.296+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-11T14:03:24.316+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO Executor: Finished task 0.0 in stage 62.0 (TID 111). 51250 bytes result sent to driver
[2025-07-11T14:03:24.319+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 111) in 39 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:24.319+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool
[2025-07-11T14:03:24.319+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO DAGScheduler: ResultStage 62 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,043 s
[2025-07-11T14:03:24.319+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:03:24.319+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 62: Stage finished
[2025-07-11T14:03:24.319+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO DAGScheduler: Job 39 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,045399 s
[2025-07-11T14:03:24.326+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 4.3 MiB, free 425.2 MiB)
[2025-07-11T14:03:24.332+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 109.6 KiB, free 425.1 MiB)
[2025-07-11T14:03:24.333+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 138.4.31.23:41705 (size: 109.6 KiB, free: 434.1 MiB)
[2025-07-11T14:03:24.333+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO SparkContext: Created broadcast 50 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:03:24.699+0200] {subprocess.py:93} INFO - 25/07/11 14:03:24 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 138.4.31.23:41705 in memory (size: 4.2 KiB, free: 434.1 MiB)
[2025-07-11T14:03:26.019+0200] {subprocess.py:93} INFO - 25/07/11 14:03:26 INFO Executor: Finished task 1.0 in stage 59.0 (TID 98). 2031 bytes result sent to driver
[2025-07-11T14:03:26.020+0200] {subprocess.py:93} INFO - 25/07/11 14:03:26 INFO TaskSetManager: Finished task 1.0 in stage 59.0 (TID 98) in 2412 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:03:26.069+0200] {subprocess.py:93} INFO - 25/07/11 14:03:26 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 138.4.31.23:41705 in memory (size: 89.9 KiB, free: 434.2 MiB)
[2025-07-11T14:03:26.072+0200] {subprocess.py:93} INFO - 25/07/11 14:03:26 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 138.4.31.23:41705 in memory (size: 9.2 KiB, free: 434.2 MiB)
[2025-07-11T14:03:26.076+0200] {subprocess.py:93} INFO - 25/07/11 14:03:26 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 138.4.31.23:41705 in memory (size: 8.7 KiB, free: 434.2 MiB)
[2025-07-11T14:03:26.080+0200] {subprocess.py:93} INFO - 25/07/11 14:03:26 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 138.4.31.23:41705 in memory (size: 38.9 KiB, free: 434.2 MiB)
[2025-07-11T14:03:34.294+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO Executor: Finished task 0.0 in stage 59.0 (TID 97). 2031 bytes result sent to driver
[2025-07-11T14:03:34.294+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 97) in 10688 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:03:34.294+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool
[2025-07-11T14:03:34.295+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO DAGScheduler: ShuffleMapStage 59 (showString at NativeMethodAccessorImpl.java:0) finished in 10,695 s
[2025-07-11T14:03:34.295+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:03:34.295+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO DAGScheduler: running: Set()
[2025-07-11T14:03:34.295+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:03:34.295+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO DAGScheduler: failed: Set()
[2025-07-11T14:03:34.313+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO ShufflePartitionsUtil: For shuffle(18), advisory target size: 67108864, actual target size 4228400, minimum partition size: 1048576
[2025-07-11T14:03:34.425+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO CodeGenerator: Code generated in 42.496458 ms
[2025-07-11T14:03:34.485+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2025-07-11T14:03:34.486+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO DAGScheduler: Got job 40 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-07-11T14:03:34.486+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO DAGScheduler: Final stage: ResultStage 64 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:03:34.486+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)
[2025-07-11T14:03:34.486+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:34.486+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[127] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:03:34.497+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 207.0 KiB, free 429.6 MiB)
[2025-07-11T14:03:34.510+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 99.7 KiB, free 429.5 MiB)
[2025-07-11T14:03:34.510+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 138.4.31.23:41705 (size: 99.7 KiB, free: 434.1 MiB)
[2025-07-11T14:03:34.510+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:34.511+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[127] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:34.511+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0
[2025-07-11T14:03:34.511+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 112) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14847 bytes)
[2025-07-11T14:03:34.511+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO Executor: Running task 0.0 in stage 64.0 (TID 112)
[2025-07-11T14:03:34.545+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO ShuffleBlockFetcherIterator: Getting 1 (7.1 MiB) non-empty blocks including 1 (7.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:34.546+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:34.582+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO CodeGenerator: Code generated in 36.351715 ms
[2025-07-11T14:03:34.604+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO CodeGenerator: Code generated in 17.298089 ms
[2025-07-11T14:03:34.641+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO CodeGenerator: Code generated in 17.4349 ms
[2025-07-11T14:03:34.658+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO Executor: Finished task 0.0 in stage 64.0 (TID 112). 4916 bytes result sent to driver
[2025-07-11T14:03:34.660+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 112) in 150 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:34.660+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool
[2025-07-11T14:03:34.661+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO DAGScheduler: ResultStage 64 (showString at NativeMethodAccessorImpl.java:0) finished in 0,174 s
[2025-07-11T14:03:34.661+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:03:34.661+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished
[2025-07-11T14:03:34.661+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO DAGScheduler: Job 40 finished: showString at NativeMethodAccessorImpl.java:0, took 0,175884 s
[2025-07-11T14:03:34.681+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO CodeGenerator: Code generated in 16.30236 ms
[2025-07-11T14:03:34.685+0200] {subprocess.py:93} INFO - +--------+-------------------+-------------------+----------+---------+---------+--------+----------+---------+--------+--------------+--------------------+
[2025-07-11T14:03:34.685+0200] {subprocess.py:93} INFO - |ArrDelay|         CRSArrTime|         CRSDepTime|DayOfMonth|DayOfWeek|DayOfYear|DepDelay|FlightDate|FlightNum|Distance|ArrDelayBucket|        Features_vec|
[2025-07-11T14:03:34.685+0200] {subprocess.py:93} INFO - +--------+-------------------+-------------------+----------+---------+---------+--------+----------+---------+--------+--------------+--------------------+
[2025-07-11T14:03:34.685+0200] {subprocess.py:93} INFO - |   -19.0|2015-01-01 19:25:00|2015-01-01 16:50:00|         1|        4|        1|     3.0|2015-01-01|       99|  1739.0|           0.0|[3.0,1739.0,1.0,4...|
[2025-07-11T14:03:34.685+0200] {subprocess.py:93} INFO - |    -3.0|2015-01-01 19:40:00|2015-01-01 17:25:00|         1|        4|        1|    -4.0|2015-01-01|     1576|   338.0|           1.0|[-4.0,338.0,1.0,4...|
[2025-07-11T14:03:34.685+0200] {subprocess.py:93} INFO - |   -30.0|2015-01-01 21:20:00|2015-01-01 18:30:00|         1|        4|        1|    -7.0|2015-01-01|      675|  1739.0|           0.0|[-7.0,1739.0,1.0,...|
[2025-07-11T14:03:34.685+0200] {subprocess.py:93} INFO - |    20.0|2015-01-01 06:00:00|2015-01-01 04:07:00|         1|        4|        1|    -3.0|2015-01-01|     1030|  1129.0|           2.0|[-3.0,1129.0,1.0,...|
[2025-07-11T14:03:34.685+0200] {subprocess.py:93} INFO - |    -7.0|2015-01-01 07:13:00|2015-01-01 05:19:00|         1|        4|        1|     4.0|2015-01-01|      730|  1129.0|           1.0|[4.0,1129.0,1.0,4...|
[2025-07-11T14:03:34.686+0200] {subprocess.py:93} INFO - |   -10.0|2015-01-01 14:20:00|2015-01-01 12:05:00|         1|        4|        1|   -12.0|2015-01-01|      634|   857.0|           1.0|[-12.0,857.0,1.0,...|
[2025-07-11T14:03:34.686+0200] {subprocess.py:93} INFO - |    -4.0|2015-01-01 18:45:00|2015-01-01 16:29:00|         1|        4|        1|    -4.0|2015-01-01|      934|   857.0|           1.0|[-4.0,857.0,1.0,4...|
[2025-07-11T14:03:34.686+0200] {subprocess.py:93} INFO - |   -10.0|2015-01-01 21:33:00|2015-01-01 20:35:00|         1|        4|        1|    -5.0|2015-01-01|     1209|   153.0|           1.0|[-5.0,153.0,1.0,4...|
[2025-07-11T14:03:34.686+0200] {subprocess.py:93} INFO - |    -4.0|2015-01-01 15:35:00|2015-01-01 14:41:00|         1|        4|        1|    -2.0|2015-01-01|     1341|   153.0|           1.0|[-2.0,153.0,1.0,4...|
[2025-07-11T14:03:34.686+0200] {subprocess.py:93} INFO - |   -14.0|2015-01-01 12:19:00|2015-01-01 11:25:00|         1|        4|        1|    -4.0|2015-01-01|     5107|   153.0|           1.0|[-4.0,153.0,1.0,4...|
[2025-07-11T14:03:34.686+0200] {subprocess.py:93} INFO - |   -10.0|2015-01-01 18:31:00|2015-01-01 17:36:00|         1|        4|        1|    -5.0|2015-01-01|     5248|   153.0|           1.0|[-5.0,153.0,1.0,4...|
[2025-07-11T14:03:34.686+0200] {subprocess.py:93} INFO - |    86.0|2015-01-01 19:42:00|2015-01-01 19:08:00|         1|        4|        1|    91.0|2015-01-01|     4601|   456.0|           3.0|[91.0,456.0,1.0,4...|
[2025-07-11T14:03:34.686+0200] {subprocess.py:93} INFO - |   152.0|2015-01-01 15:36:00|2015-01-01 15:01:00|         1|        4|        1|   151.0|2015-01-01|     5997|   456.0|           3.0|[151.0,456.0,1.0,...|
[2025-07-11T14:03:34.686+0200] {subprocess.py:93} INFO - |    20.0|2015-01-01 10:08:00|2015-01-01 09:31:00|         1|        4|        1|     5.0|2015-01-01|     6184|   456.0|           2.0|[5.0,456.0,1.0,4....|
[2025-07-11T14:03:34.686+0200] {subprocess.py:93} INFO - |    -9.0|2015-01-01 10:30:00|2015-01-01 08:15:00|         1|        4|        1|    -7.0|2015-01-01|     4134|   643.0|           1.0|[-7.0,643.0,1.0,4...|
[2025-07-11T14:03:34.686+0200] {subprocess.py:93} INFO - |    18.0|2015-01-01 17:02:00|2015-01-01 14:55:00|         1|        4|        1|    -5.0|2015-01-01|     4178|   643.0|           2.0|[-5.0,643.0,1.0,4...|
[2025-07-11T14:03:34.686+0200] {subprocess.py:93} INFO - |     8.0|2015-01-01 13:10:00|2015-01-01 11:00:00|         1|        4|        1|    -5.0|2015-01-01|     4497|   643.0|           2.0|[-5.0,643.0,1.0,4...|
[2025-07-11T14:03:34.686+0200] {subprocess.py:93} INFO - |    10.0|2015-01-01 19:12:00|2015-01-01 17:06:00|         1|        4|        1|    -6.0|2015-01-01|     4550|   643.0|           2.0|[-6.0,643.0,1.0,4...|
[2025-07-11T14:03:34.686+0200] {subprocess.py:93} INFO - |     1.0|2015-01-01 09:05:00|2015-01-01 06:50:00|         1|        4|        1|    -2.0|2015-01-01|     4555|   643.0|           2.0|[-2.0,643.0,1.0,4...|
[2025-07-11T14:03:34.686+0200] {subprocess.py:93} INFO - |     4.0|2015-01-01 21:50:00|2015-01-01 19:10:00|         1|        4|        1|     2.0|2015-01-01|     1277|   861.0|           2.0|[2.0,861.0,1.0,4....|
[2025-07-11T14:03:34.686+0200] {subprocess.py:93} INFO - +--------+-------------------+-------------------+----------+---------+---------+--------+----------+---------+--------+--------------+--------------------+
[2025-07-11T14:03:34.686+0200] {subprocess.py:93} INFO - only showing top 20 rows
[2025-07-11T14:03:34.687+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:03:34.824+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO Instrumentation: [24920823] Stage class: RandomForestClassifier
[2025-07-11T14:03:34.824+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO Instrumentation: [24920823] Stage uid: RandomForestClassifier_42137e15cb45
[2025-07-11T14:03:34.891+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO V2ScanRelationPushDown:
[2025-07-11T14:03:34.891+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:03:34.891+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:03:34.891+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:03:34.891+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:03:34.906+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO V2ScanRelationPushDown:
[2025-07-11T14:03:34.907+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-11T14:03:34.907+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:03:34.943+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:03:34.943+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:03:34.982+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 214.5 KiB, free 429.3 MiB)
[2025-07-11T14:03:34.992+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 429.2 MiB)
[2025-07-11T14:03:34.993+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 138.4.31.23:41705 (size: 38.9 KiB, free: 434.1 MiB)
[2025-07-11T14:03:34.993+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO SparkContext: Created broadcast 52 from rdd at Instrumentation.scala:62
[2025-07-11T14:03:34.994+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:03:34.998+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO DAGScheduler: Registering RDD 131 (rdd at Instrumentation.scala:62) as input to shuffle 20
[2025-07-11T14:03:34.998+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO DAGScheduler: Got map stage job 41 (rdd at Instrumentation.scala:62) with 2 output partitions
[2025-07-11T14:03:34.998+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO DAGScheduler: Final stage: ShuffleMapStage 65 (rdd at Instrumentation.scala:62)
[2025-07-11T14:03:34.998+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:03:34.998+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:34.998+0200] {subprocess.py:93} INFO - 25/07/11 14:03:34 INFO DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[131] at rdd at Instrumentation.scala:62), which has no missing parents
[2025-07-11T14:03:35.000+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 22.8 KiB, free 429.2 MiB)
[2025-07-11T14:03:35.001+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 429.2 MiB)
[2025-07-11T14:03:35.001+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 138.4.31.23:41705 (size: 9.9 KiB, free: 434.1 MiB)
[2025-07-11T14:03:35.002+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:35.002+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[131] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:03:35.002+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSchedulerImpl: Adding task set 65.0 with 2 tasks resource profile 0
[2025-07-11T14:03:35.005+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 113) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:03:35.005+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Starting task 1.0 in stage 65.0 (TID 114) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:03:35.005+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Running task 1.0 in stage 65.0 (TID 114)
[2025-07-11T14:03:35.008+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Running task 0.0 in stage 65.0 (TID 113)
[2025-07-11T14:03:35.008+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO DAGScheduler: Registering RDD 135 (rdd at Instrumentation.scala:62) as input to shuffle 21
[2025-07-11T14:03:35.009+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO DAGScheduler: Got map stage job 42 (rdd at Instrumentation.scala:62) with 12 output partitions
[2025-07-11T14:03:35.009+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO DAGScheduler: Final stage: ShuffleMapStage 66 (rdd at Instrumentation.scala:62)
[2025-07-11T14:03:35.009+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:03:35.009+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:35.009+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO DAGScheduler: Submitting ShuffleMapStage 66 (MapPartitionsRDD[135] at rdd at Instrumentation.scala:62), which has no missing parents
[2025-07-11T14:03:35.011+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 18.7 KiB, free 429.2 MiB)
[2025-07-11T14:03:35.011+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:03:35.024+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 429.2 MiB)
[2025-07-11T14:03:35.024+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 138.4.31.23:41705 (size: 9.2 KiB, free: 434.1 MiB)
[2025-07-11T14:03:35.024+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:35.024+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[135] at rdd at Instrumentation.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
[2025-07-11T14:03:35.024+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSchedulerImpl: Adding task set 66.0 with 12 tasks resource profile 0
[2025-07-11T14:03:35.025+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 115) (138.4.31.23, executor driver, partition 0, ANY, 16719 bytes)
[2025-07-11T14:03:35.025+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Starting task 1.0 in stage 66.0 (TID 116) (138.4.31.23, executor driver, partition 1, ANY, 16719 bytes)
[2025-07-11T14:03:35.025+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Running task 0.0 in stage 66.0 (TID 115)
[2025-07-11T14:03:35.025+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Running task 1.0 in stage 66.0 (TID 116)
[2025-07-11T14:03:35.035+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:03:35.120+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 138.4.31.23:41705 in memory (size: 99.7 KiB, free: 434.2 MiB)
[2025-07-11T14:03:35.202+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Finished task 1.0 in stage 66.0 (TID 116). 1988 bytes result sent to driver
[2025-07-11T14:03:35.202+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Starting task 2.0 in stage 66.0 (TID 117) (138.4.31.23, executor driver, partition 2, ANY, 16715 bytes)
[2025-07-11T14:03:35.203+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Finished task 1.0 in stage 66.0 (TID 116) in 189 ms on 138.4.31.23 (executor driver) (1/12)
[2025-07-11T14:03:35.204+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Running task 2.0 in stage 66.0 (TID 117)
[2025-07-11T14:03:35.220+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Finished task 0.0 in stage 66.0 (TID 115). 2031 bytes result sent to driver
[2025-07-11T14:03:35.221+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Starting task 3.0 in stage 66.0 (TID 118) (138.4.31.23, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-11T14:03:35.221+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Running task 3.0 in stage 66.0 (TID 118)
[2025-07-11T14:03:35.230+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 115) in 216 ms on 138.4.31.23 (executor driver) (2/12)
[2025-07-11T14:03:35.334+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Finished task 2.0 in stage 66.0 (TID 117). 1945 bytes result sent to driver
[2025-07-11T14:03:35.335+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Starting task 4.0 in stage 66.0 (TID 119) (138.4.31.23, executor driver, partition 4, ANY, 16839 bytes)
[2025-07-11T14:03:35.336+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Finished task 2.0 in stage 66.0 (TID 117) in 141 ms on 138.4.31.23 (executor driver) (3/12)
[2025-07-11T14:03:35.338+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Running task 4.0 in stage 66.0 (TID 119)
[2025-07-11T14:03:35.384+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Finished task 3.0 in stage 66.0 (TID 118). 1945 bytes result sent to driver
[2025-07-11T14:03:35.386+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Starting task 5.0 in stage 66.0 (TID 120) (138.4.31.23, executor driver, partition 5, ANY, 16839 bytes)
[2025-07-11T14:03:35.387+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Finished task 3.0 in stage 66.0 (TID 118) in 166 ms on 138.4.31.23 (executor driver) (4/12)
[2025-07-11T14:03:35.389+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Running task 5.0 in stage 66.0 (TID 120)
[2025-07-11T14:03:35.445+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Finished task 4.0 in stage 66.0 (TID 119). 1945 bytes result sent to driver
[2025-07-11T14:03:35.447+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Starting task 6.0 in stage 66.0 (TID 121) (138.4.31.23, executor driver, partition 6, ANY, 16719 bytes)
[2025-07-11T14:03:35.449+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Finished task 4.0 in stage 66.0 (TID 119) in 114 ms on 138.4.31.23 (executor driver) (5/12)
[2025-07-11T14:03:35.453+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Running task 6.0 in stage 66.0 (TID 121)
[2025-07-11T14:03:35.462+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Finished task 5.0 in stage 66.0 (TID 120). 1945 bytes result sent to driver
[2025-07-11T14:03:35.463+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Starting task 7.0 in stage 66.0 (TID 122) (138.4.31.23, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-11T14:03:35.465+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Finished task 5.0 in stage 66.0 (TID 120) in 79 ms on 138.4.31.23 (executor driver) (6/12)
[2025-07-11T14:03:35.465+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Running task 7.0 in stage 66.0 (TID 122)
[2025-07-11T14:03:35.525+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Finished task 6.0 in stage 66.0 (TID 121). 1945 bytes result sent to driver
[2025-07-11T14:03:35.526+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Starting task 8.0 in stage 66.0 (TID 123) (138.4.31.23, executor driver, partition 8, ANY, 16839 bytes)
[2025-07-11T14:03:35.527+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Finished task 6.0 in stage 66.0 (TID 121) in 81 ms on 138.4.31.23 (executor driver) (7/12)
[2025-07-11T14:03:35.529+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Running task 8.0 in stage 66.0 (TID 123)
[2025-07-11T14:03:35.602+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Finished task 7.0 in stage 66.0 (TID 122). 2031 bytes result sent to driver
[2025-07-11T14:03:35.604+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Starting task 9.0 in stage 66.0 (TID 124) (138.4.31.23, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-11T14:03:35.605+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Finished task 7.0 in stage 66.0 (TID 122) in 143 ms on 138.4.31.23 (executor driver) (8/12)
[2025-07-11T14:03:35.609+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Running task 9.0 in stage 66.0 (TID 124)
[2025-07-11T14:03:35.652+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Finished task 8.0 in stage 66.0 (TID 123). 1988 bytes result sent to driver
[2025-07-11T14:03:35.653+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Starting task 10.0 in stage 66.0 (TID 125) (138.4.31.23, executor driver, partition 10, ANY, 16839 bytes)
[2025-07-11T14:03:35.653+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Finished task 8.0 in stage 66.0 (TID 123) in 128 ms on 138.4.31.23 (executor driver) (9/12)
[2025-07-11T14:03:35.657+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Running task 10.0 in stage 66.0 (TID 125)
[2025-07-11T14:03:35.719+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Finished task 9.0 in stage 66.0 (TID 124). 1945 bytes result sent to driver
[2025-07-11T14:03:35.720+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Starting task 11.0 in stage 66.0 (TID 126) (138.4.31.23, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-11T14:03:35.721+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Finished task 9.0 in stage 66.0 (TID 124) in 117 ms on 138.4.31.23 (executor driver) (10/12)
[2025-07-11T14:03:35.727+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Running task 11.0 in stage 66.0 (TID 126)
[2025-07-11T14:03:35.792+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Finished task 10.0 in stage 66.0 (TID 125). 1945 bytes result sent to driver
[2025-07-11T14:03:35.794+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Finished task 10.0 in stage 66.0 (TID 125) in 141 ms on 138.4.31.23 (executor driver) (11/12)
[2025-07-11T14:03:35.893+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO Executor: Finished task 11.0 in stage 66.0 (TID 126). 1945 bytes result sent to driver
[2025-07-11T14:03:35.902+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSetManager: Finished task 11.0 in stage 66.0 (TID 126) in 175 ms on 138.4.31.23 (executor driver) (12/12)
[2025-07-11T14:03:35.902+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool
[2025-07-11T14:03:35.902+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO DAGScheduler: ShuffleMapStage 66 (rdd at Instrumentation.scala:62) finished in 0,884 s
[2025-07-11T14:03:35.902+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:03:35.902+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO DAGScheduler: running: Set(ShuffleMapStage 65)
[2025-07-11T14:03:35.918+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:03:35.919+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO DAGScheduler: failed: Set()
[2025-07-11T14:03:35.919+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 138.4.31.23:41705 in memory (size: 109.6 KiB, free: 434.3 MiB)
[2025-07-11T14:03:35.919+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 138.4.31.23:41705 in memory (size: 9.9 KiB, free: 434.3 MiB)
[2025-07-11T14:03:35.941+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 138.4.31.23:41705 in memory (size: 38.9 KiB, free: 434.3 MiB)
[2025-07-11T14:03:35.986+0200] {subprocess.py:93} INFO - 25/07/11 14:03:35 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:03:36.026+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:03:36.029+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO DAGScheduler: Got job 43 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-11T14:03:36.029+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO DAGScheduler: Final stage: ResultStage 68 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-11T14:03:36.029+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67)
[2025-07-11T14:03:36.029+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:36.029+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[137] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-11T14:03:36.032+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 8.2 KiB, free 434.1 MiB)
[2025-07-11T14:03:36.033+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 434.1 MiB)
[2025-07-11T14:03:36.034+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 138.4.31.23:41705 (size: 4.2 KiB, free: 434.3 MiB)
[2025-07-11T14:03:36.035+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:36.035+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[137] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:36.035+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks resource profile 0
[2025-07-11T14:03:36.037+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 127) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-11T14:03:36.037+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO Executor: Running task 0.0 in stage 68.0 (TID 127)
[2025-07-11T14:03:36.059+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO ShuffleBlockFetcherIterator: Getting 12 (214.7 KiB) non-empty blocks including 12 (214.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:36.062+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-11T14:03:36.128+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO Executor: Finished task 0.0 in stage 68.0 (TID 127). 51401 bytes result sent to driver
[2025-07-11T14:03:36.130+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 127) in 93 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:36.130+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool
[2025-07-11T14:03:36.133+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO DAGScheduler: ResultStage 68 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,100 s
[2025-07-11T14:03:36.133+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:03:36.133+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 68: Stage finished
[2025-07-11T14:03:36.133+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO DAGScheduler: Job 43 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,104970 s
[2025-07-11T14:03:36.147+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 4.3 MiB, free 429.8 MiB)
[2025-07-11T14:03:36.155+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 109.5 KiB, free 429.7 MiB)
[2025-07-11T14:03:36.156+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 138.4.31.23:41705 (size: 109.5 KiB, free: 434.2 MiB)
[2025-07-11T14:03:36.158+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO SparkContext: Created broadcast 56 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:03:36.383+0200] {subprocess.py:93} INFO - 25/07/11 14:03:36 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 138.4.31.23:41705 in memory (size: 4.2 KiB, free: 434.2 MiB)
[2025-07-11T14:03:37.258+0200] {subprocess.py:93} INFO - 25/07/11 14:03:37 INFO Executor: Finished task 1.0 in stage 65.0 (TID 114). 2074 bytes result sent to driver
[2025-07-11T14:03:37.261+0200] {subprocess.py:93} INFO - 25/07/11 14:03:37 INFO TaskSetManager: Finished task 1.0 in stage 65.0 (TID 114) in 2256 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:03:37.351+0200] {subprocess.py:93} INFO - 25/07/11 14:03:37 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 138.4.31.23:41705 in memory (size: 9.2 KiB, free: 434.2 MiB)
[2025-07-11T14:03:45.234+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Finished task 0.0 in stage 65.0 (TID 113). 2031 bytes result sent to driver
[2025-07-11T14:03:45.234+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 113) in 10231 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:03:45.234+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool
[2025-07-11T14:03:45.235+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO DAGScheduler: ShuffleMapStage 65 (rdd at Instrumentation.scala:62) finished in 10,236 s
[2025-07-11T14:03:45.235+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:03:45.235+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO DAGScheduler: running: Set()
[2025-07-11T14:03:45.235+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:03:45.235+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO DAGScheduler: failed: Set()
[2025-07-11T14:03:45.247+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 4228400, minimum partition size: 1048576
[2025-07-11T14:03:45.289+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO CodeGenerator: Code generated in 20.986275 ms
[2025-07-11T14:03:45.303+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Instrumentation: [24920823] training: numPartitions=4 storageLevel=StorageLevel(1 replicas)
[2025-07-11T14:03:45.402+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO V2ScanRelationPushDown:
[2025-07-11T14:03:45.402+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:03:45.402+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:03:45.402+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:03:45.402+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:03:45.412+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO V2ScanRelationPushDown:
[2025-07-11T14:03:45.412+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-11T14:03:45.412+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:03:45.439+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:03:45.439+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:03:45.464+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO CodeGenerator: Code generated in 7.183565 ms
[2025-07-11T14:03:45.467+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 214.5 KiB, free 429.6 MiB)
[2025-07-11T14:03:45.479+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 429.5 MiB)
[2025-07-11T14:03:45.479+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 138.4.31.23:41705 (size: 38.9 KiB, free: 434.2 MiB)
[2025-07-11T14:03:45.480+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO SparkContext: Created broadcast 57 from rdd at RandomForestClassifier.scala:155
[2025-07-11T14:03:45.481+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:03:45.489+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO DAGScheduler: Registering RDD 146 (rdd at RandomForestClassifier.scala:155) as input to shuffle 22
[2025-07-11T14:03:45.489+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO DAGScheduler: Got map stage job 44 (rdd at RandomForestClassifier.scala:155) with 2 output partitions
[2025-07-11T14:03:45.489+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO DAGScheduler: Final stage: ShuffleMapStage 69 (rdd at RandomForestClassifier.scala:155)
[2025-07-11T14:03:45.489+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:03:45.489+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:45.489+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO DAGScheduler: Submitting ShuffleMapStage 69 (MapPartitionsRDD[146] at rdd at RandomForestClassifier.scala:155), which has no missing parents
[2025-07-11T14:03:45.491+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 20.7 KiB, free 429.5 MiB)
[2025-07-11T14:03:45.491+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 9.3 KiB, free 429.5 MiB)
[2025-07-11T14:03:45.492+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 138.4.31.23:41705 (size: 9.3 KiB, free: 434.2 MiB)
[2025-07-11T14:03:45.492+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:45.493+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 69 (MapPartitionsRDD[146] at rdd at RandomForestClassifier.scala:155) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:03:45.494+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSchedulerImpl: Adding task set 69.0 with 2 tasks resource profile 0
[2025-07-11T14:03:45.494+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 128) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:03:45.494+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 129) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:03:45.494+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Running task 0.0 in stage 69.0 (TID 128)
[2025-07-11T14:03:45.494+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Running task 1.0 in stage 69.0 (TID 129)
[2025-07-11T14:03:45.508+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO CodeGenerator: Code generated in 11.483058 ms
[2025-07-11T14:03:45.522+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO CodeGenerator: Code generated in 12.132887 ms
[2025-07-11T14:03:45.523+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:03:45.523+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:03:45.533+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO DAGScheduler: Registering RDD 150 (rdd at RandomForestClassifier.scala:155) as input to shuffle 23
[2025-07-11T14:03:45.534+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO DAGScheduler: Got map stage job 45 (rdd at RandomForestClassifier.scala:155) with 12 output partitions
[2025-07-11T14:03:45.534+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO DAGScheduler: Final stage: ShuffleMapStage 70 (rdd at RandomForestClassifier.scala:155)
[2025-07-11T14:03:45.534+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:03:45.534+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:45.534+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO DAGScheduler: Submitting ShuffleMapStage 70 (MapPartitionsRDD[150] at rdd at RandomForestClassifier.scala:155), which has no missing parents
[2025-07-11T14:03:45.537+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 18.7 KiB, free 429.5 MiB)
[2025-07-11T14:03:45.538+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 429.5 MiB)
[2025-07-11T14:03:45.538+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 138.4.31.23:41705 (size: 9.2 KiB, free: 434.2 MiB)
[2025-07-11T14:03:45.539+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:45.539+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[150] at rdd at RandomForestClassifier.scala:155) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
[2025-07-11T14:03:45.539+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSchedulerImpl: Adding task set 70.0 with 12 tasks resource profile 0
[2025-07-11T14:03:45.539+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 130) (138.4.31.23, executor driver, partition 0, ANY, 16719 bytes)
[2025-07-11T14:03:45.540+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Starting task 1.0 in stage 70.0 (TID 131) (138.4.31.23, executor driver, partition 1, ANY, 16839 bytes)
[2025-07-11T14:03:45.540+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Running task 0.0 in stage 70.0 (TID 130)
[2025-07-11T14:03:45.540+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Running task 1.0 in stage 70.0 (TID 131)
[2025-07-11T14:03:45.544+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO CodeGenerator: Code generated in 18.96799 ms
[2025-07-11T14:03:45.636+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Finished task 1.0 in stage 70.0 (TID 131). 1945 bytes result sent to driver
[2025-07-11T14:03:45.638+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Starting task 2.0 in stage 70.0 (TID 132) (138.4.31.23, executor driver, partition 2, ANY, 16715 bytes)
[2025-07-11T14:03:45.638+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Finished task 1.0 in stage 70.0 (TID 131) in 99 ms on 138.4.31.23 (executor driver) (1/12)
[2025-07-11T14:03:45.639+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Running task 2.0 in stage 70.0 (TID 132)
[2025-07-11T14:03:45.659+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Finished task 0.0 in stage 70.0 (TID 130). 1988 bytes result sent to driver
[2025-07-11T14:03:45.660+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Starting task 3.0 in stage 70.0 (TID 133) (138.4.31.23, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-11T14:03:45.661+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Running task 3.0 in stage 70.0 (TID 133)
[2025-07-11T14:03:45.661+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 130) in 122 ms on 138.4.31.23 (executor driver) (2/12)
[2025-07-11T14:03:45.716+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 138.4.31.23:41705 in memory (size: 9.9 KiB, free: 434.2 MiB)
[2025-07-11T14:03:45.744+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Finished task 2.0 in stage 70.0 (TID 132). 1945 bytes result sent to driver
[2025-07-11T14:03:45.745+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Starting task 4.0 in stage 70.0 (TID 134) (138.4.31.23, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-11T14:03:45.745+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Finished task 2.0 in stage 70.0 (TID 132) in 108 ms on 138.4.31.23 (executor driver) (3/12)
[2025-07-11T14:03:45.745+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Running task 4.0 in stage 70.0 (TID 134)
[2025-07-11T14:03:45.746+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Finished task 3.0 in stage 70.0 (TID 133). 1988 bytes result sent to driver
[2025-07-11T14:03:45.748+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Starting task 5.0 in stage 70.0 (TID 135) (138.4.31.23, executor driver, partition 5, ANY, 16719 bytes)
[2025-07-11T14:03:45.748+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Finished task 3.0 in stage 70.0 (TID 133) in 89 ms on 138.4.31.23 (executor driver) (4/12)
[2025-07-11T14:03:45.749+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Running task 5.0 in stage 70.0 (TID 135)
[2025-07-11T14:03:45.816+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Finished task 5.0 in stage 70.0 (TID 135). 1945 bytes result sent to driver
[2025-07-11T14:03:45.817+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Starting task 6.0 in stage 70.0 (TID 136) (138.4.31.23, executor driver, partition 6, ANY, 16839 bytes)
[2025-07-11T14:03:45.817+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Finished task 5.0 in stage 70.0 (TID 135) in 71 ms on 138.4.31.23 (executor driver) (5/12)
[2025-07-11T14:03:45.817+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Running task 6.0 in stage 70.0 (TID 136)
[2025-07-11T14:03:45.850+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Finished task 4.0 in stage 70.0 (TID 134). 1945 bytes result sent to driver
[2025-07-11T14:03:45.851+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Starting task 7.0 in stage 70.0 (TID 137) (138.4.31.23, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-11T14:03:45.852+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Finished task 4.0 in stage 70.0 (TID 134) in 108 ms on 138.4.31.23 (executor driver) (6/12)
[2025-07-11T14:03:45.855+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Running task 7.0 in stage 70.0 (TID 137)
[2025-07-11T14:03:45.877+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Finished task 6.0 in stage 70.0 (TID 136). 1945 bytes result sent to driver
[2025-07-11T14:03:45.879+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Starting task 8.0 in stage 70.0 (TID 138) (138.4.31.23, executor driver, partition 8, ANY, 16839 bytes)
[2025-07-11T14:03:45.880+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Running task 8.0 in stage 70.0 (TID 138)
[2025-07-11T14:03:45.881+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Finished task 6.0 in stage 70.0 (TID 136) in 63 ms on 138.4.31.23 (executor driver) (7/12)
[2025-07-11T14:03:45.940+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Finished task 7.0 in stage 70.0 (TID 137). 1945 bytes result sent to driver
[2025-07-11T14:03:45.941+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Starting task 9.0 in stage 70.0 (TID 139) (138.4.31.23, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-11T14:03:45.942+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Running task 9.0 in stage 70.0 (TID 139)
[2025-07-11T14:03:45.944+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Finished task 7.0 in stage 70.0 (TID 137) in 91 ms on 138.4.31.23 (executor driver) (8/12)
[2025-07-11T14:03:45.955+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Finished task 8.0 in stage 70.0 (TID 138). 1945 bytes result sent to driver
[2025-07-11T14:03:45.958+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Starting task 10.0 in stage 70.0 (TID 140) (138.4.31.23, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-11T14:03:45.958+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO TaskSetManager: Finished task 8.0 in stage 70.0 (TID 138) in 79 ms on 138.4.31.23 (executor driver) (9/12)
[2025-07-11T14:03:45.960+0200] {subprocess.py:93} INFO - 25/07/11 14:03:45 INFO Executor: Running task 10.0 in stage 70.0 (TID 140)
[2025-07-11T14:03:46.025+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO Executor: Finished task 9.0 in stage 70.0 (TID 139). 1945 bytes result sent to driver
[2025-07-11T14:03:46.027+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO TaskSetManager: Starting task 11.0 in stage 70.0 (TID 141) (138.4.31.23, executor driver, partition 11, ANY, 16839 bytes)
[2025-07-11T14:03:46.028+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO TaskSetManager: Finished task 9.0 in stage 70.0 (TID 139) in 86 ms on 138.4.31.23 (executor driver) (10/12)
[2025-07-11T14:03:46.028+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO Executor: Running task 11.0 in stage 70.0 (TID 141)
[2025-07-11T14:03:46.038+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO Executor: Finished task 10.0 in stage 70.0 (TID 140). 1945 bytes result sent to driver
[2025-07-11T14:03:46.039+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO TaskSetManager: Finished task 10.0 in stage 70.0 (TID 140) in 82 ms on 138.4.31.23 (executor driver) (11/12)
[2025-07-11T14:03:46.154+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO Executor: Finished task 11.0 in stage 70.0 (TID 141). 1988 bytes result sent to driver
[2025-07-11T14:03:46.156+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO TaskSetManager: Finished task 11.0 in stage 70.0 (TID 141) in 129 ms on 138.4.31.23 (executor driver) (12/12)
[2025-07-11T14:03:46.156+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool
[2025-07-11T14:03:46.156+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO DAGScheduler: ShuffleMapStage 70 (rdd at RandomForestClassifier.scala:155) finished in 0,619 s
[2025-07-11T14:03:46.156+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:03:46.156+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO DAGScheduler: running: Set(ShuffleMapStage 69)
[2025-07-11T14:03:46.156+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:03:46.156+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO DAGScheduler: failed: Set()
[2025-07-11T14:03:46.178+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO ShufflePartitionsUtil: For shuffle(23), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:03:46.209+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:03:46.211+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO DAGScheduler: Got job 46 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-11T14:03:46.211+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO DAGScheduler: Final stage: ResultStage 72 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-11T14:03:46.211+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 71)
[2025-07-11T14:03:46.211+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:46.211+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[152] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-11T14:03:46.214+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 8.2 KiB, free 429.5 MiB)
[2025-07-11T14:03:46.214+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 429.5 MiB)
[2025-07-11T14:03:46.214+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 138.4.31.23:41705 (size: 4.2 KiB, free: 434.2 MiB)
[2025-07-11T14:03:46.217+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:46.217+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[152] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:46.217+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks resource profile 0
[2025-07-11T14:03:46.217+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 142) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-11T14:03:46.217+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO Executor: Running task 0.0 in stage 72.0 (TID 142)
[2025-07-11T14:03:46.221+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO ShuffleBlockFetcherIterator: Getting 12 (214.7 KiB) non-empty blocks including 12 (214.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:46.221+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-11T14:03:46.264+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO Executor: Finished task 0.0 in stage 72.0 (TID 142). 51427 bytes result sent to driver
[2025-07-11T14:03:46.266+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 142) in 49 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:46.266+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool
[2025-07-11T14:03:46.266+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO DAGScheduler: ResultStage 72 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,053 s
[2025-07-11T14:03:46.266+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:03:46.266+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished
[2025-07-11T14:03:46.266+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO DAGScheduler: Job 46 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,056476 s
[2025-07-11T14:03:46.274+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 4.3 MiB, free 425.2 MiB)
[2025-07-11T14:03:46.277+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 109.7 KiB, free 425.1 MiB)
[2025-07-11T14:03:46.277+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 138.4.31.23:41705 (size: 109.7 KiB, free: 434.1 MiB)
[2025-07-11T14:03:46.278+0200] {subprocess.py:93} INFO - 25/07/11 14:03:46 INFO SparkContext: Created broadcast 61 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:03:47.223+0200] {subprocess.py:93} INFO - 25/07/11 14:03:47 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 138.4.31.23:41705 in memory (size: 4.2 KiB, free: 434.1 MiB)
[2025-07-11T14:03:47.308+0200] {subprocess.py:93} INFO - 25/07/11 14:03:47 INFO Executor: Finished task 1.0 in stage 69.0 (TID 129). 2074 bytes result sent to driver
[2025-07-11T14:03:47.320+0200] {subprocess.py:93} INFO - 25/07/11 14:03:47 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 129) in 1818 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:03:47.436+0200] {subprocess.py:93} INFO - 25/07/11 14:03:47 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 138.4.31.23:41705 in memory (size: 9.2 KiB, free: 434.1 MiB)
[2025-07-11T14:03:53.543+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO Executor: Finished task 0.0 in stage 69.0 (TID 128). 2074 bytes result sent to driver
[2025-07-11T14:03:53.543+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 128) in 8050 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:03:53.543+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool
[2025-07-11T14:03:53.544+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO DAGScheduler: ShuffleMapStage 69 (rdd at RandomForestClassifier.scala:155) finished in 8,054 s
[2025-07-11T14:03:53.544+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:03:53.544+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO DAGScheduler: running: Set()
[2025-07-11T14:03:53.544+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:03:53.544+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO DAGScheduler: failed: Set()
[2025-07-11T14:03:53.554+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1923052, minimum partition size: 1048576
[2025-07-11T14:03:53.614+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO CodeGenerator: Code generated in 37.762334 ms
[2025-07-11T14:03:53.640+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO Instrumentation: [24920823] {"featuresCol":"Features_vec","labelCol":"ArrDelayBucket","predictionCol":"Prediction","maxMemoryInMB":1024,"maxBins":4657,"numTrees":10}
[2025-07-11T14:03:53.685+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:119
[2025-07-11T14:03:53.687+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO DAGScheduler: Got job 47 (take at DecisionTreeMetadata.scala:119) with 1 output partitions
[2025-07-11T14:03:53.687+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO DAGScheduler: Final stage: ResultStage 74 (take at DecisionTreeMetadata.scala:119)
[2025-07-11T14:03:53.687+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)
[2025-07-11T14:03:53.687+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:53.687+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[160] at map at DecisionTreeMetadata.scala:119), which has no missing parents
[2025-07-11T14:03:53.692+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 278.1 KiB, free 424.9 MiB)
[2025-07-11T14:03:53.696+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 126.9 KiB, free 424.8 MiB)
[2025-07-11T14:03:53.699+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 138.4.31.23:41705 (size: 126.9 KiB, free: 434.0 MiB)
[2025-07-11T14:03:53.699+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:53.700+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[160] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:03:53.700+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0
[2025-07-11T14:03:53.701+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 143) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14847 bytes)
[2025-07-11T14:03:53.701+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO Executor: Running task 0.0 in stage 74.0 (TID 143)
[2025-07-11T14:03:53.722+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO ShuffleBlockFetcherIterator: Getting 1 (3.2 MiB) non-empty blocks including 1 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:53.723+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:53.753+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO CodeGenerator: Code generated in 30.267292 ms
[2025-07-11T14:03:53.763+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO CodeGenerator: Code generated in 6.660145 ms
[2025-07-11T14:03:53.774+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO CodeGenerator: Code generated in 3.883808 ms
[2025-07-11T14:03:53.776+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO Executor: Finished task 0.0 in stage 74.0 (TID 143). 5038 bytes result sent to driver
[2025-07-11T14:03:53.777+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 143) in 77 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:03:53.777+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool
[2025-07-11T14:03:53.778+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO DAGScheduler: ResultStage 74 (take at DecisionTreeMetadata.scala:119) finished in 0,091 s
[2025-07-11T14:03:53.778+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:03:53.778+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished
[2025-07-11T14:03:53.778+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO DAGScheduler: Job 47 finished: take at DecisionTreeMetadata.scala:119, took 0,092559 s
[2025-07-11T14:03:53.788+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125
[2025-07-11T14:03:53.789+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO DAGScheduler: Got job 48 (aggregate at DecisionTreeMetadata.scala:125) with 4 output partitions
[2025-07-11T14:03:53.789+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO DAGScheduler: Final stage: ResultStage 76 (aggregate at DecisionTreeMetadata.scala:125)
[2025-07-11T14:03:53.789+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)
[2025-07-11T14:03:53.790+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:03:53.791+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[159] at retag at RandomForest.scala:274), which has no missing parents
[2025-07-11T14:03:53.797+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 278.2 KiB, free 424.5 MiB)
[2025-07-11T14:03:53.799+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 126.8 KiB, free 424.4 MiB)
[2025-07-11T14:03:53.799+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 138.4.31.23:41705 (size: 126.8 KiB, free: 433.9 MiB)
[2025-07-11T14:03:53.800+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:53.800+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 76 (MapPartitionsRDD[159] at retag at RandomForest.scala:274) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:03:53.800+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO TaskSchedulerImpl: Adding task set 76.0 with 4 tasks resource profile 0
[2025-07-11T14:03:53.801+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 144) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14847 bytes)
[2025-07-11T14:03:53.801+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO TaskSetManager: Starting task 1.0 in stage 76.0 (TID 145) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14847 bytes)
[2025-07-11T14:03:53.801+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO TaskSetManager: Starting task 2.0 in stage 76.0 (TID 146) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14847 bytes)
[2025-07-11T14:03:53.801+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO TaskSetManager: Starting task 3.0 in stage 76.0 (TID 147) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14847 bytes)
[2025-07-11T14:03:53.801+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO Executor: Running task 1.0 in stage 76.0 (TID 145)
[2025-07-11T14:03:53.803+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO Executor: Running task 3.0 in stage 76.0 (TID 147)
[2025-07-11T14:03:53.803+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO Executor: Running task 0.0 in stage 76.0 (TID 144)
[2025-07-11T14:03:53.803+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO Executor: Running task 2.0 in stage 76.0 (TID 146)
[2025-07-11T14:03:53.815+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO ShuffleBlockFetcherIterator: Getting 1 (384.6 KiB) non-empty blocks including 1 (384.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:53.815+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:53.821+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO ShuffleBlockFetcherIterator: Getting 1 (366.2 KiB) non-empty blocks including 1 (366.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:53.821+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:53.822+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO ShuffleBlockFetcherIterator: Getting 1 (3.2 MiB) non-empty blocks including 1 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:53.822+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:53.822+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO ShuffleBlockFetcherIterator: Getting 1 (3.4 MiB) non-empty blocks including 1 (3.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:53.822+0200] {subprocess.py:93} INFO - 25/07/11 14:03:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:54.264+0200] {subprocess.py:93} INFO - 25/07/11 14:03:54 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 138.4.31.23:41705 in memory (size: 126.9 KiB, free: 434.0 MiB)
[2025-07-11T14:03:54.349+0200] {subprocess.py:93} INFO - 25/07/11 14:03:54 INFO Executor: Finished task 2.0 in stage 76.0 (TID 146). 5927 bytes result sent to driver
[2025-07-11T14:03:54.352+0200] {subprocess.py:93} INFO - 25/07/11 14:03:54 INFO TaskSetManager: Finished task 2.0 in stage 76.0 (TID 146) in 550 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:03:54.360+0200] {subprocess.py:93} INFO - 25/07/11 14:03:54 INFO Executor: Finished task 3.0 in stage 76.0 (TID 147). 5927 bytes result sent to driver
[2025-07-11T14:03:54.361+0200] {subprocess.py:93} INFO - 25/07/11 14:03:54 INFO TaskSetManager: Finished task 3.0 in stage 76.0 (TID 147) in 559 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:03:54.905+0200] {subprocess.py:93} INFO - 25/07/11 14:03:54 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 138.4.31.23:41705 in memory (size: 9.3 KiB, free: 434.0 MiB)
[2025-07-11T14:03:54.918+0200] {subprocess.py:93} INFO - 25/07/11 14:03:54 INFO Executor: Finished task 0.0 in stage 76.0 (TID 144). 5927 bytes result sent to driver
[2025-07-11T14:03:54.919+0200] {subprocess.py:93} INFO - 25/07/11 14:03:54 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 144) in 1119 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:03:54.983+0200] {subprocess.py:93} INFO - 25/07/11 14:03:54 INFO Executor: Finished task 1.0 in stage 76.0 (TID 145). 5927 bytes result sent to driver
[2025-07-11T14:03:54.986+0200] {subprocess.py:93} INFO - 25/07/11 14:03:54 INFO TaskSetManager: Finished task 1.0 in stage 76.0 (TID 145) in 1185 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:03:54.986+0200] {subprocess.py:93} INFO - 25/07/11 14:03:54 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool
[2025-07-11T14:03:54.986+0200] {subprocess.py:93} INFO - 25/07/11 14:03:54 INFO DAGScheduler: ResultStage 76 (aggregate at DecisionTreeMetadata.scala:125) finished in 1,196 s
[2025-07-11T14:03:54.986+0200] {subprocess.py:93} INFO - 25/07/11 14:03:54 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:03:54.986+0200] {subprocess.py:93} INFO - 25/07/11 14:03:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 76: Stage finished
[2025-07-11T14:03:54.987+0200] {subprocess.py:93} INFO - 25/07/11 14:03:54 INFO DAGScheduler: Job 48 finished: aggregate at DecisionTreeMetadata.scala:125, took 1,198247 s
[2025-07-11T14:03:55.063+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:1054
[2025-07-11T14:03:55.065+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO DAGScheduler: Registering RDD 162 (flatMap at RandomForest.scala:1039) as input to shuffle 24
[2025-07-11T14:03:55.065+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO DAGScheduler: Got job 49 (collectAsMap at RandomForest.scala:1054) with 4 output partitions
[2025-07-11T14:03:55.065+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO DAGScheduler: Final stage: ResultStage 79 (collectAsMap at RandomForest.scala:1054)
[2025-07-11T14:03:55.066+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78)
[2025-07-11T14:03:55.066+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 78)
[2025-07-11T14:03:55.069+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO DAGScheduler: Submitting ShuffleMapStage 78 (MapPartitionsRDD[162] at flatMap at RandomForest.scala:1039), which has no missing parents
[2025-07-11T14:03:55.079+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 281.5 KiB, free 424.5 MiB)
[2025-07-11T14:03:55.081+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 128.1 KiB, free 424.4 MiB)
[2025-07-11T14:03:55.081+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 138.4.31.23:41705 (size: 128.1 KiB, free: 433.9 MiB)
[2025-07-11T14:03:55.081+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:55.082+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[162] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:03:55.082+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO TaskSchedulerImpl: Adding task set 78.0 with 4 tasks resource profile 0
[2025-07-11T14:03:55.083+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 148) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:03:55.084+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 149) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:03:55.084+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO TaskSetManager: Starting task 2.0 in stage 78.0 (TID 150) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:03:55.084+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO TaskSetManager: Starting task 3.0 in stage 78.0 (TID 151) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:03:55.094+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO Executor: Running task 0.0 in stage 78.0 (TID 148)
[2025-07-11T14:03:55.094+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO Executor: Running task 1.0 in stage 78.0 (TID 149)
[2025-07-11T14:03:55.094+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO Executor: Running task 3.0 in stage 78.0 (TID 151)
[2025-07-11T14:03:55.095+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO Executor: Running task 2.0 in stage 78.0 (TID 150)
[2025-07-11T14:03:55.124+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO ShuffleBlockFetcherIterator: Getting 1 (366.2 KiB) non-empty blocks including 1 (366.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:55.126+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-11T14:03:55.129+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO ShuffleBlockFetcherIterator: Getting 1 (3.2 MiB) non-empty blocks including 1 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:55.129+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:55.132+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO ShuffleBlockFetcherIterator: Getting 1 (3.4 MiB) non-empty blocks including 1 (3.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:55.132+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-11T14:03:55.138+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO ShuffleBlockFetcherIterator: Getting 1 (384.6 KiB) non-empty blocks including 1 (384.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:55.138+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:55.904+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO Executor: Finished task 2.0 in stage 78.0 (TID 150). 6108 bytes result sent to driver
[2025-07-11T14:03:55.905+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO TaskSetManager: Finished task 2.0 in stage 78.0 (TID 150) in 821 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:03:55.957+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO Executor: Finished task 3.0 in stage 78.0 (TID 151). 6108 bytes result sent to driver
[2025-07-11T14:03:55.958+0200] {subprocess.py:93} INFO - 25/07/11 14:03:55 INFO TaskSetManager: Finished task 3.0 in stage 78.0 (TID 151) in 874 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:03:56.749+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO Executor: Finished task 1.0 in stage 78.0 (TID 149). 6108 bytes result sent to driver
[2025-07-11T14:03:56.750+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 149) in 1666 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:03:56.750+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO Executor: Finished task 0.0 in stage 78.0 (TID 148). 6108 bytes result sent to driver
[2025-07-11T14:03:56.751+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 148) in 1668 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:03:56.751+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool
[2025-07-11T14:03:56.751+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO DAGScheduler: ShuffleMapStage 78 (flatMap at RandomForest.scala:1039) finished in 1,681 s
[2025-07-11T14:03:56.751+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:03:56.751+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO DAGScheduler: running: Set()
[2025-07-11T14:03:56.752+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO DAGScheduler: waiting: Set(ResultStage 79)
[2025-07-11T14:03:56.752+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO DAGScheduler: failed: Set()
[2025-07-11T14:03:56.752+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[164] at map at RandomForest.scala:1054), which has no missing parents
[2025-07-11T14:03:56.753+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 9.9 KiB, free 424.4 MiB)
[2025-07-11T14:03:56.753+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 424.4 MiB)
[2025-07-11T14:03:56.753+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 138.4.31.23:41705 (size: 4.6 KiB, free: 433.9 MiB)
[2025-07-11T14:03:56.756+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:56.757+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 79 (MapPartitionsRDD[164] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:03:56.757+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO TaskSchedulerImpl: Adding task set 79.0 with 4 tasks resource profile 0
[2025-07-11T14:03:56.758+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 152) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:03:56.762+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 153) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:03:56.762+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO TaskSetManager: Starting task 2.0 in stage 79.0 (TID 154) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:03:56.762+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO TaskSetManager: Starting task 3.0 in stage 79.0 (TID 155) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:03:56.762+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO Executor: Running task 3.0 in stage 79.0 (TID 155)
[2025-07-11T14:03:56.762+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO Executor: Running task 1.0 in stage 79.0 (TID 153)
[2025-07-11T14:03:56.762+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO Executor: Running task 0.0 in stage 79.0 (TID 152)
[2025-07-11T14:03:56.762+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO Executor: Running task 2.0 in stage 79.0 (TID 154)
[2025-07-11T14:03:56.762+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO ShuffleBlockFetcherIterator: Getting 4 (5.0 KiB) non-empty blocks including 4 (5.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:56.762+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:56.762+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO ShuffleBlockFetcherIterator: Getting 4 (22.4 KiB) non-empty blocks including 4 (22.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:56.762+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:56.763+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO ShuffleBlockFetcherIterator: Getting 4 (4.5 KiB) non-empty blocks including 4 (4.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:56.763+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-11T14:03:56.763+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO ShuffleBlockFetcherIterator: Getting 4 (50.2 KiB) non-empty blocks including 4 (50.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:56.763+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:56.790+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO Executor: Finished task 2.0 in stage 79.0 (TID 154). 2565 bytes result sent to driver
[2025-07-11T14:03:56.791+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO Executor: Finished task 3.0 in stage 79.0 (TID 155). 2133 bytes result sent to driver
[2025-07-11T14:03:56.792+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO TaskSetManager: Finished task 3.0 in stage 79.0 (TID 155) in 33 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:03:56.792+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO TaskSetManager: Finished task 2.0 in stage 79.0 (TID 154) in 33 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:03:56.793+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO Executor: Finished task 0.0 in stage 79.0 (TID 152). 14351 bytes result sent to driver
[2025-07-11T14:03:56.793+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO Executor: Finished task 1.0 in stage 79.0 (TID 153). 25393 bytes result sent to driver
[2025-07-11T14:03:56.795+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 152) in 36 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:03:56.796+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 153) in 38 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:03:56.796+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool
[2025-07-11T14:03:56.798+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO DAGScheduler: ResultStage 79 (collectAsMap at RandomForest.scala:1054) finished in 0,045 s
[2025-07-11T14:03:56.798+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:03:56.798+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 79: Stage finished
[2025-07-11T14:03:56.798+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO DAGScheduler: Job 49 finished: collectAsMap at RandomForest.scala:1054, took 1,734192 s
[2025-07-11T14:03:56.805+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 51.8 KiB, free 424.3 MiB)
[2025-07-11T14:03:56.812+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 424.3 MiB)
[2025-07-11T14:03:56.813+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 138.4.31.23:41705 in memory (size: 4.6 KiB, free: 433.9 MiB)
[2025-07-11T14:03:56.813+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 138.4.31.23:41705 (size: 9.0 KiB, free: 433.9 MiB)
[2025-07-11T14:03:56.814+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO SparkContext: Created broadcast 66 from broadcast at RandomForest.scala:293
[2025-07-11T14:03:56.815+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 138.4.31.23:41705 in memory (size: 128.1 KiB, free: 434.0 MiB)
[2025-07-11T14:03:56.826+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO Instrumentation: [24920823] {"numFeatures":9}
[2025-07-11T14:03:56.827+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO Instrumentation: [24920823] {"numClasses":4}
[2025-07-11T14:03:56.827+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO Instrumentation: [24920823] {"numExamples":457013}
[2025-07-11T14:03:56.827+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO Instrumentation: [24920823] {"sumOfWeights":457013.0}
[2025-07-11T14:03:56.838+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 1160.0 B, free 424.7 MiB)
[2025-07-11T14:03:56.838+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 412.0 B, free 424.7 MiB)
[2025-07-11T14:03:56.838+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 138.4.31.23:41705 (size: 412.0 B, free: 434.0 MiB)
[2025-07-11T14:03:56.838+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO SparkContext: Created broadcast 67 from broadcast at RandomForest.scala:622
[2025-07-11T14:03:56.864+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
[2025-07-11T14:03:56.865+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO DAGScheduler: Registering RDD 167 (mapPartitions at RandomForest.scala:644) as input to shuffle 25
[2025-07-11T14:03:56.866+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO DAGScheduler: Got job 50 (collectAsMap at RandomForest.scala:663) with 4 output partitions
[2025-07-11T14:03:56.866+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO DAGScheduler: Final stage: ResultStage 82 (collectAsMap at RandomForest.scala:663)
[2025-07-11T14:03:56.866+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 81)
[2025-07-11T14:03:56.866+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 81)
[2025-07-11T14:03:56.870+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[167] at mapPartitions at RandomForest.scala:644), which has no missing parents
[2025-07-11T14:03:56.879+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 298.0 KiB, free 424.4 MiB)
[2025-07-11T14:03:56.881+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 136.6 KiB, free 424.3 MiB)
[2025-07-11T14:03:56.881+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 138.4.31.23:41705 (size: 136.6 KiB, free: 433.8 MiB)
[2025-07-11T14:03:56.881+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:56.882+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[167] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:03:56.882+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO TaskSchedulerImpl: Adding task set 81.0 with 4 tasks resource profile 0
[2025-07-11T14:03:56.884+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 156) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:03:56.884+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 157) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:03:56.884+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO TaskSetManager: Starting task 2.0 in stage 81.0 (TID 158) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:03:56.884+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO TaskSetManager: Starting task 3.0 in stage 81.0 (TID 159) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:03:56.884+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO Executor: Running task 1.0 in stage 81.0 (TID 157)
[2025-07-11T14:03:56.886+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO Executor: Running task 3.0 in stage 81.0 (TID 159)
[2025-07-11T14:03:56.887+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO Executor: Running task 2.0 in stage 81.0 (TID 158)
[2025-07-11T14:03:56.887+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO Executor: Running task 0.0 in stage 81.0 (TID 156)
[2025-07-11T14:03:56.928+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO ShuffleBlockFetcherIterator: Getting 1 (3.4 MiB) non-empty blocks including 1 (3.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:56.928+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:56.929+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO ShuffleBlockFetcherIterator: Getting 1 (3.2 MiB) non-empty blocks including 1 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:56.930+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:56.930+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO ShuffleBlockFetcherIterator: Getting 1 (384.6 KiB) non-empty blocks including 1 (384.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:56.930+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-11T14:03:56.932+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO ShuffleBlockFetcherIterator: Getting 1 (366.2 KiB) non-empty blocks including 1 (366.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:56.932+0200] {subprocess.py:93} INFO - 25/07/11 14:03:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:57.725+0200] {subprocess.py:93} INFO - 25/07/11 14:03:57 INFO MemoryStore: Block rdd_166_3 stored as values in memory (estimated size 3.9 MiB, free 420.4 MiB)
[2025-07-11T14:03:57.729+0200] {subprocess.py:93} INFO - 25/07/11 14:03:57 INFO BlockManagerInfo: Added rdd_166_3 in memory on 138.4.31.23:41705 (size: 3.9 MiB, free: 429.9 MiB)
[2025-07-11T14:03:57.744+0200] {subprocess.py:93} INFO - 25/07/11 14:03:57 INFO MemoryStore: Block rdd_166_2 stored as values in memory (estimated size 3.8 MiB, free 416.6 MiB)
[2025-07-11T14:03:57.744+0200] {subprocess.py:93} INFO - 25/07/11 14:03:57 INFO BlockManagerInfo: Added rdd_166_2 in memory on 138.4.31.23:41705 (size: 3.8 MiB, free: 426.2 MiB)
[2025-07-11T14:03:57.983+0200] {subprocess.py:93} INFO - 25/07/11 14:03:57 INFO Executor: Finished task 2.0 in stage 81.0 (TID 158). 6108 bytes result sent to driver
[2025-07-11T14:03:57.984+0200] {subprocess.py:93} INFO - 25/07/11 14:03:57 INFO TaskSetManager: Finished task 2.0 in stage 81.0 (TID 158) in 1101 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:03:57.990+0200] {subprocess.py:93} INFO - 25/07/11 14:03:57 INFO Executor: Finished task 3.0 in stage 81.0 (TID 159). 6108 bytes result sent to driver
[2025-07-11T14:03:57.993+0200] {subprocess.py:93} INFO - 25/07/11 14:03:57 INFO TaskSetManager: Finished task 3.0 in stage 81.0 (TID 159) in 1108 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:03:58.695+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO MemoryStore: Block rdd_166_0 stored as values in memory (estimated size 34.6 MiB, free 382.0 MiB)
[2025-07-11T14:03:58.695+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO BlockManagerInfo: Added rdd_166_0 in memory on 138.4.31.23:41705 (size: 34.6 MiB, free: 391.6 MiB)
[2025-07-11T14:03:58.806+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO MemoryStore: Block rdd_166_1 stored as values in memory (estimated size 36.2 MiB, free 345.9 MiB)
[2025-07-11T14:03:58.807+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO BlockManagerInfo: Added rdd_166_1 in memory on 138.4.31.23:41705 (size: 36.2 MiB, free: 355.4 MiB)
[2025-07-11T14:03:58.835+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 138.4.31.23:41705 in memory (size: 126.8 KiB, free: 355.6 MiB)
[2025-07-11T14:03:58.922+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO Executor: Finished task 0.0 in stage 81.0 (TID 156). 6108 bytes result sent to driver
[2025-07-11T14:03:58.923+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 156) in 2040 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:03:58.980+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO Executor: Finished task 1.0 in stage 81.0 (TID 157). 6108 bytes result sent to driver
[2025-07-11T14:03:58.981+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 157) in 2098 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:03:58.982+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool
[2025-07-11T14:03:58.982+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO DAGScheduler: ShuffleMapStage 81 (mapPartitions at RandomForest.scala:644) finished in 2,112 s
[2025-07-11T14:03:58.982+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:03:58.982+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO DAGScheduler: running: Set()
[2025-07-11T14:03:58.982+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO DAGScheduler: waiting: Set(ResultStage 82)
[2025-07-11T14:03:58.982+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO DAGScheduler: failed: Set()
[2025-07-11T14:03:58.982+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[169] at map at RandomForest.scala:663), which has no missing parents
[2025-07-11T14:03:58.983+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 7.2 KiB, free 346.3 MiB)
[2025-07-11T14:03:58.984+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 346.3 MiB)
[2025-07-11T14:03:58.984+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 138.4.31.23:41705 (size: 3.8 KiB, free: 355.5 MiB)
[2025-07-11T14:03:58.984+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:58.985+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 82 (MapPartitionsRDD[169] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:03:58.985+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO TaskSchedulerImpl: Adding task set 82.0 with 4 tasks resource profile 0
[2025-07-11T14:03:58.986+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 160) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:03:58.987+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO TaskSetManager: Starting task 1.0 in stage 82.0 (TID 161) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:03:58.987+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO TaskSetManager: Starting task 2.0 in stage 82.0 (TID 162) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:03:58.987+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO TaskSetManager: Starting task 3.0 in stage 82.0 (TID 163) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:03:58.987+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO Executor: Running task 1.0 in stage 82.0 (TID 161)
[2025-07-11T14:03:58.987+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO Executor: Running task 0.0 in stage 82.0 (TID 160)
[2025-07-11T14:03:58.987+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO Executor: Running task 2.0 in stage 82.0 (TID 162)
[2025-07-11T14:03:58.987+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO Executor: Running task 3.0 in stage 82.0 (TID 163)
[2025-07-11T14:03:58.989+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO ShuffleBlockFetcherIterator: Getting 4 (179.0 KiB) non-empty blocks including 4 (179.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:58.990+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:58.991+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO ShuffleBlockFetcherIterator: Getting 4 (323.9 KiB) non-empty blocks including 4 (323.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:58.994+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO ShuffleBlockFetcherIterator: Getting 4 (267.7 KiB) non-empty blocks including 4 (267.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:58.994+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:58.994+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO ShuffleBlockFetcherIterator: Getting 4 (232.1 KiB) non-empty blocks including 4 (232.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:58.994+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-11T14:03:58.994+0200] {subprocess.py:93} INFO - 25/07/11 14:03:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-11T14:03:59.390+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO Executor: Finished task 2.0 in stage 82.0 (TID 162). 2814 bytes result sent to driver
[2025-07-11T14:03:59.399+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO TaskSetManager: Finished task 2.0 in stage 82.0 (TID 162) in 412 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:03:59.451+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO Executor: Finished task 3.0 in stage 82.0 (TID 163). 6334 bytes result sent to driver
[2025-07-11T14:03:59.453+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO Executor: Finished task 1.0 in stage 82.0 (TID 161). 6583 bytes result sent to driver
[2025-07-11T14:03:59.460+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO TaskSetManager: Finished task 3.0 in stage 82.0 (TID 163) in 472 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:03:59.462+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO TaskSetManager: Finished task 1.0 in stage 82.0 (TID 161) in 476 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:03:59.498+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO Executor: Finished task 0.0 in stage 82.0 (TID 160). 6576 bytes result sent to driver
[2025-07-11T14:03:59.499+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 160) in 514 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:03:59.499+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool
[2025-07-11T14:03:59.502+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO DAGScheduler: ResultStage 82 (collectAsMap at RandomForest.scala:663) finished in 0,518 s
[2025-07-11T14:03:59.502+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:03:59.503+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 82: Stage finished
[2025-07-11T14:03:59.503+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO DAGScheduler: Job 50 finished: collectAsMap at RandomForest.scala:663, took 2,637960 s
[2025-07-11T14:03:59.503+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO TorrentBroadcast: Destroying Broadcast(67) (from destroy at RandomForest.scala:674)
[2025-07-11T14:03:59.510+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 2.2 KiB, free 346.3 MiB)
[2025-07-11T14:03:59.511+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 537.0 B, free 346.3 MiB)
[2025-07-11T14:03:59.512+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 138.4.31.23:41705 (size: 537.0 B, free: 355.5 MiB)
[2025-07-11T14:03:59.512+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO SparkContext: Created broadcast 70 from broadcast at RandomForest.scala:622
[2025-07-11T14:03:59.514+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 138.4.31.23:41705 in memory (size: 412.0 B, free: 355.5 MiB)
[2025-07-11T14:03:59.560+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 138.4.31.23:41705 in memory (size: 3.8 KiB, free: 355.6 MiB)
[2025-07-11T14:03:59.568+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
[2025-07-11T14:03:59.570+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO DAGScheduler: Registering RDD 170 (mapPartitions at RandomForest.scala:644) as input to shuffle 26
[2025-07-11T14:03:59.570+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO DAGScheduler: Got job 51 (collectAsMap at RandomForest.scala:663) with 4 output partitions
[2025-07-11T14:03:59.570+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO DAGScheduler: Final stage: ResultStage 85 (collectAsMap at RandomForest.scala:663)
[2025-07-11T14:03:59.570+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 84)
[2025-07-11T14:03:59.570+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 84)
[2025-07-11T14:03:59.576+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO DAGScheduler: Submitting ShuffleMapStage 84 (MapPartitionsRDD[170] at mapPartitions at RandomForest.scala:644), which has no missing parents
[2025-07-11T14:03:59.593+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 311.7 KiB, free 346.0 MiB)
[2025-07-11T14:03:59.596+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 141.8 KiB, free 345.8 MiB)
[2025-07-11T14:03:59.596+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 138.4.31.23:41705 (size: 141.8 KiB, free: 355.4 MiB)
[2025-07-11T14:03:59.597+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:59.597+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 84 (MapPartitionsRDD[170] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:03:59.597+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO TaskSchedulerImpl: Adding task set 84.0 with 4 tasks resource profile 0
[2025-07-11T14:03:59.602+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 164) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:03:59.603+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO TaskSetManager: Starting task 1.0 in stage 84.0 (TID 165) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:03:59.603+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO TaskSetManager: Starting task 2.0 in stage 84.0 (TID 166) (138.4.31.23, executor driver, partition 2, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:03:59.603+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO TaskSetManager: Starting task 3.0 in stage 84.0 (TID 167) (138.4.31.23, executor driver, partition 3, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:03:59.603+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO Executor: Running task 0.0 in stage 84.0 (TID 164)
[2025-07-11T14:03:59.603+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO Executor: Running task 1.0 in stage 84.0 (TID 165)
[2025-07-11T14:03:59.603+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO Executor: Running task 2.0 in stage 84.0 (TID 166)
[2025-07-11T14:03:59.604+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO Executor: Running task 3.0 in stage 84.0 (TID 167)
[2025-07-11T14:03:59.618+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO BlockManager: Found block rdd_166_1 locally
[2025-07-11T14:03:59.620+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO BlockManager: Found block rdd_166_2 locally
[2025-07-11T14:03:59.623+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO BlockManager: Found block rdd_166_0 locally
[2025-07-11T14:03:59.626+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO BlockManager: Found block rdd_166_3 locally
[2025-07-11T14:03:59.764+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO Executor: Finished task 3.0 in stage 84.0 (TID 167). 5420 bytes result sent to driver
[2025-07-11T14:03:59.765+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO TaskSetManager: Finished task 3.0 in stage 84.0 (TID 167) in 163 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:03:59.769+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO Executor: Finished task 2.0 in stage 84.0 (TID 166). 5420 bytes result sent to driver
[2025-07-11T14:03:59.770+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO TaskSetManager: Finished task 2.0 in stage 84.0 (TID 166) in 168 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:03:59.918+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO Executor: Finished task 0.0 in stage 84.0 (TID 164). 5420 bytes result sent to driver
[2025-07-11T14:03:59.919+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 164) in 318 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:03:59.937+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO Executor: Finished task 1.0 in stage 84.0 (TID 165). 5420 bytes result sent to driver
[2025-07-11T14:03:59.937+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO TaskSetManager: Finished task 1.0 in stage 84.0 (TID 165) in 336 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:03:59.937+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool
[2025-07-11T14:03:59.938+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO DAGScheduler: ShuffleMapStage 84 (mapPartitions at RandomForest.scala:644) finished in 0,362 s
[2025-07-11T14:03:59.938+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:03:59.938+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO DAGScheduler: running: Set()
[2025-07-11T14:03:59.938+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO DAGScheduler: waiting: Set(ResultStage 85)
[2025-07-11T14:03:59.938+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO DAGScheduler: failed: Set()
[2025-07-11T14:03:59.938+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[172] at map at RandomForest.scala:663), which has no missing parents
[2025-07-11T14:03:59.940+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 9.4 KiB, free 345.8 MiB)
[2025-07-11T14:03:59.940+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 345.8 MiB)
[2025-07-11T14:03:59.940+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 138.4.31.23:41705 (size: 4.9 KiB, free: 355.4 MiB)
[2025-07-11T14:03:59.941+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:03:59.941+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 85 (MapPartitionsRDD[172] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:03:59.941+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO TaskSchedulerImpl: Adding task set 85.0 with 4 tasks resource profile 0
[2025-07-11T14:03:59.942+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 168) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:03:59.943+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO TaskSetManager: Starting task 1.0 in stage 85.0 (TID 169) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:03:59.943+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO TaskSetManager: Starting task 2.0 in stage 85.0 (TID 170) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:03:59.943+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO TaskSetManager: Starting task 3.0 in stage 85.0 (TID 171) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:03:59.943+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO Executor: Running task 0.0 in stage 85.0 (TID 168)
[2025-07-11T14:03:59.943+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO Executor: Running task 2.0 in stage 85.0 (TID 170)
[2025-07-11T14:03:59.943+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO Executor: Running task 3.0 in stage 85.0 (TID 171)
[2025-07-11T14:03:59.947+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO ShuffleBlockFetcherIterator: Getting 4 (433.2 KiB) non-empty blocks including 4 (433.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:59.947+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:59.947+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO Executor: Running task 1.0 in stage 85.0 (TID 169)
[2025-07-11T14:03:59.947+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO ShuffleBlockFetcherIterator: Getting 4 (170.9 KiB) non-empty blocks including 4 (170.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:59.952+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:59.952+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO ShuffleBlockFetcherIterator: Getting 4 (375.9 KiB) non-empty blocks including 4 (375.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:59.952+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:03:59.953+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO ShuffleBlockFetcherIterator: Getting 4 (373.7 KiB) non-empty blocks including 4 (373.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:03:59.954+0200] {subprocess.py:93} INFO - 25/07/11 14:03:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:00.035+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO Executor: Finished task 2.0 in stage 85.0 (TID 170). 10668 bytes result sent to driver
[2025-07-11T14:04:00.036+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO TaskSetManager: Finished task 2.0 in stage 85.0 (TID 170) in 93 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:04:00.083+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO Executor: Finished task 1.0 in stage 85.0 (TID 169). 43250 bytes result sent to driver
[2025-07-11T14:04:00.086+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO TaskSetManager: Finished task 1.0 in stage 85.0 (TID 169) in 144 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:04:00.204+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 138.4.31.23:41705 in memory (size: 141.8 KiB, free: 355.5 MiB)
[2025-07-11T14:04:00.213+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO Executor: Finished task 3.0 in stage 85.0 (TID 171). 113450 bytes result sent to driver
[2025-07-11T14:04:00.217+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO TaskSetManager: Finished task 3.0 in stage 85.0 (TID 171) in 273 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:04:00.223+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO Executor: Finished task 0.0 in stage 85.0 (TID 168). 89325 bytes result sent to driver
[2025-07-11T14:04:00.227+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 168) in 285 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:04:00.227+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool
[2025-07-11T14:04:00.230+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO DAGScheduler: ResultStage 85 (collectAsMap at RandomForest.scala:663) finished in 0,288 s
[2025-07-11T14:04:00.230+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:04:00.231+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 85: Stage finished
[2025-07-11T14:04:00.231+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO DAGScheduler: Job 51 finished: collectAsMap at RandomForest.scala:663, took 0,662726 s
[2025-07-11T14:04:00.231+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO TorrentBroadcast: Destroying Broadcast(70) (from destroy at RandomForest.scala:674)
[2025-07-11T14:04:00.232+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 138.4.31.23:41705 in memory (size: 537.0 B, free: 355.5 MiB)
[2025-07-11T14:04:00.233+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 4.8 KiB, free 346.3 MiB)
[2025-07-11T14:04:00.234+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 755.0 B, free 346.3 MiB)
[2025-07-11T14:04:00.234+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 138.4.31.23:41705 (size: 755.0 B, free: 355.5 MiB)
[2025-07-11T14:04:00.234+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO SparkContext: Created broadcast 73 from broadcast at RandomForest.scala:622
[2025-07-11T14:04:00.260+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
[2025-07-11T14:04:00.263+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO DAGScheduler: Registering RDD 173 (mapPartitions at RandomForest.scala:644) as input to shuffle 27
[2025-07-11T14:04:00.263+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO DAGScheduler: Got job 52 (collectAsMap at RandomForest.scala:663) with 4 output partitions
[2025-07-11T14:04:00.263+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO DAGScheduler: Final stage: ResultStage 88 (collectAsMap at RandomForest.scala:663)
[2025-07-11T14:04:00.263+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 87)
[2025-07-11T14:04:00.263+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 87)
[2025-07-11T14:04:00.263+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO DAGScheduler: Submitting ShuffleMapStage 87 (MapPartitionsRDD[173] at mapPartitions at RandomForest.scala:644), which has no missing parents
[2025-07-11T14:04:00.274+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 553.0 KiB, free 345.7 MiB)
[2025-07-11T14:04:00.277+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 246.1 KiB, free 345.5 MiB)
[2025-07-11T14:04:00.277+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 138.4.31.23:41705 (size: 246.1 KiB, free: 355.3 MiB)
[2025-07-11T14:04:00.278+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:00.278+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 87 (MapPartitionsRDD[173] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:04:00.278+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO TaskSchedulerImpl: Adding task set 87.0 with 4 tasks resource profile 0
[2025-07-11T14:04:00.279+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 172) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:04:00.279+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO TaskSetManager: Starting task 1.0 in stage 87.0 (TID 173) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:04:00.280+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO TaskSetManager: Starting task 2.0 in stage 87.0 (TID 174) (138.4.31.23, executor driver, partition 2, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:04:00.280+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO TaskSetManager: Starting task 3.0 in stage 87.0 (TID 175) (138.4.31.23, executor driver, partition 3, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:04:00.280+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO Executor: Running task 0.0 in stage 87.0 (TID 172)
[2025-07-11T14:04:00.280+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO Executor: Running task 3.0 in stage 87.0 (TID 175)
[2025-07-11T14:04:00.286+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO Executor: Running task 1.0 in stage 87.0 (TID 173)
[2025-07-11T14:04:00.286+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO Executor: Running task 2.0 in stage 87.0 (TID 174)
[2025-07-11T14:04:00.297+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO BlockManager: Found block rdd_166_3 locally
[2025-07-11T14:04:00.304+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO BlockManager: Found block rdd_166_1 locally
[2025-07-11T14:04:00.322+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO BlockManager: Found block rdd_166_0 locally
[2025-07-11T14:04:00.325+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO BlockManager: Found block rdd_166_2 locally
[2025-07-11T14:04:00.549+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 138.4.31.23:41705 in memory (size: 136.6 KiB, free: 355.4 MiB)
[2025-07-11T14:04:00.587+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO Executor: Finished task 3.0 in stage 87.0 (TID 175). 5420 bytes result sent to driver
[2025-07-11T14:04:00.595+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO TaskSetManager: Finished task 3.0 in stage 87.0 (TID 175) in 313 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:04:00.633+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO Executor: Finished task 2.0 in stage 87.0 (TID 174). 5420 bytes result sent to driver
[2025-07-11T14:04:00.633+0200] {subprocess.py:93} INFO - 25/07/11 14:04:00 INFO TaskSetManager: Finished task 2.0 in stage 87.0 (TID 174) in 352 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:04:01.057+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO Executor: Finished task 1.0 in stage 87.0 (TID 173). 5420 bytes result sent to driver
[2025-07-11T14:04:01.058+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO TaskSetManager: Finished task 1.0 in stage 87.0 (TID 173) in 779 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:04:01.059+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO Executor: Finished task 0.0 in stage 87.0 (TID 172). 5420 bytes result sent to driver
[2025-07-11T14:04:01.061+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 172) in 780 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:04:01.061+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool
[2025-07-11T14:04:01.061+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO DAGScheduler: ShuffleMapStage 87 (mapPartitions at RandomForest.scala:644) finished in 0,796 s
[2025-07-11T14:04:01.061+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:04:01.061+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO DAGScheduler: running: Set()
[2025-07-11T14:04:01.062+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO DAGScheduler: waiting: Set(ResultStage 88)
[2025-07-11T14:04:01.062+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO DAGScheduler: failed: Set()
[2025-07-11T14:04:01.062+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[175] at map at RandomForest.scala:663), which has no missing parents
[2025-07-11T14:04:01.062+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 11.5 KiB, free 345.9 MiB)
[2025-07-11T14:04:01.063+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 345.9 MiB)
[2025-07-11T14:04:01.063+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 138.4.31.23:41705 (size: 5.7 KiB, free: 355.4 MiB)
[2025-07-11T14:04:01.064+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:01.065+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 88 (MapPartitionsRDD[175] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:04:01.065+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO TaskSchedulerImpl: Adding task set 88.0 with 4 tasks resource profile 0
[2025-07-11T14:04:01.067+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 176) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:04:01.067+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO TaskSetManager: Starting task 1.0 in stage 88.0 (TID 177) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:04:01.067+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO TaskSetManager: Starting task 2.0 in stage 88.0 (TID 178) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:04:01.067+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO TaskSetManager: Starting task 3.0 in stage 88.0 (TID 179) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:04:01.067+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO Executor: Running task 2.0 in stage 88.0 (TID 178)
[2025-07-11T14:04:01.067+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO Executor: Running task 3.0 in stage 88.0 (TID 179)
[2025-07-11T14:04:01.068+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO Executor: Running task 1.0 in stage 88.0 (TID 177)
[2025-07-11T14:04:01.069+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO Executor: Running task 0.0 in stage 88.0 (TID 176)
[2025-07-11T14:04:01.070+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO ShuffleBlockFetcherIterator: Getting 4 (431.1 KiB) non-empty blocks including 4 (431.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:01.070+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO ShuffleBlockFetcherIterator: Getting 4 (342.8 KiB) non-empty blocks including 4 (342.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:01.070+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:01.070+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:01.072+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO ShuffleBlockFetcherIterator: Getting 4 (459.4 KiB) non-empty blocks including 4 (459.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:01.072+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:01.077+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO ShuffleBlockFetcherIterator: Getting 4 (577.0 KiB) non-empty blocks including 4 (577.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:01.078+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:01.100+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 138.4.31.23:41705 in memory (size: 4.9 KiB, free: 355.4 MiB)
[2025-07-11T14:04:01.101+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 138.4.31.23:41705 in memory (size: 246.1 KiB, free: 355.7 MiB)
[2025-07-11T14:04:01.291+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO Executor: Finished task 2.0 in stage 88.0 (TID 178). 28033 bytes result sent to driver
[2025-07-11T14:04:01.293+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO TaskSetManager: Finished task 2.0 in stage 88.0 (TID 178) in 226 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:04:01.335+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO Executor: Finished task 0.0 in stage 88.0 (TID 176). 4990 bytes result sent to driver
[2025-07-11T14:04:01.336+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 176) in 269 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:04:01.377+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO Executor: Finished task 3.0 in stage 88.0 (TID 179). 11338 bytes result sent to driver
[2025-07-11T14:04:01.378+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO TaskSetManager: Finished task 3.0 in stage 88.0 (TID 179) in 311 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:04:01.455+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO Executor: Finished task 1.0 in stage 88.0 (TID 177). 172614 bytes result sent to driver
[2025-07-11T14:04:01.457+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO TaskSetManager: Finished task 1.0 in stage 88.0 (TID 177) in 390 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:04:01.457+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool
[2025-07-11T14:04:01.458+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO DAGScheduler: ResultStage 88 (collectAsMap at RandomForest.scala:663) finished in 0,397 s
[2025-07-11T14:04:01.458+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:04:01.458+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 88: Stage finished
[2025-07-11T14:04:01.458+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO DAGScheduler: Job 52 finished: collectAsMap at RandomForest.scala:663, took 1,197863 s
[2025-07-11T14:04:01.459+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO TorrentBroadcast: Destroying Broadcast(73) (from destroy at RandomForest.scala:674)
[2025-07-11T14:04:01.462+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 9.7 KiB, free 346.7 MiB)
[2025-07-11T14:04:01.463+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 138.4.31.23:41705 in memory (size: 755.0 B, free: 355.7 MiB)
[2025-07-11T14:04:01.465+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 1216.0 B, free 346.7 MiB)
[2025-07-11T14:04:01.465+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 138.4.31.23:41705 (size: 1216.0 B, free: 355.7 MiB)
[2025-07-11T14:04:01.465+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO SparkContext: Created broadcast 76 from broadcast at RandomForest.scala:622
[2025-07-11T14:04:01.486+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
[2025-07-11T14:04:01.486+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO DAGScheduler: Registering RDD 176 (mapPartitions at RandomForest.scala:644) as input to shuffle 28
[2025-07-11T14:04:01.486+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO DAGScheduler: Got job 53 (collectAsMap at RandomForest.scala:663) with 4 output partitions
[2025-07-11T14:04:01.486+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO DAGScheduler: Final stage: ResultStage 91 (collectAsMap at RandomForest.scala:663)
[2025-07-11T14:04:01.486+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)
[2025-07-11T14:04:01.486+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 90)
[2025-07-11T14:04:01.487+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO DAGScheduler: Submitting ShuffleMapStage 90 (MapPartitionsRDD[176] at mapPartitions at RandomForest.scala:644), which has no missing parents
[2025-07-11T14:04:01.498+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 757.7 KiB, free 345.9 MiB)
[2025-07-11T14:04:01.500+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 329.8 KiB, free 345.6 MiB)
[2025-07-11T14:04:01.501+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 138.4.31.23:41705 (size: 329.8 KiB, free: 355.4 MiB)
[2025-07-11T14:04:01.501+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:01.501+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 90 (MapPartitionsRDD[176] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:04:01.501+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO TaskSchedulerImpl: Adding task set 90.0 with 4 tasks resource profile 0
[2025-07-11T14:04:01.502+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 180) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:04:01.502+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO TaskSetManager: Starting task 1.0 in stage 90.0 (TID 181) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:04:01.512+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO TaskSetManager: Starting task 2.0 in stage 90.0 (TID 182) (138.4.31.23, executor driver, partition 2, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:04:01.512+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO TaskSetManager: Starting task 3.0 in stage 90.0 (TID 183) (138.4.31.23, executor driver, partition 3, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:04:01.513+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO Executor: Running task 0.0 in stage 90.0 (TID 180)
[2025-07-11T14:04:01.513+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO Executor: Running task 2.0 in stage 90.0 (TID 182)
[2025-07-11T14:04:01.513+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO Executor: Running task 1.0 in stage 90.0 (TID 181)
[2025-07-11T14:04:01.513+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO Executor: Running task 3.0 in stage 90.0 (TID 183)
[2025-07-11T14:04:01.524+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO BlockManager: Found block rdd_166_0 locally
[2025-07-11T14:04:01.533+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO BlockManager: Found block rdd_166_3 locally
[2025-07-11T14:04:01.538+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO BlockManager: Found block rdd_166_2 locally
[2025-07-11T14:04:01.540+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO BlockManager: Found block rdd_166_1 locally
[2025-07-11T14:04:01.793+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO Executor: Finished task 3.0 in stage 90.0 (TID 183). 5463 bytes result sent to driver
[2025-07-11T14:04:01.794+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO TaskSetManager: Finished task 3.0 in stage 90.0 (TID 183) in 292 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:04:01.819+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO Executor: Finished task 2.0 in stage 90.0 (TID 182). 5463 bytes result sent to driver
[2025-07-11T14:04:01.821+0200] {subprocess.py:93} INFO - 25/07/11 14:04:01 INFO TaskSetManager: Finished task 2.0 in stage 90.0 (TID 182) in 318 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:04:02.169+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO Executor: Finished task 0.0 in stage 90.0 (TID 180). 5463 bytes result sent to driver
[2025-07-11T14:04:02.170+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 180) in 668 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:04:02.200+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO Executor: Finished task 1.0 in stage 90.0 (TID 181). 5463 bytes result sent to driver
[2025-07-11T14:04:02.200+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO TaskSetManager: Finished task 1.0 in stage 90.0 (TID 181) in 698 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:04:02.201+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool
[2025-07-11T14:04:02.201+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO DAGScheduler: ShuffleMapStage 90 (mapPartitions at RandomForest.scala:644) finished in 0,714 s
[2025-07-11T14:04:02.201+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:04:02.201+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO DAGScheduler: running: Set()
[2025-07-11T14:04:02.201+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO DAGScheduler: waiting: Set(ResultStage 91)
[2025-07-11T14:04:02.201+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO DAGScheduler: failed: Set()
[2025-07-11T14:04:02.201+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[178] at map at RandomForest.scala:663), which has no missing parents
[2025-07-11T14:04:02.207+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 15.6 KiB, free 345.6 MiB)
[2025-07-11T14:04:02.208+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 345.6 MiB)
[2025-07-11T14:04:02.208+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 138.4.31.23:41705 (size: 7.3 KiB, free: 355.3 MiB)
[2025-07-11T14:04:02.209+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:02.209+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 91 (MapPartitionsRDD[178] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:04:02.211+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO TaskSchedulerImpl: Adding task set 91.0 with 4 tasks resource profile 0
[2025-07-11T14:04:02.213+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 184) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:04:02.214+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 185) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:04:02.220+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO TaskSetManager: Starting task 2.0 in stage 91.0 (TID 186) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:04:02.221+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO TaskSetManager: Starting task 3.0 in stage 91.0 (TID 187) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:04:02.221+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO Executor: Running task 2.0 in stage 91.0 (TID 186)
[2025-07-11T14:04:02.221+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO Executor: Running task 1.0 in stage 91.0 (TID 185)
[2025-07-11T14:04:02.221+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO Executor: Running task 3.0 in stage 91.0 (TID 187)
[2025-07-11T14:04:02.221+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO ShuffleBlockFetcherIterator: Getting 4 (619.3 KiB) non-empty blocks including 4 (619.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:02.221+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:02.221+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO ShuffleBlockFetcherIterator: Getting 4 (784.8 KiB) non-empty blocks including 4 (784.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:02.221+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:02.221+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO Executor: Running task 0.0 in stage 91.0 (TID 184)
[2025-07-11T14:04:02.224+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO ShuffleBlockFetcherIterator: Getting 4 (578.3 KiB) non-empty blocks including 4 (578.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:02.224+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:02.226+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO ShuffleBlockFetcherIterator: Getting 4 (666.0 KiB) non-empty blocks including 4 (666.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:02.227+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:02.954+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO Executor: Finished task 3.0 in stage 91.0 (TID 187). 117379 bytes result sent to driver
[2025-07-11T14:04:02.957+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO TaskSetManager: Finished task 3.0 in stage 91.0 (TID 187) in 743 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:04:02.972+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO Executor: Finished task 0.0 in stage 91.0 (TID 184). 79002 bytes result sent to driver
[2025-07-11T14:04:02.975+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 184) in 760 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:04:02.998+0200] {subprocess.py:93} INFO - 25/07/11 14:04:02 INFO Executor: Finished task 1.0 in stage 91.0 (TID 185). 97189 bytes result sent to driver
[2025-07-11T14:04:03.000+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 185) in 787 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:04:03.043+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO Executor: Finished task 2.0 in stage 91.0 (TID 186). 79339 bytes result sent to driver
[2025-07-11T14:04:03.045+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO TaskSetManager: Finished task 2.0 in stage 91.0 (TID 186) in 830 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:04:03.045+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool
[2025-07-11T14:04:03.045+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO DAGScheduler: ResultStage 91 (collectAsMap at RandomForest.scala:663) finished in 0,843 s
[2025-07-11T14:04:03.045+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:04:03.045+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 91: Stage finished
[2025-07-11T14:04:03.046+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO DAGScheduler: Job 53 finished: collectAsMap at RandomForest.scala:663, took 1,559816 s
[2025-07-11T14:04:03.046+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO TorrentBroadcast: Destroying Broadcast(76) (from destroy at RandomForest.scala:674)
[2025-07-11T14:04:03.047+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 138.4.31.23:41705 in memory (size: 1216.0 B, free: 355.4 MiB)
[2025-07-11T14:04:03.050+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 18.9 KiB, free 345.6 MiB)
[2025-07-11T14:04:03.051+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 2.1 KiB, free 345.6 MiB)
[2025-07-11T14:04:03.051+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 138.4.31.23:41705 (size: 2.1 KiB, free: 355.3 MiB)
[2025-07-11T14:04:03.053+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO SparkContext: Created broadcast 79 from broadcast at RandomForest.scala:622
[2025-07-11T14:04:03.075+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663
[2025-07-11T14:04:03.076+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO DAGScheduler: Registering RDD 179 (mapPartitions at RandomForest.scala:644) as input to shuffle 29
[2025-07-11T14:04:03.076+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO DAGScheduler: Got job 54 (collectAsMap at RandomForest.scala:663) with 4 output partitions
[2025-07-11T14:04:03.076+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO DAGScheduler: Final stage: ResultStage 94 (collectAsMap at RandomForest.scala:663)
[2025-07-11T14:04:03.076+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 93)
[2025-07-11T14:04:03.076+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 93)
[2025-07-11T14:04:03.077+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO DAGScheduler: Submitting ShuffleMapStage 93 (MapPartitionsRDD[179] at mapPartitions at RandomForest.scala:644), which has no missing parents
[2025-07-11T14:04:03.092+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 WARN DAGScheduler: Broadcasting large task binary with size 1118.1 KiB
[2025-07-11T14:04:03.092+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 1118.1 KiB, free 344.5 MiB)
[2025-07-11T14:04:03.096+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 479.7 KiB, free 344.0 MiB)
[2025-07-11T14:04:03.096+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 138.4.31.23:41705 (size: 479.7 KiB, free: 354.9 MiB)
[2025-07-11T14:04:03.096+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:03.096+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 93 (MapPartitionsRDD[179] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:04:03.096+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO TaskSchedulerImpl: Adding task set 93.0 with 4 tasks resource profile 0
[2025-07-11T14:04:03.097+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 188) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:04:03.097+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO TaskSetManager: Starting task 1.0 in stage 93.0 (TID 189) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:04:03.098+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO TaskSetManager: Starting task 2.0 in stage 93.0 (TID 190) (138.4.31.23, executor driver, partition 2, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:04:03.098+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO TaskSetManager: Starting task 3.0 in stage 93.0 (TID 191) (138.4.31.23, executor driver, partition 3, PROCESS_LOCAL, 14836 bytes)
[2025-07-11T14:04:03.098+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO Executor: Running task 3.0 in stage 93.0 (TID 191)
[2025-07-11T14:04:03.098+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO Executor: Running task 1.0 in stage 93.0 (TID 189)
[2025-07-11T14:04:03.098+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO Executor: Running task 2.0 in stage 93.0 (TID 190)
[2025-07-11T14:04:03.099+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO Executor: Running task 0.0 in stage 93.0 (TID 188)
[2025-07-11T14:04:03.130+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO BlockManager: Found block rdd_166_0 locally
[2025-07-11T14:04:03.134+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO BlockManager: Found block rdd_166_2 locally
[2025-07-11T14:04:03.141+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO BlockManager: Found block rdd_166_3 locally
[2025-07-11T14:04:03.149+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO BlockManager: Found block rdd_166_1 locally
[2025-07-11T14:04:03.264+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO Executor: Finished task 2.0 in stage 93.0 (TID 190). 5420 bytes result sent to driver
[2025-07-11T14:04:03.286+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO TaskSetManager: Finished task 2.0 in stage 93.0 (TID 190) in 184 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:04:03.300+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO Executor: Finished task 3.0 in stage 93.0 (TID 191). 5420 bytes result sent to driver
[2025-07-11T14:04:03.302+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO TaskSetManager: Finished task 3.0 in stage 93.0 (TID 191) in 204 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:04:03.362+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 138.4.31.23:41705 in memory (size: 7.3 KiB, free: 354.9 MiB)
[2025-07-11T14:04:03.807+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO Executor: Finished task 1.0 in stage 93.0 (TID 189). 5463 bytes result sent to driver
[2025-07-11T14:04:03.808+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO TaskSetManager: Finished task 1.0 in stage 93.0 (TID 189) in 711 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:04:03.880+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO Executor: Finished task 0.0 in stage 93.0 (TID 188). 5463 bytes result sent to driver
[2025-07-11T14:04:03.881+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 188) in 784 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:04:03.881+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool
[2025-07-11T14:04:03.882+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO DAGScheduler: ShuffleMapStage 93 (mapPartitions at RandomForest.scala:644) finished in 0,805 s
[2025-07-11T14:04:03.883+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:04:03.883+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO DAGScheduler: running: Set()
[2025-07-11T14:04:03.883+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO DAGScheduler: waiting: Set(ResultStage 94)
[2025-07-11T14:04:03.883+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO DAGScheduler: failed: Set()
[2025-07-11T14:04:03.883+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[181] at map at RandomForest.scala:663), which has no missing parents
[2025-07-11T14:04:03.886+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 24.0 KiB, free 344.0 MiB)
[2025-07-11T14:04:03.886+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 344.0 MiB)
[2025-07-11T14:04:03.886+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 138.4.31.23:41705 (size: 10.3 KiB, free: 354.9 MiB)
[2025-07-11T14:04:03.888+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:03.888+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 94 (MapPartitionsRDD[181] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:04:03.888+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO TaskSchedulerImpl: Adding task set 94.0 with 4 tasks resource profile 0
[2025-07-11T14:04:03.890+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 192) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:04:03.890+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO TaskSetManager: Starting task 1.0 in stage 94.0 (TID 193) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:04:03.890+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO TaskSetManager: Starting task 2.0 in stage 94.0 (TID 194) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:04:03.890+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO TaskSetManager: Starting task 3.0 in stage 94.0 (TID 195) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:04:03.894+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO Executor: Running task 1.0 in stage 94.0 (TID 193)
[2025-07-11T14:04:03.895+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO Executor: Running task 3.0 in stage 94.0 (TID 195)
[2025-07-11T14:04:03.897+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO ShuffleBlockFetcherIterator: Getting 4 (757.6 KiB) non-empty blocks including 4 (757.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:03.897+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:03.899+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO ShuffleBlockFetcherIterator: Getting 4 (897.4 KiB) non-empty blocks including 4 (897.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:03.899+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:03.905+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO Executor: Running task 0.0 in stage 94.0 (TID 192)
[2025-07-11T14:04:03.910+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO ShuffleBlockFetcherIterator: Getting 4 (749.4 KiB) non-empty blocks including 4 (749.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:03.911+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:03.918+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO Executor: Running task 2.0 in stage 94.0 (TID 194)
[2025-07-11T14:04:03.920+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO ShuffleBlockFetcherIterator: Getting 4 (861.8 KiB) non-empty blocks including 4 (861.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:03.920+0200] {subprocess.py:93} INFO - 25/07/11 14:04:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:04.718+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO Executor: Finished task 3.0 in stage 94.0 (TID 195). 132045 bytes result sent to driver
[2025-07-11T14:04:04.721+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO TaskSetManager: Finished task 3.0 in stage 94.0 (TID 195) in 831 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:04:04.724+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO Executor: Finished task 1.0 in stage 94.0 (TID 193). 163209 bytes result sent to driver
[2025-07-11T14:04:04.727+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO TaskSetManager: Finished task 1.0 in stage 94.0 (TID 193) in 837 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:04:04.739+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO Executor: Finished task 0.0 in stage 94.0 (TID 192). 102018 bytes result sent to driver
[2025-07-11T14:04:04.742+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 192) in 852 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:04:04.938+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO Executor: Finished task 2.0 in stage 94.0 (TID 194). 327296 bytes result sent to driver
[2025-07-11T14:04:04.945+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO TaskSetManager: Finished task 2.0 in stage 94.0 (TID 194) in 1055 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:04:04.945+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool
[2025-07-11T14:04:04.946+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO DAGScheduler: ResultStage 94 (collectAsMap at RandomForest.scala:663) finished in 1,062 s
[2025-07-11T14:04:04.946+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:04:04.946+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 94: Stage finished
[2025-07-11T14:04:04.946+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO DAGScheduler: Job 54 finished: collectAsMap at RandomForest.scala:663, took 1,870934 s
[2025-07-11T14:04:04.947+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO TorrentBroadcast: Destroying Broadcast(79) (from destroy at RandomForest.scala:674)
[2025-07-11T14:04:04.948+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO RandomForest: Internal timing for DecisionTree:
[2025-07-11T14:04:04.948+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 138.4.31.23:41705 in memory (size: 2.1 KiB, free: 354.9 MiB)
[2025-07-11T14:04:04.949+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO RandomForest:   init: 0.001784376
[2025-07-11T14:04:04.949+0200] {subprocess.py:93} INFO -   total: 8.12237182
[2025-07-11T14:04:04.949+0200] {subprocess.py:93} INFO -   findBestSplits: 8.111100182
[2025-07-11T14:04:04.949+0200] {subprocess.py:93} INFO -   chooseSplits: 8.099888606
[2025-07-11T14:04:04.958+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO MapPartitionsRDD: Removing RDD 166 from persistence list
[2025-07-11T14:04:04.967+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO BlockManager: Removing RDD 166
[2025-07-11T14:04:04.968+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO TorrentBroadcast: Destroying Broadcast(66) (from destroy at RandomForest.scala:305)
[2025-07-11T14:04:04.968+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 138.4.31.23:41705 in memory (size: 9.0 KiB, free: 433.3 MiB)
[2025-07-11T14:04:04.971+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO Instrumentation: [24920823] {"numClasses":4}
[2025-07-11T14:04:04.971+0200] {subprocess.py:93} INFO - 25/07/11 14:04:04 INFO Instrumentation: [24920823] {"numFeatures":9}
[2025-07-11T14:04:05.179+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO V2ScanRelationPushDown:
[2025-07-11T14:04:05.179+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:04:05.179+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:04:05.180+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:04:05.180+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:04:05.186+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO V2ScanRelationPushDown:
[2025-07-11T14:04:05.187+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-11T14:04:05.187+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:04:05.202+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:04:05.202+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:04:05.215+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 214.5 KiB, free 422.3 MiB)
[2025-07-11T14:04:05.222+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 422.3 MiB)
[2025-07-11T14:04:05.223+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 138.4.31.23:41705 (size: 38.9 KiB, free: 433.3 MiB)
[2025-07-11T14:04:05.223+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO SparkContext: Created broadcast 82 from rdd at ClassificationSummary.scala:58
[2025-07-11T14:04:05.224+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:04:05.228+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: Registering RDD 185 (rdd at ClassificationSummary.scala:58) as input to shuffle 30
[2025-07-11T14:04:05.229+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: Got map stage job 55 (rdd at ClassificationSummary.scala:58) with 2 output partitions
[2025-07-11T14:04:05.229+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: Final stage: ShuffleMapStage 95 (rdd at ClassificationSummary.scala:58)
[2025-07-11T14:04:05.229+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:04:05.229+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:05.229+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: Submitting ShuffleMapStage 95 (MapPartitionsRDD[185] at rdd at ClassificationSummary.scala:58), which has no missing parents
[2025-07-11T14:04:05.231+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 20.7 KiB, free 422.3 MiB)
[2025-07-11T14:04:05.232+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 9.3 KiB, free 422.2 MiB)
[2025-07-11T14:04:05.232+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 138.4.31.23:41705 (size: 9.3 KiB, free: 433.3 MiB)
[2025-07-11T14:04:05.234+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:05.234+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 95 (MapPartitionsRDD[185] at rdd at ClassificationSummary.scala:58) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:04:05.234+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSchedulerImpl: Adding task set 95.0 with 2 tasks resource profile 0
[2025-07-11T14:04:05.234+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: Registering RDD 189 (rdd at ClassificationSummary.scala:58) as input to shuffle 31
[2025-07-11T14:04:05.234+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: Got map stage job 56 (rdd at ClassificationSummary.scala:58) with 12 output partitions
[2025-07-11T14:04:05.234+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: Final stage: ShuffleMapStage 96 (rdd at ClassificationSummary.scala:58)
[2025-07-11T14:04:05.234+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:04:05.234+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:05.235+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 196) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:04:05.235+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Starting task 1.0 in stage 95.0 (TID 197) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:04:05.235+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Running task 1.0 in stage 95.0 (TID 197)
[2025-07-11T14:04:05.235+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Running task 0.0 in stage 95.0 (TID 196)
[2025-07-11T14:04:05.236+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: Submitting ShuffleMapStage 96 (MapPartitionsRDD[189] at rdd at ClassificationSummary.scala:58), which has no missing parents
[2025-07-11T14:04:05.238+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 18.7 KiB, free 422.2 MiB)
[2025-07-11T14:04:05.239+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 422.2 MiB)
[2025-07-11T14:04:05.239+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 138.4.31.23:41705 (size: 9.2 KiB, free: 433.2 MiB)
[2025-07-11T14:04:05.239+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:04:05.239+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:04:05.240+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:05.240+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 96 (MapPartitionsRDD[189] at rdd at ClassificationSummary.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
[2025-07-11T14:04:05.240+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSchedulerImpl: Adding task set 96.0 with 12 tasks resource profile 0
[2025-07-11T14:04:05.242+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 198) (138.4.31.23, executor driver, partition 0, ANY, 16719 bytes)
[2025-07-11T14:04:05.242+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Starting task 1.0 in stage 96.0 (TID 199) (138.4.31.23, executor driver, partition 1, ANY, 16839 bytes)
[2025-07-11T14:04:05.242+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Running task 0.0 in stage 96.0 (TID 198)
[2025-07-11T14:04:05.246+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Running task 1.0 in stage 96.0 (TID 199)
[2025-07-11T14:04:05.275+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 138.4.31.23:41705 in memory (size: 10.3 KiB, free: 433.3 MiB)
[2025-07-11T14:04:05.337+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Finished task 0.0 in stage 96.0 (TID 198). 1988 bytes result sent to driver
[2025-07-11T14:04:05.338+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Starting task 2.0 in stage 96.0 (TID 200) (138.4.31.23, executor driver, partition 2, ANY, 16715 bytes)
[2025-07-11T14:04:05.338+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 198) in 97 ms on 138.4.31.23 (executor driver) (1/12)
[2025-07-11T14:04:05.338+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Running task 2.0 in stage 96.0 (TID 200)
[2025-07-11T14:04:05.342+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Finished task 1.0 in stage 96.0 (TID 199). 1988 bytes result sent to driver
[2025-07-11T14:04:05.344+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Starting task 3.0 in stage 96.0 (TID 201) (138.4.31.23, executor driver, partition 3, ANY, 16839 bytes)
[2025-07-11T14:04:05.344+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Finished task 1.0 in stage 96.0 (TID 199) in 102 ms on 138.4.31.23 (executor driver) (2/12)
[2025-07-11T14:04:05.347+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Running task 3.0 in stage 96.0 (TID 201)
[2025-07-11T14:04:05.418+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Finished task 3.0 in stage 96.0 (TID 201). 1945 bytes result sent to driver
[2025-07-11T14:04:05.421+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Starting task 4.0 in stage 96.0 (TID 202) (138.4.31.23, executor driver, partition 4, ANY, 16839 bytes)
[2025-07-11T14:04:05.421+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Running task 4.0 in stage 96.0 (TID 202)
[2025-07-11T14:04:05.421+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Finished task 3.0 in stage 96.0 (TID 201) in 76 ms on 138.4.31.23 (executor driver) (3/12)
[2025-07-11T14:04:05.421+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Finished task 2.0 in stage 96.0 (TID 200). 1945 bytes result sent to driver
[2025-07-11T14:04:05.424+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Starting task 5.0 in stage 96.0 (TID 203) (138.4.31.23, executor driver, partition 5, ANY, 16839 bytes)
[2025-07-11T14:04:05.424+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Finished task 2.0 in stage 96.0 (TID 200) in 86 ms on 138.4.31.23 (executor driver) (4/12)
[2025-07-11T14:04:05.427+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Running task 5.0 in stage 96.0 (TID 203)
[2025-07-11T14:04:05.483+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Finished task 4.0 in stage 96.0 (TID 202). 1945 bytes result sent to driver
[2025-07-11T14:04:05.484+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Starting task 6.0 in stage 96.0 (TID 204) (138.4.31.23, executor driver, partition 6, ANY, 16719 bytes)
[2025-07-11T14:04:05.484+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Finished task 4.0 in stage 96.0 (TID 202) in 66 ms on 138.4.31.23 (executor driver) (5/12)
[2025-07-11T14:04:05.484+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Running task 6.0 in stage 96.0 (TID 204)
[2025-07-11T14:04:05.497+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Finished task 5.0 in stage 96.0 (TID 203). 1945 bytes result sent to driver
[2025-07-11T14:04:05.497+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Starting task 7.0 in stage 96.0 (TID 205) (138.4.31.23, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-11T14:04:05.497+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Finished task 5.0 in stage 96.0 (TID 203) in 74 ms on 138.4.31.23 (executor driver) (6/12)
[2025-07-11T14:04:05.500+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Running task 7.0 in stage 96.0 (TID 205)
[2025-07-11T14:04:05.536+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Finished task 6.0 in stage 96.0 (TID 204). 1945 bytes result sent to driver
[2025-07-11T14:04:05.537+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Starting task 8.0 in stage 96.0 (TID 206) (138.4.31.23, executor driver, partition 8, ANY, 16719 bytes)
[2025-07-11T14:04:05.537+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Running task 8.0 in stage 96.0 (TID 206)
[2025-07-11T14:04:05.537+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Finished task 6.0 in stage 96.0 (TID 204) in 53 ms on 138.4.31.23 (executor driver) (7/12)
[2025-07-11T14:04:05.592+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Finished task 7.0 in stage 96.0 (TID 205). 1945 bytes result sent to driver
[2025-07-11T14:04:05.592+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Finished task 8.0 in stage 96.0 (TID 206). 1945 bytes result sent to driver
[2025-07-11T14:04:05.593+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Starting task 9.0 in stage 96.0 (TID 207) (138.4.31.23, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-11T14:04:05.593+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Running task 9.0 in stage 96.0 (TID 207)
[2025-07-11T14:04:05.593+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Finished task 7.0 in stage 96.0 (TID 205) in 96 ms on 138.4.31.23 (executor driver) (8/12)
[2025-07-11T14:04:05.595+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Starting task 10.0 in stage 96.0 (TID 208) (138.4.31.23, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-11T14:04:05.595+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Running task 10.0 in stage 96.0 (TID 208)
[2025-07-11T14:04:05.596+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Finished task 8.0 in stage 96.0 (TID 206) in 59 ms on 138.4.31.23 (executor driver) (9/12)
[2025-07-11T14:04:05.684+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Finished task 10.0 in stage 96.0 (TID 208). 1945 bytes result sent to driver
[2025-07-11T14:04:05.685+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Starting task 11.0 in stage 96.0 (TID 209) (138.4.31.23, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-11T14:04:05.685+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Finished task 10.0 in stage 96.0 (TID 208) in 91 ms on 138.4.31.23 (executor driver) (10/12)
[2025-07-11T14:04:05.689+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Running task 11.0 in stage 96.0 (TID 209)
[2025-07-11T14:04:05.695+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Finished task 9.0 in stage 96.0 (TID 207). 1945 bytes result sent to driver
[2025-07-11T14:04:05.696+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Finished task 9.0 in stage 96.0 (TID 207) in 104 ms on 138.4.31.23 (executor driver) (11/12)
[2025-07-11T14:04:05.789+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Finished task 11.0 in stage 96.0 (TID 209). 1988 bytes result sent to driver
[2025-07-11T14:04:05.789+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Finished task 11.0 in stage 96.0 (TID 209) in 95 ms on 138.4.31.23 (executor driver) (12/12)
[2025-07-11T14:04:05.789+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool
[2025-07-11T14:04:05.789+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: ShuffleMapStage 96 (rdd at ClassificationSummary.scala:58) finished in 0,544 s
[2025-07-11T14:04:05.789+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:04:05.789+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: running: Set(ShuffleMapStage 95)
[2025-07-11T14:04:05.789+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:04:05.789+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: failed: Set()
[2025-07-11T14:04:05.806+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO ShufflePartitionsUtil: For shuffle(31), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:04:05.836+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:04:05.840+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: Got job 57 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-11T14:04:05.840+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: Final stage: ResultStage 98 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-11T14:04:05.840+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 97)
[2025-07-11T14:04:05.840+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:05.841+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[191] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-11T14:04:05.841+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 8.2 KiB, free 422.2 MiB)
[2025-07-11T14:04:05.847+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 422.2 MiB)
[2025-07-11T14:04:05.847+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 138.4.31.23:41705 (size: 4.2 KiB, free: 433.3 MiB)
[2025-07-11T14:04:05.848+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:05.849+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[191] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:04:05.849+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks resource profile 0
[2025-07-11T14:04:05.849+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 210) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-11T14:04:05.849+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Running task 0.0 in stage 98.0 (TID 210)
[2025-07-11T14:04:05.853+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO ShuffleBlockFetcherIterator: Getting 12 (214.7 KiB) non-empty blocks including 12 (214.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:05.853+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-11T14:04:05.906+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO Executor: Finished task 0.0 in stage 98.0 (TID 210). 51368 bytes result sent to driver
[2025-07-11T14:04:05.906+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 210) in 58 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:04:05.907+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool
[2025-07-11T14:04:05.909+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: ResultStage 98 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,070 s
[2025-07-11T14:04:05.909+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:04:05.909+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 98: Stage finished
[2025-07-11T14:04:05.909+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO DAGScheduler: Job 57 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,071785 s
[2025-07-11T14:04:05.932+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 4.3 MiB, free 418.0 MiB)
[2025-07-11T14:04:05.957+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 109.5 KiB, free 417.9 MiB)
[2025-07-11T14:04:05.957+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 138.4.31.23:41705 (size: 109.5 KiB, free: 433.1 MiB)
[2025-07-11T14:04:05.958+0200] {subprocess.py:93} INFO - 25/07/11 14:04:05 INFO SparkContext: Created broadcast 86 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:04:06.799+0200] {subprocess.py:93} INFO - 25/07/11 14:04:06 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 138.4.31.23:41705 in memory (size: 4.2 KiB, free: 433.2 MiB)
[2025-07-11T14:04:06.859+0200] {subprocess.py:93} INFO - 25/07/11 14:04:06 INFO Executor: Finished task 1.0 in stage 95.0 (TID 197). 2031 bytes result sent to driver
[2025-07-11T14:04:06.861+0200] {subprocess.py:93} INFO - 25/07/11 14:04:06 INFO TaskSetManager: Finished task 1.0 in stage 95.0 (TID 197) in 1627 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:04:06.942+0200] {subprocess.py:93} INFO - 25/07/11 14:04:06 INFO BlockManager: Removing RDD 166
[2025-07-11T14:04:06.944+0200] {subprocess.py:93} INFO - 25/07/11 14:04:06 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 138.4.31.23:41705 in memory (size: 5.7 KiB, free: 433.2 MiB)
[2025-07-11T14:04:06.950+0200] {subprocess.py:93} INFO - 25/07/11 14:04:06 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 138.4.31.23:41705 in memory (size: 479.7 KiB, free: 433.6 MiB)
[2025-07-11T14:04:06.967+0200] {subprocess.py:93} INFO - 25/07/11 14:04:06 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 138.4.31.23:41705 in memory (size: 329.8 KiB, free: 433.9 MiB)
[2025-07-11T14:04:13.203+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Finished task 0.0 in stage 95.0 (TID 196). 2031 bytes result sent to driver
[2025-07-11T14:04:13.204+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 196) in 7970 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:04:13.204+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool
[2025-07-11T14:04:13.204+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: ShuffleMapStage 95 (rdd at ClassificationSummary.scala:58) finished in 7,975 s
[2025-07-11T14:04:13.204+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:04:13.204+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: running: Set()
[2025-07-11T14:04:13.204+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:04:13.204+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: failed: Set()
[2025-07-11T14:04:13.213+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO ShufflePartitionsUtil: For shuffle(30), advisory target size: 67108864, actual target size 1923052, minimum partition size: 1048576
[2025-07-11T14:04:13.240+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO CodeGenerator: Code generated in 15.726976 ms
[2025-07-11T14:04:13.276+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Instrumentation: [24920823] training finished
[2025-07-11T14:04:13.309+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileSystemOverwrite: Path /home/monica.fernandez/practica_creativa/models/spark_random_forest_classifier.flight_delays.5.0.bin already exists. It will be overwritten.
[2025-07-11T14:04:13.332+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:04:13.332+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:13.332+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:13.357+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-11T14:04:13.360+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Got job 58 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-11T14:04:13.360+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Final stage: ResultStage 99 (runJob at SparkHadoopWriter.scala:83)
[2025-07-11T14:04:13.360+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:04:13.360+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:13.360+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[199] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-11T14:04:13.365+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 101.4 KiB, free 420.4 MiB)
[2025-07-11T14:04:13.366+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 420.4 MiB)
[2025-07-11T14:04:13.367+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 138.4.31.23:41705 (size: 36.5 KiB, free: 433.9 MiB)
[2025-07-11T14:04:13.367+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:13.367+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[199] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:04:13.367+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks resource profile 0
[2025-07-11T14:04:13.368+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 211) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15042 bytes)
[2025-07-11T14:04:13.368+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Running task 0.0 in stage 99.0 (TID 211)
[2025-07-11T14:04:13.374+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:04:13.374+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:13.374+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:13.409+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: Saved output of task 'attempt_202507111404138997798431661726951_0199_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/spark_random_forest_classifier.flight_delays.5.0.bin/metadata/_temporary/0/task_202507111404138997798431661726951_0199_m_000000
[2025-07-11T14:04:13.409+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO SparkHadoopMapRedUtil: attempt_202507111404138997798431661726951_0199_m_000000_0: Committed. Elapsed time: 1 ms.
[2025-07-11T14:04:13.409+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Finished task 0.0 in stage 99.0 (TID 211). 1170 bytes result sent to driver
[2025-07-11T14:04:13.409+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 211) in 41 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:04:13.409+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool
[2025-07-11T14:04:13.410+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: ResultStage 99 (runJob at SparkHadoopWriter.scala:83) finished in 0,052 s
[2025-07-11T14:04:13.410+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:04:13.410+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 99: Stage finished
[2025-07-11T14:04:13.410+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Job 58 finished: runJob at SparkHadoopWriter.scala:83, took 0,052611 s
[2025-07-11T14:04:13.410+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO SparkHadoopWriter: Start to commit write Job job_202507111404138997798431661726951_0199.
[2025-07-11T14:04:13.436+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO SparkHadoopWriter: Write Job job_202507111404138997798431661726951_0199 committed. Elapsed time: 25 ms.
[2025-07-11T14:04:13.448+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:04:13.449+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:13.449+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:13.481+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-11T14:04:13.481+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Got job 59 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-11T14:04:13.481+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Final stage: ResultStage 100 (runJob at SparkHadoopWriter.scala:83)
[2025-07-11T14:04:13.481+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:04:13.482+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:13.482+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[201] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-11T14:04:13.488+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 101.5 KiB, free 420.3 MiB)
[2025-07-11T14:04:13.489+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 36.6 KiB, free 420.3 MiB)
[2025-07-11T14:04:13.490+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 138.4.31.23:41705 (size: 36.6 KiB, free: 433.9 MiB)
[2025-07-11T14:04:13.490+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:13.490+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[201] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:04:13.490+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks resource profile 0
[2025-07-11T14:04:13.491+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 212) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15658 bytes)
[2025-07-11T14:04:13.491+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Running task 0.0 in stage 100.0 (TID 212)
[2025-07-11T14:04:13.496+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:04:13.496+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:13.496+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:13.521+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: Saved output of task 'attempt_202507111404137773874976251690798_0201_m_000000_0' to file:/home/monica.fernandez/practica_creativa/models/spark_random_forest_classifier.flight_delays.5.0.bin/stages/0_RandomForestClassifier_42137e15cb45/metadata/_temporary/0/task_202507111404137773874976251690798_0201_m_000000
[2025-07-11T14:04:13.521+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO SparkHadoopMapRedUtil: attempt_202507111404137773874976251690798_0201_m_000000_0: Committed. Elapsed time: 1 ms.
[2025-07-11T14:04:13.521+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Finished task 0.0 in stage 100.0 (TID 212). 1170 bytes result sent to driver
[2025-07-11T14:04:13.522+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 212) in 31 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:04:13.522+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool
[2025-07-11T14:04:13.522+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: ResultStage 100 (runJob at SparkHadoopWriter.scala:83) finished in 0,041 s
[2025-07-11T14:04:13.522+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:04:13.522+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 100: Stage finished
[2025-07-11T14:04:13.522+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Job 59 finished: runJob at SparkHadoopWriter.scala:83, took 0,041914 s
[2025-07-11T14:04:13.523+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO SparkHadoopWriter: Start to commit write Job job_202507111404137773874976251690798_0201.
[2025-07-11T14:04:13.544+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO SparkHadoopWriter: Write Job job_202507111404137773874976251690798_0201 committed. Elapsed time: 21 ms.
[2025-07-11T14:04:13.602+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO CodeGenerator: Code generated in 4.217432 ms
[2025-07-11T14:04:13.605+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Registering RDD 204 (parquet at treeModels.scala:483) as input to shuffle 32
[2025-07-11T14:04:13.605+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Got map stage job 60 (parquet at treeModels.scala:483) with 4 output partitions
[2025-07-11T14:04:13.605+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Final stage: ShuffleMapStage 101 (parquet at treeModels.scala:483)
[2025-07-11T14:04:13.605+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:04:13.605+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:13.605+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Submitting ShuffleMapStage 101 (MapPartitionsRDD[204] at parquet at treeModels.scala:483), which has no missing parents
[2025-07-11T14:04:13.608+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 8.3 KiB, free 420.3 MiB)
[2025-07-11T14:04:13.608+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 420.2 MiB)
[2025-07-11T14:04:13.608+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 138.4.31.23:41705 (size: 4.5 KiB, free: 433.9 MiB)
[2025-07-11T14:04:13.608+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:13.608+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 101 (MapPartitionsRDD[204] at parquet at treeModels.scala:483) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:04:13.609+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSchedulerImpl: Adding task set 101.0 with 4 tasks resource profile 0
[2025-07-11T14:04:13.610+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 213) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 16404 bytes)
[2025-07-11T14:04:13.610+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Starting task 1.0 in stage 101.0 (TID 214) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 17128 bytes)
[2025-07-11T14:04:13.610+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Starting task 2.0 in stage 101.0 (TID 215) (138.4.31.23, executor driver, partition 2, PROCESS_LOCAL, 16404 bytes)
[2025-07-11T14:04:13.610+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Starting task 3.0 in stage 101.0 (TID 216) (138.4.31.23, executor driver, partition 3, PROCESS_LOCAL, 17128 bytes)
[2025-07-11T14:04:13.610+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Running task 2.0 in stage 101.0 (TID 215)
[2025-07-11T14:04:13.610+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Running task 0.0 in stage 101.0 (TID 213)
[2025-07-11T14:04:13.610+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Running task 3.0 in stage 101.0 (TID 216)
[2025-07-11T14:04:13.610+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Running task 1.0 in stage 101.0 (TID 214)
[2025-07-11T14:04:13.620+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Finished task 1.0 in stage 101.0 (TID 214). 1714 bytes result sent to driver
[2025-07-11T14:04:13.620+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Finished task 1.0 in stage 101.0 (TID 214) in 9 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:04:13.621+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Finished task 3.0 in stage 101.0 (TID 216). 1671 bytes result sent to driver
[2025-07-11T14:04:13.621+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 138.4.31.23:41705 in memory (size: 36.5 KiB, free: 433.9 MiB)
[2025-07-11T14:04:13.622+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Finished task 3.0 in stage 101.0 (TID 216) in 13 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:04:13.622+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Finished task 2.0 in stage 101.0 (TID 215). 1671 bytes result sent to driver
[2025-07-11T14:04:13.624+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Finished task 0.0 in stage 101.0 (TID 213). 1628 bytes result sent to driver
[2025-07-11T14:04:13.625+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Finished task 2.0 in stage 101.0 (TID 215) in 15 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:04:13.625+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 213) in 16 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:04:13.625+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool
[2025-07-11T14:04:13.626+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: ShuffleMapStage 101 (parquet at treeModels.scala:483) finished in 0,019 s
[2025-07-11T14:04:13.626+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:04:13.626+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: running: Set()
[2025-07-11T14:04:13.626+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:04:13.627+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: failed: Set()
[2025-07-11T14:04:13.628+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 138.4.31.23:41705 in memory (size: 36.6 KiB, free: 433.9 MiB)
[2025-07-11T14:04:13.631+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:04:13.631+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:13.631+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:13.631+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:04:13.631+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:13.631+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:13.632+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:04:13.649+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO SparkContext: Starting job: parquet at treeModels.scala:483
[2025-07-11T14:04:13.652+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Got job 61 (parquet at treeModels.scala:483) with 1 output partitions
[2025-07-11T14:04:13.652+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Final stage: ResultStage 103 (parquet at treeModels.scala:483)
[2025-07-11T14:04:13.652+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 102)
[2025-07-11T14:04:13.652+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:13.652+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[206] at parquet at treeModels.scala:483), which has no missing parents
[2025-07-11T14:04:13.669+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 239.9 KiB, free 420.3 MiB)
[2025-07-11T14:04:13.670+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 84.0 KiB, free 420.2 MiB)
[2025-07-11T14:04:13.670+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 138.4.31.23:41705 (size: 84.0 KiB, free: 433.9 MiB)
[2025-07-11T14:04:13.671+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:13.671+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[206] at parquet at treeModels.scala:483) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:04:13.671+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks resource profile 0
[2025-07-11T14:04:13.673+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 217) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:04:13.674+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Running task 0.0 in stage 103.0 (TID 217)
[2025-07-11T14:04:13.682+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:13.682+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:13.685+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:13.685+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:13.685+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:04:13.686+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:13.686+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:13.686+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:04:13.686+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:04:13.687+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:04:13.688+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-11T14:04:13.689+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-11T14:04:13.689+0200] {subprocess.py:93} INFO - {
[2025-07-11T14:04:13.689+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-11T14:04:13.690+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-11T14:04:13.690+0200] {subprocess.py:93} INFO -     "name" : "treeID",
[2025-07-11T14:04:13.690+0200] {subprocess.py:93} INFO -     "type" : "integer",
[2025-07-11T14:04:13.690+0200] {subprocess.py:93} INFO -     "nullable" : false,
[2025-07-11T14:04:13.690+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:04:13.690+0200] {subprocess.py:93} INFO -   }, {
[2025-07-11T14:04:13.690+0200] {subprocess.py:93} INFO -     "name" : "metadata",
[2025-07-11T14:04:13.690+0200] {subprocess.py:93} INFO -     "type" : "string",
[2025-07-11T14:04:13.690+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-11T14:04:13.690+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:04:13.690+0200] {subprocess.py:93} INFO -   }, {
[2025-07-11T14:04:13.690+0200] {subprocess.py:93} INFO -     "name" : "weights",
[2025-07-11T14:04:13.690+0200] {subprocess.py:93} INFO -     "type" : "double",
[2025-07-11T14:04:13.690+0200] {subprocess.py:93} INFO -     "nullable" : false,
[2025-07-11T14:04:13.690+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:04:13.690+0200] {subprocess.py:93} INFO -   } ]
[2025-07-11T14:04:13.691+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:04:13.691+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-11T14:04:13.691+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-11T14:04:13.691+0200] {subprocess.py:93} INFO -   required int32 treeID;
[2025-07-11T14:04:13.691+0200] {subprocess.py:93} INFO -   optional binary metadata (STRING);
[2025-07-11T14:04:13.691+0200] {subprocess.py:93} INFO -   required double weights;
[2025-07-11T14:04:13.691+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:04:13.691+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:04:13.691+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:04:13.752+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: Saved output of task 'attempt_202507111404131386299991045522212_0103_m_000000_217' to file:/home/monica.fernandez/practica_creativa/models/spark_random_forest_classifier.flight_delays.5.0.bin/stages/0_RandomForestClassifier_42137e15cb45/treesMetadata/_temporary/0/task_202507111404131386299991045522212_0103_m_000000
[2025-07-11T14:04:13.752+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO SparkHadoopMapRedUtil: attempt_202507111404131386299991045522212_0103_m_000000_217: Committed. Elapsed time: 1 ms.
[2025-07-11T14:04:13.753+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Finished task 0.0 in stage 103.0 (TID 217). 4740 bytes result sent to driver
[2025-07-11T14:04:13.753+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 217) in 80 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:04:13.753+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool
[2025-07-11T14:04:13.753+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: ResultStage 103 (parquet at treeModels.scala:483) finished in 0,103 s
[2025-07-11T14:04:13.754+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:04:13.754+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 103: Stage finished
[2025-07-11T14:04:13.754+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Job 61 finished: parquet at treeModels.scala:483, took 0,104670 s
[2025-07-11T14:04:13.754+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileFormatWriter: Start to commit write Job 9f283f19-6c0e-4eaf-bc09-8e4893883590.
[2025-07-11T14:04:13.775+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileFormatWriter: Write Job 9f283f19-6c0e-4eaf-bc09-8e4893883590 committed. Elapsed time: 21 ms.
[2025-07-11T14:04:13.775+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileFormatWriter: Finished processing stats for write job 9f283f19-6c0e-4eaf-bc09-8e4893883590.
[2025-07-11T14:04:13.869+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO CodeGenerator: Code generated in 20.666876 ms
[2025-07-11T14:04:13.872+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Registering RDD 211 (parquet at treeModels.scala:491) as input to shuffle 33
[2025-07-11T14:04:13.873+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Got map stage job 62 (parquet at treeModels.scala:491) with 4 output partitions
[2025-07-11T14:04:13.873+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Final stage: ShuffleMapStage 104 (parquet at treeModels.scala:491)
[2025-07-11T14:04:13.873+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:04:13.873+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:13.873+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Submitting ShuffleMapStage 104 (MapPartitionsRDD[211] at parquet at treeModels.scala:491), which has no missing parents
[2025-07-11T14:04:13.877+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 41.5 KiB, free 420.2 MiB)
[2025-07-11T14:04:13.883+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 12.3 KiB, free 420.1 MiB)
[2025-07-11T14:04:13.883+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 138.4.31.23:41705 (size: 12.3 KiB, free: 433.8 MiB)
[2025-07-11T14:04:13.884+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:13.884+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 104 (MapPartitionsRDD[211] at parquet at treeModels.scala:491) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:04:13.884+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSchedulerImpl: Adding task set 104.0 with 4 tasks resource profile 0
[2025-07-11T14:04:13.887+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 218) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 140337 bytes)
[2025-07-11T14:04:13.889+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 138.4.31.23:41705 in memory (size: 4.5 KiB, free: 433.9 MiB)
[2025-07-11T14:04:13.893+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Starting task 1.0 in stage 104.0 (TID 219) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 386293 bytes)
[2025-07-11T14:04:13.895+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Starting task 2.0 in stage 104.0 (TID 220) (138.4.31.23, executor driver, partition 2, PROCESS_LOCAL, 128364 bytes)
[2025-07-11T14:04:13.898+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Starting task 3.0 in stage 104.0 (TID 221) (138.4.31.23, executor driver, partition 3, PROCESS_LOCAL, 208919 bytes)
[2025-07-11T14:04:13.899+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Running task 1.0 in stage 104.0 (TID 219)
[2025-07-11T14:04:13.899+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Running task 0.0 in stage 104.0 (TID 218)
[2025-07-11T14:04:13.900+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Running task 2.0 in stage 104.0 (TID 220)
[2025-07-11T14:04:13.901+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Running task 3.0 in stage 104.0 (TID 221)
[2025-07-11T14:04:13.910+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 138.4.31.23:41705 in memory (size: 84.0 KiB, free: 433.9 MiB)
[2025-07-11T14:04:13.934+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO CodeGenerator: Code generated in 22.13183 ms
[2025-07-11T14:04:13.946+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Finished task 0.0 in stage 104.0 (TID 218). 1700 bytes result sent to driver
[2025-07-11T14:04:13.947+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 218) in 62 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:04:13.949+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Finished task 2.0 in stage 104.0 (TID 220). 1700 bytes result sent to driver
[2025-07-11T14:04:13.949+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Finished task 2.0 in stage 104.0 (TID 220) in 55 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:04:13.953+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Finished task 3.0 in stage 104.0 (TID 221). 1700 bytes result sent to driver
[2025-07-11T14:04:13.954+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Finished task 3.0 in stage 104.0 (TID 221) in 59 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:04:13.965+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO Executor: Finished task 1.0 in stage 104.0 (TID 219). 1700 bytes result sent to driver
[2025-07-11T14:04:13.966+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSetManager: Finished task 1.0 in stage 104.0 (TID 219) in 78 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:04:13.966+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool
[2025-07-11T14:04:13.966+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: ShuffleMapStage 104 (parquet at treeModels.scala:491) finished in 0,092 s
[2025-07-11T14:04:13.966+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:04:13.966+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: running: Set()
[2025-07-11T14:04:13.966+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:04:13.966+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: failed: Set()
[2025-07-11T14:04:13.975+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:04:13.975+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:13.975+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:13.975+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:04:13.976+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:13.976+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:13.976+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:04:13.997+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO SparkContext: Starting job: parquet at treeModels.scala:491
[2025-07-11T14:04:13.997+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Got job 63 (parquet at treeModels.scala:491) with 1 output partitions
[2025-07-11T14:04:13.997+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Final stage: ResultStage 106 (parquet at treeModels.scala:491)
[2025-07-11T14:04:13.997+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 105)
[2025-07-11T14:04:13.997+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:13.998+0200] {subprocess.py:93} INFO - 25/07/11 14:04:13 INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[213] at parquet at treeModels.scala:491), which has no missing parents
[2025-07-11T14:04:14.014+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 241.5 KiB, free 420.2 MiB)
[2025-07-11T14:04:14.021+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 84.9 KiB, free 420.2 MiB)
[2025-07-11T14:04:14.021+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 138.4.31.23:41705 (size: 84.9 KiB, free: 433.9 MiB)
[2025-07-11T14:04:14.021+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:14.021+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[213] at parquet at treeModels.scala:491) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:04:14.021+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks resource profile 0
[2025-07-11T14:04:14.022+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 138.4.31.23:41705 in memory (size: 12.3 KiB, free: 433.9 MiB)
[2025-07-11T14:04:14.023+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 222) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:04:14.023+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Running task 0.0 in stage 106.0 (TID 222)
[2025-07-11T14:04:14.034+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO ShuffleBlockFetcherIterator: Getting 4 (176.9 KiB) non-empty blocks including 4 (176.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:14.034+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:14.035+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:14.035+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:14.036+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:04:14.036+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:14.036+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:14.036+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:04:14.036+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:04:14.036+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:04:14.037+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-11T14:04:14.039+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-11T14:04:14.039+0200] {subprocess.py:93} INFO - {
[2025-07-11T14:04:14.040+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-11T14:04:14.041+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-11T14:04:14.041+0200] {subprocess.py:93} INFO -     "name" : "treeID",
[2025-07-11T14:04:14.041+0200] {subprocess.py:93} INFO -     "type" : "integer",
[2025-07-11T14:04:14.041+0200] {subprocess.py:93} INFO -     "nullable" : false,
[2025-07-11T14:04:14.041+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:04:14.041+0200] {subprocess.py:93} INFO -   }, {
[2025-07-11T14:04:14.041+0200] {subprocess.py:93} INFO -     "name" : "nodeData",
[2025-07-11T14:04:14.041+0200] {subprocess.py:93} INFO -     "type" : {
[2025-07-11T14:04:14.041+0200] {subprocess.py:93} INFO -       "type" : "struct",
[2025-07-11T14:04:14.041+0200] {subprocess.py:93} INFO -       "fields" : [ {
[2025-07-11T14:04:14.041+0200] {subprocess.py:93} INFO -         "name" : "id",
[2025-07-11T14:04:14.041+0200] {subprocess.py:93} INFO -         "type" : "integer",
[2025-07-11T14:04:14.041+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:04:14.041+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:04:14.041+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:04:14.041+0200] {subprocess.py:93} INFO -         "name" : "prediction",
[2025-07-11T14:04:14.042+0200] {subprocess.py:93} INFO -         "type" : "double",
[2025-07-11T14:04:14.042+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:04:14.042+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:04:14.042+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:04:14.042+0200] {subprocess.py:93} INFO -         "name" : "impurity",
[2025-07-11T14:04:14.042+0200] {subprocess.py:93} INFO -         "type" : "double",
[2025-07-11T14:04:14.042+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:04:14.042+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:04:14.042+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:04:14.042+0200] {subprocess.py:93} INFO -         "name" : "impurityStats",
[2025-07-11T14:04:14.042+0200] {subprocess.py:93} INFO -         "type" : {
[2025-07-11T14:04:14.042+0200] {subprocess.py:93} INFO -           "type" : "array",
[2025-07-11T14:04:14.042+0200] {subprocess.py:93} INFO -           "elementType" : "double",
[2025-07-11T14:04:14.042+0200] {subprocess.py:93} INFO -           "containsNull" : false
[2025-07-11T14:04:14.042+0200] {subprocess.py:93} INFO -         },
[2025-07-11T14:04:14.042+0200] {subprocess.py:93} INFO -         "nullable" : true,
[2025-07-11T14:04:14.042+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:04:14.042+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:04:14.043+0200] {subprocess.py:93} INFO -         "name" : "rawCount",
[2025-07-11T14:04:14.043+0200] {subprocess.py:93} INFO -         "type" : "long",
[2025-07-11T14:04:14.043+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:04:14.043+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:04:14.043+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:04:14.043+0200] {subprocess.py:93} INFO -         "name" : "gain",
[2025-07-11T14:04:14.043+0200] {subprocess.py:93} INFO -         "type" : "double",
[2025-07-11T14:04:14.043+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:04:14.043+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:04:14.043+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:04:14.043+0200] {subprocess.py:93} INFO -         "name" : "leftChild",
[2025-07-11T14:04:14.043+0200] {subprocess.py:93} INFO -         "type" : "integer",
[2025-07-11T14:04:14.043+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:04:14.043+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:04:14.043+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:04:14.043+0200] {subprocess.py:93} INFO -         "name" : "rightChild",
[2025-07-11T14:04:14.043+0200] {subprocess.py:93} INFO -         "type" : "integer",
[2025-07-11T14:04:14.043+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:04:14.043+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:04:14.044+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:04:14.044+0200] {subprocess.py:93} INFO -         "name" : "split",
[2025-07-11T14:04:14.044+0200] {subprocess.py:93} INFO -         "type" : {
[2025-07-11T14:04:14.044+0200] {subprocess.py:93} INFO -           "type" : "struct",
[2025-07-11T14:04:14.044+0200] {subprocess.py:93} INFO -           "fields" : [ {
[2025-07-11T14:04:14.044+0200] {subprocess.py:93} INFO -             "name" : "featureIndex",
[2025-07-11T14:04:14.044+0200] {subprocess.py:93} INFO -             "type" : "integer",
[2025-07-11T14:04:14.044+0200] {subprocess.py:93} INFO -             "nullable" : false,
[2025-07-11T14:04:14.044+0200] {subprocess.py:93} INFO -             "metadata" : { }
[2025-07-11T14:04:14.044+0200] {subprocess.py:93} INFO -           }, {
[2025-07-11T14:04:14.044+0200] {subprocess.py:93} INFO -             "name" : "leftCategoriesOrThreshold",
[2025-07-11T14:04:14.044+0200] {subprocess.py:93} INFO -             "type" : {
[2025-07-11T14:04:14.044+0200] {subprocess.py:93} INFO -               "type" : "array",
[2025-07-11T14:04:14.044+0200] {subprocess.py:93} INFO -               "elementType" : "double",
[2025-07-11T14:04:14.044+0200] {subprocess.py:93} INFO -               "containsNull" : false
[2025-07-11T14:04:14.044+0200] {subprocess.py:93} INFO -             },
[2025-07-11T14:04:14.044+0200] {subprocess.py:93} INFO -             "nullable" : true,
[2025-07-11T14:04:14.044+0200] {subprocess.py:93} INFO -             "metadata" : { }
[2025-07-11T14:04:14.044+0200] {subprocess.py:93} INFO -           }, {
[2025-07-11T14:04:14.045+0200] {subprocess.py:93} INFO -             "name" : "numCategories",
[2025-07-11T14:04:14.045+0200] {subprocess.py:93} INFO -             "type" : "integer",
[2025-07-11T14:04:14.045+0200] {subprocess.py:93} INFO -             "nullable" : false,
[2025-07-11T14:04:14.045+0200] {subprocess.py:93} INFO -             "metadata" : { }
[2025-07-11T14:04:14.045+0200] {subprocess.py:93} INFO -           } ]
[2025-07-11T14:04:14.045+0200] {subprocess.py:93} INFO -         },
[2025-07-11T14:04:14.045+0200] {subprocess.py:93} INFO -         "nullable" : true,
[2025-07-11T14:04:14.045+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:04:14.045+0200] {subprocess.py:93} INFO -       } ]
[2025-07-11T14:04:14.045+0200] {subprocess.py:93} INFO -     },
[2025-07-11T14:04:14.045+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-11T14:04:14.045+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:04:14.045+0200] {subprocess.py:93} INFO -   } ]
[2025-07-11T14:04:14.045+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:04:14.045+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-11T14:04:14.045+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-11T14:04:14.045+0200] {subprocess.py:93} INFO -   required int32 treeID;
[2025-07-11T14:04:14.045+0200] {subprocess.py:93} INFO -   optional group nodeData {
[2025-07-11T14:04:14.046+0200] {subprocess.py:93} INFO -     required int32 id;
[2025-07-11T14:04:14.046+0200] {subprocess.py:93} INFO -     required double prediction;
[2025-07-11T14:04:14.046+0200] {subprocess.py:93} INFO -     required double impurity;
[2025-07-11T14:04:14.046+0200] {subprocess.py:93} INFO -     optional group impurityStats (LIST) {
[2025-07-11T14:04:14.046+0200] {subprocess.py:93} INFO -       repeated group list {
[2025-07-11T14:04:14.046+0200] {subprocess.py:93} INFO -         required double element;
[2025-07-11T14:04:14.046+0200] {subprocess.py:93} INFO -       }
[2025-07-11T14:04:14.046+0200] {subprocess.py:93} INFO -     }
[2025-07-11T14:04:14.046+0200] {subprocess.py:93} INFO -     required int64 rawCount;
[2025-07-11T14:04:14.046+0200] {subprocess.py:93} INFO -     required double gain;
[2025-07-11T14:04:14.046+0200] {subprocess.py:93} INFO -     required int32 leftChild;
[2025-07-11T14:04:14.046+0200] {subprocess.py:93} INFO -     required int32 rightChild;
[2025-07-11T14:04:14.046+0200] {subprocess.py:93} INFO -     optional group split {
[2025-07-11T14:04:14.046+0200] {subprocess.py:93} INFO -       required int32 featureIndex;
[2025-07-11T14:04:14.046+0200] {subprocess.py:93} INFO -       optional group leftCategoriesOrThreshold (LIST) {
[2025-07-11T14:04:14.046+0200] {subprocess.py:93} INFO -         repeated group list {
[2025-07-11T14:04:14.046+0200] {subprocess.py:93} INFO -           required double element;
[2025-07-11T14:04:14.046+0200] {subprocess.py:93} INFO -         }
[2025-07-11T14:04:14.046+0200] {subprocess.py:93} INFO -       }
[2025-07-11T14:04:14.047+0200] {subprocess.py:93} INFO -       required int32 numCategories;
[2025-07-11T14:04:14.047+0200] {subprocess.py:93} INFO -     }
[2025-07-11T14:04:14.047+0200] {subprocess.py:93} INFO -   }
[2025-07-11T14:04:14.047+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:04:14.047+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:04:14.047+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:04:14.135+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO FileOutputCommitter: Saved output of task 'attempt_20250711140413149690333953124571_0106_m_000000_222' to file:/home/monica.fernandez/practica_creativa/models/spark_random_forest_classifier.flight_delays.5.0.bin/stages/0_RandomForestClassifier_42137e15cb45/data/_temporary/0/task_20250711140413149690333953124571_0106_m_000000
[2025-07-11T14:04:14.135+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO SparkHadoopMapRedUtil: attempt_20250711140413149690333953124571_0106_m_000000_222: Committed. Elapsed time: 1 ms.
[2025-07-11T14:04:14.136+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Finished task 0.0 in stage 106.0 (TID 222). 4740 bytes result sent to driver
[2025-07-11T14:04:14.136+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 222) in 114 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:04:14.136+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool
[2025-07-11T14:04:14.136+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: ResultStage 106 (parquet at treeModels.scala:491) finished in 0,138 s
[2025-07-11T14:04:14.137+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:04:14.137+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 106: Stage finished
[2025-07-11T14:04:14.137+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Job 63 finished: parquet at treeModels.scala:491, took 0,140068 s
[2025-07-11T14:04:14.137+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO FileFormatWriter: Start to commit write Job 8ab0503f-1366-4cae-a448-e9afc6b6945b.
[2025-07-11T14:04:14.157+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO FileFormatWriter: Write Job 8ab0503f-1366-4cae-a448-e9afc6b6945b committed. Elapsed time: 20 ms.
[2025-07-11T14:04:14.157+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO FileFormatWriter: Finished processing stats for write job 8ab0503f-1366-4cae-a448-e9afc6b6945b.
[2025-07-11T14:04:14.159+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Instrumentation: [5eca0b78] training finished
[2025-07-11T14:04:14.159+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Instrumentation: [313fc463] training finished
[2025-07-11T14:04:14.253+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO V2ScanRelationPushDown:
[2025-07-11T14:04:14.253+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:04:14.253+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:04:14.253+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:04:14.253+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:04:14.258+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO V2ScanRelationPushDown:
[2025-07-11T14:04:14.259+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-11T14:04:14.259+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:04:14.285+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:04:14.285+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:04:14.296+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 214.5 KiB, free 420.0 MiB)
[2025-07-11T14:04:14.304+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 420.0 MiB)
[2025-07-11T14:04:14.304+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 138.4.31.23:41705 (size: 38.9 KiB, free: 433.8 MiB)
[2025-07-11T14:04:14.304+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO SparkContext: Created broadcast 93 from rdd at MulticlassClassificationEvaluator.scala:191
[2025-07-11T14:04:14.305+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:04:14.309+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Registering RDD 217 (rdd at MulticlassClassificationEvaluator.scala:191) as input to shuffle 34
[2025-07-11T14:04:14.309+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Got map stage job 64 (rdd at MulticlassClassificationEvaluator.scala:191) with 2 output partitions
[2025-07-11T14:04:14.309+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Final stage: ShuffleMapStage 107 (rdd at MulticlassClassificationEvaluator.scala:191)
[2025-07-11T14:04:14.309+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:04:14.309+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:14.309+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Submitting ShuffleMapStage 107 (MapPartitionsRDD[217] at rdd at MulticlassClassificationEvaluator.scala:191), which has no missing parents
[2025-07-11T14:04:14.312+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 20.7 KiB, free 419.9 MiB)
[2025-07-11T14:04:14.320+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 9.3 KiB, free 419.9 MiB)
[2025-07-11T14:04:14.320+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 138.4.31.23:41705 (size: 9.3 KiB, free: 433.8 MiB)
[2025-07-11T14:04:14.320+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 138.4.31.23:41705 in memory (size: 84.9 KiB, free: 433.9 MiB)
[2025-07-11T14:04:14.320+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:14.321+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 107 (MapPartitionsRDD[217] at rdd at MulticlassClassificationEvaluator.scala:191) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:04:14.321+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSchedulerImpl: Adding task set 107.0 with 2 tasks resource profile 0
[2025-07-11T14:04:14.322+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Registering RDD 221 (rdd at MulticlassClassificationEvaluator.scala:191) as input to shuffle 35
[2025-07-11T14:04:14.322+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Got map stage job 65 (rdd at MulticlassClassificationEvaluator.scala:191) with 12 output partitions
[2025-07-11T14:04:14.322+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Final stage: ShuffleMapStage 108 (rdd at MulticlassClassificationEvaluator.scala:191)
[2025-07-11T14:04:14.322+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:04:14.322+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 223) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:04:14.322+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:14.322+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Submitting ShuffleMapStage 108 (MapPartitionsRDD[221] at rdd at MulticlassClassificationEvaluator.scala:191), which has no missing parents
[2025-07-11T14:04:14.322+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Starting task 1.0 in stage 107.0 (TID 224) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:04:14.328+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Running task 1.0 in stage 107.0 (TID 224)
[2025-07-11T14:04:14.329+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Running task 0.0 in stage 107.0 (TID 223)
[2025-07-11T14:04:14.329+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 18.7 KiB, free 420.2 MiB)
[2025-07-11T14:04:14.330+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 420.2 MiB)
[2025-07-11T14:04:14.330+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 138.4.31.23:41705 (size: 9.2 KiB, free: 433.9 MiB)
[2025-07-11T14:04:14.330+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:14.330+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 108 (MapPartitionsRDD[221] at rdd at MulticlassClassificationEvaluator.scala:191) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
[2025-07-11T14:04:14.330+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSchedulerImpl: Adding task set 108.0 with 12 tasks resource profile 0
[2025-07-11T14:04:14.330+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:04:14.330+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 225) (138.4.31.23, executor driver, partition 0, ANY, 16839 bytes)
[2025-07-11T14:04:14.330+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Starting task 1.0 in stage 108.0 (TID 226) (138.4.31.23, executor driver, partition 1, ANY, 16719 bytes)
[2025-07-11T14:04:14.330+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Running task 1.0 in stage 108.0 (TID 226)
[2025-07-11T14:04:14.330+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Running task 0.0 in stage 108.0 (TID 225)
[2025-07-11T14:04:14.332+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:04:14.373+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Finished task 1.0 in stage 108.0 (TID 226). 1945 bytes result sent to driver
[2025-07-11T14:04:14.374+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Starting task 2.0 in stage 108.0 (TID 227) (138.4.31.23, executor driver, partition 2, ANY, 16839 bytes)
[2025-07-11T14:04:14.374+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Finished task 1.0 in stage 108.0 (TID 226) in 46 ms on 138.4.31.23 (executor driver) (1/12)
[2025-07-11T14:04:14.374+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Running task 2.0 in stage 108.0 (TID 227)
[2025-07-11T14:04:14.428+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Finished task 0.0 in stage 108.0 (TID 225). 1988 bytes result sent to driver
[2025-07-11T14:04:14.432+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Starting task 3.0 in stage 108.0 (TID 228) (138.4.31.23, executor driver, partition 3, ANY, 16715 bytes)
[2025-07-11T14:04:14.433+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 225) in 105 ms on 138.4.31.23 (executor driver) (2/12)
[2025-07-11T14:04:14.433+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Running task 3.0 in stage 108.0 (TID 228)
[2025-07-11T14:04:14.452+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Finished task 2.0 in stage 108.0 (TID 227). 1945 bytes result sent to driver
[2025-07-11T14:04:14.453+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Starting task 4.0 in stage 108.0 (TID 229) (138.4.31.23, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-11T14:04:14.454+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Running task 4.0 in stage 108.0 (TID 229)
[2025-07-11T14:04:14.454+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Finished task 2.0 in stage 108.0 (TID 227) in 80 ms on 138.4.31.23 (executor driver) (3/12)
[2025-07-11T14:04:14.502+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Finished task 3.0 in stage 108.0 (TID 228). 1945 bytes result sent to driver
[2025-07-11T14:04:14.508+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Starting task 5.0 in stage 108.0 (TID 230) (138.4.31.23, executor driver, partition 5, ANY, 16839 bytes)
[2025-07-11T14:04:14.509+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Finished task 3.0 in stage 108.0 (TID 228) in 78 ms on 138.4.31.23 (executor driver) (4/12)
[2025-07-11T14:04:14.509+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Running task 5.0 in stage 108.0 (TID 230)
[2025-07-11T14:04:14.551+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Finished task 4.0 in stage 108.0 (TID 229). 1945 bytes result sent to driver
[2025-07-11T14:04:14.553+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Starting task 6.0 in stage 108.0 (TID 231) (138.4.31.23, executor driver, partition 6, ANY, 16719 bytes)
[2025-07-11T14:04:14.553+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Running task 6.0 in stage 108.0 (TID 231)
[2025-07-11T14:04:14.554+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Finished task 4.0 in stage 108.0 (TID 229) in 102 ms on 138.4.31.23 (executor driver) (5/12)
[2025-07-11T14:04:14.612+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Finished task 5.0 in stage 108.0 (TID 230). 1945 bytes result sent to driver
[2025-07-11T14:04:14.615+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Finished task 6.0 in stage 108.0 (TID 231). 1945 bytes result sent to driver
[2025-07-11T14:04:14.616+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Starting task 7.0 in stage 108.0 (TID 232) (138.4.31.23, executor driver, partition 7, ANY, 16839 bytes)
[2025-07-11T14:04:14.616+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Finished task 5.0 in stage 108.0 (TID 230) in 109 ms on 138.4.31.23 (executor driver) (6/12)
[2025-07-11T14:04:14.616+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Finished task 6.0 in stage 108.0 (TID 231) in 63 ms on 138.4.31.23 (executor driver) (7/12)
[2025-07-11T14:04:14.616+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Running task 7.0 in stage 108.0 (TID 232)
[2025-07-11T14:04:14.618+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Starting task 8.0 in stage 108.0 (TID 233) (138.4.31.23, executor driver, partition 8, ANY, 16719 bytes)
[2025-07-11T14:04:14.618+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Running task 8.0 in stage 108.0 (TID 233)
[2025-07-11T14:04:14.694+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Finished task 7.0 in stage 108.0 (TID 232). 1945 bytes result sent to driver
[2025-07-11T14:04:14.695+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Starting task 9.0 in stage 108.0 (TID 234) (138.4.31.23, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-11T14:04:14.696+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Finished task 7.0 in stage 108.0 (TID 232) in 80 ms on 138.4.31.23 (executor driver) (8/12)
[2025-07-11T14:04:14.696+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Running task 9.0 in stage 108.0 (TID 234)
[2025-07-11T14:04:14.700+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Finished task 8.0 in stage 108.0 (TID 233). 1945 bytes result sent to driver
[2025-07-11T14:04:14.709+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Starting task 10.0 in stage 108.0 (TID 235) (138.4.31.23, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-11T14:04:14.710+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Running task 10.0 in stage 108.0 (TID 235)
[2025-07-11T14:04:14.710+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Finished task 8.0 in stage 108.0 (TID 233) in 93 ms on 138.4.31.23 (executor driver) (9/12)
[2025-07-11T14:04:14.767+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Finished task 9.0 in stage 108.0 (TID 234). 1945 bytes result sent to driver
[2025-07-11T14:04:14.769+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Starting task 11.0 in stage 108.0 (TID 236) (138.4.31.23, executor driver, partition 11, ANY, 16719 bytes)
[2025-07-11T14:04:14.769+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Finished task 9.0 in stage 108.0 (TID 234) in 74 ms on 138.4.31.23 (executor driver) (10/12)
[2025-07-11T14:04:14.789+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Finished task 10.0 in stage 108.0 (TID 235). 2031 bytes result sent to driver
[2025-07-11T14:04:14.790+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Finished task 10.0 in stage 108.0 (TID 235) in 80 ms on 138.4.31.23 (executor driver) (11/12)
[2025-07-11T14:04:14.790+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Running task 11.0 in stage 108.0 (TID 236)
[2025-07-11T14:04:14.872+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Finished task 11.0 in stage 108.0 (TID 236). 1988 bytes result sent to driver
[2025-07-11T14:04:14.882+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Finished task 11.0 in stage 108.0 (TID 236) in 113 ms on 138.4.31.23 (executor driver) (12/12)
[2025-07-11T14:04:14.882+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool
[2025-07-11T14:04:14.884+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: ShuffleMapStage 108 (rdd at MulticlassClassificationEvaluator.scala:191) finished in 0,561 s
[2025-07-11T14:04:14.884+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:04:14.884+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: running: Set(ShuffleMapStage 107)
[2025-07-11T14:04:14.884+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:04:14.884+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: failed: Set()
[2025-07-11T14:04:14.899+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO ShufflePartitionsUtil: For shuffle(35), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:04:14.924+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:04:14.924+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Got job 66 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-11T14:04:14.924+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Final stage: ResultStage 110 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-11T14:04:14.926+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 109)
[2025-07-11T14:04:14.926+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:14.926+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Submitting ResultStage 110 (MapPartitionsRDD[223] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-11T14:04:14.926+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 8.2 KiB, free 420.2 MiB)
[2025-07-11T14:04:14.929+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 420.2 MiB)
[2025-07-11T14:04:14.929+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 138.4.31.23:41705 (size: 4.2 KiB, free: 433.9 MiB)
[2025-07-11T14:04:14.931+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:14.931+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 110 (MapPartitionsRDD[223] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:04:14.931+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSchedulerImpl: Adding task set 110.0 with 1 tasks resource profile 0
[2025-07-11T14:04:14.934+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 237) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-11T14:04:14.935+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO Executor: Running task 0.0 in stage 110.0 (TID 237)
[2025-07-11T14:04:14.947+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO ShuffleBlockFetcherIterator: Getting 12 (214.7 KiB) non-empty blocks including 12 (214.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:14.948+0200] {subprocess.py:93} INFO - 25/07/11 14:04:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-11T14:04:15.048+0200] {subprocess.py:93} INFO - 25/07/11 14:04:15 INFO Executor: Finished task 0.0 in stage 110.0 (TID 237). 51289 bytes result sent to driver
[2025-07-11T14:04:15.049+0200] {subprocess.py:93} INFO - 25/07/11 14:04:15 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 237) in 115 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:04:15.049+0200] {subprocess.py:93} INFO - 25/07/11 14:04:15 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool
[2025-07-11T14:04:15.069+0200] {subprocess.py:93} INFO - 25/07/11 14:04:15 INFO DAGScheduler: ResultStage 110 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,124 s
[2025-07-11T14:04:15.069+0200] {subprocess.py:93} INFO - 25/07/11 14:04:15 INFO DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:04:15.069+0200] {subprocess.py:93} INFO - 25/07/11 14:04:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 110: Stage finished
[2025-07-11T14:04:15.069+0200] {subprocess.py:93} INFO - 25/07/11 14:04:15 INFO DAGScheduler: Job 66 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,127115 s
[2025-07-11T14:04:15.075+0200] {subprocess.py:93} INFO - 25/07/11 14:04:15 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 4.3 MiB, free 416.0 MiB)
[2025-07-11T14:04:15.079+0200] {subprocess.py:93} INFO - 25/07/11 14:04:15 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 109.4 KiB, free 415.9 MiB)
[2025-07-11T14:04:15.080+0200] {subprocess.py:93} INFO - 25/07/11 14:04:15 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 138.4.31.23:41705 (size: 109.4 KiB, free: 433.8 MiB)
[2025-07-11T14:04:15.080+0200] {subprocess.py:93} INFO - 25/07/11 14:04:15 INFO SparkContext: Created broadcast 97 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:04:15.650+0200] {subprocess.py:93} INFO - 25/07/11 14:04:15 INFO Executor: Finished task 1.0 in stage 107.0 (TID 224). 2031 bytes result sent to driver
[2025-07-11T14:04:15.653+0200] {subprocess.py:93} INFO - 25/07/11 14:04:15 INFO TaskSetManager: Finished task 1.0 in stage 107.0 (TID 224) in 1328 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:04:15.962+0200] {subprocess.py:93} INFO - 25/07/11 14:04:15 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 138.4.31.23:41705 in memory (size: 4.2 KiB, free: 433.8 MiB)
[2025-07-11T14:04:21.942+0200] {subprocess.py:93} INFO - 25/07/11 14:04:21 INFO Executor: Finished task 0.0 in stage 107.0 (TID 223). 2031 bytes result sent to driver
[2025-07-11T14:04:21.942+0200] {subprocess.py:93} INFO - 25/07/11 14:04:21 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 223) in 7620 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:04:21.943+0200] {subprocess.py:93} INFO - 25/07/11 14:04:21 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool
[2025-07-11T14:04:21.943+0200] {subprocess.py:93} INFO - 25/07/11 14:04:21 INFO DAGScheduler: ShuffleMapStage 107 (rdd at MulticlassClassificationEvaluator.scala:191) finished in 7,634 s
[2025-07-11T14:04:21.943+0200] {subprocess.py:93} INFO - 25/07/11 14:04:21 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:04:21.943+0200] {subprocess.py:93} INFO - 25/07/11 14:04:21 INFO DAGScheduler: running: Set()
[2025-07-11T14:04:21.943+0200] {subprocess.py:93} INFO - 25/07/11 14:04:21 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:04:21.943+0200] {subprocess.py:93} INFO - 25/07/11 14:04:21 INFO DAGScheduler: failed: Set()
[2025-07-11T14:04:21.960+0200] {subprocess.py:93} INFO - 25/07/11 14:04:21 INFO ShufflePartitionsUtil: For shuffle(34), advisory target size: 67108864, actual target size 1923052, minimum partition size: 1048576
[2025-07-11T14:04:22.007+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO CodeGenerator: Code generated in 28.867827 ms
[2025-07-11T14:04:22.034+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO SparkContext: Starting job: collectAsMap at MulticlassMetrics.scala:61
[2025-07-11T14:04:22.035+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO DAGScheduler: Registering RDD 230 (map at MulticlassMetrics.scala:52) as input to shuffle 36
[2025-07-11T14:04:22.035+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO DAGScheduler: Got job 67 (collectAsMap at MulticlassMetrics.scala:61) with 4 output partitions
[2025-07-11T14:04:22.035+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO DAGScheduler: Final stage: ResultStage 113 (collectAsMap at MulticlassMetrics.scala:61)
[2025-07-11T14:04:22.035+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 112)
[2025-07-11T14:04:22.035+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 112)
[2025-07-11T14:04:22.035+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO DAGScheduler: Submitting ShuffleMapStage 112 (MapPartitionsRDD[230] at map at MulticlassMetrics.scala:52), which has no missing parents
[2025-07-11T14:04:22.049+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 WARN DAGScheduler: Broadcasting large task binary with size 1043.2 KiB
[2025-07-11T14:04:22.049+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 1043.3 KiB, free 414.9 MiB)
[2025-07-11T14:04:22.053+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 454.3 KiB, free 414.4 MiB)
[2025-07-11T14:04:22.053+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 138.4.31.23:41705 (size: 454.3 KiB, free: 433.3 MiB)
[2025-07-11T14:04:22.054+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:22.054+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 112 (MapPartitionsRDD[230] at map at MulticlassMetrics.scala:52) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:04:22.054+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO TaskSchedulerImpl: Adding task set 112.0 with 4 tasks resource profile 0
[2025-07-11T14:04:22.055+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 238) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:04:22.057+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO TaskSetManager: Starting task 1.0 in stage 112.0 (TID 239) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:04:22.058+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO TaskSetManager: Starting task 2.0 in stage 112.0 (TID 240) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:04:22.058+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO TaskSetManager: Starting task 3.0 in stage 112.0 (TID 241) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:04:22.058+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO Executor: Running task 3.0 in stage 112.0 (TID 241)
[2025-07-11T14:04:22.058+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO Executor: Running task 0.0 in stage 112.0 (TID 238)
[2025-07-11T14:04:22.058+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO Executor: Running task 1.0 in stage 112.0 (TID 239)
[2025-07-11T14:04:22.058+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO Executor: Running task 2.0 in stage 112.0 (TID 240)
[2025-07-11T14:04:22.087+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO ShuffleBlockFetcherIterator: Getting 1 (3.2 MiB) non-empty blocks including 1 (3.2 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:22.087+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:22.088+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO ShuffleBlockFetcherIterator: Getting 1 (3.4 MiB) non-empty blocks including 1 (3.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:22.088+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-11T14:04:22.088+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO ShuffleBlockFetcherIterator: Getting 1 (366.2 KiB) non-empty blocks including 1 (366.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:22.088+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:22.091+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO ShuffleBlockFetcherIterator: Getting 1 (384.6 KiB) non-empty blocks including 1 (384.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:22.091+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:22.106+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO CodeGenerator: Code generated in 18.214845 ms
[2025-07-11T14:04:22.114+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO CodeGenerator: Code generated in 4.827016 ms
[2025-07-11T14:04:22.607+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO Executor: Finished task 2.0 in stage 112.0 (TID 240). 6108 bytes result sent to driver
[2025-07-11T14:04:22.607+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO TaskSetManager: Finished task 2.0 in stage 112.0 (TID 240) in 552 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:04:22.671+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO Executor: Finished task 3.0 in stage 112.0 (TID 241). 6108 bytes result sent to driver
[2025-07-11T14:04:22.672+0200] {subprocess.py:93} INFO - 25/07/11 14:04:22 INFO TaskSetManager: Finished task 3.0 in stage 112.0 (TID 241) in 617 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:04:23.784+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO Executor: Finished task 0.0 in stage 112.0 (TID 238). 6108 bytes result sent to driver
[2025-07-11T14:04:23.784+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 238) in 1730 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:04:23.911+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO Executor: Finished task 1.0 in stage 112.0 (TID 239). 6108 bytes result sent to driver
[2025-07-11T14:04:23.920+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO TaskSetManager: Finished task 1.0 in stage 112.0 (TID 239) in 1856 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:04:23.920+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool
[2025-07-11T14:04:23.920+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO DAGScheduler: ShuffleMapStage 112 (map at MulticlassMetrics.scala:52) finished in 1,875 s
[2025-07-11T14:04:23.920+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:04:23.920+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO DAGScheduler: running: Set()
[2025-07-11T14:04:23.920+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO DAGScheduler: waiting: Set(ResultStage 113)
[2025-07-11T14:04:23.921+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO DAGScheduler: failed: Set()
[2025-07-11T14:04:23.921+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO DAGScheduler: Submitting ResultStage 113 (ShuffledRDD[231] at reduceByKey at MulticlassMetrics.scala:61), which has no missing parents
[2025-07-11T14:04:23.921+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 4.7 KiB, free 414.4 MiB)
[2025-07-11T14:04:23.921+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 2.8 KiB, free 414.4 MiB)
[2025-07-11T14:04:23.921+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 138.4.31.23:41705 (size: 2.8 KiB, free: 433.3 MiB)
[2025-07-11T14:04:23.921+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:23.921+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 113 (ShuffledRDD[231] at reduceByKey at MulticlassMetrics.scala:61) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:04:23.921+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO TaskSchedulerImpl: Adding task set 113.0 with 4 tasks resource profile 0
[2025-07-11T14:04:23.921+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 242) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:04:23.921+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO TaskSetManager: Starting task 1.0 in stage 113.0 (TID 243) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:04:23.921+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO TaskSetManager: Starting task 2.0 in stage 113.0 (TID 244) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:04:23.921+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO TaskSetManager: Starting task 3.0 in stage 113.0 (TID 245) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14646 bytes)
[2025-07-11T14:04:23.921+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO Executor: Running task 0.0 in stage 113.0 (TID 242)
[2025-07-11T14:04:23.921+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO Executor: Running task 2.0 in stage 113.0 (TID 244)
[2025-07-11T14:04:23.921+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO Executor: Running task 1.0 in stage 113.0 (TID 243)
[2025-07-11T14:04:23.921+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO Executor: Running task 3.0 in stage 113.0 (TID 245)
[2025-07-11T14:04:23.921+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO ShuffleBlockFetcherIterator: Getting 4 (1054.0 B) non-empty blocks including 4 (1054.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:23.921+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:23.922+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO ShuffleBlockFetcherIterator: Getting 4 (1104.0 B) non-empty blocks including 4 (1104.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:23.922+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:23.922+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO Executor: Finished task 0.0 in stage 113.0 (TID 242). 1980 bytes result sent to driver
[2025-07-11T14:04:23.922+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 242) in 7 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:04:23.930+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO ShuffleBlockFetcherIterator: Getting 4 (1370.0 B) non-empty blocks including 4 (1370.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:23.930+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:23.930+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO ShuffleBlockFetcherIterator: Getting 4 (1472.0 B) non-empty blocks including 4 (1472.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:23.931+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:23.931+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO Executor: Finished task 3.0 in stage 113.0 (TID 245). 2199 bytes result sent to driver
[2025-07-11T14:04:23.931+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO TaskSetManager: Finished task 3.0 in stage 113.0 (TID 245) in 15 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:04:23.931+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO Executor: Finished task 2.0 in stage 113.0 (TID 244). 2199 bytes result sent to driver
[2025-07-11T14:04:23.931+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO Executor: Finished task 1.0 in stage 113.0 (TID 243). 2066 bytes result sent to driver
[2025-07-11T14:04:23.931+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 138.4.31.23:41705 in memory (size: 454.3 KiB, free: 433.8 MiB)
[2025-07-11T14:04:23.933+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO TaskSetManager: Finished task 1.0 in stage 113.0 (TID 243) in 18 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:04:23.934+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO TaskSetManager: Finished task 2.0 in stage 113.0 (TID 244) in 19 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:04:23.935+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool
[2025-07-11T14:04:23.935+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO DAGScheduler: ResultStage 113 (collectAsMap at MulticlassMetrics.scala:61) finished in 0,023 s
[2025-07-11T14:04:23.935+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:04:23.935+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 113: Stage finished
[2025-07-11T14:04:23.936+0200] {subprocess.py:93} INFO - 25/07/11 14:04:23 INFO DAGScheduler: Job 67 finished: collectAsMap at MulticlassMetrics.scala:61, took 1,900533 s
[2025-07-11T14:04:23.937+0200] {subprocess.py:93} INFO - Accuracy: 0.5919
[2025-07-11T14:04:24.107+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO V2ScanRelationPushDown:
[2025-07-11T14:04:24.107+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:04:24.107+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:04:24.107+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:04:24.107+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:04:24.114+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO V2ScanRelationPushDown:
[2025-07-11T14:04:24.114+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-11T14:04:24.114+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:04:24.153+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:04:24.154+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:04:24.217+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO CodeGenerator: Code generated in 12.762508 ms
[2025-07-11T14:04:24.220+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 214.5 KiB, free 415.7 MiB)
[2025-07-11T14:04:24.234+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 415.6 MiB)
[2025-07-11T14:04:24.235+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 138.4.31.23:41705 (size: 38.9 KiB, free: 433.7 MiB)
[2025-07-11T14:04:24.239+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO SparkContext: Created broadcast 100 from showString at NativeMethodAccessorImpl.java:0
[2025-07-11T14:04:24.240+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:04:24.248+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: Registering RDD 235 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 37
[2025-07-11T14:04:24.248+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: Got map stage job 68 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-07-11T14:04:24.248+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: Final stage: ShuffleMapStage 114 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:04:24.249+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:04:24.249+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:24.250+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: Submitting ShuffleMapStage 114 (MapPartitionsRDD[235] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:04:24.252+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 20.2 KiB, free 415.6 MiB)
[2025-07-11T14:04:24.263+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 415.6 MiB)
[2025-07-11T14:04:24.263+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 138.4.31.23:41705 (size: 9.2 KiB, free: 433.7 MiB)
[2025-07-11T14:04:24.264+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:24.264+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 114 (MapPartitionsRDD[235] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:04:24.265+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSchedulerImpl: Adding task set 114.0 with 2 tasks resource profile 0
[2025-07-11T14:04:24.265+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 246) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:04:24.265+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Starting task 1.0 in stage 114.0 (TID 247) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:04:24.265+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Running task 1.0 in stage 114.0 (TID 247)
[2025-07-11T14:04:24.265+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Running task 0.0 in stage 114.0 (TID 246)
[2025-07-11T14:04:24.273+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: Registering RDD 239 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 38
[2025-07-11T14:04:24.274+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: Got map stage job 69 (showString at NativeMethodAccessorImpl.java:0) with 12 output partitions
[2025-07-11T14:04:24.274+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: Final stage: ShuffleMapStage 115 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:04:24.274+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:04:24.274+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:24.274+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: Submitting ShuffleMapStage 115 (MapPartitionsRDD[239] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:04:24.275+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 18.7 KiB, free 415.6 MiB)
[2025-07-11T14:04:24.275+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 138.4.31.23:41705 in memory (size: 2.8 KiB, free: 433.7 MiB)
[2025-07-11T14:04:24.275+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 415.6 MiB)
[2025-07-11T14:04:24.275+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 138.4.31.23:41705 (size: 9.2 KiB, free: 433.7 MiB)
[2025-07-11T14:04:24.276+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:24.277+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 115 (MapPartitionsRDD[239] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
[2025-07-11T14:04:24.278+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSchedulerImpl: Adding task set 115.0 with 12 tasks resource profile 0
[2025-07-11T14:04:24.280+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 248) (138.4.31.23, executor driver, partition 0, ANY, 16719 bytes)
[2025-07-11T14:04:24.280+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Starting task 1.0 in stage 115.0 (TID 249) (138.4.31.23, executor driver, partition 1, ANY, 16719 bytes)
[2025-07-11T14:04:24.280+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Running task 0.0 in stage 115.0 (TID 248)
[2025-07-11T14:04:24.280+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Running task 1.0 in stage 115.0 (TID 249)
[2025-07-11T14:04:24.296+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO CodeGenerator: Code generated in 28.665503 ms
[2025-07-11T14:04:24.316+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO CodeGenerator: Code generated in 17.074792 ms
[2025-07-11T14:04:24.317+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:04:24.317+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:04:24.323+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO CodeGenerator: Code generated in 4.674027 ms
[2025-07-11T14:04:24.411+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Finished task 0.0 in stage 115.0 (TID 248). 2031 bytes result sent to driver
[2025-07-11T14:04:24.412+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Starting task 2.0 in stage 115.0 (TID 250) (138.4.31.23, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-11T14:04:24.413+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Running task 2.0 in stage 115.0 (TID 250)
[2025-07-11T14:04:24.413+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 248) in 134 ms on 138.4.31.23 (executor driver) (1/12)
[2025-07-11T14:04:24.435+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Finished task 1.0 in stage 115.0 (TID 249). 1988 bytes result sent to driver
[2025-07-11T14:04:24.435+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Starting task 3.0 in stage 115.0 (TID 251) (138.4.31.23, executor driver, partition 3, ANY, 16839 bytes)
[2025-07-11T14:04:24.435+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Running task 3.0 in stage 115.0 (TID 251)
[2025-07-11T14:04:24.435+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Finished task 1.0 in stage 115.0 (TID 249) in 145 ms on 138.4.31.23 (executor driver) (2/12)
[2025-07-11T14:04:24.515+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Finished task 3.0 in stage 115.0 (TID 251). 1945 bytes result sent to driver
[2025-07-11T14:04:24.517+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Starting task 4.0 in stage 115.0 (TID 252) (138.4.31.23, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-11T14:04:24.517+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Running task 4.0 in stage 115.0 (TID 252)
[2025-07-11T14:04:24.517+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Finished task 3.0 in stage 115.0 (TID 251) in 93 ms on 138.4.31.23 (executor driver) (3/12)
[2025-07-11T14:04:24.534+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Finished task 2.0 in stage 115.0 (TID 250). 1945 bytes result sent to driver
[2025-07-11T14:04:24.535+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Starting task 5.0 in stage 115.0 (TID 253) (138.4.31.23, executor driver, partition 5, ANY, 16839 bytes)
[2025-07-11T14:04:24.536+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Finished task 2.0 in stage 115.0 (TID 250) in 124 ms on 138.4.31.23 (executor driver) (4/12)
[2025-07-11T14:04:24.537+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Running task 5.0 in stage 115.0 (TID 253)
[2025-07-11T14:04:24.600+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Finished task 4.0 in stage 115.0 (TID 252). 1945 bytes result sent to driver
[2025-07-11T14:04:24.602+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Starting task 6.0 in stage 115.0 (TID 254) (138.4.31.23, executor driver, partition 6, ANY, 16715 bytes)
[2025-07-11T14:04:24.602+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Finished task 4.0 in stage 115.0 (TID 252) in 86 ms on 138.4.31.23 (executor driver) (5/12)
[2025-07-11T14:04:24.602+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Running task 6.0 in stage 115.0 (TID 254)
[2025-07-11T14:04:24.611+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 138.4.31.23:41705 in memory (size: 38.9 KiB, free: 433.8 MiB)
[2025-07-11T14:04:24.646+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Finished task 5.0 in stage 115.0 (TID 253). 1945 bytes result sent to driver
[2025-07-11T14:04:24.647+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Starting task 7.0 in stage 115.0 (TID 255) (138.4.31.23, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-11T14:04:24.647+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Finished task 5.0 in stage 115.0 (TID 253) in 113 ms on 138.4.31.23 (executor driver) (6/12)
[2025-07-11T14:04:24.649+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Running task 7.0 in stage 115.0 (TID 255)
[2025-07-11T14:04:24.684+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Finished task 6.0 in stage 115.0 (TID 254). 1945 bytes result sent to driver
[2025-07-11T14:04:24.685+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Starting task 8.0 in stage 115.0 (TID 256) (138.4.31.23, executor driver, partition 8, ANY, 16839 bytes)
[2025-07-11T14:04:24.686+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Finished task 6.0 in stage 115.0 (TID 254) in 84 ms on 138.4.31.23 (executor driver) (7/12)
[2025-07-11T14:04:24.689+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Running task 8.0 in stage 115.0 (TID 256)
[2025-07-11T14:04:24.699+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 138.4.31.23:41705 in memory (size: 9.2 KiB, free: 433.8 MiB)
[2025-07-11T14:04:24.735+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Finished task 7.0 in stage 115.0 (TID 255). 1945 bytes result sent to driver
[2025-07-11T14:04:24.739+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Starting task 9.0 in stage 115.0 (TID 257) (138.4.31.23, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-11T14:04:24.740+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Finished task 7.0 in stage 115.0 (TID 255) in 93 ms on 138.4.31.23 (executor driver) (8/12)
[2025-07-11T14:04:24.740+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Running task 9.0 in stage 115.0 (TID 257)
[2025-07-11T14:04:24.756+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Finished task 8.0 in stage 115.0 (TID 256). 1945 bytes result sent to driver
[2025-07-11T14:04:24.757+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Starting task 10.0 in stage 115.0 (TID 258) (138.4.31.23, executor driver, partition 10, ANY, 16719 bytes)
[2025-07-11T14:04:24.757+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Finished task 8.0 in stage 115.0 (TID 256) in 73 ms on 138.4.31.23 (executor driver) (9/12)
[2025-07-11T14:04:24.758+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Running task 10.0 in stage 115.0 (TID 258)
[2025-07-11T14:04:24.763+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 138.4.31.23:41705 in memory (size: 9.3 KiB, free: 433.8 MiB)
[2025-07-11T14:04:24.826+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Finished task 10.0 in stage 115.0 (TID 258). 1988 bytes result sent to driver
[2025-07-11T14:04:24.827+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Starting task 11.0 in stage 115.0 (TID 259) (138.4.31.23, executor driver, partition 11, ANY, 16839 bytes)
[2025-07-11T14:04:24.828+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Finished task 10.0 in stage 115.0 (TID 258) in 71 ms on 138.4.31.23 (executor driver) (10/12)
[2025-07-11T14:04:24.829+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Running task 11.0 in stage 115.0 (TID 259)
[2025-07-11T14:04:24.830+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 138.4.31.23:41705 in memory (size: 9.3 KiB, free: 433.8 MiB)
[2025-07-11T14:04:24.847+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Finished task 9.0 in stage 115.0 (TID 257). 1988 bytes result sent to driver
[2025-07-11T14:04:24.848+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Finished task 9.0 in stage 115.0 (TID 257) in 109 ms on 138.4.31.23 (executor driver) (11/12)
[2025-07-11T14:04:24.865+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 138.4.31.23:41705 in memory (size: 38.9 KiB, free: 433.8 MiB)
[2025-07-11T14:04:24.888+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Finished task 11.0 in stage 115.0 (TID 259). 1945 bytes result sent to driver
[2025-07-11T14:04:24.889+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Finished task 11.0 in stage 115.0 (TID 259) in 63 ms on 138.4.31.23 (executor driver) (12/12)
[2025-07-11T14:04:24.889+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool
[2025-07-11T14:04:24.891+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: ShuffleMapStage 115 (showString at NativeMethodAccessorImpl.java:0) finished in 0,617 s
[2025-07-11T14:04:24.891+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:04:24.891+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: running: Set(ShuffleMapStage 114)
[2025-07-11T14:04:24.891+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:04:24.891+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: failed: Set()
[2025-07-11T14:04:24.891+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 138.4.31.23:41705 in memory (size: 9.2 KiB, free: 433.8 MiB)
[2025-07-11T14:04:24.910+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO ShufflePartitionsUtil: For shuffle(38), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:04:24.916+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 138.4.31.23:41705 in memory (size: 109.5 KiB, free: 433.9 MiB)
[2025-07-11T14:04:24.924+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 138.4.31.23:41705 in memory (size: 109.7 KiB, free: 434.1 MiB)
[2025-07-11T14:04:24.933+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:04:24.934+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: Got job 70 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-11T14:04:24.935+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: Final stage: ResultStage 117 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-11T14:04:24.935+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 116)
[2025-07-11T14:04:24.935+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:24.935+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[241] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-11T14:04:24.937+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 8.2 KiB, free 424.9 MiB)
[2025-07-11T14:04:24.938+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 424.9 MiB)
[2025-07-11T14:04:24.938+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 138.4.31.23:41705 (size: 4.2 KiB, free: 434.1 MiB)
[2025-07-11T14:04:24.940+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:24.940+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[241] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:04:24.940+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSchedulerImpl: Adding task set 117.0 with 1 tasks resource profile 0
[2025-07-11T14:04:24.940+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 260) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-11T14:04:24.940+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Running task 0.0 in stage 117.0 (TID 260)
[2025-07-11T14:04:24.944+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO ShuffleBlockFetcherIterator: Getting 12 (214.7 KiB) non-empty blocks including 12 (214.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:24.944+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-11T14:04:24.961+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO Executor: Finished task 0.0 in stage 117.0 (TID 260). 51278 bytes result sent to driver
[2025-07-11T14:04:24.962+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 260) in 23 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:04:24.962+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool
[2025-07-11T14:04:24.963+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: ResultStage 117 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,027 s
[2025-07-11T14:04:24.964+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:04:24.964+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 117: Stage finished
[2025-07-11T14:04:24.964+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO DAGScheduler: Job 70 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,029619 s
[2025-07-11T14:04:24.972+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 4.3 MiB, free 420.6 MiB)
[2025-07-11T14:04:24.975+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 109.6 KiB, free 420.5 MiB)
[2025-07-11T14:04:24.976+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 138.4.31.23:41705 (size: 109.6 KiB, free: 433.9 MiB)
[2025-07-11T14:04:24.976+0200] {subprocess.py:93} INFO - 25/07/11 14:04:24 INFO SparkContext: Created broadcast 104 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:04:25.511+0200] {subprocess.py:93} INFO - 25/07/11 14:04:25 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 138.4.31.23:41705 in memory (size: 4.2 KiB, free: 433.9 MiB)
[2025-07-11T14:04:25.657+0200] {subprocess.py:93} INFO - 25/07/11 14:04:25 INFO Executor: Finished task 1.0 in stage 114.0 (TID 247). 2031 bytes result sent to driver
[2025-07-11T14:04:25.658+0200] {subprocess.py:93} INFO - 25/07/11 14:04:25 INFO TaskSetManager: Finished task 1.0 in stage 114.0 (TID 247) in 1393 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:04:30.962+0200] {subprocess.py:93} INFO - 25/07/11 14:04:30 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 138.4.31.23:41705 in memory (size: 9.2 KiB, free: 434.0 MiB)
[2025-07-11T14:04:30.976+0200] {subprocess.py:93} INFO - 25/07/11 14:04:30 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 138.4.31.23:41705 in memory (size: 38.9 KiB, free: 434.0 MiB)
[2025-07-11T14:04:30.977+0200] {subprocess.py:93} INFO - 25/07/11 14:04:30 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 138.4.31.23:41705 in memory (size: 109.4 KiB, free: 434.1 MiB)
[2025-07-11T14:04:31.583+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO Executor: Finished task 0.0 in stage 114.0 (TID 246). 2031 bytes result sent to driver
[2025-07-11T14:04:31.583+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 246) in 7319 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:04:31.583+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool
[2025-07-11T14:04:31.584+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO DAGScheduler: ShuffleMapStage 114 (showString at NativeMethodAccessorImpl.java:0) finished in 7,332 s
[2025-07-11T14:04:31.584+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:04:31.584+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO DAGScheduler: running: Set()
[2025-07-11T14:04:31.584+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:04:31.584+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO DAGScheduler: failed: Set()
[2025-07-11T14:04:31.596+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO ShufflePartitionsUtil: For shuffle(37), advisory target size: 67108864, actual target size 1399865, minimum partition size: 1048576
[2025-07-11T14:04:31.699+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO CodeGenerator: Code generated in 54.652861 ms
[2025-07-11T14:04:31.725+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO DAGScheduler: Registering RDD 244 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 39
[2025-07-11T14:04:31.725+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO DAGScheduler: Got map stage job 71 (showString at NativeMethodAccessorImpl.java:0) with 4 output partitions
[2025-07-11T14:04:31.726+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO DAGScheduler: Final stage: ShuffleMapStage 119 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:04:31.726+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 118)
[2025-07-11T14:04:31.726+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:31.726+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO DAGScheduler: Submitting ShuffleMapStage 119 (MapPartitionsRDD[244] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:04:31.754+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 WARN DAGScheduler: Broadcasting large task binary with size 1020.3 KiB
[2025-07-11T14:04:31.754+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 1020.4 KiB, free 424.2 MiB)
[2025-07-11T14:04:31.759+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 452.5 KiB, free 423.7 MiB)
[2025-07-11T14:04:31.759+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 138.4.31.23:41705 (size: 452.5 KiB, free: 433.7 MiB)
[2025-07-11T14:04:31.759+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:31.759+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 119 (MapPartitionsRDD[244] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:04:31.760+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO TaskSchedulerImpl: Adding task set 119.0 with 4 tasks resource profile 0
[2025-07-11T14:04:31.760+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 261) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:04:31.760+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO TaskSetManager: Starting task 1.0 in stage 119.0 (TID 262) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:04:31.761+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO TaskSetManager: Starting task 2.0 in stage 119.0 (TID 263) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:04:31.761+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO TaskSetManager: Starting task 3.0 in stage 119.0 (TID 264) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14836 bytes)
[2025-07-11T14:04:31.764+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO Executor: Running task 0.0 in stage 119.0 (TID 261)
[2025-07-11T14:04:31.764+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO Executor: Running task 3.0 in stage 119.0 (TID 264)
[2025-07-11T14:04:31.765+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO Executor: Running task 1.0 in stage 119.0 (TID 262)
[2025-07-11T14:04:31.765+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO Executor: Running task 2.0 in stage 119.0 (TID 263)
[2025-07-11T14:04:31.786+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO ShuffleBlockFetcherIterator: Getting 1 (268.8 KiB) non-empty blocks including 1 (268.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:31.786+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-11T14:04:31.799+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO ShuffleBlockFetcherIterator: Getting 1 (2.5 MiB) non-empty blocks including 1 (2.5 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:31.800+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:31.807+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO ShuffleBlockFetcherIterator: Getting 1 (2.3 MiB) non-empty blocks including 1 (2.3 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:31.807+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:31.809+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO ShuffleBlockFetcherIterator: Getting 1 (283.3 KiB) non-empty blocks including 1 (283.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:31.810+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:31.844+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO CodeGenerator: Code generated in 56.933021 ms
[2025-07-11T14:04:31.862+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO CodeGenerator: Code generated in 15.713989 ms
[2025-07-11T14:04:31.868+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO CodeGenerator: Code generated in 3.003055 ms
[2025-07-11T14:04:31.875+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO CodeGenerator: Code generated in 4.046194 ms
[2025-07-11T14:04:31.885+0200] {subprocess.py:93} INFO - 25/07/11 14:04:31 INFO CodeGenerator: Code generated in 7.331087 ms
[2025-07-11T14:04:32.327+0200] {subprocess.py:93} INFO - 25/07/11 14:04:32 INFO Executor: Finished task 3.0 in stage 119.0 (TID 264). 6904 bytes result sent to driver
[2025-07-11T14:04:32.333+0200] {subprocess.py:93} INFO - 25/07/11 14:04:32 INFO TaskSetManager: Finished task 3.0 in stage 119.0 (TID 264) in 572 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:04:32.476+0200] {subprocess.py:93} INFO - 25/07/11 14:04:32 INFO Executor: Finished task 2.0 in stage 119.0 (TID 263). 6947 bytes result sent to driver
[2025-07-11T14:04:32.478+0200] {subprocess.py:93} INFO - 25/07/11 14:04:32 INFO TaskSetManager: Finished task 2.0 in stage 119.0 (TID 263) in 717 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:04:32.637+0200] {subprocess.py:93} INFO - 25/07/11 14:04:32 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 138.4.31.23:41705 in memory (size: 9.2 KiB, free: 433.7 MiB)
[2025-07-11T14:04:33.466+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO Executor: Finished task 0.0 in stage 119.0 (TID 261). 6904 bytes result sent to driver
[2025-07-11T14:04:33.468+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 261) in 1708 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:04:33.597+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO Executor: Finished task 1.0 in stage 119.0 (TID 262). 6904 bytes result sent to driver
[2025-07-11T14:04:33.597+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO TaskSetManager: Finished task 1.0 in stage 119.0 (TID 262) in 1837 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:04:33.597+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool
[2025-07-11T14:04:33.599+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: ShuffleMapStage 119 (showString at NativeMethodAccessorImpl.java:0) finished in 1,871 s
[2025-07-11T14:04:33.599+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:04:33.599+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: running: Set()
[2025-07-11T14:04:33.599+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:04:33.599+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: failed: Set()
[2025-07-11T14:04:33.604+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO ShufflePartitionsUtil: For shuffle(39), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:04:33.610+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-07-11T14:04:33.632+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO CodeGenerator: Code generated in 15.238716 ms
[2025-07-11T14:04:33.680+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2025-07-11T14:04:33.682+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: Got job 72 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-07-11T14:04:33.682+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: Final stage: ResultStage 122 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:04:33.682+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 121)
[2025-07-11T14:04:33.682+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:33.683+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: Submitting ResultStage 122 (MapPartitionsRDD[247] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:04:33.696+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 WARN DAGScheduler: Broadcasting large task binary with size 1004.9 KiB
[2025-07-11T14:04:33.697+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 1004.9 KiB, free 422.8 MiB)
[2025-07-11T14:04:33.700+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 446.5 KiB, free 422.3 MiB)
[2025-07-11T14:04:33.700+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 138.4.31.23:41705 (size: 446.5 KiB, free: 433.2 MiB)
[2025-07-11T14:04:33.700+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:33.700+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 122 (MapPartitionsRDD[247] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:04:33.700+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO TaskSchedulerImpl: Adding task set 122.0 with 1 tasks resource profile 0
[2025-07-11T14:04:33.701+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 265) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:04:33.701+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO Executor: Running task 0.0 in stage 122.0 (TID 265)
[2025-07-11T14:04:33.719+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO ShuffleBlockFetcherIterator: Getting 4 (1008.0 B) non-empty blocks including 4 (1008.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:33.720+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:33.727+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO CodeGenerator: Code generated in 7.422155 ms
[2025-07-11T14:04:33.731+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO Executor: Finished task 0.0 in stage 122.0 (TID 265). 8218 bytes result sent to driver
[2025-07-11T14:04:33.731+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 265) in 30 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:04:33.731+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool
[2025-07-11T14:04:33.731+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: ResultStage 122 (showString at NativeMethodAccessorImpl.java:0) finished in 0,048 s
[2025-07-11T14:04:33.732+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:04:33.732+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 122: Stage finished
[2025-07-11T14:04:33.732+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: Job 72 finished: showString at NativeMethodAccessorImpl.java:0, took 0,052252 s
[2025-07-11T14:04:33.737+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO CodeGenerator: Code generated in 3.381735 ms
[2025-07-11T14:04:33.740+0200] {subprocess.py:93} INFO - +----------+------+
[2025-07-11T14:04:33.740+0200] {subprocess.py:93} INFO - |Prediction| count|
[2025-07-11T14:04:33.740+0200] {subprocess.py:93} INFO - +----------+------+
[2025-07-11T14:04:33.740+0200] {subprocess.py:93} INFO - |       0.0|  6192|
[2025-07-11T14:04:33.740+0200] {subprocess.py:93} INFO - |       1.0|315771|
[2025-07-11T14:04:33.740+0200] {subprocess.py:93} INFO - |       3.0| 51427|
[2025-07-11T14:04:33.740+0200] {subprocess.py:93} INFO - |       2.0| 83623|
[2025-07-11T14:04:33.740+0200] {subprocess.py:93} INFO - +----------+------+
[2025-07-11T14:04:33.741+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:04:33.789+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO V2ScanRelationPushDown:
[2025-07-11T14:04:33.789+0200] {subprocess.py:93} INFO - Pushing operators to origin_dest_distances
[2025-07-11T14:04:33.789+0200] {subprocess.py:93} INFO - Pushed Filters:
[2025-07-11T14:04:33.789+0200] {subprocess.py:93} INFO - Post-Scan Filters:
[2025-07-11T14:04:33.789+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:04:33.795+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO V2ScanRelationPushDown:
[2025-07-11T14:04:33.796+0200] {subprocess.py:93} INFO - Output: origin#67, dest#68, distance#69
[2025-07-11T14:04:33.796+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:04:33.818+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO FileSourceStrategy: Pushed Filters:
[2025-07-11T14:04:33.819+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO FileSourceStrategy: Post-Scan Filters:
[2025-07-11T14:04:33.842+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 214.5 KiB, free 422.1 MiB)
[2025-07-11T14:04:33.850+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 38.9 KiB, free 422.1 MiB)
[2025-07-11T14:04:33.850+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 138.4.31.23:41705 (size: 38.9 KiB, free: 433.2 MiB)
[2025-07-11T14:04:33.850+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO SparkContext: Created broadcast 107 from showString at NativeMethodAccessorImpl.java:0
[2025-07-11T14:04:33.851+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2025-07-11T14:04:33.853+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: Registering RDD 251 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 40
[2025-07-11T14:04:33.854+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: Got map stage job 73 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-07-11T14:04:33.854+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: Final stage: ShuffleMapStage 123 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:04:33.854+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:04:33.854+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:33.854+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: Submitting ShuffleMapStage 123 (MapPartitionsRDD[251] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:04:33.855+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 22.8 KiB, free 422.1 MiB)
[2025-07-11T14:04:33.856+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 422.1 MiB)
[2025-07-11T14:04:33.856+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 138.4.31.23:41705 (size: 9.9 KiB, free: 433.2 MiB)
[2025-07-11T14:04:33.857+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:33.857+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 123 (MapPartitionsRDD[251] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-07-11T14:04:33.858+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO TaskSchedulerImpl: Adding task set 123.0 with 2 tasks resource profile 0
[2025-07-11T14:04:33.860+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: Registering RDD 255 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 41
[2025-07-11T14:04:33.860+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: Got map stage job 74 (showString at NativeMethodAccessorImpl.java:0) with 12 output partitions
[2025-07-11T14:04:33.860+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: Final stage: ShuffleMapStage 124 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:04:33.860+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:04:33.861+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 266) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:04:33.861+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:33.861+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: Submitting ShuffleMapStage 124 (MapPartitionsRDD[255] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:04:33.861+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO TaskSetManager: Starting task 1.0 in stage 123.0 (TID 267) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 15471 bytes)
[2025-07-11T14:04:33.861+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO Executor: Running task 1.0 in stage 123.0 (TID 267)
[2025-07-11T14:04:33.861+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO Executor: Running task 0.0 in stage 123.0 (TID 266)
[2025-07-11T14:04:33.861+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 18.7 KiB, free 422.0 MiB)
[2025-07-11T14:04:33.862+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 422.0 MiB)
[2025-07-11T14:04:33.863+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 4194304-4676447, partition values: [empty row]
[2025-07-11T14:04:33.863+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 138.4.31.23:41705 (size: 9.2 KiB, free: 433.2 MiB)
[2025-07-11T14:04:33.863+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO FileScanRDD: Reading File path: file:///home/monica.fernandez/practica_creativa/data/simple_flight_delay_features.jsonl.bz2, range: 0-4194304, partition values: [empty row]
[2025-07-11T14:04:33.864+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:33.864+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 124 (MapPartitionsRDD[255] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
[2025-07-11T14:04:33.864+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO TaskSchedulerImpl: Adding task set 124.0 with 12 tasks resource profile 0
[2025-07-11T14:04:33.865+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 268) (138.4.31.23, executor driver, partition 0, ANY, 16839 bytes)
[2025-07-11T14:04:33.865+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO TaskSetManager: Starting task 1.0 in stage 124.0 (TID 269) (138.4.31.23, executor driver, partition 1, ANY, 16719 bytes)
[2025-07-11T14:04:33.865+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO Executor: Running task 0.0 in stage 124.0 (TID 268)
[2025-07-11T14:04:33.867+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO Executor: Running task 1.0 in stage 124.0 (TID 269)
[2025-07-11T14:04:33.895+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 138.4.31.23:41705 in memory (size: 446.5 KiB, free: 433.6 MiB)
[2025-07-11T14:04:33.949+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO Executor: Finished task 1.0 in stage 124.0 (TID 269). 1988 bytes result sent to driver
[2025-07-11T14:04:33.951+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO TaskSetManager: Starting task 2.0 in stage 124.0 (TID 270) (138.4.31.23, executor driver, partition 2, ANY, 16719 bytes)
[2025-07-11T14:04:33.951+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO Executor: Finished task 0.0 in stage 124.0 (TID 268). 1988 bytes result sent to driver
[2025-07-11T14:04:33.951+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO Executor: Running task 2.0 in stage 124.0 (TID 270)
[2025-07-11T14:04:33.951+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO TaskSetManager: Starting task 3.0 in stage 124.0 (TID 271) (138.4.31.23, executor driver, partition 3, ANY, 16719 bytes)
[2025-07-11T14:04:33.951+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO Executor: Running task 3.0 in stage 124.0 (TID 271)
[2025-07-11T14:04:33.951+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO TaskSetManager: Finished task 1.0 in stage 124.0 (TID 269) in 87 ms on 138.4.31.23 (executor driver) (1/12)
[2025-07-11T14:04:33.953+0200] {subprocess.py:93} INFO - 25/07/11 14:04:33 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 268) in 89 ms on 138.4.31.23 (executor driver) (2/12)
[2025-07-11T14:04:34.011+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO Executor: Finished task 2.0 in stage 124.0 (TID 270). 1945 bytes result sent to driver
[2025-07-11T14:04:34.012+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSetManager: Starting task 4.0 in stage 124.0 (TID 272) (138.4.31.23, executor driver, partition 4, ANY, 16719 bytes)
[2025-07-11T14:04:34.012+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSetManager: Finished task 2.0 in stage 124.0 (TID 270) in 63 ms on 138.4.31.23 (executor driver) (3/12)
[2025-07-11T14:04:34.013+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO Executor: Finished task 3.0 in stage 124.0 (TID 271). 1945 bytes result sent to driver
[2025-07-11T14:04:34.014+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO Executor: Running task 4.0 in stage 124.0 (TID 272)
[2025-07-11T14:04:34.015+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSetManager: Starting task 5.0 in stage 124.0 (TID 273) (138.4.31.23, executor driver, partition 5, ANY, 16839 bytes)
[2025-07-11T14:04:34.015+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO Executor: Running task 5.0 in stage 124.0 (TID 273)
[2025-07-11T14:04:34.015+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSetManager: Finished task 3.0 in stage 124.0 (TID 271) in 64 ms on 138.4.31.23 (executor driver) (4/12)
[2025-07-11T14:04:34.086+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO Executor: Finished task 4.0 in stage 124.0 (TID 272). 1945 bytes result sent to driver
[2025-07-11T14:04:34.088+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSetManager: Starting task 6.0 in stage 124.0 (TID 274) (138.4.31.23, executor driver, partition 6, ANY, 16715 bytes)
[2025-07-11T14:04:34.088+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSetManager: Finished task 4.0 in stage 124.0 (TID 272) in 76 ms on 138.4.31.23 (executor driver) (5/12)
[2025-07-11T14:04:34.089+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO Executor: Running task 6.0 in stage 124.0 (TID 274)
[2025-07-11T14:04:34.096+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO Executor: Finished task 5.0 in stage 124.0 (TID 273). 1945 bytes result sent to driver
[2025-07-11T14:04:34.101+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSetManager: Starting task 7.0 in stage 124.0 (TID 275) (138.4.31.23, executor driver, partition 7, ANY, 16719 bytes)
[2025-07-11T14:04:34.102+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO Executor: Running task 7.0 in stage 124.0 (TID 275)
[2025-07-11T14:04:34.102+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSetManager: Finished task 5.0 in stage 124.0 (TID 273) in 88 ms on 138.4.31.23 (executor driver) (6/12)
[2025-07-11T14:04:34.142+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO Executor: Finished task 6.0 in stage 124.0 (TID 274). 1945 bytes result sent to driver
[2025-07-11T14:04:34.147+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSetManager: Starting task 8.0 in stage 124.0 (TID 276) (138.4.31.23, executor driver, partition 8, ANY, 16719 bytes)
[2025-07-11T14:04:34.147+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSetManager: Finished task 6.0 in stage 124.0 (TID 274) in 56 ms on 138.4.31.23 (executor driver) (7/12)
[2025-07-11T14:04:34.147+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO Executor: Running task 8.0 in stage 124.0 (TID 276)
[2025-07-11T14:04:34.154+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO Executor: Finished task 7.0 in stage 124.0 (TID 275). 1945 bytes result sent to driver
[2025-07-11T14:04:34.155+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSetManager: Starting task 9.0 in stage 124.0 (TID 277) (138.4.31.23, executor driver, partition 9, ANY, 16719 bytes)
[2025-07-11T14:04:34.155+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSetManager: Finished task 7.0 in stage 124.0 (TID 275) in 55 ms on 138.4.31.23 (executor driver) (8/12)
[2025-07-11T14:04:34.174+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO Executor: Running task 9.0 in stage 124.0 (TID 277)
[2025-07-11T14:04:34.256+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO Executor: Finished task 8.0 in stage 124.0 (TID 276). 2031 bytes result sent to driver
[2025-07-11T14:04:34.257+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSetManager: Starting task 10.0 in stage 124.0 (TID 278) (138.4.31.23, executor driver, partition 10, ANY, 16839 bytes)
[2025-07-11T14:04:34.258+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSetManager: Finished task 8.0 in stage 124.0 (TID 276) in 115 ms on 138.4.31.23 (executor driver) (9/12)
[2025-07-11T14:04:34.261+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO Executor: Running task 10.0 in stage 124.0 (TID 278)
[2025-07-11T14:04:34.277+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO Executor: Finished task 9.0 in stage 124.0 (TID 277). 1988 bytes result sent to driver
[2025-07-11T14:04:34.277+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSetManager: Starting task 11.0 in stage 124.0 (TID 279) (138.4.31.23, executor driver, partition 11, ANY, 16839 bytes)
[2025-07-11T14:04:34.278+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSetManager: Finished task 9.0 in stage 124.0 (TID 277) in 124 ms on 138.4.31.23 (executor driver) (10/12)
[2025-07-11T14:04:34.281+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO Executor: Running task 11.0 in stage 124.0 (TID 279)
[2025-07-11T14:04:34.318+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO Executor: Finished task 10.0 in stage 124.0 (TID 278). 1945 bytes result sent to driver
[2025-07-11T14:04:34.323+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSetManager: Finished task 10.0 in stage 124.0 (TID 278) in 66 ms on 138.4.31.23 (executor driver) (11/12)
[2025-07-11T14:04:34.390+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO Executor: Finished task 11.0 in stage 124.0 (TID 279). 1945 bytes result sent to driver
[2025-07-11T14:04:34.396+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSetManager: Finished task 11.0 in stage 124.0 (TID 279) in 119 ms on 138.4.31.23 (executor driver) (12/12)
[2025-07-11T14:04:34.397+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool
[2025-07-11T14:04:34.402+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO DAGScheduler: ShuffleMapStage 124 (showString at NativeMethodAccessorImpl.java:0) finished in 0,537 s
[2025-07-11T14:04:34.402+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:04:34.402+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO DAGScheduler: running: Set(ShuffleMapStage 123)
[2025-07-11T14:04:34.402+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:04:34.402+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO DAGScheduler: failed: Set()
[2025-07-11T14:04:34.431+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO ShufflePartitionsUtil: For shuffle(41), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-07-11T14:04:34.470+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:04:34.473+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO DAGScheduler: Got job 75 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-07-11T14:04:34.473+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO DAGScheduler: Final stage: ResultStage 126 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-07-11T14:04:34.473+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 125)
[2025-07-11T14:04:34.473+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:34.473+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[257] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-07-11T14:04:34.473+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 8.2 KiB, free 423.4 MiB)
[2025-07-11T14:04:34.475+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 423.4 MiB)
[2025-07-11T14:04:34.475+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 138.4.31.23:41705 (size: 4.2 KiB, free: 433.6 MiB)
[2025-07-11T14:04:34.493+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:34.493+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 126 (MapPartitionsRDD[257] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:04:34.493+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSchedulerImpl: Adding task set 126.0 with 1 tasks resource profile 0
[2025-07-11T14:04:34.501+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 138.4.31.23:41705 in memory (size: 452.5 KiB, free: 434.0 MiB)
[2025-07-11T14:04:34.504+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 280) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14844 bytes)
[2025-07-11T14:04:34.504+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO Executor: Running task 0.0 in stage 126.0 (TID 280)
[2025-07-11T14:04:34.509+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO ShuffleBlockFetcherIterator: Getting 12 (214.7 KiB) non-empty blocks including 12 (214.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:34.510+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-11T14:04:34.510+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 138.4.31.23:41705 in memory (size: 109.6 KiB, free: 434.2 MiB)
[2025-07-11T14:04:34.514+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 138.4.31.23:41705 in memory (size: 38.9 KiB, free: 434.2 MiB)
[2025-07-11T14:04:34.535+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO Executor: Finished task 0.0 in stage 126.0 (TID 280). 51189 bytes result sent to driver
[2025-07-11T14:04:34.540+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 280) in 47 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:04:34.541+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool
[2025-07-11T14:04:34.547+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO DAGScheduler: ResultStage 126 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0,069 s
[2025-07-11T14:04:34.547+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:04:34.547+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 126: Stage finished
[2025-07-11T14:04:34.547+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO DAGScheduler: Job 75 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0,071613 s
[2025-07-11T14:04:34.551+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 4.3 MiB, free 425.2 MiB)
[2025-07-11T14:04:34.554+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 109.8 KiB, free 425.1 MiB)
[2025-07-11T14:04:34.555+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 138.4.31.23:41705 (size: 109.8 KiB, free: 434.1 MiB)
[2025-07-11T14:04:34.556+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO SparkContext: Created broadcast 111 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-07-11T14:04:34.953+0200] {subprocess.py:93} INFO - 25/07/11 14:04:34 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 138.4.31.23:41705 in memory (size: 4.2 KiB, free: 434.1 MiB)
[2025-07-11T14:04:35.478+0200] {subprocess.py:93} INFO - 25/07/11 14:04:35 INFO Executor: Finished task 1.0 in stage 123.0 (TID 267). 2031 bytes result sent to driver
[2025-07-11T14:04:35.478+0200] {subprocess.py:93} INFO - 25/07/11 14:04:35 INFO TaskSetManager: Finished task 1.0 in stage 123.0 (TID 267) in 1619 ms on 138.4.31.23 (executor driver) (1/2)
[2025-07-11T14:04:37.789+0200] {subprocess.py:93} INFO - 25/07/11 14:04:37 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 138.4.31.23:41705 in memory (size: 9.2 KiB, free: 434.1 MiB)
[2025-07-11T14:04:43.822+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO Executor: Finished task 0.0 in stage 123.0 (TID 266). 2074 bytes result sent to driver
[2025-07-11T14:04:43.822+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 266) in 9963 ms on 138.4.31.23 (executor driver) (2/2)
[2025-07-11T14:04:43.823+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool
[2025-07-11T14:04:43.823+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO DAGScheduler: ShuffleMapStage 123 (showString at NativeMethodAccessorImpl.java:0) finished in 9,969 s
[2025-07-11T14:04:43.823+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:04:43.823+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO DAGScheduler: running: Set()
[2025-07-11T14:04:43.823+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:04:43.823+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO DAGScheduler: failed: Set()
[2025-07-11T14:04:43.838+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO ShufflePartitionsUtil: For shuffle(40), advisory target size: 67108864, actual target size 4228400, minimum partition size: 1048576
[2025-07-11T14:04:43.851+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO CodeGenerator: Code generated in 4.139893 ms
[2025-07-11T14:04:43.898+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO CodeGenerator: Code generated in 30.130486 ms
[2025-07-11T14:04:43.979+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2025-07-11T14:04:43.980+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO DAGScheduler: Got job 76 (showString at NativeMethodAccessorImpl.java:0) with 4 output partitions
[2025-07-11T14:04:43.980+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO DAGScheduler: Final stage: ResultStage 128 (showString at NativeMethodAccessorImpl.java:0)
[2025-07-11T14:04:43.980+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 127)
[2025-07-11T14:04:43.980+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:43.980+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO DAGScheduler: Submitting ResultStage 128 (MapPartitionsRDD[261] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-07-11T14:04:43.994+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 WARN DAGScheduler: Broadcasting large task binary with size 1009.3 KiB
[2025-07-11T14:04:43.994+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 1009.4 KiB, free 424.2 MiB)
[2025-07-11T14:04:43.997+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 439.9 KiB, free 423.7 MiB)
[2025-07-11T14:04:43.997+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 138.4.31.23:41705 (size: 439.9 KiB, free: 433.7 MiB)
[2025-07-11T14:04:43.997+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:43.998+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 128 (MapPartitionsRDD[261] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:04:43.998+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO TaskSchedulerImpl: Adding task set 128.0 with 4 tasks resource profile 0
[2025-07-11T14:04:44.000+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 281) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14847 bytes)
[2025-07-11T14:04:44.000+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO TaskSetManager: Starting task 1.0 in stage 128.0 (TID 282) (138.4.31.23, executor driver, partition 1, NODE_LOCAL, 14847 bytes)
[2025-07-11T14:04:44.000+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO TaskSetManager: Starting task 2.0 in stage 128.0 (TID 283) (138.4.31.23, executor driver, partition 2, NODE_LOCAL, 14847 bytes)
[2025-07-11T14:04:44.000+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO TaskSetManager: Starting task 3.0 in stage 128.0 (TID 284) (138.4.31.23, executor driver, partition 3, NODE_LOCAL, 14847 bytes)
[2025-07-11T14:04:44.000+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO Executor: Running task 0.0 in stage 128.0 (TID 281)
[2025-07-11T14:04:44.000+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO Executor: Running task 1.0 in stage 128.0 (TID 282)
[2025-07-11T14:04:44.000+0200] {subprocess.py:93} INFO - 25/07/11 14:04:43 INFO Executor: Running task 2.0 in stage 128.0 (TID 283)
[2025-07-11T14:04:44.000+0200] {subprocess.py:93} INFO - 25/07/11 14:04:44 INFO Executor: Running task 3.0 in stage 128.0 (TID 284)
[2025-07-11T14:04:44.029+0200] {subprocess.py:93} INFO - 25/07/11 14:04:44 INFO CodeGenerator: Code generated in 3.226414 ms
[2025-07-11T14:04:44.034+0200] {subprocess.py:93} INFO - 25/07/11 14:04:44 INFO ShuffleBlockFetcherIterator: Getting 1 (7.4 MiB) non-empty blocks including 1 (7.4 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:44.034+0200] {subprocess.py:93} INFO - 25/07/11 14:04:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:44.035+0200] {subprocess.py:93} INFO - 25/07/11 14:04:44 INFO ShuffleBlockFetcherIterator: Getting 1 (840.2 KiB) non-empty blocks including 1 (840.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:44.035+0200] {subprocess.py:93} INFO - 25/07/11 14:04:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:44.040+0200] {subprocess.py:93} INFO - 25/07/11 14:04:44 INFO ShuffleBlockFetcherIterator: Getting 1 (802.7 KiB) non-empty blocks including 1 (802.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:44.040+0200] {subprocess.py:93} INFO - 25/07/11 14:04:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:44.047+0200] {subprocess.py:93} INFO - 25/07/11 14:04:44 INFO ShuffleBlockFetcherIterator: Getting 1 (7.1 MiB) non-empty blocks including 1 (7.1 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:44.047+0200] {subprocess.py:93} INFO - 25/07/11 14:04:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:44.073+0200] {subprocess.py:93} INFO - 25/07/11 14:04:44 INFO CodeGenerator: Code generated in 39.033011 ms
[2025-07-11T14:04:44.370+0200] {subprocess.py:93} INFO - 25/07/11 14:04:44 INFO Executor: Finished task 3.0 in stage 128.0 (TID 284). 7241 bytes result sent to driver
[2025-07-11T14:04:44.371+0200] {subprocess.py:93} INFO - 25/07/11 14:04:44 INFO TaskSetManager: Finished task 3.0 in stage 128.0 (TID 284) in 372 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:04:44.398+0200] {subprocess.py:93} INFO - 25/07/11 14:04:44 INFO Executor: Finished task 2.0 in stage 128.0 (TID 283). 7241 bytes result sent to driver
[2025-07-11T14:04:44.399+0200] {subprocess.py:93} INFO - 25/07/11 14:04:44 INFO TaskSetManager: Finished task 2.0 in stage 128.0 (TID 283) in 400 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:04:45.022+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 138.4.31.23:41705 in memory (size: 9.9 KiB, free: 433.7 MiB)
[2025-07-11T14:04:45.323+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO Executor: Finished task 0.0 in stage 128.0 (TID 281). 7241 bytes result sent to driver
[2025-07-11T14:04:45.325+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 281) in 1326 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:04:45.405+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO Executor: Finished task 1.0 in stage 128.0 (TID 282). 7241 bytes result sent to driver
[2025-07-11T14:04:45.405+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSetManager: Finished task 1.0 in stage 128.0 (TID 282) in 1406 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:04:45.405+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool
[2025-07-11T14:04:45.406+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: ResultStage 128 (showString at NativeMethodAccessorImpl.java:0) finished in 1,424 s
[2025-07-11T14:04:45.406+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:04:45.406+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 128: Stage finished
[2025-07-11T14:04:45.406+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Job 76 finished: showString at NativeMethodAccessorImpl.java:0, took 1,426361 s
[2025-07-11T14:04:45.417+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO CodeGenerator: Code generated in 8.025095 ms
[2025-07-11T14:04:45.427+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO CodeGenerator: Code generated in 5.16703 ms
[2025-07-11T14:04:45.429+0200] {subprocess.py:93} INFO - +--------+-------------------+-------------------+----------+---------+---------+--------+----------+---------+-----------------+--------------+--------------------+--------------------+--------------------+----------+
[2025-07-11T14:04:45.429+0200] {subprocess.py:93} INFO - |ArrDelay|         CRSArrTime|         CRSDepTime|DayOfMonth|DayOfWeek|DayOfYear|DepDelay|FlightDate|FlightNum|         Distance|ArrDelayBucket|        Features_vec|       rawPrediction|         probability|Prediction|
[2025-07-11T14:04:45.429+0200] {subprocess.py:93} INFO - +--------+-------------------+-------------------+----------+---------+---------+--------+----------+---------+-----------------+--------------+--------------------+--------------------+--------------------+----------+
[2025-07-11T14:04:45.429+0200] {subprocess.py:93} INFO - |   -22.0|2015-01-01 10:11:00|2015-01-01 07:00:00|         1|        4|        1|    -2.0|2015-01-01|     2282|            946.0|           0.0|[-2.0,946.0,1.0,4...|[2.80066385023886...|[0.28006638502388...|       1.0|
[2025-07-11T14:04:45.429+0200] {subprocess.py:93} INFO - |    -7.0|2015-01-01 12:42:00|2015-01-01 11:25:00|         1|        4|        1|    -6.0|2015-01-01|      626|            369.0|           1.0|[-6.0,369.0,1.0,4...|[1.53803424467514...|[0.15380342446751...|       1.0|
[2025-07-11T14:04:45.429+0200] {subprocess.py:93} INFO - |    -7.0|2015-01-01 17:09:00|2015-01-01 14:11:00|         1|        4|        1|    10.0|2015-01-01|     1236|588.7860861334595|           1.0|[10.0,588.7860861...|[1.29589735250055...|[0.12958973525005...|       2.0|
[2025-07-11T14:04:45.429+0200] {subprocess.py:93} INFO - |     8.0|2015-01-01 16:38:00|2015-01-01 15:45:00|         1|        4|        1|    -3.0|2015-01-01|     6603|            160.0|           2.0|[-3.0,160.0,1.0,4...|[0.96674469553972...|[0.09667446955397...|       1.0|
[2025-07-11T14:04:45.430+0200] {subprocess.py:93} INFO - |   -28.0|2015-01-01 19:10:00|2015-01-01 17:05:00|         1|        4|        1|    -8.0|2015-01-01|     3101|            693.0|           0.0|[-8.0,693.0,1.0,4...|[1.61008925327684...|[0.16100892532768...|       1.0|
[2025-07-11T14:04:45.430+0200] {subprocess.py:93} INFO - |    53.0|2015-01-01 21:18:00|2015-01-01 18:15:00|         1|        4|        1|    53.0|2015-01-01|     5159|            946.0|           3.0|[53.0,946.0,1.0,4...|[0.24994993756609...|[0.02499499375660...|       3.0|
[2025-07-11T14:04:45.430+0200] {subprocess.py:93} INFO - +--------+-------------------+-------------------+----------+---------+---------+--------+----------+---------+-----------------+--------------+--------------------+--------------------+--------------------+----------+
[2025-07-11T14:04:45.430+0200] {subprocess.py:93} INFO - only showing top 6 rows
[2025-07-11T14:04:45.430+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:04:45.536+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:04:45.536+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:45.537+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:45.577+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-11T14:04:45.577+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Got job 77 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-11T14:04:45.577+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Final stage: ResultStage 129 (runJob at SparkHadoopWriter.scala:83)
[2025-07-11T14:04:45.577+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:04:45.577+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:45.577+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Submitting ResultStage 129 (MapPartitionsRDD[263] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-11T14:04:45.589+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 101.3 KiB, free 423.7 MiB)
[2025-07-11T14:04:45.590+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 423.6 MiB)
[2025-07-11T14:04:45.590+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 138.4.31.23:41705 (size: 36.4 KiB, free: 433.6 MiB)
[2025-07-11T14:04:45.590+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:45.591+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 129 (MapPartitionsRDD[263] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:04:45.591+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSchedulerImpl: Adding task set 129.0 with 1 tasks resource profile 0
[2025-07-11T14:04:45.591+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 285) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15042 bytes)
[2025-07-11T14:04:45.592+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO Executor: Running task 0.0 in stage 129.0 (TID 285)
[2025-07-11T14:04:45.597+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:04:45.597+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:45.597+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:45.625+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO FileOutputCommitter: Saved output of task 'attempt_202507111404459175493345698558750_0263_m_000000_0' to file:/tmp/mlflow/3e725c6a-f969-4217-ab0f-ce75eef14217/metadata/_temporary/0/task_202507111404459175493345698558750_0263_m_000000
[2025-07-11T14:04:45.625+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO SparkHadoopMapRedUtil: attempt_202507111404459175493345698558750_0263_m_000000_0: Committed. Elapsed time: 0 ms.
[2025-07-11T14:04:45.625+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO Executor: Finished task 0.0 in stage 129.0 (TID 285). 1170 bytes result sent to driver
[2025-07-11T14:04:45.625+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 285) in 33 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:04:45.625+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool
[2025-07-11T14:04:45.625+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: ResultStage 129 (runJob at SparkHadoopWriter.scala:83) finished in 0,048 s
[2025-07-11T14:04:45.626+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Job 77 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:04:45.626+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 129: Stage finished
[2025-07-11T14:04:45.626+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Job 77 finished: runJob at SparkHadoopWriter.scala:83, took 0,049000 s
[2025-07-11T14:04:45.626+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO SparkHadoopWriter: Start to commit write Job job_202507111404459175493345698558750_0263.
[2025-07-11T14:04:45.634+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO SparkHadoopWriter: Write Job job_202507111404459175493345698558750_0263 committed. Elapsed time: 8 ms.
[2025-07-11T14:04:45.643+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:04:45.644+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:45.645+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:45.672+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-07-11T14:04:45.672+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Got job 78 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-07-11T14:04:45.673+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Final stage: ResultStage 130 (runJob at SparkHadoopWriter.scala:83)
[2025-07-11T14:04:45.673+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:04:45.673+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:45.673+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Submitting ResultStage 130 (MapPartitionsRDD[265] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
[2025-07-11T14:04:45.679+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 101.4 KiB, free 423.5 MiB)
[2025-07-11T14:04:45.685+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 423.5 MiB)
[2025-07-11T14:04:45.686+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 138.4.31.23:41705 (size: 36.5 KiB, free: 433.6 MiB)
[2025-07-11T14:04:45.686+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 138.4.31.23:41705 in memory (size: 36.4 KiB, free: 433.6 MiB)
[2025-07-11T14:04:45.687+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:45.687+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 130 (MapPartitionsRDD[265] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:04:45.687+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSchedulerImpl: Adding task set 130.0 with 1 tasks resource profile 0
[2025-07-11T14:04:45.689+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 286) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 15658 bytes)
[2025-07-11T14:04:45.690+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO Executor: Running task 0.0 in stage 130.0 (TID 286)
[2025-07-11T14:04:45.696+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-07-11T14:04:45.696+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:45.697+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:45.714+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO FileOutputCommitter: Saved output of task 'attempt_20250711140445222269472911794622_0265_m_000000_0' to file:/tmp/mlflow/3e725c6a-f969-4217-ab0f-ce75eef14217/stages/0_RandomForestClassifier_42137e15cb45/metadata/_temporary/0/task_20250711140445222269472911794622_0265_m_000000
[2025-07-11T14:04:45.714+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO SparkHadoopMapRedUtil: attempt_20250711140445222269472911794622_0265_m_000000_0: Committed. Elapsed time: 0 ms.
[2025-07-11T14:04:45.716+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO Executor: Finished task 0.0 in stage 130.0 (TID 286). 1170 bytes result sent to driver
[2025-07-11T14:04:45.716+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 286) in 28 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:04:45.717+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool
[2025-07-11T14:04:45.717+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: ResultStage 130 (runJob at SparkHadoopWriter.scala:83) finished in 0,044 s
[2025-07-11T14:04:45.717+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:04:45.717+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 130: Stage finished
[2025-07-11T14:04:45.717+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Job 78 finished: runJob at SparkHadoopWriter.scala:83, took 0,045891 s
[2025-07-11T14:04:45.717+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO SparkHadoopWriter: Start to commit write Job job_20250711140445222269472911794622_0265.
[2025-07-11T14:04:45.727+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO SparkHadoopWriter: Write Job job_20250711140445222269472911794622_0265 committed. Elapsed time: 9 ms.
[2025-07-11T14:04:45.777+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Registering RDD 268 (parquet at treeModels.scala:483) as input to shuffle 42
[2025-07-11T14:04:45.777+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Got map stage job 79 (parquet at treeModels.scala:483) with 4 output partitions
[2025-07-11T14:04:45.778+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Final stage: ShuffleMapStage 131 (parquet at treeModels.scala:483)
[2025-07-11T14:04:45.778+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:04:45.778+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:45.778+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Submitting ShuffleMapStage 131 (MapPartitionsRDD[268] at parquet at treeModels.scala:483), which has no missing parents
[2025-07-11T14:04:45.780+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 8.3 KiB, free 423.6 MiB)
[2025-07-11T14:04:45.780+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 423.6 MiB)
[2025-07-11T14:04:45.780+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 138.4.31.23:41705 (size: 4.5 KiB, free: 433.6 MiB)
[2025-07-11T14:04:45.780+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:45.782+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 131 (MapPartitionsRDD[268] at parquet at treeModels.scala:483) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:04:45.782+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSchedulerImpl: Adding task set 131.0 with 4 tasks resource profile 0
[2025-07-11T14:04:45.788+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 287) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 16404 bytes)
[2025-07-11T14:04:45.788+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSetManager: Starting task 1.0 in stage 131.0 (TID 288) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 17128 bytes)
[2025-07-11T14:04:45.788+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSetManager: Starting task 2.0 in stage 131.0 (TID 289) (138.4.31.23, executor driver, partition 2, PROCESS_LOCAL, 16404 bytes)
[2025-07-11T14:04:45.788+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSetManager: Starting task 3.0 in stage 131.0 (TID 290) (138.4.31.23, executor driver, partition 3, PROCESS_LOCAL, 17128 bytes)
[2025-07-11T14:04:45.788+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO Executor: Running task 0.0 in stage 131.0 (TID 287)
[2025-07-11T14:04:45.788+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO Executor: Running task 3.0 in stage 131.0 (TID 290)
[2025-07-11T14:04:45.788+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO Executor: Running task 1.0 in stage 131.0 (TID 288)
[2025-07-11T14:04:45.788+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO Executor: Running task 2.0 in stage 131.0 (TID 289)
[2025-07-11T14:04:45.788+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO Executor: Finished task 0.0 in stage 131.0 (TID 287). 1585 bytes result sent to driver
[2025-07-11T14:04:45.788+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO Executor: Finished task 2.0 in stage 131.0 (TID 289). 1542 bytes result sent to driver
[2025-07-11T14:04:45.797+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO Executor: Finished task 3.0 in stage 131.0 (TID 290). 1628 bytes result sent to driver
[2025-07-11T14:04:45.797+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO Executor: Finished task 1.0 in stage 131.0 (TID 288). 1671 bytes result sent to driver
[2025-07-11T14:04:45.798+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 138.4.31.23:41705 in memory (size: 36.5 KiB, free: 433.7 MiB)
[2025-07-11T14:04:45.804+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 287) in 20 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:04:45.804+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSetManager: Finished task 2.0 in stage 131.0 (TID 289) in 21 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:04:45.804+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSetManager: Finished task 3.0 in stage 131.0 (TID 290) in 21 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:04:45.804+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSetManager: Finished task 1.0 in stage 131.0 (TID 288) in 22 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:04:45.804+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool
[2025-07-11T14:04:45.805+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: ShuffleMapStage 131 (parquet at treeModels.scala:483) finished in 0,026 s
[2025-07-11T14:04:45.805+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:04:45.805+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: running: Set()
[2025-07-11T14:04:45.805+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:04:45.805+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: failed: Set()
[2025-07-11T14:04:45.809+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:04:45.812+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:45.812+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:45.812+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:04:45.813+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:45.813+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:45.813+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:04:45.831+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO SparkContext: Starting job: parquet at treeModels.scala:483
[2025-07-11T14:04:45.831+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Got job 80 (parquet at treeModels.scala:483) with 1 output partitions
[2025-07-11T14:04:45.831+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Final stage: ResultStage 133 (parquet at treeModels.scala:483)
[2025-07-11T14:04:45.832+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 132)
[2025-07-11T14:04:45.832+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:45.832+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Submitting ResultStage 133 (MapPartitionsRDD[270] at parquet at treeModels.scala:483), which has no missing parents
[2025-07-11T14:04:45.850+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 239.7 KiB, free 423.5 MiB)
[2025-07-11T14:04:45.851+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 83.9 KiB, free 423.4 MiB)
[2025-07-11T14:04:45.852+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 138.4.31.23:41705 (size: 83.9 KiB, free: 433.6 MiB)
[2025-07-11T14:04:45.852+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:45.852+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 133 (MapPartitionsRDD[270] at parquet at treeModels.scala:483) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:04:45.852+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSchedulerImpl: Adding task set 133.0 with 1 tasks resource profile 0
[2025-07-11T14:04:45.853+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 291) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:04:45.853+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO Executor: Running task 0.0 in stage 133.0 (TID 291)
[2025-07-11T14:04:45.869+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO ShuffleBlockFetcherIterator: Getting 4 (3.4 KiB) non-empty blocks including 4 (3.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:45.869+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:45.870+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:45.871+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:45.871+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:04:45.871+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:45.871+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:45.871+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:04:45.871+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:04:45.871+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:04:45.872+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-11T14:04:45.873+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-11T14:04:45.873+0200] {subprocess.py:93} INFO - {
[2025-07-11T14:04:45.873+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-11T14:04:45.873+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-11T14:04:45.873+0200] {subprocess.py:93} INFO -     "name" : "treeID",
[2025-07-11T14:04:45.873+0200] {subprocess.py:93} INFO -     "type" : "integer",
[2025-07-11T14:04:45.874+0200] {subprocess.py:93} INFO -     "nullable" : false,
[2025-07-11T14:04:45.874+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:04:45.874+0200] {subprocess.py:93} INFO -   }, {
[2025-07-11T14:04:45.874+0200] {subprocess.py:93} INFO -     "name" : "metadata",
[2025-07-11T14:04:45.874+0200] {subprocess.py:93} INFO -     "type" : "string",
[2025-07-11T14:04:45.874+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-11T14:04:45.874+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:04:45.874+0200] {subprocess.py:93} INFO -   }, {
[2025-07-11T14:04:45.874+0200] {subprocess.py:93} INFO -     "name" : "weights",
[2025-07-11T14:04:45.874+0200] {subprocess.py:93} INFO -     "type" : "double",
[2025-07-11T14:04:45.874+0200] {subprocess.py:93} INFO -     "nullable" : false,
[2025-07-11T14:04:45.874+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:04:45.874+0200] {subprocess.py:93} INFO -   } ]
[2025-07-11T14:04:45.874+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:04:45.874+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-11T14:04:45.874+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-11T14:04:45.874+0200] {subprocess.py:93} INFO -   required int32 treeID;
[2025-07-11T14:04:45.875+0200] {subprocess.py:93} INFO -   optional binary metadata (STRING);
[2025-07-11T14:04:45.875+0200] {subprocess.py:93} INFO -   required double weights;
[2025-07-11T14:04:45.875+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:04:45.875+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:04:45.875+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:04:45.902+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO FileOutputCommitter: Saved output of task 'attempt_202507111404454631301259059348692_0133_m_000000_291' to file:/tmp/mlflow/3e725c6a-f969-4217-ab0f-ce75eef14217/stages/0_RandomForestClassifier_42137e15cb45/treesMetadata/_temporary/0/task_202507111404454631301259059348692_0133_m_000000
[2025-07-11T14:04:45.902+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO SparkHadoopMapRedUtil: attempt_202507111404454631301259059348692_0133_m_000000_291: Committed. Elapsed time: 0 ms.
[2025-07-11T14:04:45.902+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO Executor: Finished task 0.0 in stage 133.0 (TID 291). 4740 bytes result sent to driver
[2025-07-11T14:04:45.902+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 291) in 50 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:04:45.903+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool
[2025-07-11T14:04:45.903+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: ResultStage 133 (parquet at treeModels.scala:483) finished in 0,071 s
[2025-07-11T14:04:45.904+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:04:45.904+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 133: Stage finished
[2025-07-11T14:04:45.904+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO DAGScheduler: Job 80 finished: parquet at treeModels.scala:483, took 0,072202 s
[2025-07-11T14:04:45.904+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO FileFormatWriter: Start to commit write Job bca8e4f2-539e-4d0e-98ae-af610e9eb0a5.
[2025-07-11T14:04:45.936+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO FileFormatWriter: Write Job bca8e4f2-539e-4d0e-98ae-af610e9eb0a5 committed. Elapsed time: 30 ms.
[2025-07-11T14:04:45.936+0200] {subprocess.py:93} INFO - 25/07/11 14:04:45 INFO FileFormatWriter: Finished processing stats for write job bca8e4f2-539e-4d0e-98ae-af610e9eb0a5.
[2025-07-11T14:04:46.017+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO DAGScheduler: Registering RDD 275 (parquet at treeModels.scala:491) as input to shuffle 43
[2025-07-11T14:04:46.018+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO DAGScheduler: Got map stage job 81 (parquet at treeModels.scala:491) with 4 output partitions
[2025-07-11T14:04:46.018+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO DAGScheduler: Final stage: ShuffleMapStage 134 (parquet at treeModels.scala:491)
[2025-07-11T14:04:46.018+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO DAGScheduler: Parents of final stage: List()
[2025-07-11T14:04:46.018+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:46.018+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO DAGScheduler: Submitting ShuffleMapStage 134 (MapPartitionsRDD[275] at parquet at treeModels.scala:491), which has no missing parents
[2025-07-11T14:04:46.018+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 41.5 KiB, free 423.4 MiB)
[2025-07-11T14:04:46.018+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 12.3 KiB, free 423.4 MiB)
[2025-07-11T14:04:46.018+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 138.4.31.23:41705 (size: 12.3 KiB, free: 433.6 MiB)
[2025-07-11T14:04:46.018+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:46.018+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 134 (MapPartitionsRDD[275] at parquet at treeModels.scala:491) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-07-11T14:04:46.018+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO TaskSchedulerImpl: Adding task set 134.0 with 4 tasks resource profile 0
[2025-07-11T14:04:46.018+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 292) (138.4.31.23, executor driver, partition 0, PROCESS_LOCAL, 140337 bytes)
[2025-07-11T14:04:46.029+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 138.4.31.23:41705 in memory (size: 83.9 KiB, free: 433.7 MiB)
[2025-07-11T14:04:46.030+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 138.4.31.23:41705 in memory (size: 4.5 KiB, free: 433.7 MiB)
[2025-07-11T14:04:46.033+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO TaskSetManager: Starting task 1.0 in stage 134.0 (TID 293) (138.4.31.23, executor driver, partition 1, PROCESS_LOCAL, 386293 bytes)
[2025-07-11T14:04:46.035+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO TaskSetManager: Starting task 2.0 in stage 134.0 (TID 294) (138.4.31.23, executor driver, partition 2, PROCESS_LOCAL, 128364 bytes)
[2025-07-11T14:04:46.038+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO TaskSetManager: Starting task 3.0 in stage 134.0 (TID 295) (138.4.31.23, executor driver, partition 3, PROCESS_LOCAL, 208919 bytes)
[2025-07-11T14:04:46.039+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO Executor: Running task 3.0 in stage 134.0 (TID 295)
[2025-07-11T14:04:46.040+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO Executor: Running task 1.0 in stage 134.0 (TID 293)
[2025-07-11T14:04:46.041+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO Executor: Running task 2.0 in stage 134.0 (TID 294)
[2025-07-11T14:04:46.049+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO Executor: Running task 0.0 in stage 134.0 (TID 292)
[2025-07-11T14:04:46.060+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO Executor: Finished task 3.0 in stage 134.0 (TID 295). 1700 bytes result sent to driver
[2025-07-11T14:04:46.066+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO TaskSetManager: Finished task 3.0 in stage 134.0 (TID 295) in 31 ms on 138.4.31.23 (executor driver) (1/4)
[2025-07-11T14:04:46.066+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO Executor: Finished task 2.0 in stage 134.0 (TID 294). 1700 bytes result sent to driver
[2025-07-11T14:04:46.068+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO TaskSetManager: Finished task 2.0 in stage 134.0 (TID 294) in 35 ms on 138.4.31.23 (executor driver) (2/4)
[2025-07-11T14:04:46.070+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO Executor: Finished task 0.0 in stage 134.0 (TID 292). 1700 bytes result sent to driver
[2025-07-11T14:04:46.071+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 292) in 54 ms on 138.4.31.23 (executor driver) (3/4)
[2025-07-11T14:04:46.083+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO Executor: Finished task 1.0 in stage 134.0 (TID 293). 1700 bytes result sent to driver
[2025-07-11T14:04:46.084+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO TaskSetManager: Finished task 1.0 in stage 134.0 (TID 293) in 65 ms on 138.4.31.23 (executor driver) (4/4)
[2025-07-11T14:04:46.084+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool
[2025-07-11T14:04:46.084+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO DAGScheduler: ShuffleMapStage 134 (parquet at treeModels.scala:491) finished in 0,070 s
[2025-07-11T14:04:46.085+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO DAGScheduler: looking for newly runnable stages
[2025-07-11T14:04:46.085+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO DAGScheduler: running: Set()
[2025-07-11T14:04:46.085+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO DAGScheduler: waiting: Set()
[2025-07-11T14:04:46.085+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO DAGScheduler: failed: Set()
[2025-07-11T14:04:46.092+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:04:46.093+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:46.093+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:46.093+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:04:46.093+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:46.094+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:46.094+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:04:46.124+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO SparkContext: Starting job: parquet at treeModels.scala:491
[2025-07-11T14:04:46.128+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO DAGScheduler: Got job 82 (parquet at treeModels.scala:491) with 1 output partitions
[2025-07-11T14:04:46.128+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO DAGScheduler: Final stage: ResultStage 136 (parquet at treeModels.scala:491)
[2025-07-11T14:04:46.129+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 135)
[2025-07-11T14:04:46.129+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO DAGScheduler: Missing parents: List()
[2025-07-11T14:04:46.129+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO DAGScheduler: Submitting ResultStage 136 (MapPartitionsRDD[277] at parquet at treeModels.scala:491), which has no missing parents
[2025-07-11T14:04:46.148+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 241.4 KiB, free 423.5 MiB)
[2025-07-11T14:04:46.151+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 84.8 KiB, free 423.4 MiB)
[2025-07-11T14:04:46.151+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 138.4.31.23:41705 (size: 84.8 KiB, free: 433.6 MiB)
[2025-07-11T14:04:46.162+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1585
[2025-07-11T14:04:46.162+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 136 (MapPartitionsRDD[277] at parquet at treeModels.scala:491) (first 15 tasks are for partitions Vector(0))
[2025-07-11T14:04:46.162+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO TaskSchedulerImpl: Adding task set 136.0 with 1 tasks resource profile 0
[2025-07-11T14:04:46.164+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 296) (138.4.31.23, executor driver, partition 0, NODE_LOCAL, 14828 bytes)
[2025-07-11T14:04:46.165+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO Executor: Running task 0.0 in stage 136.0 (TID 296)
[2025-07-11T14:04:46.175+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO ShuffleBlockFetcherIterator: Getting 4 (176.9 KiB) non-empty blocks including 4 (176.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-11T14:04:46.176+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-11T14:04:46.177+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:46.177+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:46.178+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:04:46.178+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-07-11T14:04:46.178+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-07-11T14:04:46.179+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
[2025-07-11T14:04:46.179+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:04:46.179+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO CodecConfig: Compression: SNAPPY
[2025-07-11T14:04:46.180+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
[2025-07-11T14:04:46.186+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
[2025-07-11T14:04:46.186+0200] {subprocess.py:93} INFO - {
[2025-07-11T14:04:46.186+0200] {subprocess.py:93} INFO -   "type" : "struct",
[2025-07-11T14:04:46.186+0200] {subprocess.py:93} INFO -   "fields" : [ {
[2025-07-11T14:04:46.186+0200] {subprocess.py:93} INFO -     "name" : "treeID",
[2025-07-11T14:04:46.187+0200] {subprocess.py:93} INFO -     "type" : "integer",
[2025-07-11T14:04:46.187+0200] {subprocess.py:93} INFO -     "nullable" : false,
[2025-07-11T14:04:46.187+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:04:46.187+0200] {subprocess.py:93} INFO -   }, {
[2025-07-11T14:04:46.187+0200] {subprocess.py:93} INFO -     "name" : "nodeData",
[2025-07-11T14:04:46.187+0200] {subprocess.py:93} INFO -     "type" : {
[2025-07-11T14:04:46.187+0200] {subprocess.py:93} INFO -       "type" : "struct",
[2025-07-11T14:04:46.187+0200] {subprocess.py:93} INFO -       "fields" : [ {
[2025-07-11T14:04:46.187+0200] {subprocess.py:93} INFO -         "name" : "id",
[2025-07-11T14:04:46.187+0200] {subprocess.py:93} INFO -         "type" : "integer",
[2025-07-11T14:04:46.187+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:04:46.187+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:04:46.187+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:04:46.187+0200] {subprocess.py:93} INFO -         "name" : "prediction",
[2025-07-11T14:04:46.187+0200] {subprocess.py:93} INFO -         "type" : "double",
[2025-07-11T14:04:46.187+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:04:46.187+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:04:46.188+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:04:46.188+0200] {subprocess.py:93} INFO -         "name" : "impurity",
[2025-07-11T14:04:46.188+0200] {subprocess.py:93} INFO -         "type" : "double",
[2025-07-11T14:04:46.188+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:04:46.188+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:04:46.188+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:04:46.188+0200] {subprocess.py:93} INFO -         "name" : "impurityStats",
[2025-07-11T14:04:46.188+0200] {subprocess.py:93} INFO -         "type" : {
[2025-07-11T14:04:46.188+0200] {subprocess.py:93} INFO -           "type" : "array",
[2025-07-11T14:04:46.188+0200] {subprocess.py:93} INFO -           "elementType" : "double",
[2025-07-11T14:04:46.188+0200] {subprocess.py:93} INFO -           "containsNull" : false
[2025-07-11T14:04:46.188+0200] {subprocess.py:93} INFO -         },
[2025-07-11T14:04:46.188+0200] {subprocess.py:93} INFO -         "nullable" : true,
[2025-07-11T14:04:46.188+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:04:46.188+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:04:46.188+0200] {subprocess.py:93} INFO -         "name" : "rawCount",
[2025-07-11T14:04:46.188+0200] {subprocess.py:93} INFO -         "type" : "long",
[2025-07-11T14:04:46.188+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:04:46.189+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:04:46.189+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:04:46.189+0200] {subprocess.py:93} INFO -         "name" : "gain",
[2025-07-11T14:04:46.189+0200] {subprocess.py:93} INFO -         "type" : "double",
[2025-07-11T14:04:46.189+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:04:46.189+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:04:46.189+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:04:46.189+0200] {subprocess.py:93} INFO -         "name" : "leftChild",
[2025-07-11T14:04:46.189+0200] {subprocess.py:93} INFO -         "type" : "integer",
[2025-07-11T14:04:46.190+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:04:46.190+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:04:46.190+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:04:46.190+0200] {subprocess.py:93} INFO -         "name" : "rightChild",
[2025-07-11T14:04:46.190+0200] {subprocess.py:93} INFO -         "type" : "integer",
[2025-07-11T14:04:46.190+0200] {subprocess.py:93} INFO -         "nullable" : false,
[2025-07-11T14:04:46.190+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:04:46.190+0200] {subprocess.py:93} INFO -       }, {
[2025-07-11T14:04:46.190+0200] {subprocess.py:93} INFO -         "name" : "split",
[2025-07-11T14:04:46.190+0200] {subprocess.py:93} INFO -         "type" : {
[2025-07-11T14:04:46.190+0200] {subprocess.py:93} INFO -           "type" : "struct",
[2025-07-11T14:04:46.190+0200] {subprocess.py:93} INFO -           "fields" : [ {
[2025-07-11T14:04:46.190+0200] {subprocess.py:93} INFO -             "name" : "featureIndex",
[2025-07-11T14:04:46.190+0200] {subprocess.py:93} INFO -             "type" : "integer",
[2025-07-11T14:04:46.190+0200] {subprocess.py:93} INFO -             "nullable" : false,
[2025-07-11T14:04:46.190+0200] {subprocess.py:93} INFO -             "metadata" : { }
[2025-07-11T14:04:46.190+0200] {subprocess.py:93} INFO -           }, {
[2025-07-11T14:04:46.191+0200] {subprocess.py:93} INFO -             "name" : "leftCategoriesOrThreshold",
[2025-07-11T14:04:46.191+0200] {subprocess.py:93} INFO -             "type" : {
[2025-07-11T14:04:46.191+0200] {subprocess.py:93} INFO -               "type" : "array",
[2025-07-11T14:04:46.191+0200] {subprocess.py:93} INFO -               "elementType" : "double",
[2025-07-11T14:04:46.191+0200] {subprocess.py:93} INFO -               "containsNull" : false
[2025-07-11T14:04:46.191+0200] {subprocess.py:93} INFO -             },
[2025-07-11T14:04:46.191+0200] {subprocess.py:93} INFO -             "nullable" : true,
[2025-07-11T14:04:46.191+0200] {subprocess.py:93} INFO -             "metadata" : { }
[2025-07-11T14:04:46.191+0200] {subprocess.py:93} INFO -           }, {
[2025-07-11T14:04:46.191+0200] {subprocess.py:93} INFO -             "name" : "numCategories",
[2025-07-11T14:04:46.191+0200] {subprocess.py:93} INFO -             "type" : "integer",
[2025-07-11T14:04:46.191+0200] {subprocess.py:93} INFO -             "nullable" : false,
[2025-07-11T14:04:46.191+0200] {subprocess.py:93} INFO -             "metadata" : { }
[2025-07-11T14:04:46.191+0200] {subprocess.py:93} INFO -           } ]
[2025-07-11T14:04:46.191+0200] {subprocess.py:93} INFO -         },
[2025-07-11T14:04:46.191+0200] {subprocess.py:93} INFO -         "nullable" : true,
[2025-07-11T14:04:46.191+0200] {subprocess.py:93} INFO -         "metadata" : { }
[2025-07-11T14:04:46.191+0200] {subprocess.py:93} INFO -       } ]
[2025-07-11T14:04:46.192+0200] {subprocess.py:93} INFO -     },
[2025-07-11T14:04:46.192+0200] {subprocess.py:93} INFO -     "nullable" : true,
[2025-07-11T14:04:46.192+0200] {subprocess.py:93} INFO -     "metadata" : { }
[2025-07-11T14:04:46.192+0200] {subprocess.py:93} INFO -   } ]
[2025-07-11T14:04:46.192+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:04:46.192+0200] {subprocess.py:93} INFO - and corresponding Parquet message type:
[2025-07-11T14:04:46.192+0200] {subprocess.py:93} INFO - message spark_schema {
[2025-07-11T14:04:46.192+0200] {subprocess.py:93} INFO -   required int32 treeID;
[2025-07-11T14:04:46.192+0200] {subprocess.py:93} INFO -   optional group nodeData {
[2025-07-11T14:04:46.192+0200] {subprocess.py:93} INFO -     required int32 id;
[2025-07-11T14:04:46.192+0200] {subprocess.py:93} INFO -     required double prediction;
[2025-07-11T14:04:46.192+0200] {subprocess.py:93} INFO -     required double impurity;
[2025-07-11T14:04:46.192+0200] {subprocess.py:93} INFO -     optional group impurityStats (LIST) {
[2025-07-11T14:04:46.192+0200] {subprocess.py:93} INFO -       repeated group list {
[2025-07-11T14:04:46.192+0200] {subprocess.py:93} INFO -         required double element;
[2025-07-11T14:04:46.193+0200] {subprocess.py:93} INFO -       }
[2025-07-11T14:04:46.193+0200] {subprocess.py:93} INFO -     }
[2025-07-11T14:04:46.193+0200] {subprocess.py:93} INFO -     required int64 rawCount;
[2025-07-11T14:04:46.193+0200] {subprocess.py:93} INFO -     required double gain;
[2025-07-11T14:04:46.194+0200] {subprocess.py:93} INFO -     required int32 leftChild;
[2025-07-11T14:04:46.194+0200] {subprocess.py:93} INFO -     required int32 rightChild;
[2025-07-11T14:04:46.194+0200] {subprocess.py:93} INFO -     optional group split {
[2025-07-11T14:04:46.194+0200] {subprocess.py:93} INFO -       required int32 featureIndex;
[2025-07-11T14:04:46.194+0200] {subprocess.py:93} INFO -       optional group leftCategoriesOrThreshold (LIST) {
[2025-07-11T14:04:46.194+0200] {subprocess.py:93} INFO -         repeated group list {
[2025-07-11T14:04:46.194+0200] {subprocess.py:93} INFO -           required double element;
[2025-07-11T14:04:46.194+0200] {subprocess.py:93} INFO -         }
[2025-07-11T14:04:46.194+0200] {subprocess.py:93} INFO -       }
[2025-07-11T14:04:46.194+0200] {subprocess.py:93} INFO -       required int32 numCategories;
[2025-07-11T14:04:46.194+0200] {subprocess.py:93} INFO -     }
[2025-07-11T14:04:46.194+0200] {subprocess.py:93} INFO -   }
[2025-07-11T14:04:46.194+0200] {subprocess.py:93} INFO - }
[2025-07-11T14:04:46.194+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:04:46.194+0200] {subprocess.py:93} INFO - 
[2025-07-11T14:04:46.238+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO FileOutputCommitter: Saved output of task 'attempt_20250711140446335111693458638654_0136_m_000000_296' to file:/tmp/mlflow/3e725c6a-f969-4217-ab0f-ce75eef14217/stages/0_RandomForestClassifier_42137e15cb45/data/_temporary/0/task_20250711140446335111693458638654_0136_m_000000
[2025-07-11T14:04:46.238+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO SparkHadoopMapRedUtil: attempt_20250711140446335111693458638654_0136_m_000000_296: Committed. Elapsed time: 0 ms.
[2025-07-11T14:04:46.239+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO Executor: Finished task 0.0 in stage 136.0 (TID 296). 4740 bytes result sent to driver
[2025-07-11T14:04:46.239+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 296) in 75 ms on 138.4.31.23 (executor driver) (1/1)
[2025-07-11T14:04:46.239+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool
[2025-07-11T14:04:46.239+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO DAGScheduler: ResultStage 136 (parquet at treeModels.scala:491) finished in 0,114 s
[2025-07-11T14:04:46.240+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-11T14:04:46.240+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 136: Stage finished
[2025-07-11T14:04:46.240+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO DAGScheduler: Job 82 finished: parquet at treeModels.scala:491, took 0,115605 s
[2025-07-11T14:04:46.240+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO FileFormatWriter: Start to commit write Job c18a111f-4b21-4159-b0ad-dd6edefd5050.
[2025-07-11T14:04:46.249+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO FileFormatWriter: Write Job c18a111f-4b21-4159-b0ad-dd6edefd5050 committed. Elapsed time: 9 ms.
[2025-07-11T14:04:46.249+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO FileFormatWriter: Finished processing stats for write job c18a111f-4b21-4159-b0ad-dd6edefd5050.
[2025-07-11T14:04:46.250+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO Instrumentation: [d5fcd408] training finished
[2025-07-11T14:04:46.250+0200] {subprocess.py:93} INFO - 25/07/11 14:04:46 INFO Instrumentation: [1b72c697] training finished
[2025-07-11T14:05:21.349+0200] {subprocess.py:93} INFO - 2025/07/11 14:05:21 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpwy1pvc85/model, flavor: spark). Fall back to return ['pyspark==3.5.3']. Set logging level to DEBUG to see the full traceback.
[2025-07-11T14:05:21.364+0200] {subprocess.py:93} INFO - [31m2025/07/11 14:05:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
[2025-07-11T14:05:21.485+0200] {subprocess.py:93} INFO - MLflow: Model and metrics logged successfully.
[2025-07-11T14:05:21.497+0200] {subprocess.py:93} INFO - 25/07/11 14:05:21 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2025-07-11T14:05:21.518+0200] {subprocess.py:93} INFO - 25/07/11 14:05:21 INFO SparkUI: Stopped Spark web UI at http://138.4.31.23:4041
[2025-07-11T14:05:21.537+0200] {subprocess.py:93} INFO - 25/07/11 14:05:21 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-07-11T14:05:21.570+0200] {subprocess.py:93} INFO - 25/07/11 14:05:21 INFO MemoryStore: MemoryStore cleared
[2025-07-11T14:05:21.570+0200] {subprocess.py:93} INFO - 25/07/11 14:05:21 INFO BlockManager: BlockManager stopped
[2025-07-11T14:05:21.575+0200] {subprocess.py:93} INFO - 25/07/11 14:05:21 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-07-11T14:05:21.580+0200] {subprocess.py:93} INFO - 25/07/11 14:05:21 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-07-11T14:05:21.594+0200] {subprocess.py:93} INFO - 25/07/11 14:05:21 INFO SparkContext: Successfully stopped SparkContext
[2025-07-11T14:05:22.295+0200] {subprocess.py:93} INFO - 25/07/11 14:05:22 INFO ShutdownHookManager: Shutdown hook called
[2025-07-11T14:05:22.297+0200] {subprocess.py:93} INFO - 25/07/11 14:05:22 INFO ShutdownHookManager: Deleting directory /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f
[2025-07-11T14:05:22.330+0200] {subprocess.py:93} INFO - 25/07/11 14:05:22 INFO ShutdownHookManager: Deleting directory /tmp/spark-94b95a2f-4f80-456d-843e-74adbd9fd5d8
[2025-07-11T14:05:22.343+0200] {subprocess.py:93} INFO - 25/07/11 14:05:22 INFO ShutdownHookManager: Deleting directory /tmp/spark-0de55202-ec81-4eb3-994a-f2a91a44948f/pyspark-8ed12dd1-bb59-4829-9857-d55b1402b6e8
[2025-07-11T14:05:22.379+0200] {subprocess.py:93} INFO - 25/07/11 14:05:22 INFO CassandraConnector: Disconnected from Cassandra cluster.
[2025-07-11T14:05:22.379+0200] {subprocess.py:93} INFO - 25/07/11 14:05:22 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
[2025-07-11T14:05:22.537+0200] {subprocess.py:97} INFO - Command exited with return code 0
[2025-07-11T14:05:22.588+0200] {taskinstance.py:1318} INFO - Marking task as SUCCESS. dag_id=agile_data_science_batch_prediction_model_training, task_id=pyspark_train_classifier_model, execution_date=20250711T115133, start_date=20250711T120225, end_date=20250711T120522
[2025-07-11T14:05:22.674+0200] {local_task_job.py:208} INFO - Task exited with return code 0
[2025-07-11T14:05:22.726+0200] {taskinstance.py:2578} INFO - 0 downstream tasks scheduled from follow-on schedule check
