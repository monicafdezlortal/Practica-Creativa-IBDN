#version: '3.8'

services:

  kafka:
    image: bitnami/kafka:3.9.0
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_KRAFT_CLUSTER_ID: "abcdefghijklmnopqrstuv"
      KAFKA_CFG_NODE_ID: 1
      KAFKA_CFG_PROCESS_ROLES: "broker,controller"
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_CFG_LISTENERS: "PLAINTEXT://:9092,CONTROLLER://:9093"
      KAFKA_CFG_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092"
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT"
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_CFG_LOG_DIRS: "/bitnami/kafka/data"
    volumes:
      - kafka_data:/bitnami/kafka
    networks:
      - prediction-net

  kafka-topic-init:
    image: bitnami/kafka:3.9.0
    container_name: kafka-topic-init
    depends_on:
      - kafka
    networks:
      - prediction-net
    entrypoint: >
      bash -c '
        echo "Esperando a que Kafka estÃ© disponible...";
        until kafka-topics.sh --bootstrap-server kafka:9092 --list > /dev/null 2>&1; do
          sleep 2;
        done &&
        echo "Kafka disponible. Creando topics..." &&
        kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --replication-factor 1 --partitions 1 --topic flight-delay-ml-request &&
        kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --replication-factor 1 --partitions 1 --topic flight-delay-ml-response
      '
  nifi:
    image: apache/nifi:1.25.0
    container_name: nifi
    environment:
      - SINGLE_USER_CREDENTIALS_USERNAME=admin
      - SINGLE_USER_CREDENTIALS_PASSWORD=098765432100
    ports:
      - "8443:8443"
      - "5050:5050"
    volumes:
      - ./destino:/dat
    networks:
      - prediction-net
 
  mongo:
    image: mongo:7.0.17
    container_name: mongo
    ports:
      - "27018:27017"
    volumes:
      - mongo_data:/data/db
    networks:
      - prediction-net

  mongo-importer:
    image: mongo:7.0.17
    container_name: mongo-importer
    depends_on:
      - mongo
    volumes:
      - ./data:/import-data
    entrypoint: >
      bash -c '
        until mongosh "mongodb://mongo:27017" --eval "db.adminCommand(\"ping\")" > /dev/null 2>&1; do
          echo waiting for mongo...; sleep 2;
        done &&
        mongoimport --host mongo --db agile_data_science --collection origin_dest_distances --file /import-data/origin_dest_distances.jsonl
      '
    networks:
      - prediction-net


  flask:
    build:
      context: ./resources/web
      dockerfile: Dockerfile
    container_name: flask-app
    ports:
      - "5001:5001"
    volumes:
      - ./resources/web:/app
    depends_on:
      - kafka
      - mongo
    networks:
      - prediction-net
    environment:
      - PROJECT_HOME=/app


  spark-master:
    image: bde2020/spark-master:3.2.1-hadoop3.2
    container_name: spark-master
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - "INIT_DAEMON_STEP=setup_spark"
      - "constraint:node==spark-master"
    ports:
      - "7077:7077"
      - "9001:9001"
      - "8080:8080"
    networks:
      - prediction-net

    volumes:
      - ./flight_prediction/target/scala-2.12:/app
      - ./spark-jars:/jars
      - ./models:/app/models


  spark-worker-1:
    image: bde2020/spark-worker:3.2.1-hadoop3.2
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - "INIT_DAEMON_STEP=setup_spark"
      - "constraint:node==spark-worker"
    networks:
      - prediction-net
    volumes:
      - ./flight_prediction/target/scala-2.12:/app
      - ./spark-jars:/jars
      - ./models:/app/models
    restart: always
    
  spark-worker-2:
    image: bde2020/spark-worker:3.2.1-hadoop3.2
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - "INIT_DAEMON_STEP=setup_spark"
      - "constraint:node==spark-worker"
    networks:
      - prediction-net
    volumes:
      - ./flight_prediction/target/scala-2.12:/app
      - ./spark-jars:/jars
      - ./models:/app/models

    restart: always

  spark-submit:
    image: bde2020/spark-submit:3.2.1-hadoop3.2
    container_name: spark-submit
    depends_on:
      - spark-master
      - spark-worker-1
      - spark-worker-2
      - cassandra-migrator
    ports:
      - "4040:4040"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - "constraint:node==spark-worker"       

      
    volumes:
      - ./flight_prediction/target/scala-2.12:/app
      - ./spark-jars:/jars
      - ./models:/app/models
      - ./flight_prediction/target/scala-2.12/flight_prediction_2.12-0.1.jar:/app/flight_prediction_2.12-0.1.jar

    command: >
      bash -c "sleep 60 &&
      /spark/bin/spark-submit
      --packages com.datastax.spark:spark-cassandra-connector_2.12:3.2.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.1,org.mongodb.spark:mongo-spark-connector_2.12:10.1.1
      --conf spark.cassandra.connection.host=cassandra
      --conf spark.cassandra.connection.port=9042
      --class es.upm.dit.ging.predictor.MakePrediction
      --master spark://spark-master:7077
      /app/flight_prediction_2.12-0.1.jar &&
      tail -f /dev/null
      "
    networks:
      - prediction-net


  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    ports:
      - 9870:9870
      - 9000:9000
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env
    networks:
      - prediction-net

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    restart: always
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env
    networks:
      - prediction-net
  
  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864"
    env_file:
      - ./hadoop.env
    networks:
      - prediction-net

  nodemanager:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    env_file:
      - ./hadoop.env
    networks:
      - prediction-net
  
  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: historyserver
    restart: always
    ports: 
     - "19888:8188"
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env
    networks:
      - prediction-net

  cassandra:
    image: cassandra:4.1
     
    container_name: cassandra
    ports:
      - "9042:9042"
    networks:
      - prediction-net
    volumes:
      - cassandra_data:/var/lib/cassandra
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "cqlsh -e 'describe keyspaces' || exit 1"]
      interval: 20s
      timeout: 10s
      retries: 10

  cassandra-migrator:
    image: python:3.9
    container_name: cassandra-migrator
    volumes:
      - ./data:/app
    command: >
      bash -c "
        pip install cassandra-driver &&
        python /app/migracion_cassandra.py"
    depends_on:
      - cassandra
    networks:
      - prediction-net



    
volumes:
  mongo_data:
  kafka_data:
  hadoop_namenode:
  hadoop_datanode:
  hadoop_historyserver:
  cassandra_data:

networks:
  prediction-net:
    driver: bridge
